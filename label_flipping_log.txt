2025-02-24T13:05:09.373214+0300 | DEBUG | Loading Fashion MNIST train data
2025-02-24T13:05:49.228270+0300 | DEBUG | Finished loading Fashion MNIST train data
2025-02-24T13:05:49.229273+0300 | DEBUG | Loading Fashion MNIST test data
2025-02-24T13:05:50.824846+0300 | DEBUG | Finished loading Fashion MNIST test data
2025-02-24T13:06:32.890815+0300 | DEBUG | Loading CIFAR10 train data
2025-02-24T13:07:07.054995+0300 | WARNING | ⚠️ Flipped 1000 samples from Class 5 → Class 3
2025-02-24T13:07:31.474159+0300 | DEBUG | Finished loading CIFAR10 train data
2025-02-24T13:07:31.480733+0300 | DEBUG | Loading CIFAR10 test data
2025-02-24T13:07:32.153209+0300 | WARNING | ⚠️ Flipped 200 samples from Class 5 → Class 3
2025-02-24T13:07:35.221038+0300 | DEBUG | Finished loading CIFAR10 test data
2025-02-24T13:07:37.495728+0300 | DEBUG | Loading Fashion MNIST train data
2025-02-24T13:08:13.227992+0300 | DEBUG | Finished loading Fashion MNIST train data
2025-02-24T13:08:13.229987+0300 | DEBUG | Loading Fashion MNIST test data
2025-02-24T13:08:14.611388+0300 | DEBUG | Finished loading Fashion MNIST test data
2025-02-24T13:09:12.895150+0300 | DEBUG | Arguments: 
Batch Size: 10
Test Batch Size: 10000
Epochs: 200
Learning Rate: 0.0001
Momentum: 0.5
Beta1: 0.9
Beta2: 0.999
EPS: 1e-08
CUDA Enabled: True
Shuffle Enabled: False
Log Interval: 100
Scheduler Step Size: 50
Scheduler Gamma: 0.5
Scheduler Minimum Learning Rate: 1e-10
Client Selection Strategy: <federated_learning.worker_selection.random.RandomSelectionStrategy object at 0x0000025CA2703F20>
Client Selection Strategy Arguments: {
    "NUM_WORKERS_PER_ROUND": 1
}
Model Saving Enabled: True
Model Saving Interval: 1
Model Saving Path (Relative): 3000_models
Epoch Save Start Prefix: start
Epoch Save End Suffix: end
Number of Clients: 1
Number of Poisoned Clients: 1
NN: <class 'federated_learning.nets.cifar_10_cnn.Cifar10CNN'>
Train Data Loader Path: data_loaders/cifar10/train_data_loader.pickle
Test Data Loader Path: data_loaders/cifar10/test_data_loader.pickle
Loss Function: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
Default Model Folder Path: default_models
Data Path: data

2025-02-24T13:09:12.895150+0300 | INFO | Loading data loader from file: data_loaders/cifar10/train_data_loader.pickle
2025-02-24T13:09:13.276333+0300 | INFO | Loading data loader from file: data_loaders/cifar10/test_data_loader.pickle
2025-02-24T13:09:14.750836+0300 | INFO | Poisoning data for workers: [0]
2025-02-24T13:09:14.762834+0300 | INFO | Client #0 has data distribution: [5000, 5000, 5000, 6000, 5000, 4000, 5000, 5000, 5000, 5000]
2025-02-24T13:09:14.782565+0300 | INFO | Training epoch #1 on client #0
2025-02-24T13:09:14.783565+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-02-24T13:09:14.921990+0300 | INFO | [1,     0] loss: 0.023
2025-02-24T13:09:18.913368+0300 | INFO | [1,   100] loss: 2.247
2025-02-24T13:09:23.659209+0300 | INFO | [1,   200] loss: 2.180
2025-02-24T13:09:28.733885+0300 | INFO | [1,   300] loss: 2.137
2025-02-24T13:09:33.697523+0300 | INFO | [1,   400] loss: 2.115
2025-02-24T13:09:38.871608+0300 | INFO | [1,   500] loss: 2.116
2025-02-24T13:09:44.002345+0300 | INFO | [1,   600] loss: 2.094
2025-02-24T13:09:48.757885+0300 | INFO | [1,   700] loss: 2.069
2025-02-24T13:09:53.889659+0300 | INFO | [1,   800] loss: 2.094
2025-02-24T13:09:59.379934+0300 | INFO | [1,   900] loss: 2.074
2025-02-24T13:10:04.182487+0300 | INFO | [1,  1000] loss: 2.066
2025-02-24T13:10:09.204186+0300 | INFO | [1,  1100] loss: 2.030
2025-02-24T13:10:14.815527+0300 | INFO | [1,  1200] loss: 2.066
2025-02-24T13:10:19.632799+0300 | INFO | [1,  1300] loss: 2.042
2025-02-24T13:10:24.371703+0300 | INFO | [1,  1400] loss: 2.052
2025-02-24T13:10:30.068660+0300 | INFO | [1,  1500] loss: 2.057
2025-02-24T13:10:35.183305+0300 | INFO | [1,  1600] loss: 2.057
2025-02-24T13:10:43.193454+0300 | INFO | [1,  1700] loss: 2.043
2025-02-24T13:10:48.213093+0300 | INFO | [1,  1800] loss: 2.024
2025-02-24T13:10:53.408653+0300 | INFO | [1,  1900] loss: 2.041
2025-02-24T13:10:58.749097+0300 | INFO | [1,  2000] loss: 2.030
2025-02-24T13:11:05.765095+0300 | INFO | [1,  2100] loss: 2.024
2025-02-24T13:11:13.717432+0300 | INFO | [1,  2200] loss: 2.058
2025-02-24T13:11:21.009673+0300 | INFO | [1,  2300] loss: 2.004
2025-02-24T13:11:25.706412+0300 | INFO | [1,  2400] loss: 2.013
2025-02-24T13:11:30.396040+0300 | INFO | [1,  2500] loss: 1.986
2025-02-24T13:11:35.418601+0300 | INFO | [1,  2600] loss: 1.999
2025-02-24T13:11:40.633058+0300 | INFO | [1,  2700] loss: 1.998
2025-02-24T13:11:45.764905+0300 | INFO | [1,  2800] loss: 1.994
2025-02-24T13:11:50.597111+0300 | INFO | [1,  2900] loss: 2.009
2025-02-24T13:11:56.767274+0300 | INFO | [1,  3000] loss: 2.005
2025-02-24T13:12:04.215878+0300 | INFO | [1,  3100] loss: 1.995
2025-02-24T13:12:16.426070+0300 | INFO | [1,  3200] loss: 1.991
2025-02-24T13:12:26.461424+0300 | INFO | [1,  3300] loss: 2.011
2025-02-24T13:12:30.846779+0300 | INFO | [1,  3400] loss: 1.991
2025-02-24T13:12:36.058706+0300 | INFO | [1,  3500] loss: 2.002
2025-02-24T13:12:41.060324+0300 | INFO | [1,  3600] loss: 1.983
2025-02-24T13:12:45.725290+0300 | INFO | [1,  3700] loss: 1.989
2025-02-24T13:12:51.030467+0300 | INFO | [1,  3800] loss: 1.976
2025-02-24T13:12:56.214548+0300 | INFO | [1,  3900] loss: 1.970
2025-02-24T13:13:02.397842+0300 | INFO | [1,  4000] loss: 1.975
2025-02-24T13:13:07.776191+0300 | INFO | [1,  4100] loss: 1.924
2025-02-24T13:13:12.816426+0300 | INFO | [1,  4200] loss: 1.964
2025-02-24T13:13:17.600214+0300 | INFO | [1,  4300] loss: 1.950
2025-02-24T13:13:22.614814+0300 | INFO | [1,  4400] loss: 1.943
2025-02-24T13:13:28.426883+0300 | INFO | [1,  4500] loss: 1.971
2025-02-24T13:13:33.291136+0300 | INFO | [1,  4600] loss: 1.957
2025-02-24T13:13:38.071993+0300 | INFO | [1,  4700] loss: 1.955
2025-02-24T13:13:43.172884+0300 | INFO | [1,  4800] loss: 1.912
2025-02-24T13:13:48.545673+0300 | INFO | [1,  4900] loss: 1.943
2025-02-24T13:13:54.045207+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-02-24T13:13:54.052528+0300 | INFO | Averaging client parameters
2025-02-24T13:13:54.057107+0300 | INFO | Updating parameters on client #0
2025-02-24T13:14:05.345663+0300 | DEBUG | Test set: Accuracy: 5410/10000 (54%)
2025-02-24T13:14:05.346672+0300 | DEBUG | Test set: Loss: 1.9151060581207275
2025-02-24T13:14:05.405448+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.63      0.53      0.58      1000
           1       0.65      0.67      0.66      1000
           2       0.35      0.57      0.43      1000
           3       0.39      0.52      0.45      1200
           4       0.56      0.43      0.48      1000
           5       0.00      0.00      0.00       800
           6       0.54      0.64      0.58      1000
           7       0.65      0.56      0.60      1000
           8       0.69      0.71      0.70      1000
           9       0.65      0.68      0.66      1000

    accuracy                           0.54     10000
   macro avg       0.51      0.53      0.51     10000
weighted avg       0.52      0.54      0.52     10000

2025-02-24T13:14:05.406450+0300 | DEBUG | Confusion Matrix:
[[533  31 183  29   8   0  15  25 130  46]
 [ 59 672  15  20   4   0  21  17  36 156]
 [ 46  19 568 124  88   0  89  32  21  13]
 [ 19  29 223 624  36   0 162  44  25  38]
 [ 25  21 189  74 426   0 155  84  21   5]
 [  5  14 163 441  39   0  36  60  18  24]
 [  6  19 121 106  82   0 637  16   6   7]
 [ 15  15 118 133  69   0  32 558   5  55]
 [105  72  41  25   6   0  10   4 710  27]
 [ 38 143  14  26   4   0  24  15  54 682]]
2025-02-24T13:14:05.407927+0300 | DEBUG | Class precision: [0.62632197 0.64927536 0.34740061 0.38951311 0.55905512        nan
 0.53937341 0.65263158 0.6920078  0.64767331]
2025-02-24T13:14:05.408941+0300 | DEBUG | Class recall: [0.533 0.672 0.568 0.52  0.426 0.    0.637 0.558 0.71  0.682]
2025-02-24T13:14:05.452077+0300 | INFO | Training epoch #2 on client #0
2025-02-24T13:14:05.453210+0300 | DEBUG | Saving model to flat file storage. Save #2
2025-02-24T13:14:05.527624+0300 | INFO | [2,     0] loss: 0.018
2025-02-24T13:14:10.633606+0300 | INFO | [2,   100] loss: 1.934
2025-02-24T13:14:16.381305+0300 | INFO | [2,   200] loss: 1.956
2025-02-24T13:14:21.553852+0300 | INFO | [2,   300] loss: 1.936
2025-02-24T13:14:26.474083+0300 | INFO | [2,   400] loss: 1.926
2025-02-24T13:14:32.036376+0300 | INFO | [2,   500] loss: 1.937
2025-02-24T13:14:37.992327+0300 | INFO | [2,   600] loss: 1.920
2025-02-24T13:14:44.289065+0300 | INFO | [2,   700] loss: 1.938
2025-02-24T13:14:50.107141+0300 | INFO | [2,   800] loss: 1.892
2025-02-24T13:14:56.314956+0300 | INFO | [2,   900] loss: 1.925
2025-02-24T13:15:02.584645+0300 | INFO | [2,  1000] loss: 1.946
2025-02-24T13:15:11.576196+0300 | INFO | [2,  1100] loss: 1.917
2025-02-24T13:15:20.677355+0300 | INFO | [2,  1200] loss: 1.914
2025-02-24T13:15:29.871502+0300 | INFO | [2,  1300] loss: 1.950
2025-02-24T13:15:38.939307+0300 | INFO | [2,  1400] loss: 1.915
2025-02-24T13:15:47.565538+0300 | INFO | [2,  1500] loss: 1.908
2025-02-24T13:15:59.012561+0300 | INFO | [2,  1600] loss: 1.893
2025-02-24T13:16:06.649473+0300 | INFO | [2,  1700] loss: 1.897
2025-02-24T13:16:15.683804+0300 | INFO | [2,  1800] loss: 1.910
2025-02-24T13:16:24.833942+0300 | INFO | [2,  1900] loss: 1.896
2025-02-24T13:16:34.776296+0300 | INFO | [2,  2000] loss: 1.926
2025-02-24T13:16:44.242417+0300 | INFO | [2,  2100] loss: 1.905
2025-02-24T13:16:53.121104+0300 | INFO | [2,  2200] loss: 1.913
2025-02-24T13:17:02.303767+0300 | INFO | [2,  2300] loss: 1.924
2025-02-24T13:17:09.854009+0300 | INFO | [2,  2400] loss: 1.903
2025-02-24T13:17:18.319305+0300 | INFO | [2,  2500] loss: 1.869
2025-02-24T13:17:26.782291+0300 | INFO | [2,  2600] loss: 1.906
2025-02-24T13:17:37.087543+0300 | INFO | [2,  2700] loss: 1.880
2025-02-24T13:17:46.691625+0300 | INFO | [2,  2800] loss: 1.910
2025-02-24T13:17:54.476060+0300 | INFO | [2,  2900] loss: 1.904
2025-02-24T13:18:03.166632+0300 | INFO | [2,  3000] loss: 1.883
2025-02-24T13:18:13.427496+0300 | INFO | [2,  3100] loss: 1.886
2025-02-24T13:18:23.852625+0300 | INFO | [2,  3200] loss: 1.882
2025-02-24T13:18:33.150391+0300 | INFO | [2,  3300] loss: 1.878
2025-02-24T13:18:41.030846+0300 | INFO | [2,  3400] loss: 1.885
2025-02-24T13:18:51.012197+0300 | INFO | [2,  3500] loss: 1.904
2025-02-24T13:19:00.488904+0300 | INFO | [2,  3600] loss: 1.909
2025-02-24T13:19:10.546640+0300 | INFO | [2,  3700] loss: 1.912
2025-02-24T13:19:22.334085+0300 | INFO | [2,  3800] loss: 1.893
2025-02-24T13:19:31.824320+0300 | INFO | [2,  3900] loss: 1.931
2025-02-24T13:19:41.944154+0300 | INFO | [2,  4000] loss: 1.889
2025-02-24T13:19:53.504201+0300 | INFO | [2,  4100] loss: 1.906
2025-02-24T13:19:59.671006+0300 | INFO | [2,  4200] loss: 1.879
2025-02-24T13:20:05.195463+0300 | INFO | [2,  4300] loss: 1.921
2025-02-24T13:20:11.907776+0300 | INFO | [2,  4400] loss: 1.896
2025-02-24T13:20:21.729574+0300 | INFO | [2,  4500] loss: 1.879
2025-02-24T13:20:31.560780+0300 | INFO | [2,  4600] loss: 1.859
2025-02-24T13:20:39.203801+0300 | INFO | [2,  4700] loss: 1.890
2025-02-24T13:20:47.448930+0300 | INFO | [2,  4800] loss: 1.893
2025-02-24T13:21:03.436380+0300 | INFO | [2,  4900] loss: 1.898
2025-02-24T13:21:16.418992+0300 | DEBUG | Saving model to flat file storage. Save #2
2025-02-24T13:21:16.436310+0300 | INFO | Averaging client parameters
2025-02-24T13:21:16.442103+0300 | INFO | Updating parameters on client #0
2025-02-24T13:21:34.125920+0300 | DEBUG | Test set: Accuracy: 5915/10000 (59%)
2025-02-24T13:21:34.127918+0300 | DEBUG | Test set: Loss: 1.86776602268219
2025-02-24T13:21:34.199175+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66      1000
           1       0.62      0.92      0.74      1000
           2       0.47      0.49      0.48      1000
           3       0.37      0.74      0.49      1200
           4       0.66      0.32      0.43      1000
           5       0.00      0.00      0.00       800
           6       0.66      0.74      0.70      1000
           7       0.70      0.63      0.66      1000
           8       0.84      0.61      0.71      1000
           9       0.79      0.66      0.72      1000

    accuracy                           0.59     10000
   macro avg       0.58      0.58      0.56     10000
weighted avg       0.58      0.59      0.57     10000

2025-02-24T13:21:34.201177+0300 | DEBUG | Confusion Matrix:
[[659  74  67  82   8   0  16  16  45  33]
 [ 12 923   7  10   0   0   6   5   4  33]
 [ 85  26 490 238  40   0  73  26  12  10]
 [ 22  26  66 887  24   0 109  35  10  21]
 [ 51  16 205 189 318   0 107  95  14   5]
 [ 13  12  59 612  22   0  24  40   6  12]
 [  8   7  86 114  15   0 738  25   4   3]
 [ 22  13  40 206  54   0  13 627   3  22]
 [108 154  13  54   1   0  15   2 614  39]
 [ 23 230   3  33   1   0  16  20  15 659]]
2025-02-24T13:21:34.202177+0300 | DEBUG | Class precision: [0.65702891 0.62322755 0.47297297 0.3657732  0.65838509        nan
 0.6606983  0.7037037  0.84456671 0.78733572]
2025-02-24T13:21:34.203507+0300 | DEBUG | Class recall: [0.659      0.923      0.49       0.73916667 0.318      0.
 0.738      0.627      0.614      0.659     ]
2025-02-24T13:21:34.204521+0300 | INFO | Training epoch #3 on client #0
2025-02-24T13:21:34.205521+0300 | DEBUG | Saving model to flat file storage. Save #3
2025-02-24T13:21:34.315653+0300 | INFO | [3,     0] loss: 0.019
2025-02-24T13:21:45.058708+0300 | INFO | [3,   100] loss: 1.899
2025-02-24T13:21:52.434152+0300 | INFO | [3,   200] loss: 1.868
2025-02-24T13:22:02.111404+0300 | INFO | [3,   300] loss: 1.868
2025-02-24T13:22:11.322547+0300 | INFO | [3,   400] loss: 1.847
2025-02-24T13:22:21.416542+0300 | INFO | [3,   500] loss: 1.867
2025-02-24T13:22:30.531903+0300 | INFO | [3,   600] loss: 1.862
2025-02-24T13:22:38.622578+0300 | INFO | [3,   700] loss: 1.845
2025-02-24T13:22:46.935360+0300 | INFO | [3,   800] loss: 1.882
2025-02-24T13:22:54.714678+0300 | INFO | [3,   900] loss: 1.868
2025-02-24T13:23:03.006739+0300 | INFO | [3,  1000] loss: 1.899
2025-02-24T13:23:10.759858+0300 | INFO | [3,  1100] loss: 1.860
2025-02-24T13:23:20.155666+0300 | INFO | [3,  1200] loss: 1.843
2025-02-24T13:23:28.490727+0300 | INFO | [3,  1300] loss: 1.878
2025-02-24T13:23:36.054749+0300 | INFO | [3,  1400] loss: 1.847
2025-02-24T13:23:45.454106+0300 | INFO | [3,  1500] loss: 1.869
2025-02-24T13:23:54.052219+0300 | INFO | [3,  1600] loss: 1.868
2025-02-24T13:24:02.673716+0300 | INFO | [3,  1700] loss: 1.886
2025-02-24T13:24:11.407304+0300 | INFO | [3,  1800] loss: 1.857
2025-02-24T13:24:19.110485+0300 | INFO | [3,  1900] loss: 1.844
2025-02-24T13:24:28.271104+0300 | INFO | [3,  2000] loss: 1.847
2025-02-24T13:24:36.530996+0300 | INFO | [3,  2100] loss: 1.861
2025-02-24T13:24:45.642748+0300 | INFO | [3,  2200] loss: 1.862
2025-02-24T13:24:53.404147+0300 | INFO | [3,  2300] loss: 1.855
2025-02-24T13:25:01.206464+0300 | INFO | [3,  2400] loss: 1.862
2025-02-24T13:25:09.390851+0300 | INFO | [3,  2500] loss: 1.845
2025-02-24T13:25:18.311813+0300 | INFO | [3,  2600] loss: 1.856
2025-02-24T13:25:27.773512+0300 | INFO | [3,  2700] loss: 1.844
2025-02-24T13:25:36.081779+0300 | INFO | [3,  2800] loss: 1.863
2025-02-24T13:25:44.237385+0300 | INFO | [3,  2900] loss: 1.838
2025-02-24T13:25:52.719736+0300 | INFO | [3,  3000] loss: 1.863
2025-02-24T13:26:01.023418+0300 | INFO | [3,  3100] loss: 1.799
2025-02-24T13:26:09.305165+0300 | INFO | [3,  3200] loss: 1.837
2025-02-24T13:26:16.950993+0300 | INFO | [3,  3300] loss: 1.837
2025-02-24T13:26:26.022173+0300 | INFO | [3,  3400] loss: 1.867
2025-02-24T13:26:33.656933+0300 | INFO | [3,  3500] loss: 1.868
2025-02-24T13:26:42.134045+0300 | INFO | [3,  3600] loss: 1.843
2025-02-24T13:26:49.718997+0300 | INFO | [3,  3700] loss: 1.850
2025-02-24T13:26:58.183264+0300 | INFO | [3,  3800] loss: 1.858
2025-02-24T13:27:05.032291+0300 | INFO | [3,  3900] loss: 1.852
2025-02-24T13:27:12.892651+0300 | INFO | [3,  4000] loss: 1.832
2025-02-24T13:27:22.105782+0300 | INFO | [3,  4100] loss: 1.839
2025-02-24T13:27:31.904497+0300 | INFO | [3,  4200] loss: 1.834
2025-02-24T13:27:41.143761+0300 | INFO | [3,  4300] loss: 1.833
2025-02-24T13:27:49.070792+0300 | INFO | [3,  4400] loss: 1.839
2025-02-24T13:27:56.673158+0300 | INFO | [3,  4500] loss: 1.867
2025-02-24T13:28:04.512764+0300 | INFO | [3,  4600] loss: 1.841
2025-02-24T13:28:12.673741+0300 | INFO | [3,  4700] loss: 1.835
2025-02-24T13:28:20.849982+0300 | INFO | [3,  4800] loss: 1.833
2025-02-24T13:28:29.162124+0300 | INFO | [3,  4900] loss: 1.851
2025-02-24T13:28:35.923481+0300 | DEBUG | Saving model to flat file storage. Save #3
2025-02-24T13:28:35.946046+0300 | INFO | Averaging client parameters
2025-02-24T13:28:35.952492+0300 | INFO | Updating parameters on client #0
2025-02-24T13:28:48.168006+0300 | DEBUG | Test set: Accuracy: 6427/10000 (64%)
2025-02-24T13:28:48.169008+0300 | DEBUG | Test set: Loss: 1.816850185394287
2025-02-24T13:28:48.219890+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.65      0.68      1000
           1       0.87      0.74      0.80      1000
           2       0.59      0.50      0.54      1000
           3       0.40      0.73      0.52      1200
           4       0.69      0.51      0.59      1000
           5       0.00      0.00      0.00       800
           6       0.61      0.84      0.70      1000
           7       0.76      0.65      0.70      1000
           8       0.79      0.80      0.79      1000
           9       0.70      0.86      0.77      1000

    accuracy                           0.64     10000
   macro avg       0.61      0.63      0.61     10000
weighted avg       0.62      0.64      0.62     10000

2025-02-24T13:28:48.221886+0300 | DEBUG | Confusion Matrix:
[[650  17  64  54  20   0  21   9  98  67]
 [ 26 739   5  18   2   0  30   4  18 158]
 [ 75   8 503 174  60   0 117  28  21  14]
 [ 14   3  64 877  40   0 132  33  14  23]
 [ 30   3  66 143 509   0 155  64  20  10]
 [  7   1  62 593  30   0  37  52  11   7]
 [  7   0  44  89  13   0 838   4   4   1]
 [ 13   3  36 163  61   0  24 653  11  36]
 [ 57  28   4  32   1   0  21   3 800  54]
 [ 23  47   4  31   4   0  10   5  18 858]]
2025-02-24T13:28:48.223902+0300 | DEBUG | Class precision: [0.72062084 0.87043581 0.59037559 0.40340386 0.68783784        nan
 0.60505415 0.76374269 0.78817734 0.69869707]
2025-02-24T13:28:48.224890+0300 | DEBUG | Class recall: [0.65       0.739      0.503      0.73083333 0.509      0.
 0.838      0.653      0.8        0.858     ]
2025-02-24T13:28:48.226894+0300 | INFO | Training epoch #4 on client #0
2025-02-24T13:28:48.227897+0300 | DEBUG | Saving model to flat file storage. Save #4
2025-02-24T13:28:48.312129+0300 | INFO | [4,     0] loss: 0.017
2025-02-24T13:28:56.900746+0300 | INFO | [4,   100] loss: 1.837
2025-02-24T13:29:04.603382+0300 | INFO | [4,   200] loss: 1.833
2025-02-24T13:29:12.671240+0300 | INFO | [4,   300] loss: 1.838
2025-02-24T13:29:21.893899+0300 | INFO | [4,   400] loss: 1.851
2025-02-24T13:29:30.134209+0300 | INFO | [4,   500] loss: 1.824
2025-02-24T13:29:37.783456+0300 | INFO | [4,   600] loss: 1.804
2025-02-24T13:29:46.249822+0300 | INFO | [4,   700] loss: 1.826
2025-02-24T13:29:53.637916+0300 | INFO | [4,   800] loss: 1.870
2025-02-24T13:30:01.501349+0300 | INFO | [4,   900] loss: 1.809
2025-02-24T13:30:09.661298+0300 | INFO | [4,  1000] loss: 1.840
2025-02-24T13:30:17.151879+0300 | INFO | [4,  1100] loss: 1.840
2025-02-24T13:30:25.210870+0300 | INFO | [4,  1200] loss: 1.803
2025-02-24T13:30:33.399730+0300 | INFO | [4,  1300] loss: 1.816
2025-02-24T13:30:41.982285+0300 | INFO | [4,  1400] loss: 1.815
2025-02-24T13:30:50.091414+0300 | INFO | [4,  1500] loss: 1.810
2025-02-24T13:30:59.480797+0300 | INFO | [4,  1600] loss: 1.819
2025-02-24T13:31:07.514882+0300 | INFO | [4,  1700] loss: 1.816
2025-02-24T13:31:15.129749+0300 | INFO | [4,  1800] loss: 1.824
2025-02-24T13:31:23.645700+0300 | INFO | [4,  1900] loss: 1.865
2025-02-24T13:31:30.924240+0300 | INFO | [4,  2000] loss: 1.826
2025-02-24T13:31:39.127196+0300 | INFO | [4,  2100] loss: 1.810
2025-02-24T13:31:46.262131+0300 | INFO | [4,  2200] loss: 1.849
2025-02-24T13:31:54.417700+0300 | INFO | [4,  2300] loss: 1.806
2025-02-24T13:32:02.517661+0300 | INFO | [4,  2400] loss: 1.842
2025-02-24T13:32:10.598187+0300 | INFO | [4,  2500] loss: 1.811
2025-02-24T13:32:18.082898+0300 | INFO | [4,  2600] loss: 1.819
2025-02-24T13:32:27.208758+0300 | INFO | [4,  2700] loss: 1.818
2025-02-24T13:32:35.726997+0300 | INFO | [4,  2800] loss: 1.822
2025-02-24T13:32:44.886636+0300 | INFO | [4,  2900] loss: 1.816
2025-02-24T13:32:53.548833+0300 | INFO | [4,  3000] loss: 1.844
2025-02-24T13:33:03.344039+0300 | INFO | [4,  3100] loss: 1.803
2025-02-24T13:33:11.596795+0300 | INFO | [4,  3200] loss: 1.810
2025-02-24T13:33:19.350604+0300 | INFO | [4,  3300] loss: 1.836
2025-02-24T13:33:27.740322+0300 | INFO | [4,  3400] loss: 1.797
2025-02-24T13:33:35.838315+0300 | INFO | [4,  3500] loss: 1.819
2025-02-24T13:33:44.270768+0300 | INFO | [4,  3600] loss: 1.837
2025-02-24T13:33:52.191292+0300 | INFO | [4,  3700] loss: 1.807
2025-02-24T13:34:00.826316+0300 | INFO | [4,  3800] loss: 1.838
2025-02-24T13:34:09.683422+0300 | INFO | [4,  3900] loss: 1.810
2025-02-24T13:34:17.321512+0300 | INFO | [4,  4000] loss: 1.839
2025-02-24T13:34:24.509106+0300 | INFO | [4,  4100] loss: 1.827
2025-02-24T13:34:32.909691+0300 | INFO | [4,  4200] loss: 1.822
2025-02-24T13:34:42.236466+0300 | INFO | [4,  4300] loss: 1.823
2025-02-24T13:34:51.077608+0300 | INFO | [4,  4400] loss: 1.809
2025-02-24T13:34:58.673802+0300 | INFO | [4,  4500] loss: 1.825
2025-02-24T13:35:05.134040+0300 | INFO | [4,  4600] loss: 1.816
2025-02-24T13:35:12.819187+0300 | INFO | [4,  4700] loss: 1.804
2025-02-24T13:35:20.904749+0300 | INFO | [4,  4800] loss: 1.805
2025-02-24T13:35:30.124381+0300 | INFO | [4,  4900] loss: 1.830
2025-02-24T13:35:39.034831+0300 | DEBUG | Saving model to flat file storage. Save #4
2025-02-24T13:35:39.052000+0300 | INFO | Averaging client parameters
2025-02-24T13:35:39.057107+0300 | INFO | Updating parameters on client #0
2025-02-24T13:35:50.650766+0300 | DEBUG | Test set: Accuracy: 6674/10000 (67%)
2025-02-24T13:35:50.651765+0300 | DEBUG | Test set: Loss: 1.790898084640503
2025-02-24T13:35:50.700626+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.69      0.71      1000
           1       0.79      0.89      0.84      1000
           2       0.60      0.51      0.55      1000
           3       0.45      0.66      0.53      1200
           4       0.64      0.62      0.63      1000
           5       0.00      0.00      0.00       800
           6       0.66      0.80      0.72      1000
           7       0.68      0.77      0.72      1000
           8       0.76      0.84      0.80      1000
           9       0.82      0.78      0.80      1000

    accuracy                           0.67     10000
   macro avg       0.61      0.65      0.63     10000
weighted avg       0.62      0.67      0.64     10000

2025-02-24T13:35:50.702969+0300 | DEBUG | Confusion Matrix:
[[688  33  54  18  41   0  15  20  99  32]
 [  8 885   1   8   2   0   4   5  24  63]
 [ 76  15 509 114  88   0 111  51  24  12]
 [ 32  13  55 787  62   0 125  73  31  22]
 [ 18   5  65 108 616   0  82  94   9   3]
 [  5   6  68 528  47   0  36  85  15  10]
 [  6   8  42  80  30   0 796  15  20   3]
 [ 14   7  38  81  56   0  21 774   4   5]
 [ 46  42  13  11  15   0   7   7 840  19]
 [ 34 101   5  18   4   0   6  18  35 779]]
2025-02-24T13:35:50.705282+0300 | DEBUG | Class precision: [0.74217907 0.79372197 0.59882353 0.44894467 0.64099896        nan
 0.66167914 0.67775832 0.76294278 0.82172996]
2025-02-24T13:35:50.706279+0300 | DEBUG | Class recall: [0.688      0.885      0.509      0.65583333 0.616      0.
 0.796      0.774      0.84       0.779     ]
2025-02-24T13:35:50.753193+0300 | INFO | Training epoch #5 on client #0
2025-02-24T13:35:50.754403+0300 | DEBUG | Saving model to flat file storage. Save #5
2025-02-24T13:35:50.827485+0300 | INFO | [5,     0] loss: 0.018
2025-02-24T13:35:59.095687+0300 | INFO | [5,   100] loss: 1.819
2025-02-24T13:36:07.160543+0300 | INFO | [5,   200] loss: 1.807
2025-02-24T13:36:14.535138+0300 | INFO | [5,   300] loss: 1.790
2025-02-24T13:36:22.729558+0300 | INFO | [5,   400] loss: 1.781
2025-02-24T13:36:30.994387+0300 | INFO | [5,   500] loss: 1.808
2025-02-24T13:36:40.159698+0300 | INFO | [5,   600] loss: 1.795
2025-02-24T13:36:49.716093+0300 | INFO | [5,   700] loss: 1.769
2025-02-24T13:36:59.523849+0300 | INFO | [5,   800] loss: 1.797
2025-02-24T13:37:08.808267+0300 | INFO | [5,   900] loss: 1.797
2025-02-24T13:37:18.677648+0300 | INFO | [5,  1000] loss: 1.788
2025-02-24T13:37:27.923063+0300 | INFO | [5,  1100] loss: 1.820
2025-02-24T13:37:37.051879+0300 | INFO | [5,  1200] loss: 1.825
2025-02-24T13:37:45.434936+0300 | INFO | [5,  1300] loss: 1.821
2025-02-24T13:37:54.955861+0300 | INFO | [5,  1400] loss: 1.819
2025-02-24T13:38:03.669839+0300 | INFO | [5,  1500] loss: 1.803
2025-02-24T13:38:14.487398+0300 | INFO | [5,  1600] loss: 1.785
2025-02-24T13:38:23.659017+0300 | INFO | [5,  1700] loss: 1.797
2025-02-24T13:38:31.567417+0300 | INFO | [5,  1800] loss: 1.786
2025-02-24T13:38:35.241861+0300 | INFO | [5,  1900] loss: 1.791
2025-02-24T13:38:39.034164+0300 | INFO | [5,  2000] loss: 1.797
2025-02-24T13:38:42.224632+0300 | INFO | [5,  2100] loss: 1.791
2025-02-24T13:38:46.580065+0300 | INFO | [5,  2200] loss: 1.779
2025-02-24T13:38:51.530831+0300 | INFO | [5,  2300] loss: 1.836
2025-02-24T13:38:56.962022+0300 | INFO | [5,  2400] loss: 1.789
2025-02-24T13:39:01.551482+0300 | INFO | [5,  2500] loss: 1.787
2025-02-24T13:39:05.764582+0300 | INFO | [5,  2600] loss: 1.783
2025-02-24T13:39:10.068344+0300 | INFO | [5,  2700] loss: 1.812
2025-02-24T13:39:14.305680+0300 | INFO | [5,  2800] loss: 1.801
2025-02-24T13:39:19.008375+0300 | INFO | [5,  2900] loss: 1.804
2025-02-24T13:39:23.465631+0300 | INFO | [5,  3000] loss: 1.813
2025-02-24T13:39:28.063181+0300 | INFO | [5,  3100] loss: 1.804
2025-02-24T13:39:32.531926+0300 | INFO | [5,  3200] loss: 1.785
2025-02-24T13:39:37.173675+0300 | INFO | [5,  3300] loss: 1.771
2025-02-24T13:39:41.588921+0300 | INFO | [5,  3400] loss: 1.785
2025-02-24T13:39:45.942983+0300 | INFO | [5,  3500] loss: 1.807
2025-02-24T13:39:50.583414+0300 | INFO | [5,  3600] loss: 1.811
2025-02-24T13:39:55.258711+0300 | INFO | [5,  3700] loss: 1.809
2025-02-24T13:40:00.059054+0300 | INFO | [5,  3800] loss: 1.806
2025-02-24T13:40:06.253121+0300 | INFO | [5,  3900] loss: 1.809
2025-02-24T13:40:10.616936+0300 | INFO | [5,  4000] loss: 1.775
2025-02-24T13:40:15.217966+0300 | INFO | [5,  4100] loss: 1.804
2025-02-24T13:40:19.429301+0300 | INFO | [5,  4200] loss: 1.807
2025-02-24T13:40:23.747580+0300 | INFO | [5,  4300] loss: 1.788
2025-02-24T13:40:27.900268+0300 | INFO | [5,  4400] loss: 1.809
2025-02-24T13:40:32.377824+0300 | INFO | [5,  4500] loss: 1.777
2025-02-24T13:40:37.082685+0300 | INFO | [5,  4600] loss: 1.783
2025-02-24T13:40:41.725261+0300 | INFO | [5,  4700] loss: 1.771
2025-02-24T13:40:46.116957+0300 | INFO | [5,  4800] loss: 1.791
2025-02-24T13:40:50.469870+0300 | INFO | [5,  4900] loss: 1.786
2025-02-24T13:40:55.064256+0300 | DEBUG | Saving model to flat file storage. Save #5
2025-02-24T13:40:55.070349+0300 | INFO | Averaging client parameters
2025-02-24T13:40:55.074351+0300 | INFO | Updating parameters on client #0
2025-02-24T13:41:03.390608+0300 | DEBUG | Test set: Accuracy: 6784/10000 (68%)
2025-02-24T13:41:03.390608+0300 | DEBUG | Test set: Loss: 1.7810347080230713
2025-02-24T13:41:03.429309+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.64      0.71      1000
           1       0.75      0.92      0.83      1000
           2       0.57      0.60      0.58      1000
           3       0.44      0.73      0.55      1200
           4       0.71      0.64      0.67      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.71      0.75      1000
           7       0.78      0.72      0.75      1000
           8       0.76      0.88      0.82      1000
           9       0.76      0.80      0.78      1000

    accuracy                           0.68     10000
   macro avg       0.64      0.66      0.64     10000
weighted avg       0.64      0.68      0.65     10000

2025-02-24T13:41:03.430315+0300 | DEBUG | Confusion Matrix:
[[639  34  67  31  19   0   1   9 141  59]
 [  9 918   2   8   1   0   0   0  18  44]
 [ 60  22 596 121  81   0  54  26  23  17]
 [ 20  28  96 871  45   0  49  34  20  37]
 [ 17  11  60 112 642   0  50  74  22  12]
 [  5   7  90 586  36   0  11  44  10  11]
 [ 12  23  71 115  37   0 713   5  12  12]
 [ 13  15  39 119  44   0   9 724   3  34]
 [ 24  40  12  15   1   0   1   2 880  25]
 [ 12 126   7  15   3   0   1   5  30 801]]
2025-02-24T13:41:03.431303+0300 | DEBUG | Class precision: [0.78791615 0.75       0.57307692 0.4370296  0.70627063        nan
 0.80202475 0.7843987  0.75927524 0.76140684]
2025-02-24T13:41:03.432324+0300 | DEBUG | Class recall: [0.639      0.918      0.596      0.72583333 0.642      0.
 0.713      0.724      0.88       0.801     ]
2025-02-24T13:41:03.477733+0300 | INFO | Training epoch #6 on client #0
2025-02-24T13:41:03.479730+0300 | DEBUG | Saving model to flat file storage. Save #6
2025-02-24T13:41:03.539089+0300 | INFO | [6,     0] loss: 0.016
2025-02-24T13:41:08.152066+0300 | INFO | [6,   100] loss: 1.789
2025-02-24T13:41:12.496927+0300 | INFO | [6,   200] loss: 1.775
2025-02-24T13:41:16.899830+0300 | INFO | [6,   300] loss: 1.779
2025-02-24T13:41:21.089824+0300 | INFO | [6,   400] loss: 1.775
2025-02-24T13:41:25.822760+0300 | INFO | [6,   500] loss: 1.767
2025-02-24T13:41:30.059317+0300 | INFO | [6,   600] loss: 1.772
2025-02-24T13:41:34.251099+0300 | INFO | [6,   700] loss: 1.792
2025-02-24T13:41:39.440988+0300 | INFO | [6,   800] loss: 1.804
2025-02-24T13:41:44.395163+0300 | INFO | [6,   900] loss: 1.767
2025-02-24T13:41:48.740886+0300 | INFO | [6,  1000] loss: 1.757
2025-02-24T13:41:53.050795+0300 | INFO | [6,  1100] loss: 1.766
2025-02-24T13:41:57.960041+0300 | INFO | [6,  1200] loss: 1.771
2025-02-24T13:42:02.115107+0300 | INFO | [6,  1300] loss: 1.776
2025-02-24T13:42:07.119416+0300 | INFO | [6,  1400] loss: 1.765
2025-02-24T13:42:11.998164+0300 | INFO | [6,  1500] loss: 1.762
2025-02-24T13:42:16.480772+0300 | INFO | [6,  1600] loss: 1.778
2025-02-24T13:42:20.677105+0300 | INFO | [6,  1700] loss: 1.777
2025-02-24T13:42:25.188360+0300 | INFO | [6,  1800] loss: 1.809
2025-02-24T13:42:29.731941+0300 | INFO | [6,  1900] loss: 1.790
2025-02-24T13:42:33.952562+0300 | INFO | [6,  2000] loss: 1.761
2025-02-24T13:42:38.150038+0300 | INFO | [6,  2100] loss: 1.780
2025-02-24T13:42:42.360066+0300 | INFO | [6,  2200] loss: 1.784
2025-02-24T13:42:47.220786+0300 | INFO | [6,  2300] loss: 1.782
2025-02-24T13:42:51.748387+0300 | INFO | [6,  2400] loss: 1.781
2025-02-24T13:42:56.504797+0300 | INFO | [6,  2500] loss: 1.798
2025-02-24T13:43:01.953219+0300 | INFO | [6,  2600] loss: 1.769
2025-02-24T13:43:09.221771+0300 | INFO | [6,  2700] loss: 1.781
2025-02-24T13:43:14.990212+0300 | INFO | [6,  2800] loss: 1.775
2025-02-24T13:43:20.270528+0300 | INFO | [6,  2900] loss: 1.779
2025-02-24T13:43:25.004086+0300 | INFO | [6,  3000] loss: 1.789
2025-02-24T13:43:29.701637+0300 | INFO | [6,  3100] loss: 1.806
2025-02-24T13:43:34.516049+0300 | INFO | [6,  3200] loss: 1.781
2025-02-24T13:43:39.028884+0300 | INFO | [6,  3300] loss: 1.753
2025-02-24T13:43:43.462981+0300 | INFO | [6,  3400] loss: 1.784
2025-02-24T13:43:48.517810+0300 | INFO | [6,  3500] loss: 1.788
2025-02-24T13:43:53.355119+0300 | INFO | [6,  3600] loss: 1.768
2025-02-24T13:43:57.823648+0300 | INFO | [6,  3700] loss: 1.766
2025-02-24T13:44:03.120373+0300 | INFO | [6,  3800] loss: 1.780
2025-02-24T13:44:09.244495+0300 | INFO | [6,  3900] loss: 1.768
2025-02-24T13:44:13.621624+0300 | INFO | [6,  4000] loss: 1.783
2025-02-24T13:44:17.843518+0300 | INFO | [6,  4100] loss: 1.791
2025-02-24T13:44:22.526299+0300 | INFO | [6,  4200] loss: 1.757
2025-02-24T13:44:27.014146+0300 | INFO | [6,  4300] loss: 1.774
2025-02-24T13:44:31.203079+0300 | INFO | [6,  4400] loss: 1.765
2025-02-24T13:44:35.610471+0300 | INFO | [6,  4500] loss: 1.786
2025-02-24T13:44:40.017397+0300 | INFO | [6,  4600] loss: 1.782
2025-02-24T13:44:44.566259+0300 | INFO | [6,  4700] loss: 1.773
2025-02-24T13:44:48.704833+0300 | INFO | [6,  4800] loss: 1.773
2025-02-24T13:44:53.293238+0300 | INFO | [6,  4900] loss: 1.786
2025-02-24T13:44:57.538115+0300 | DEBUG | Saving model to flat file storage. Save #6
2025-02-24T13:44:57.543115+0300 | INFO | Averaging client parameters
2025-02-24T13:44:57.547099+0300 | INFO | Updating parameters on client #0
2025-02-24T13:45:05.764732+0300 | DEBUG | Test set: Accuracy: 6988/10000 (70%)
2025-02-24T13:45:05.765716+0300 | DEBUG | Test set: Loss: 1.7625254392623901
2025-02-24T13:45:05.796544+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.82      0.75      1000
           1       0.91      0.83      0.87      1000
           2       0.66      0.51      0.58      1000
           3       0.47      0.72      0.57      1200
           4       0.66      0.72      0.69      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.77      0.76      1000
           7       0.75      0.74      0.75      1000
           8       0.85      0.84      0.85      1000
           9       0.74      0.89      0.81      1000

    accuracy                           0.70     10000
   macro avg       0.65      0.68      0.66     10000
weighted avg       0.66      0.70      0.67     10000

2025-02-24T13:45:05.797543+0300 | DEBUG | Confusion Matrix:
[[820   8  17  15  17   0  11   9  54  49]
 [ 17 829   1   4   1   0  12   2  13 121]
 [119   4 514  94 132   0  60  46  10  21]
 [ 42   7  68 863  51   0  72  48  17  32]
 [ 28   4  35  92 721   0  51  50  11   8]
 [ 19   2  63 547  45   0  22  71  17  14]
 [ 12   0  45  97  52   0 772   7   5  10]
 [ 28   3  23 104  61   0  13 739   4  25]
 [ 73  18   8  13   4   0   8   3 844  29]
 [ 36  34   2  16   2   0   3   4  17 886]]
2025-02-24T13:45:05.797543+0300 | DEBUG | Class precision: [0.68676717 0.9119912  0.66237113 0.46775068 0.66390424        nan
 0.75390625 0.75485189 0.85080645 0.74142259]
2025-02-24T13:45:05.799543+0300 | DEBUG | Class recall: [0.82       0.829      0.514      0.71916667 0.721      0.
 0.772      0.739      0.844      0.886     ]
2025-02-24T13:45:05.800543+0300 | INFO | Training epoch #7 on client #0
2025-02-24T13:45:05.801546+0300 | DEBUG | Saving model to flat file storage. Save #7
2025-02-24T13:45:05.898995+0300 | INFO | [7,     0] loss: 0.019
2025-02-24T13:45:11.535870+0300 | INFO | [7,   100] loss: 1.748
2025-02-24T13:45:15.751911+0300 | INFO | [7,   200] loss: 1.762
2025-02-24T13:45:20.322091+0300 | INFO | [7,   300] loss: 1.757
2025-02-24T13:45:25.261669+0300 | INFO | [7,   400] loss: 1.764
2025-02-24T13:45:29.582851+0300 | INFO | [7,   500] loss: 1.775
2025-02-24T13:45:33.962832+0300 | INFO | [7,   600] loss: 1.750
2025-02-24T13:45:38.607026+0300 | INFO | [7,   700] loss: 1.767
2025-02-24T13:45:43.796531+0300 | INFO | [7,   800] loss: 1.782
2025-02-24T13:45:51.137647+0300 | INFO | [7,   900] loss: 1.765
2025-02-24T13:45:59.875199+0300 | INFO | [7,  1000] loss: 1.780
2025-02-24T13:46:08.744819+0300 | INFO | [7,  1100] loss: 1.756
2025-02-24T13:46:18.675821+0300 | INFO | [7,  1200] loss: 1.756
2025-02-24T13:46:27.843150+0300 | INFO | [7,  1300] loss: 1.736
2025-02-24T13:46:36.162441+0300 | INFO | [7,  1400] loss: 1.779
2025-02-24T13:46:44.873591+0300 | INFO | [7,  1500] loss: 1.756
2025-02-24T13:46:54.244469+0300 | INFO | [7,  1600] loss: 1.772
2025-02-24T13:47:02.249079+0300 | INFO | [7,  1700] loss: 1.755
2025-02-24T13:47:10.504707+0300 | INFO | [7,  1800] loss: 1.773
2025-02-24T13:47:18.511025+0300 | INFO | [7,  1900] loss: 1.763
2025-02-24T13:47:27.654271+0300 | INFO | [7,  2000] loss: 1.777
2025-02-24T13:47:37.383454+0300 | INFO | [7,  2100] loss: 1.752
2025-02-24T13:47:46.759122+0300 | INFO | [7,  2200] loss: 1.760
2025-02-24T13:47:56.441239+0300 | INFO | [7,  2300] loss: 1.772
2025-02-24T13:48:04.786167+0300 | INFO | [7,  2400] loss: 1.756
2025-02-24T13:48:13.032942+0300 | INFO | [7,  2500] loss: 1.758
2025-02-24T13:48:21.081568+0300 | INFO | [7,  2600] loss: 1.755
2025-02-24T13:48:30.718693+0300 | INFO | [7,  2700] loss: 1.758
2025-02-24T13:48:40.152777+0300 | INFO | [7,  2800] loss: 1.773
2025-02-24T13:48:47.756635+0300 | INFO | [7,  2900] loss: 1.763
2025-02-24T13:48:57.330701+0300 | INFO | [7,  3000] loss: 1.758
2025-02-24T13:49:06.914418+0300 | INFO | [7,  3100] loss: 1.765
2025-02-24T13:49:16.752583+0300 | INFO | [7,  3200] loss: 1.774
2025-02-24T13:49:25.411675+0300 | INFO | [7,  3300] loss: 1.788
2025-02-24T13:49:34.442188+0300 | INFO | [7,  3400] loss: 1.765
2025-02-24T13:49:43.717616+0300 | INFO | [7,  3500] loss: 1.775
2025-02-24T13:49:52.402254+0300 | INFO | [7,  3600] loss: 1.749
2025-02-24T13:49:59.227632+0300 | INFO | [7,  3700] loss: 1.759
2025-02-24T13:50:07.274477+0300 | INFO | [7,  3800] loss: 1.767
2025-02-24T13:50:16.052273+0300 | INFO | [7,  3900] loss: 1.763
2025-02-24T13:50:22.784842+0300 | INFO | [7,  4000] loss: 1.766
2025-02-24T13:50:28.798085+0300 | INFO | [7,  4100] loss: 1.751
2025-02-24T13:50:34.980106+0300 | INFO | [7,  4200] loss: 1.774
2025-02-24T13:50:48.830615+0300 | INFO | [7,  4300] loss: 1.756
2025-02-24T13:51:02.338507+0300 | INFO | [7,  4400] loss: 1.801
2025-02-24T13:51:11.813818+0300 | INFO | [7,  4500] loss: 1.752
2025-02-24T13:51:21.860357+0300 | INFO | [7,  4600] loss: 1.763
2025-02-24T13:51:31.647786+0300 | INFO | [7,  4700] loss: 1.768
2025-02-24T13:51:40.236219+0300 | INFO | [7,  4800] loss: 1.762
2025-02-24T13:51:48.425669+0300 | INFO | [7,  4900] loss: 1.781
2025-02-24T13:51:58.362057+0300 | DEBUG | Saving model to flat file storage. Save #7
2025-02-24T13:51:58.370057+0300 | INFO | Averaging client parameters
2025-02-24T13:51:58.373586+0300 | INFO | Updating parameters on client #0
2025-02-24T13:52:10.360834+0300 | DEBUG | Test set: Accuracy: 7008/10000 (70%)
2025-02-24T13:52:10.361833+0300 | DEBUG | Test set: Loss: 1.7579526901245117
2025-02-24T13:52:10.406932+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.81      0.74      1000
           1       0.86      0.88      0.87      1000
           2       0.65      0.55      0.59      1000
           3       0.45      0.74      0.56      1200
           4       0.70      0.69      0.70      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.78      0.78      1000
           7       0.71      0.79      0.75      1000
           8       0.87      0.81      0.84      1000
           9       0.87      0.81      0.84      1000

    accuracy                           0.70     10000
   macro avg       0.66      0.69      0.67     10000
weighted avg       0.67      0.70      0.68     10000

2025-02-24T13:52:10.407943+0300 | DEBUG | Confusion Matrix:
[[813  19  42  29   3   0   9  25  35  25]
 [ 16 881   0  10   1   0   4  11  19  58]
 [ 97   6 549 132  79   0  80  48   5   4]
 [ 44   8  62 892  52   0  53  62  13  14]
 [ 39   3  53 102 692   0  41  63   7   0]
 [ 11   0  58 585  47   0  21  62  12   4]
 [  8   4  42  89  53   0 777  20   7   0]
 [ 23   7  23  92  49   0   9 785   4   8]
 [109  27  13  22   3   0   3   5 807  11]
 [ 39  69   5  25   6   0   3  21  20 812]]
2025-02-24T13:52:10.408935+0300 | DEBUG | Class precision: [0.67806505 0.86035156 0.64817001 0.45096057 0.70253807        nan
 0.777      0.7123412  0.868676   0.86752137]
2025-02-24T13:52:10.410938+0300 | DEBUG | Class recall: [0.813      0.881      0.549      0.74333333 0.692      0.
 0.777      0.785      0.807      0.812     ]
2025-02-24T13:52:10.466727+0300 | INFO | Training epoch #8 on client #0
2025-02-24T13:52:10.468723+0300 | DEBUG | Saving model to flat file storage. Save #8
2025-02-24T13:52:10.569191+0300 | INFO | [8,     0] loss: 0.017
2025-02-24T13:52:18.345251+0300 | INFO | [8,   100] loss: 1.744
2025-02-24T13:52:27.485054+0300 | INFO | [8,   200] loss: 1.738
2025-02-24T13:52:35.349242+0300 | INFO | [8,   300] loss: 1.736
2025-02-24T13:52:44.076892+0300 | INFO | [8,   400] loss: 1.743
2025-02-24T13:52:53.019122+0300 | INFO | [8,   500] loss: 1.742
2025-02-24T13:53:02.480642+0300 | INFO | [8,   600] loss: 1.729
2025-02-24T13:53:09.793317+0300 | INFO | [8,   700] loss: 1.752
2025-02-24T13:53:16.701465+0300 | INFO | [8,   800] loss: 1.743
2025-02-24T13:53:24.475472+0300 | INFO | [8,   900] loss: 1.753
2025-02-24T13:53:32.190371+0300 | INFO | [8,  1000] loss: 1.770
2025-02-24T13:53:39.853660+0300 | INFO | [8,  1100] loss: 1.744
2025-02-24T13:53:47.737820+0300 | INFO | [8,  1200] loss: 1.728
2025-02-24T13:53:55.895477+0300 | INFO | [8,  1300] loss: 1.741
2025-02-24T13:54:03.714189+0300 | INFO | [8,  1400] loss: 1.737
2025-02-24T13:54:11.672314+0300 | INFO | [8,  1500] loss: 1.736
2025-02-24T13:54:23.004514+0300 | INFO | [8,  1600] loss: 1.740
2025-02-24T13:54:38.744288+0300 | INFO | [8,  1700] loss: 1.768
2025-02-24T13:54:51.423380+0300 | INFO | [8,  1800] loss: 1.724
2025-02-24T13:55:02.828030+0300 | INFO | [8,  1900] loss: 1.772
2025-02-24T13:55:13.825805+0300 | INFO | [8,  2000] loss: 1.739
2025-02-24T13:55:24.123860+0300 | INFO | [8,  2100] loss: 1.755
2025-02-24T13:55:33.355522+0300 | INFO | [8,  2200] loss: 1.773
2025-02-24T13:55:45.588333+0300 | INFO | [8,  2300] loss: 1.774
2025-02-24T13:55:56.887653+0300 | INFO | [8,  2400] loss: 1.747
2025-02-24T13:56:06.676949+0300 | INFO | [8,  2500] loss: 1.747
2025-02-24T13:56:18.398681+0300 | INFO | [8,  2600] loss: 1.742
2025-02-24T13:56:28.617542+0300 | INFO | [8,  2700] loss: 1.733
2025-02-24T13:56:40.143515+0300 | INFO | [8,  2800] loss: 1.757
2025-02-24T13:56:52.426047+0300 | INFO | [8,  2900] loss: 1.737
2025-02-24T13:57:10.507047+0300 | INFO | [8,  3000] loss: 1.773
2025-02-24T13:57:21.703759+0300 | INFO | [8,  3100] loss: 1.764
2025-02-24T13:57:33.118898+0300 | INFO | [8,  3200] loss: 1.758
2025-02-24T13:57:44.961880+0300 | INFO | [8,  3300] loss: 1.749
2025-02-24T13:57:58.028504+0300 | INFO | [8,  3400] loss: 1.779
2025-02-24T13:58:09.916483+0300 | INFO | [8,  3500] loss: 1.776
2025-02-24T13:58:21.767644+0300 | INFO | [8,  3600] loss: 1.763
2025-02-24T13:58:32.768928+0300 | INFO | [8,  3700] loss: 1.724
2025-02-24T13:58:42.254218+0300 | INFO | [8,  3800] loss: 1.749
2025-02-24T13:58:51.735891+0300 | INFO | [8,  3900] loss: 1.752
2025-02-24T13:59:01.127215+0300 | INFO | [8,  4000] loss: 1.741
2025-02-24T13:59:10.089756+0300 | INFO | [8,  4100] loss: 1.762
2025-02-24T13:59:19.336458+0300 | INFO | [8,  4200] loss: 1.747
2025-02-24T13:59:28.441065+0300 | INFO | [8,  4300] loss: 1.747
2025-02-24T13:59:42.183653+0300 | INFO | [8,  4400] loss: 1.762
2025-02-24T13:59:52.155297+0300 | INFO | [8,  4500] loss: 1.740
2025-02-24T14:00:01.557133+0300 | INFO | [8,  4600] loss: 1.753
2025-02-24T14:00:12.189769+0300 | INFO | [8,  4700] loss: 1.769
2025-02-24T14:00:22.061135+0300 | INFO | [8,  4800] loss: 1.747
2025-02-24T14:00:30.829381+0300 | INFO | [8,  4900] loss: 1.742
2025-02-24T14:00:40.161053+0300 | DEBUG | Saving model to flat file storage. Save #8
2025-02-24T14:00:40.178023+0300 | INFO | Averaging client parameters
2025-02-24T14:00:40.191245+0300 | INFO | Updating parameters on client #0
2025-02-24T14:01:01.995073+0300 | DEBUG | Test set: Accuracy: 6941/10000 (69%)
2025-02-24T14:01:01.997557+0300 | DEBUG | Test set: Loss: 1.7636100053787231
2025-02-24T14:01:02.110171+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.75      0.75      1000
           1       0.84      0.88      0.86      1000
           2       0.56      0.62      0.59      1000
           3       0.48      0.65      0.55      1200
           4       0.68      0.67      0.68      1000
           5       0.00      0.00      0.00       800
           6       0.65      0.86      0.74      1000
           7       0.75      0.78      0.76      1000
           8       0.89      0.77      0.82      1000
           9       0.84      0.83      0.83      1000

    accuracy                           0.69     10000
   macro avg       0.64      0.68      0.66     10000
weighted avg       0.65      0.69      0.67     10000

2025-02-24T14:01:02.117403+0300 | DEBUG | Confusion Matrix:
[[754  26  68  32  19   0   9  17  36  39]
 [ 14 879   6   6   1   0  10  10  18  56]
 [ 66   4 624  79  91   0  96  32   2   6]
 [ 17  11 121 776  60   0 132  61   9  13]
 [ 17   3  64  55 674   0 134  45   7   1]
 [  5   5 110 505  53   0  50  63   5   4]
 [  7   8  55  48  13   0 862   4   3   0]
 [ 16   2  48  58  72   0  18 777   1   8]
 [ 96  35  14  38   7   0   3   7 768  32]
 [ 30  68   9  15   4   0  14  18  15 827]]
2025-02-24T14:01:02.122359+0300 | DEBUG | Class precision: [0.73776908 0.8443804  0.55764075 0.48138958 0.67806841        nan
 0.64909639 0.75145068 0.88888889 0.83874239]
2025-02-24T14:01:02.124466+0300 | DEBUG | Class recall: [0.754      0.879      0.624      0.64666667 0.674      0.
 0.862      0.777      0.768      0.827     ]
2025-02-24T14:01:02.249593+0300 | INFO | Training epoch #9 on client #0
2025-02-24T14:01:02.249593+0300 | DEBUG | Saving model to flat file storage. Save #9
2025-02-24T14:01:02.416091+0300 | INFO | [9,     0] loss: 0.016
2025-02-24T14:01:15.786325+0300 | INFO | [9,   100] loss: 1.743
2025-02-24T14:01:29.268014+0300 | INFO | [9,   200] loss: 1.741
2025-02-24T14:01:42.769518+0300 | INFO | [9,   300] loss: 1.722
2025-02-24T14:01:55.589057+0300 | INFO | [9,   400] loss: 1.738
2025-02-24T14:02:07.573992+0300 | INFO | [9,   500] loss: 1.731
2025-02-24T14:02:18.542045+0300 | INFO | [9,   600] loss: 1.726
2025-02-24T14:02:28.727700+0300 | INFO | [9,   700] loss: 1.727
2025-02-24T14:02:40.086263+0300 | INFO | [9,   800] loss: 1.726
2025-02-24T14:02:51.662463+0300 | INFO | [9,   900] loss: 1.714
2025-02-24T14:03:05.671792+0300 | INFO | [9,  1000] loss: 1.713
2025-02-24T14:03:19.384101+0300 | INFO | [9,  1100] loss: 1.736
2025-02-24T14:03:32.455307+0300 | INFO | [9,  1200] loss: 1.733
2025-02-24T14:03:46.040417+0300 | INFO | [9,  1300] loss: 1.710
2025-02-24T14:04:00.422629+0300 | INFO | [9,  1400] loss: 1.731
2025-02-24T14:04:13.729383+0300 | INFO | [9,  1500] loss: 1.724
2025-02-24T14:04:26.239302+0300 | INFO | [9,  1600] loss: 1.742
2025-02-24T14:04:38.692340+0300 | INFO | [9,  1700] loss: 1.724
2025-02-24T14:04:49.738194+0300 | INFO | [9,  1800] loss: 1.720
2025-02-24T14:05:03.493261+0300 | INFO | [9,  1900] loss: 1.735
2025-02-24T14:05:17.003437+0300 | INFO | [9,  2000] loss: 1.742
2025-02-24T14:05:30.390977+0300 | INFO | [9,  2100] loss: 1.749
2025-02-24T14:05:43.720580+0300 | INFO | [9,  2200] loss: 1.752
2025-02-24T14:05:57.091389+0300 | INFO | [9,  2300] loss: 1.750
2025-02-24T14:06:12.424491+0300 | INFO | [9,  2400] loss: 1.735
2025-02-24T14:06:23.777576+0300 | INFO | [9,  2500] loss: 1.744
2025-02-24T14:06:35.392706+0300 | INFO | [9,  2600] loss: 1.746
2025-02-24T14:06:47.319993+0300 | INFO | [9,  2700] loss: 1.747
2025-02-24T14:07:00.418177+0300 | INFO | [9,  2800] loss: 1.747
2025-02-24T14:07:12.917668+0300 | INFO | [9,  2900] loss: 1.744
2025-02-24T14:07:25.431328+0300 | INFO | [9,  3000] loss: 1.735
2025-02-24T14:07:38.775452+0300 | INFO | [9,  3100] loss: 1.723
2025-02-24T14:07:51.628057+0300 | INFO | [9,  3200] loss: 1.744
2025-02-24T14:08:04.926185+0300 | INFO | [9,  3300] loss: 1.754
2025-02-24T14:08:19.941638+0300 | INFO | [9,  3400] loss: 1.745
2025-02-24T14:08:34.077035+0300 | INFO | [9,  3500] loss: 1.731
2025-02-24T14:08:51.276073+0300 | INFO | [9,  3600] loss: 1.734
2025-02-24T14:09:04.903214+0300 | INFO | [9,  3700] loss: 1.720
2025-02-24T14:09:18.502399+0300 | INFO | [9,  3800] loss: 1.745
2025-02-24T14:09:31.547883+0300 | INFO | [9,  3900] loss: 1.731
2025-02-24T14:09:44.973207+0300 | INFO | [9,  4000] loss: 1.759
2025-02-24T14:09:57.933613+0300 | INFO | [9,  4100] loss: 1.763
2025-02-24T14:10:08.974727+0300 | INFO | [9,  4200] loss: 1.759
2025-02-24T14:10:23.104356+0300 | INFO | [9,  4300] loss: 1.737
2025-02-24T14:10:34.548453+0300 | INFO | [9,  4400] loss: 1.733
2025-02-24T14:10:45.716842+0300 | INFO | [9,  4500] loss: 1.710
2025-02-24T14:10:58.719406+0300 | INFO | [9,  4600] loss: 1.719
2025-02-24T14:11:11.661970+0300 | INFO | [9,  4700] loss: 1.727
2025-02-24T14:11:24.679924+0300 | INFO | [9,  4800] loss: 1.749
2025-02-24T14:11:37.969664+0300 | INFO | [9,  4900] loss: 1.746
2025-02-24T14:11:50.953432+0300 | DEBUG | Saving model to flat file storage. Save #9
2025-02-24T14:11:50.975971+0300 | INFO | Averaging client parameters
2025-02-24T14:11:50.986353+0300 | INFO | Updating parameters on client #0
2025-02-24T14:12:11.160260+0300 | DEBUG | Test set: Accuracy: 7072/10000 (71%)
2025-02-24T14:12:11.166262+0300 | DEBUG | Test set: Loss: 1.7519121170043945
2025-02-24T14:12:11.282667+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.74      0.76      1000
           1       0.89      0.87      0.88      1000
           2       0.63      0.61      0.62      1000
           3       0.51      0.65      0.57      1200
           4       0.58      0.80      0.67      1000
           5       0.00      0.00      0.00       800
           6       0.70      0.84      0.76      1000
           7       0.82      0.70      0.76      1000
           8       0.79      0.91      0.84      1000
           9       0.84      0.82      0.83      1000

    accuracy                           0.71     10000
   macro avg       0.65      0.69      0.67     10000
weighted avg       0.66      0.71      0.68     10000

2025-02-24T14:12:11.283715+0300 | DEBUG | Confusion Matrix:
[[745  12  52  10  44   0  10   2  82  43]
 [ 16 869   4   4   3   0  13   2  36  53]
 [ 70   3 610  63 128   0  81  19  18   8]
 [ 21   3  87 776 132   0  99  42  26  14]
 [ 11   2  30  46 795   0  79  22  14   1]
 [  5   2  86 500  88   0  44  50  21   4]
 [  7   0  59  45  33   0 838   2  16   0]
 [ 20   5  27  73 134   0  18 701   5  17]
 [ 29  14   7   4   8   0   3   3 913  19]
 [ 30  68   6  13   6   0  14   7  31 825]]
2025-02-24T14:12:11.284725+0300 | DEBUG | Class precision: [0.78092243 0.88854806 0.63016529 0.50586701 0.57986871        nan
 0.69891576 0.82470588 0.78571429 0.83841463]
2025-02-24T14:12:11.285888+0300 | DEBUG | Class recall: [0.745      0.869      0.61       0.64666667 0.795      0.
 0.838      0.701      0.913      0.825     ]
2025-02-24T14:12:11.286899+0300 | INFO | Training epoch #10 on client #0
2025-02-24T14:12:11.287905+0300 | DEBUG | Saving model to flat file storage. Save #10
2025-02-24T14:12:11.483590+0300 | INFO | [10,     0] loss: 0.017
2025-02-24T14:12:24.019215+0300 | INFO | [10,   100] loss: 1.737
2025-02-24T14:12:35.153783+0300 | INFO | [10,   200] loss: 1.710
2025-02-24T14:12:47.269431+0300 | INFO | [10,   300] loss: 1.717
2025-02-24T14:13:00.240979+0300 | INFO | [10,   400] loss: 1.734
2025-02-24T14:13:13.471392+0300 | INFO | [10,   500] loss: 1.705
2025-02-24T14:13:26.367403+0300 | INFO | [10,   600] loss: 1.716
2025-02-24T14:13:38.723717+0300 | INFO | [10,   700] loss: 1.721
2025-02-24T14:13:51.581137+0300 | INFO | [10,   800] loss: 1.725
2025-02-24T14:14:05.279302+0300 | INFO | [10,   900] loss: 1.727
2025-02-24T14:14:17.813119+0300 | INFO | [10,  1000] loss: 1.736
2025-02-24T14:14:29.275821+0300 | INFO | [10,  1100] loss: 1.728
2025-02-24T14:14:40.025939+0300 | INFO | [10,  1200] loss: 1.717
2025-02-24T14:14:52.575194+0300 | INFO | [10,  1300] loss: 1.725
2025-02-24T14:15:04.712775+0300 | INFO | [10,  1400] loss: 1.740
2025-02-24T14:15:18.323713+0300 | INFO | [10,  1500] loss: 1.724
2025-02-24T14:15:31.263867+0300 | INFO | [10,  1600] loss: 1.686
2025-02-24T14:15:44.971723+0300 | INFO | [10,  1700] loss: 1.701
2025-02-24T14:15:57.373723+0300 | INFO | [10,  1800] loss: 1.714
2025-02-24T14:16:09.757301+0300 | INFO | [10,  1900] loss: 1.709
2025-02-24T14:16:22.073917+0300 | INFO | [10,  2000] loss: 1.711
2025-02-24T14:16:33.452641+0300 | INFO | [10,  2100] loss: 1.730
2025-02-24T14:16:44.576363+0300 | INFO | [10,  2200] loss: 1.732
2025-02-24T14:16:55.765702+0300 | INFO | [10,  2300] loss: 1.732
2025-02-24T14:17:07.230984+0300 | INFO | [10,  2400] loss: 1.754
2025-02-24T14:17:18.510326+0300 | INFO | [10,  2500] loss: 1.722
2025-02-24T14:17:29.919002+0300 | INFO | [10,  2600] loss: 1.716
2025-02-24T14:17:42.100607+0300 | INFO | [10,  2700] loss: 1.744
2025-02-24T14:17:59.630664+0300 | INFO | [10,  2800] loss: 1.752
2025-02-24T14:18:12.958639+0300 | INFO | [10,  2900] loss: 1.756
2025-02-24T14:18:24.257003+0300 | INFO | [10,  3000] loss: 1.742
2025-02-24T14:18:34.518139+0300 | INFO | [10,  3100] loss: 1.724
2025-02-24T14:18:44.670045+0300 | INFO | [10,  3200] loss: 1.719
2025-02-24T14:18:54.478887+0300 | INFO | [10,  3300] loss: 1.718
2025-02-24T14:19:05.412114+0300 | INFO | [10,  3400] loss: 1.748
2025-02-24T14:19:16.680963+0300 | INFO | [10,  3500] loss: 1.725
2025-02-24T14:19:26.265609+0300 | INFO | [10,  3600] loss: 1.743
2025-02-24T14:19:37.779917+0300 | INFO | [10,  3700] loss: 1.734
2025-02-24T14:19:48.794495+0300 | INFO | [10,  3800] loss: 1.743
2025-02-24T14:19:58.524399+0300 | INFO | [10,  3900] loss: 1.720
2025-02-24T14:20:09.041452+0300 | INFO | [10,  4000] loss: 1.739
2025-02-24T14:20:18.997735+0300 | INFO | [10,  4100] loss: 1.727
2025-02-24T14:20:28.633528+0300 | INFO | [10,  4200] loss: 1.745
2025-02-24T14:20:38.738513+0300 | INFO | [10,  4300] loss: 1.730
2025-02-24T14:20:48.949653+0300 | INFO | [10,  4400] loss: 1.730
2025-02-24T14:20:59.064468+0300 | INFO | [10,  4500] loss: 1.712
2025-02-24T14:21:09.629237+0300 | INFO | [10,  4600] loss: 1.723
2025-02-24T14:21:20.133660+0300 | INFO | [10,  4700] loss: 1.708
2025-02-24T14:21:30.381572+0300 | INFO | [10,  4800] loss: 1.712
2025-02-24T14:21:40.563035+0300 | INFO | [10,  4900] loss: 1.716
2025-02-24T14:21:50.906430+0300 | DEBUG | Saving model to flat file storage. Save #10
2025-02-24T14:21:50.931537+0300 | INFO | Averaging client parameters
2025-02-24T14:21:50.939657+0300 | INFO | Updating parameters on client #0
2025-02-24T14:22:06.160522+0300 | DEBUG | Test set: Accuracy: 7198/10000 (72%)
2025-02-24T14:22:06.164495+0300 | DEBUG | Test set: Loss: 1.7397301197052002
2025-02-24T14:22:06.277303+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.82      0.77      1000
           1       0.84      0.91      0.87      1000
           2       0.68      0.59      0.63      1000
           3       0.48      0.70      0.57      1200
           4       0.65      0.81      0.72      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.83      0.80      1000
           7       0.76      0.78      0.77      1000
           8       0.90      0.81      0.86      1000
           9       0.87      0.81      0.84      1000

    accuracy                           0.72     10000
   macro avg       0.67      0.71      0.68     10000
weighted avg       0.68      0.72      0.69     10000

2025-02-24T14:22:06.279311+0300 | DEBUG | Confusion Matrix:
[[817  21  29  22  27   0   8  14  34  28]
 [ 16 905   2   7   0   0   8   4   7  51]
 [ 88   2 587  85 121   0  66  40   4   7]
 [ 28  12  74 844  82   0  80  65   7   8]
 [ 19   3  35  55 807   0  34  38   9   0]
 [ 13   4  54 561  67   0  32  59   9   1]
 [  7   0  46  61  44   0 830   5   6   1]
 [ 21   6  20  78  78   0   9 782   2   4]
 [ 79  40   8  18   6   0   5   6 814  24]
 [ 38  86   6  21   5   0   3  19  10 812]]
2025-02-24T14:22:06.282310+0300 | DEBUG | Class precision: [0.72557726 0.83873957 0.68176539 0.48173516 0.6523848         nan
 0.77209302 0.75775194 0.90243902 0.86752137]
2025-02-24T14:22:06.283309+0300 | DEBUG | Class recall: [0.817      0.905      0.587      0.70333333 0.807      0.
 0.83       0.782      0.814      0.812     ]
2025-02-24T14:22:06.286310+0300 | INFO | Training epoch #11 on client #0
2025-02-24T14:22:06.287316+0300 | DEBUG | Saving model to flat file storage. Save #11
2025-02-24T14:22:06.421466+0300 | INFO | [11,     0] loss: 0.017
2025-02-24T14:22:16.297217+0300 | INFO | [11,   100] loss: 1.718
2025-02-24T14:22:25.654140+0300 | INFO | [11,   200] loss: 1.706
2025-02-24T14:22:35.296998+0300 | INFO | [11,   300] loss: 1.693
2025-02-24T14:22:44.626369+0300 | INFO | [11,   400] loss: 1.709
2025-02-24T14:22:55.236893+0300 | INFO | [11,   500] loss: 1.703
2025-02-24T14:23:05.590727+0300 | INFO | [11,   600] loss: 1.699
2025-02-24T14:23:15.571459+0300 | INFO | [11,   700] loss: 1.708
2025-02-24T14:23:25.152657+0300 | INFO | [11,   800] loss: 1.710
2025-02-24T14:23:34.759421+0300 | INFO | [11,   900] loss: 1.716
2025-02-24T14:23:44.821756+0300 | INFO | [11,  1000] loss: 1.700
2025-02-24T14:23:54.620433+0300 | INFO | [11,  1100] loss: 1.703
2025-02-24T14:24:04.526932+0300 | INFO | [11,  1200] loss: 1.720
2025-02-24T14:24:14.378449+0300 | INFO | [11,  1300] loss: 1.740
2025-02-24T14:24:23.271833+0300 | INFO | [11,  1400] loss: 1.715
2025-02-24T14:24:32.652248+0300 | INFO | [11,  1500] loss: 1.722
2025-02-24T14:24:42.716513+0300 | INFO | [11,  1600] loss: 1.738
2025-02-24T14:24:52.915114+0300 | INFO | [11,  1700] loss: 1.710
2025-02-24T14:25:03.622889+0300 | INFO | [11,  1800] loss: 1.707
2025-02-24T14:25:15.516587+0300 | INFO | [11,  1900] loss: 1.739
2025-02-24T14:25:28.678265+0300 | INFO | [11,  2000] loss: 1.694
2025-02-24T14:25:38.062890+0300 | INFO | [11,  2100] loss: 1.744
2025-02-24T14:25:47.432632+0300 | INFO | [11,  2200] loss: 1.755
2025-02-24T14:25:58.753704+0300 | INFO | [11,  2300] loss: 1.701
2025-02-24T14:26:09.359360+0300 | INFO | [11,  2400] loss: 1.723
2025-02-24T14:26:21.726253+0300 | INFO | [11,  2500] loss: 1.711
2025-02-24T14:26:31.947853+0300 | INFO | [11,  2600] loss: 1.708
2025-02-24T14:26:41.373770+0300 | INFO | [11,  2700] loss: 1.719
2025-02-24T14:26:50.635135+0300 | INFO | [11,  2800] loss: 1.720
2025-02-24T14:27:02.677289+0300 | INFO | [11,  2900] loss: 1.737
2025-02-24T14:27:15.718648+0300 | INFO | [11,  3000] loss: 1.719
2025-02-24T14:27:26.491043+0300 | INFO | [11,  3100] loss: 1.710
2025-02-24T14:27:38.581922+0300 | INFO | [11,  3200] loss: 1.741
2025-02-24T14:27:51.088126+0300 | INFO | [11,  3300] loss: 1.734
2025-02-24T14:28:03.485552+0300 | INFO | [11,  3400] loss: 1.681
2025-02-24T14:28:17.168388+0300 | INFO | [11,  3500] loss: 1.712
2025-02-24T14:28:29.736779+0300 | INFO | [11,  3600] loss: 1.689
2025-02-24T14:28:42.096070+0300 | INFO | [11,  3700] loss: 1.720
2025-02-24T14:28:54.232599+0300 | INFO | [11,  3800] loss: 1.757
2025-02-24T14:29:06.681899+0300 | INFO | [11,  3900] loss: 1.719
2025-02-24T14:29:20.260179+0300 | INFO | [11,  4000] loss: 1.717
2025-02-24T14:29:33.021475+0300 | INFO | [11,  4100] loss: 1.738
2025-02-24T14:29:44.909816+0300 | INFO | [11,  4200] loss: 1.724
2025-02-24T14:29:55.716557+0300 | INFO | [11,  4300] loss: 1.704
2025-02-24T14:30:07.530833+0300 | INFO | [11,  4400] loss: 1.693
2025-02-24T14:30:19.459645+0300 | INFO | [11,  4500] loss: 1.725
2025-02-24T14:30:31.393070+0300 | INFO | [11,  4600] loss: 1.728
2025-02-24T14:30:43.702454+0300 | INFO | [11,  4700] loss: 1.725
2025-02-24T14:30:53.577880+0300 | INFO | [11,  4800] loss: 1.728
2025-02-24T14:31:04.188272+0300 | INFO | [11,  4900] loss: 1.712
2025-02-24T14:31:15.183479+0300 | DEBUG | Saving model to flat file storage. Save #11
2025-02-24T14:31:15.212098+0300 | INFO | Averaging client parameters
2025-02-24T14:31:15.228445+0300 | INFO | Updating parameters on client #0
2025-02-24T14:31:32.086882+0300 | DEBUG | Test set: Accuracy: 7321/10000 (73%)
2025-02-24T14:31:32.091901+0300 | DEBUG | Test set: Loss: 1.7278822660446167
2025-02-24T14:31:32.195069+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.84      0.79      1000
           1       0.85      0.92      0.88      1000
           2       0.65      0.65      0.65      1000
           3       0.49      0.72      0.58      1200
           4       0.78      0.70      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.83      0.79      1000
           7       0.78      0.83      0.80      1000
           8       0.88      0.84      0.86      1000
           9       0.85      0.85      0.85      1000

    accuracy                           0.73     10000
   macro avg       0.68      0.72      0.69     10000
weighted avg       0.69      0.73      0.71     10000

2025-02-24T14:31:32.198074+0300 | DEBUG | Confusion Matrix:
[[839  21  37  17   4   0   4  12  31  35]
 [  7 918   2   2   1   0   5   3  14  48]
 [ 85   5 651  67  66   0  75  33   6  12]
 [ 34  12  90 863  49   0  67  58   7  20]
 [ 25   2  52  90 701   0  71  48   5   6]
 [ 14   7  79 548  38   0  33  66  11   4]
 [ 12   3  50  76  13   0 829   3  13   1]
 [ 15   7  32  70  21   0  14 826   3  12]
 [ 82  25   9  14   3   0   1   5 844  17]
 [ 22  80   5   6   2   0   7   8  20 850]]
2025-02-24T14:31:32.199069+0300 | DEBUG | Class precision: [0.73920705 0.85       0.64647468 0.49229892 0.78062361        nan
 0.74954792 0.77777778 0.88469602 0.84577114]
2025-02-24T14:31:32.200075+0300 | DEBUG | Class recall: [0.839      0.918      0.651      0.71916667 0.701      0.
 0.829      0.826      0.844      0.85      ]
2025-02-24T14:31:32.205070+0300 | INFO | Training epoch #12 on client #0
2025-02-24T14:31:32.206071+0300 | DEBUG | Saving model to flat file storage. Save #12
2025-02-24T14:31:32.361540+0300 | INFO | [12,     0] loss: 0.016
2025-02-24T14:31:42.877578+0300 | INFO | [12,   100] loss: 1.692
2025-02-24T14:31:53.453897+0300 | INFO | [12,   200] loss: 1.700
2025-02-24T14:32:03.418636+0300 | INFO | [12,   300] loss: 1.714
2025-02-24T14:32:13.549771+0300 | INFO | [12,   400] loss: 1.720
2025-02-24T14:32:23.862008+0300 | INFO | [12,   500] loss: 1.693
2025-02-24T14:32:34.216263+0300 | INFO | [12,   600] loss: 1.700
2025-02-24T14:32:44.500971+0300 | INFO | [12,   700] loss: 1.707
2025-02-24T14:32:54.867794+0300 | INFO | [12,   800] loss: 1.720
2025-02-24T14:33:05.634017+0300 | INFO | [12,   900] loss: 1.708
2025-02-24T14:33:15.659935+0300 | INFO | [12,  1000] loss: 1.719
2025-02-24T14:33:27.652190+0300 | INFO | [12,  1100] loss: 1.702
2025-02-24T14:33:40.036031+0300 | INFO | [12,  1200] loss: 1.696
2025-02-24T14:33:48.975711+0300 | INFO | [12,  1300] loss: 1.705
2025-02-24T14:33:59.847789+0300 | INFO | [12,  1400] loss: 1.736
2025-02-24T14:34:10.126370+0300 | INFO | [12,  1500] loss: 1.713
2025-02-24T14:34:21.608882+0300 | INFO | [12,  1600] loss: 1.694
2025-02-24T14:34:33.902461+0300 | INFO | [12,  1700] loss: 1.709
2025-02-24T14:34:45.687091+0300 | INFO | [12,  1800] loss: 1.701
2025-02-24T14:34:57.060806+0300 | INFO | [12,  1900] loss: 1.700
2025-02-24T14:35:10.190078+0300 | INFO | [12,  2000] loss: 1.702
2025-02-24T14:35:22.243930+0300 | INFO | [12,  2100] loss: 1.718
2025-02-24T14:35:34.663717+0300 | INFO | [12,  2200] loss: 1.709
2025-02-24T14:35:46.322772+0300 | INFO | [12,  2300] loss: 1.712
2025-02-24T14:35:57.880866+0300 | INFO | [12,  2400] loss: 1.706
2025-02-24T14:36:10.631405+0300 | INFO | [12,  2500] loss: 1.704
2025-02-24T14:36:23.521592+0300 | INFO | [12,  2600] loss: 1.717
2025-02-24T14:36:35.462558+0300 | INFO | [12,  2700] loss: 1.707
2025-02-24T14:36:47.420668+0300 | INFO | [12,  2800] loss: 1.698
2025-02-24T14:36:59.549901+0300 | INFO | [12,  2900] loss: 1.681
2025-02-24T14:37:11.629878+0300 | INFO | [12,  3000] loss: 1.706
2025-02-24T14:37:24.331581+0300 | INFO | [12,  3100] loss: 1.701
2025-02-24T14:37:37.188358+0300 | INFO | [12,  3200] loss: 1.703
2025-02-24T14:37:49.760870+0300 | INFO | [12,  3300] loss: 1.696
2025-02-24T14:38:01.786705+0300 | INFO | [12,  3400] loss: 1.737
2025-02-24T14:38:14.431012+0300 | INFO | [12,  3500] loss: 1.728
2025-02-24T14:38:27.896515+0300 | INFO | [12,  3600] loss: 1.712
2025-02-24T14:38:39.325628+0300 | INFO | [12,  3700] loss: 1.717
2025-02-24T14:38:51.233393+0300 | INFO | [12,  3800] loss: 1.709
2025-02-24T14:39:04.094340+0300 | INFO | [12,  3900] loss: 1.722
2025-02-24T14:39:17.497458+0300 | INFO | [12,  4000] loss: 1.725
2025-02-24T14:39:31.799724+0300 | INFO | [12,  4100] loss: 1.719
2025-02-24T14:39:44.986118+0300 | INFO | [12,  4200] loss: 1.713
2025-02-24T14:39:57.726175+0300 | INFO | [12,  4300] loss: 1.722
2025-02-24T14:40:10.886604+0300 | INFO | [12,  4400] loss: 1.715
2025-02-24T14:40:23.388789+0300 | INFO | [12,  4500] loss: 1.728
2025-02-24T14:40:35.333233+0300 | INFO | [12,  4600] loss: 1.700
2025-02-24T14:40:47.741713+0300 | INFO | [12,  4700] loss: 1.721
2025-02-24T14:41:00.862922+0300 | INFO | [12,  4800] loss: 1.718
2025-02-24T14:41:13.568521+0300 | INFO | [12,  4900] loss: 1.719
2025-02-24T14:41:29.952593+0300 | DEBUG | Saving model to flat file storage. Save #12
2025-02-24T14:41:29.979594+0300 | INFO | Averaging client parameters
2025-02-24T14:41:29.990313+0300 | INFO | Updating parameters on client #0
2025-02-24T14:41:51.064670+0300 | DEBUG | Test set: Accuracy: 7227/10000 (72%)
2025-02-24T14:41:51.066674+0300 | DEBUG | Test set: Loss: 1.7364318370819092
2025-02-24T14:41:51.207875+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.85      0.76      1000
           1       0.95      0.78      0.86      1000
           2       0.70      0.56      0.62      1000
           3       0.48      0.75      0.59      1200
           4       0.70      0.78      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.81      0.81      1000
           7       0.79      0.77      0.78      1000
           8       0.87      0.86      0.86      1000
           9       0.76      0.91      0.83      1000

    accuracy                           0.72     10000
   macro avg       0.68      0.71      0.69     10000
weighted avg       0.69      0.72      0.70     10000

2025-02-24T14:41:51.213685+0300 | DEBUG | Confusion Matrix:
[[854   8  30  16   8   0   2   7  42  33]
 [ 23 778   3   9   2   0   6   1  21 157]
 [116   0 565 110 100   0  50  35  11  13]
 [ 45   3  60 903  54   0  59  46  12  18]
 [ 28   0  37  72 782   0  32  37   8   4]
 [ 16   0  39 601  46   0  22  55  12   9]
 [ 18   1  42  58  46   0 815   6   9   5]
 [ 36   4  20  80  68   0   9 766   1  16]
 [ 72   5   6  16   3   0   3   3 859  33]
 [ 31  19   6  13   2   0   2   9  13 905]]
2025-02-24T14:41:51.217688+0300 | DEBUG | Class precision: [0.68926554 0.95110024 0.69925743 0.48083067 0.70387039        nan
 0.815      0.79378238 0.8694332  0.75859179]
2025-02-24T14:41:51.218704+0300 | DEBUG | Class recall: [0.854  0.778  0.565  0.7525 0.782  0.     0.815  0.766  0.859  0.905 ]
2025-02-24T14:41:51.291270+0300 | INFO | Training epoch #13 on client #0
2025-02-24T14:41:51.295619+0300 | DEBUG | Saving model to flat file storage. Save #13
2025-02-24T14:41:51.637230+0300 | INFO | [13,     0] loss: 0.018
2025-02-24T14:42:05.813361+0300 | INFO | [13,   100] loss: 1.693
2025-02-24T14:42:21.826423+0300 | INFO | [13,   200] loss: 1.681
2025-02-24T14:42:42.027264+0300 | INFO | [13,   300] loss: 1.703
2025-02-24T14:42:54.706667+0300 | INFO | [13,   400] loss: 1.692
2025-02-24T14:43:10.979823+0300 | INFO | [13,   500] loss: 1.691
2025-02-24T14:43:24.650681+0300 | INFO | [13,   600] loss: 1.698
2025-02-24T14:43:39.533642+0300 | INFO | [13,   700] loss: 1.707
2025-02-24T14:43:51.469353+0300 | INFO | [13,   800] loss: 1.696
2025-02-24T14:44:07.207573+0300 | INFO | [13,   900] loss: 1.692
2025-02-24T14:44:22.706388+0300 | INFO | [13,  1000] loss: 1.706
2025-02-24T14:44:36.903819+0300 | INFO | [13,  1100] loss: 1.673
2025-02-24T14:44:51.460531+0300 | INFO | [13,  1200] loss: 1.697
2025-02-24T14:45:04.178439+0300 | INFO | [13,  1300] loss: 1.680
2025-02-24T14:45:17.054627+0300 | INFO | [13,  1400] loss: 1.688
2025-02-24T14:45:29.725370+0300 | INFO | [13,  1500] loss: 1.705
2025-02-24T14:45:42.617587+0300 | INFO | [13,  1600] loss: 1.696
2025-02-24T14:45:56.309877+0300 | INFO | [13,  1700] loss: 1.680
2025-02-24T14:46:09.272307+0300 | INFO | [13,  1800] loss: 1.696
2025-02-24T14:46:22.912783+0300 | INFO | [13,  1900] loss: 1.692
2025-02-24T14:46:34.484203+0300 | INFO | [13,  2000] loss: 1.687
2025-02-24T14:46:46.236386+0300 | INFO | [13,  2100] loss: 1.691
2025-02-24T14:46:57.603564+0300 | INFO | [13,  2200] loss: 1.698
2025-02-24T14:47:09.199259+0300 | INFO | [13,  2300] loss: 1.695
2025-02-24T14:47:21.872604+0300 | INFO | [13,  2400] loss: 1.735
2025-02-24T14:47:36.452457+0300 | INFO | [13,  2500] loss: 1.699
2025-02-24T14:47:49.290382+0300 | INFO | [13,  2600] loss: 1.703
2025-02-24T14:48:06.994314+0300 | INFO | [13,  2700] loss: 1.694
2025-02-24T14:48:20.520720+0300 | INFO | [13,  2800] loss: 1.709
2025-02-24T14:48:34.368183+0300 | INFO | [13,  2900] loss: 1.690
2025-02-24T14:48:47.587452+0300 | INFO | [13,  3000] loss: 1.712
2025-02-24T14:48:59.359854+0300 | INFO | [13,  3100] loss: 1.724
2025-02-24T14:49:11.969363+0300 | INFO | [13,  3200] loss: 1.688
2025-02-24T14:49:24.185332+0300 | INFO | [13,  3300] loss: 1.691
2025-02-24T14:49:36.380110+0300 | INFO | [13,  3400] loss: 1.702
2025-02-24T14:49:49.969222+0300 | INFO | [13,  3500] loss: 1.731
2025-02-24T14:50:04.638654+0300 | INFO | [13,  3600] loss: 1.691
2025-02-24T14:50:22.119841+0300 | INFO | [13,  3700] loss: 1.709
2025-02-24T14:50:38.199293+0300 | INFO | [13,  3800] loss: 1.695
2025-02-24T14:50:51.550974+0300 | INFO | [13,  3900] loss: 1.729
2025-02-24T14:51:05.098174+0300 | INFO | [13,  4000] loss: 1.689
2025-02-24T14:51:18.228722+0300 | INFO | [13,  4100] loss: 1.707
2025-02-24T14:51:30.688721+0300 | INFO | [13,  4200] loss: 1.699
2025-02-24T14:51:43.277130+0300 | INFO | [13,  4300] loss: 1.713
2025-02-24T14:51:55.984082+0300 | INFO | [13,  4400] loss: 1.690
2025-02-24T14:52:10.839392+0300 | INFO | [13,  4500] loss: 1.699
2025-02-24T14:52:28.209389+0300 | INFO | [13,  4600] loss: 1.691
2025-02-24T14:52:43.176162+0300 | INFO | [13,  4700] loss: 1.692
2025-02-24T14:52:56.554753+0300 | INFO | [13,  4800] loss: 1.706
2025-02-24T14:53:08.517141+0300 | INFO | [13,  4900] loss: 1.685
2025-02-24T14:53:20.399349+0300 | DEBUG | Saving model to flat file storage. Save #13
2025-02-24T14:53:20.427948+0300 | INFO | Averaging client parameters
2025-02-24T14:53:20.438145+0300 | INFO | Updating parameters on client #0
2025-02-24T14:53:41.936411+0300 | DEBUG | Test set: Accuracy: 7292/10000 (73%)
2025-02-24T14:53:41.938813+0300 | DEBUG | Test set: Loss: 1.7306644916534424
2025-02-24T14:53:42.061691+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.84      0.77      1000
           1       0.91      0.86      0.88      1000
           2       0.71      0.56      0.63      1000
           3       0.49      0.76      0.59      1200
           4       0.73      0.74      0.73      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.83      0.80      1000
           7       0.77      0.80      0.79      1000
           8       0.84      0.87      0.86      1000
           9       0.84      0.87      0.85      1000

    accuracy                           0.73     10000
   macro avg       0.68      0.71      0.69     10000
weighted avg       0.69      0.73      0.70     10000

2025-02-24T14:53:42.064522+0300 | DEBUG | Confusion Matrix:
[[845  10  31  15  10   0   9  11  43  26]
 [ 22 865   4   1   1   0   4   3  29  71]
 [ 93   2 561 100 103   0  89  35   8   9]
 [ 39   8  55 909  44   0  61  52  14  18]
 [ 26   3  31  94 742   0  45  47   7   5]
 [ 16   6  44 587  39   0  18  71  12   7]
 [ 18   3  24  70  30   0 832   4  14   5]
 [ 29   4  22  70  46   0   9 802   5  13]
 [ 71  15  12  11   4   0   2   5 869  11]
 [ 32  39  10  12   1   0   2   8  29 867]]
2025-02-24T14:53:42.068897+0300 | DEBUG | Class precision: [0.70948783 0.90575916 0.70654912 0.48635634 0.72745098        nan
 0.77684407 0.77263969 0.84368932 0.84011628]
2025-02-24T14:53:42.072162+0300 | DEBUG | Class recall: [0.845  0.865  0.561  0.7575 0.742  0.     0.832  0.802  0.869  0.867 ]
2025-02-24T14:53:42.129495+0300 | INFO | Training epoch #14 on client #0
2025-02-24T14:53:42.131007+0300 | DEBUG | Saving model to flat file storage. Save #14
2025-02-24T14:53:42.276738+0300 | INFO | [14,     0] loss: 0.017
2025-02-24T14:53:54.283952+0300 | INFO | [14,   100] loss: 1.687
2025-02-24T14:54:09.526667+0300 | INFO | [14,   200] loss: 1.696
2025-02-24T14:54:28.536301+0300 | INFO | [14,   300] loss: 1.698
2025-02-24T14:54:44.950903+0300 | INFO | [14,   400] loss: 1.712
2025-02-24T14:54:58.444842+0300 | INFO | [14,   500] loss: 1.711
2025-02-24T14:55:11.083072+0300 | INFO | [14,   600] loss: 1.672
2025-02-24T14:55:23.317184+0300 | INFO | [14,   700] loss: 1.684
2025-02-24T14:55:36.696623+0300 | INFO | [14,   800] loss: 1.672
2025-02-24T14:55:49.739808+0300 | INFO | [14,   900] loss: 1.678
2025-02-24T14:56:02.515000+0300 | INFO | [14,  1000] loss: 1.696
2025-02-24T14:56:14.651286+0300 | INFO | [14,  1100] loss: 1.714
2025-02-24T14:56:26.639831+0300 | INFO | [14,  1200] loss: 1.693
2025-02-24T14:56:38.320026+0300 | INFO | [14,  1300] loss: 1.674
2025-02-24T14:56:49.634848+0300 | INFO | [14,  1400] loss: 1.674
2025-02-24T14:57:01.985192+0300 | INFO | [14,  1500] loss: 1.700
2025-02-24T14:57:15.512312+0300 | INFO | [14,  1600] loss: 1.679
2025-02-24T14:57:28.246474+0300 | INFO | [14,  1700] loss: 1.682
2025-02-24T14:57:41.056802+0300 | INFO | [14,  1800] loss: 1.720
2025-02-24T14:57:52.675094+0300 | INFO | [14,  1900] loss: 1.709
2025-02-24T14:58:05.733864+0300 | INFO | [14,  2000] loss: 1.664
2025-02-24T14:58:18.083973+0300 | INFO | [14,  2100] loss: 1.690
2025-02-24T14:58:29.586570+0300 | INFO | [14,  2200] loss: 1.692
2025-02-24T14:58:41.023247+0300 | INFO | [14,  2300] loss: 1.685
2025-02-24T14:58:52.603567+0300 | INFO | [14,  2400] loss: 1.674
2025-02-24T14:59:04.698597+0300 | INFO | [14,  2500] loss: 1.681
2025-02-24T14:59:16.686248+0300 | INFO | [14,  2600] loss: 1.678
2025-02-24T14:59:28.131138+0300 | INFO | [14,  2700] loss: 1.700
2025-02-24T14:59:39.790492+0300 | INFO | [14,  2800] loss: 1.716
2025-02-24T14:59:51.378339+0300 | INFO | [14,  2900] loss: 1.693
2025-02-24T15:00:03.344417+0300 | INFO | [14,  3000] loss: 1.709
2025-02-24T15:00:17.100215+0300 | INFO | [14,  3100] loss: 1.687
2025-02-24T15:00:29.270960+0300 | INFO | [14,  3200] loss: 1.712
2025-02-24T15:00:41.296148+0300 | INFO | [14,  3300] loss: 1.683
2025-02-24T15:00:54.667118+0300 | INFO | [14,  3400] loss: 1.698
2025-02-24T15:01:06.903217+0300 | INFO | [14,  3500] loss: 1.705
2025-02-24T15:01:19.000570+0300 | INFO | [14,  3600] loss: 1.697
2025-02-24T15:01:39.520583+0300 | INFO | [14,  3700] loss: 1.706
2025-02-24T15:01:52.729802+0300 | INFO | [14,  3800] loss: 1.674
2025-02-24T15:02:04.993788+0300 | INFO | [14,  3900] loss: 1.702
2025-02-24T15:02:17.093471+0300 | INFO | [14,  4000] loss: 1.695
2025-02-24T15:02:28.325774+0300 | INFO | [14,  4100] loss: 1.680
2025-02-24T15:02:39.610714+0300 | INFO | [14,  4200] loss: 1.710
2025-02-24T15:02:51.233744+0300 | INFO | [14,  4300] loss: 1.693
2025-02-24T15:03:02.964663+0300 | INFO | [14,  4400] loss: 1.703
2025-02-24T15:03:14.916449+0300 | INFO | [14,  4500] loss: 1.697
2025-02-24T15:03:26.615935+0300 | INFO | [14,  4600] loss: 1.702
2025-02-24T15:03:38.269417+0300 | INFO | [14,  4700] loss: 1.689
2025-02-24T15:03:50.664865+0300 | INFO | [14,  4800] loss: 1.691
2025-02-24T15:04:02.020285+0300 | INFO | [14,  4900] loss: 1.689
2025-02-24T15:04:13.698860+0300 | DEBUG | Saving model to flat file storage. Save #14
2025-02-24T15:04:13.727313+0300 | INFO | Averaging client parameters
2025-02-24T15:04:13.738345+0300 | INFO | Updating parameters on client #0
2025-02-24T15:04:33.624433+0300 | DEBUG | Test set: Accuracy: 7332/10000 (73%)
2025-02-24T15:04:33.627447+0300 | DEBUG | Test set: Loss: 1.7264115810394287
2025-02-24T15:04:33.761083+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.86      0.76      1000
           1       0.89      0.88      0.88      1000
           2       0.62      0.66      0.64      1000
           3       0.54      0.66      0.60      1200
           4       0.69      0.78      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.73      0.88      0.80      1000
           7       0.81      0.77      0.79      1000
           8       0.85      0.88      0.87      1000
           9       0.90      0.82      0.86      1000

    accuracy                           0.73     10000
   macro avg       0.67      0.72      0.69     10000
weighted avg       0.68      0.73      0.71     10000

2025-02-24T15:04:33.762499+0300 | DEBUG | Confusion Matrix:
[[860  11  27  10  10   0   7   7  53  15]
 [ 30 878   5   7   1   0   8   0  28  43]
 [ 93   1 662  39  96   0  77  21   6   5]
 [ 47   2 118 794  68   0 104  47   9  11]
 [ 23   1  54  48 781   0  56  26   7   4]
 [ 19   1 115 486  60   0  44  64  10   1]
 [ 12   0  41  25  26   0 884   2   9   1]
 [ 45   4  41  42  73   0  14 769   3   9]
 [ 72  17   6   3   4   0   4   4 884   6]
 [ 50  70   7   7   5   0   6   4  31 820]]
2025-02-24T15:04:33.765442+0300 | DEBUG | Class precision: [0.68745004 0.89137056 0.61524164 0.54346338 0.69483986        nan
 0.73421927 0.81461864 0.85       0.89617486]
2025-02-24T15:04:33.770417+0300 | DEBUG | Class recall: [0.86       0.878      0.662      0.66166667 0.781      0.
 0.884      0.769      0.884      0.82      ]
2025-02-24T15:04:33.826962+0300 | INFO | Training epoch #15 on client #0
2025-02-24T15:04:33.829817+0300 | DEBUG | Saving model to flat file storage. Save #15
2025-02-24T15:04:33.974459+0300 | INFO | [15,     0] loss: 0.018
2025-02-24T15:04:45.667709+0300 | INFO | [15,   100] loss: 1.656
2025-02-24T15:04:57.453555+0300 | INFO | [15,   200] loss: 1.675
2025-02-24T15:05:10.277606+0300 | INFO | [15,   300] loss: 1.691
2025-02-24T15:05:21.866386+0300 | INFO | [15,   400] loss: 1.670
2025-02-24T15:05:33.402797+0300 | INFO | [15,   500] loss: 1.674
2025-02-24T15:05:45.167471+0300 | INFO | [15,   600] loss: 1.689
2025-02-24T15:05:57.524538+0300 | INFO | [15,   700] loss: 1.697
2025-02-24T15:06:09.603861+0300 | INFO | [15,   800] loss: 1.690
2025-02-24T15:06:21.605284+0300 | INFO | [15,   900] loss: 1.665
2025-02-24T15:06:32.755296+0300 | INFO | [15,  1000] loss: 1.706
2025-02-24T15:06:44.234717+0300 | INFO | [15,  1100] loss: 1.679
2025-02-24T15:06:55.837555+0300 | INFO | [15,  1200] loss: 1.677
2025-02-24T15:07:08.032560+0300 | INFO | [15,  1300] loss: 1.675
2025-02-24T15:07:19.879897+0300 | INFO | [15,  1400] loss: 1.697
2025-02-24T15:07:31.822681+0300 | INFO | [15,  1500] loss: 1.688
2025-02-24T15:07:45.195439+0300 | INFO | [15,  1600] loss: 1.679
2025-02-24T15:07:58.694777+0300 | INFO | [15,  1700] loss: 1.667
2025-02-24T15:08:14.021042+0300 | INFO | [15,  1800] loss: 1.679
2025-02-24T15:08:27.849030+0300 | INFO | [15,  1900] loss: 1.686
2025-02-24T15:08:42.178297+0300 | INFO | [15,  2000] loss: 1.683
2025-02-24T15:08:56.470853+0300 | INFO | [15,  2100] loss: 1.698
2025-02-24T15:09:08.398034+0300 | INFO | [15,  2200] loss: 1.706
2025-02-24T15:09:20.007273+0300 | INFO | [15,  2300] loss: 1.649
2025-02-24T15:09:31.751193+0300 | INFO | [15,  2400] loss: 1.704
2025-02-24T15:09:43.464568+0300 | INFO | [15,  2500] loss: 1.679
2025-02-24T15:09:55.760317+0300 | INFO | [15,  2600] loss: 1.677
2025-02-24T15:10:08.188138+0300 | INFO | [15,  2700] loss: 1.712
2025-02-24T15:10:22.683629+0300 | INFO | [15,  2800] loss: 1.697
2025-02-24T15:10:38.427805+0300 | INFO | [15,  2900] loss: 1.709
2025-02-24T15:10:49.525125+0300 | INFO | [15,  3000] loss: 1.717
2025-02-24T15:11:01.469458+0300 | INFO | [15,  3100] loss: 1.687
2025-02-24T15:11:13.026275+0300 | INFO | [15,  3200] loss: 1.669
2025-02-24T15:11:24.755019+0300 | INFO | [15,  3300] loss: 1.666
2025-02-24T15:11:36.119310+0300 | INFO | [15,  3400] loss: 1.686
2025-02-24T15:11:47.376131+0300 | INFO | [15,  3500] loss: 1.684
2025-02-24T15:11:58.643722+0300 | INFO | [15,  3600] loss: 1.689
2025-02-24T15:12:10.196968+0300 | INFO | [15,  3700] loss: 1.704
2025-02-24T15:12:22.555131+0300 | INFO | [15,  3800] loss: 1.678
2025-02-24T15:12:33.592722+0300 | INFO | [15,  3900] loss: 1.702
2025-02-24T15:12:45.030699+0300 | INFO | [15,  4000] loss: 1.683
2025-02-24T15:12:58.975403+0300 | INFO | [15,  4100] loss: 1.712
2025-02-24T15:13:14.421381+0300 | INFO | [15,  4200] loss: 1.703
2025-02-24T15:13:29.295888+0300 | INFO | [15,  4300] loss: 1.694
2025-02-24T15:13:42.417011+0300 | INFO | [15,  4400] loss: 1.701
2025-02-24T15:13:56.266979+0300 | INFO | [15,  4500] loss: 1.704
2025-02-24T15:14:11.080795+0300 | INFO | [15,  4600] loss: 1.678
2025-02-24T15:14:28.739482+0300 | INFO | [15,  4700] loss: 1.693
2025-02-24T15:14:42.934427+0300 | INFO | [15,  4800] loss: 1.693
2025-02-24T15:14:57.170033+0300 | INFO | [15,  4900] loss: 1.694
2025-02-24T15:15:09.550441+0300 | DEBUG | Saving model to flat file storage. Save #15
2025-02-24T15:15:09.581393+0300 | INFO | Averaging client parameters
2025-02-24T15:15:09.592587+0300 | INFO | Updating parameters on client #0
2025-02-24T15:15:33.003729+0300 | DEBUG | Test set: Accuracy: 7339/10000 (73%)
2025-02-24T15:15:33.008728+0300 | DEBUG | Test set: Loss: 1.7260754108428955
2025-02-24T15:15:33.145163+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.77      0.78      1000
           1       0.87      0.90      0.89      1000
           2       0.63      0.68      0.65      1000
           3       0.53      0.64      0.58      1200
           4       0.69      0.81      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.84      0.82      1000
           7       0.77      0.80      0.78      1000
           8       0.84      0.90      0.86      1000
           9       0.80      0.86      0.83      1000

    accuracy                           0.73     10000
   macro avg       0.67      0.72      0.69     10000
weighted avg       0.68      0.73      0.71     10000

2025-02-24T15:15:33.147619+0300 | DEBUG | Confusion Matrix:
[[774  14  66  14  17   0   5   7  72  31]
 [ 13 904   7   1   0   0   2   1  13  59]
 [ 54   5 681  43  97   0  64  34   8  14]
 [ 27  12 103 769  87   0  78  59  22  43]
 [ 18   3  45  32 813   0  32  38   8  11]
 [  6   6 101 492  53   0  25  85  17  15]
 [ 10   7  38  38  39   0 842   4  10  12]
 [ 23   4  29  40  74   0   8 797   4  21]
 [ 38  20  10   9   4   0   2   5 896  16]
 [ 27  65   9   6   1   0   3   4  22 863]]
2025-02-24T15:15:33.152212+0300 | DEBUG | Class precision: [0.78181818 0.86923077 0.62534435 0.53254848 0.68607595        nan
 0.79359095 0.77079304 0.8358209  0.79539171]
2025-02-24T15:15:33.154214+0300 | DEBUG | Class recall: [0.774      0.904      0.681      0.64083333 0.813      0.
 0.842      0.797      0.896      0.863     ]
2025-02-24T15:15:33.161652+0300 | INFO | Training epoch #16 on client #0
2025-02-24T15:15:33.167094+0300 | DEBUG | Saving model to flat file storage. Save #16
2025-02-24T15:15:33.367173+0300 | INFO | [16,     0] loss: 0.019
2025-02-24T15:15:45.587208+0300 | INFO | [16,   100] loss: 1.670
2025-02-24T15:15:58.744532+0300 | INFO | [16,   200] loss: 1.677
2025-02-24T15:16:09.313339+0300 | INFO | [16,   300] loss: 1.680
2025-02-24T15:16:20.002687+0300 | INFO | [16,   400] loss: 1.680
2025-02-24T15:16:29.199043+0300 | INFO | [16,   500] loss: 1.678
2025-02-24T15:16:40.041887+0300 | INFO | [16,   600] loss: 1.667
2025-02-24T15:16:49.938329+0300 | INFO | [16,   700] loss: 1.641
2025-02-24T15:16:59.259425+0300 | INFO | [16,   800] loss: 1.687
2025-02-24T15:17:11.307608+0300 | INFO | [16,   900] loss: 1.677
2025-02-24T15:17:22.676806+0300 | INFO | [16,  1000] loss: 1.687
2025-02-24T15:17:35.183609+0300 | INFO | [16,  1100] loss: 1.680
2025-02-24T15:17:47.021295+0300 | INFO | [16,  1200] loss: 1.679
2025-02-24T15:17:59.286437+0300 | INFO | [16,  1300] loss: 1.687
2025-02-24T15:18:11.235599+0300 | INFO | [16,  1400] loss: 1.663
2025-02-24T15:18:24.016228+0300 | INFO | [16,  1500] loss: 1.687
2025-02-24T15:18:35.016431+0300 | INFO | [16,  1600] loss: 1.658
2025-02-24T15:18:46.631281+0300 | INFO | [16,  1700] loss: 1.687
2025-02-24T15:18:58.312393+0300 | INFO | [16,  1800] loss: 1.663
2025-02-24T15:19:08.999896+0300 | INFO | [16,  1900] loss: 1.663
2025-02-24T15:19:27.251952+0300 | INFO | [16,  2000] loss: 1.686
2025-02-24T15:19:39.624090+0300 | INFO | [16,  2100] loss: 1.698
2025-02-24T15:19:49.394607+0300 | INFO | [16,  2200] loss: 1.682
2025-02-24T15:19:59.607957+0300 | INFO | [16,  2300] loss: 1.679
2025-02-24T15:20:11.738897+0300 | INFO | [16,  2400] loss: 1.711
2025-02-24T15:20:25.211927+0300 | INFO | [16,  2500] loss: 1.674
2025-02-24T15:20:38.975659+0300 | INFO | [16,  2600] loss: 1.675
2025-02-24T15:20:51.631686+0300 | INFO | [16,  2700] loss: 1.690
2025-02-24T15:21:01.256064+0300 | INFO | [16,  2800] loss: 1.679
2025-02-24T15:21:10.318670+0300 | INFO | [16,  2900] loss: 1.689
2025-02-24T15:21:19.601406+0300 | INFO | [16,  3000] loss: 1.693
2025-02-24T15:21:28.475277+0300 | INFO | [16,  3100] loss: 1.668
2025-02-24T15:21:40.841623+0300 | INFO | [16,  3200] loss: 1.683
2025-02-24T15:21:51.303716+0300 | INFO | [16,  3300] loss: 1.694
2025-02-24T15:22:03.049908+0300 | INFO | [16,  3400] loss: 1.686
2025-02-24T15:22:14.687190+0300 | INFO | [16,  3500] loss: 1.683
2025-02-24T15:22:26.079775+0300 | INFO | [16,  3600] loss: 1.704
2025-02-24T15:22:37.143866+0300 | INFO | [16,  3700] loss: 1.699
2025-02-24T15:22:51.140613+0300 | INFO | [16,  3800] loss: 1.670
2025-02-24T15:23:03.482586+0300 | INFO | [16,  3900] loss: 1.678
2025-02-24T15:23:13.756712+0300 | INFO | [16,  4000] loss: 1.674
2025-02-24T15:23:24.313535+0300 | INFO | [16,  4100] loss: 1.664
2025-02-24T15:23:34.723163+0300 | INFO | [16,  4200] loss: 1.678
2025-02-24T15:23:44.753027+0300 | INFO | [16,  4300] loss: 1.684
2025-02-24T15:23:55.092974+0300 | INFO | [16,  4400] loss: 1.681
2025-02-24T15:24:08.144379+0300 | INFO | [16,  4500] loss: 1.675
2025-02-24T15:24:20.446472+0300 | INFO | [16,  4600] loss: 1.691
2025-02-24T15:24:30.538977+0300 | INFO | [16,  4700] loss: 1.685
2025-02-24T15:24:43.444075+0300 | INFO | [16,  4800] loss: 1.706
2025-02-24T15:24:55.184094+0300 | INFO | [16,  4900] loss: 1.681
2025-02-24T15:25:07.577934+0300 | DEBUG | Saving model to flat file storage. Save #16
2025-02-24T15:25:07.598368+0300 | INFO | Averaging client parameters
2025-02-24T15:25:07.624066+0300 | INFO | Updating parameters on client #0
2025-02-24T15:25:25.696965+0300 | DEBUG | Test set: Accuracy: 7421/10000 (74%)
2025-02-24T15:25:25.699340+0300 | DEBUG | Test set: Loss: 1.7184158563613892
2025-02-24T15:25:25.799274+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.82      0.79      1000
           1       0.85      0.91      0.88      1000
           2       0.69      0.64      0.66      1000
           3       0.53      0.72      0.61      1200
           4       0.76      0.75      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.73      0.90      0.81      1000
           7       0.75      0.83      0.79      1000
           8       0.84      0.89      0.87      1000
           9       0.90      0.82      0.86      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-24T15:25:25.801844+0300 | DEBUG | Confusion Matrix:
[[822  15  36  24  13   0   9   8  60  13]
 [ 12 912   3   1   1   0  12   0  26  33]
 [ 75   9 640  73  72   0  87  33   6   5]
 [ 25  13  75 865  44   0  89  67  13   9]
 [ 16   5  44  64 749   0  70  40  11   1]
 [ 13   5  63 522  36   0  37 112  11   1]
 [  7   2  26  37   8   0 901   8   9   2]
 [ 25   3  29  41  49   0  14 827   2  10]
 [ 50  16   9  11   5   0   3   5 887  14]
 [ 31  96   7   6   3   0   8   6  25 818]]
2025-02-24T15:25:25.805837+0300 | DEBUG | Class precision: [0.76394052 0.84758364 0.68669528 0.52615572 0.76428571        nan
 0.73252033 0.7477396  0.8447619  0.90286976]
2025-02-24T15:25:25.809213+0300 | DEBUG | Class recall: [0.822      0.912      0.64       0.72083333 0.749      0.
 0.901      0.827      0.887      0.818     ]
2025-02-24T15:25:25.871766+0300 | INFO | Training epoch #17 on client #0
2025-02-24T15:25:25.874806+0300 | DEBUG | Saving model to flat file storage. Save #17
2025-02-24T15:25:26.032795+0300 | INFO | [17,     0] loss: 0.017
2025-02-24T15:25:36.976800+0300 | INFO | [17,   100] loss: 1.658
2025-02-24T15:25:48.457474+0300 | INFO | [17,   200] loss: 1.689
2025-02-24T15:26:00.632982+0300 | INFO | [17,   300] loss: 1.674
2025-02-24T15:26:12.984770+0300 | INFO | [17,   400] loss: 1.684
2025-02-24T15:26:26.153318+0300 | INFO | [17,   500] loss: 1.663
2025-02-24T15:26:38.689621+0300 | INFO | [17,   600] loss: 1.662
2025-02-24T15:26:51.168099+0300 | INFO | [17,   700] loss: 1.701
2025-02-24T15:27:03.368632+0300 | INFO | [17,   800] loss: 1.670
2025-02-24T15:27:14.280024+0300 | INFO | [17,   900] loss: 1.668
2025-02-24T15:27:25.923012+0300 | INFO | [17,  1000] loss: 1.672
2025-02-24T15:27:37.272280+0300 | INFO | [17,  1100] loss: 1.693
2025-02-24T15:27:53.965773+0300 | INFO | [17,  1200] loss: 1.659
2025-02-24T15:28:08.776646+0300 | INFO | [17,  1300] loss: 1.663
2025-02-24T15:28:21.068577+0300 | INFO | [17,  1400] loss: 1.668
2025-02-24T15:28:31.774836+0300 | INFO | [17,  1500] loss: 1.670
2025-02-24T15:28:43.193349+0300 | INFO | [17,  1600] loss: 1.659
2025-02-24T15:28:54.207761+0300 | INFO | [17,  1700] loss: 1.669
2025-02-24T15:29:05.125900+0300 | INFO | [17,  1800] loss: 1.685
2025-02-24T15:29:19.309649+0300 | INFO | [17,  1900] loss: 1.681
2025-02-24T15:29:31.090717+0300 | INFO | [17,  2000] loss: 1.661
2025-02-24T15:29:43.218070+0300 | INFO | [17,  2100] loss: 1.649
2025-02-24T15:29:54.147783+0300 | INFO | [17,  2200] loss: 1.689
2025-02-24T15:30:05.425950+0300 | INFO | [17,  2300] loss: 1.685
2025-02-24T15:30:17.036890+0300 | INFO | [17,  2400] loss: 1.685
2025-02-24T15:30:28.573433+0300 | INFO | [17,  2500] loss: 1.693
2025-02-24T15:30:40.643799+0300 | INFO | [17,  2600] loss: 1.664
2025-02-24T15:30:52.990980+0300 | INFO | [17,  2700] loss: 1.688
2025-02-24T15:31:07.128130+0300 | INFO | [17,  2800] loss: 1.648
2025-02-24T15:31:19.173365+0300 | INFO | [17,  2900] loss: 1.687
2025-02-24T15:31:30.791874+0300 | INFO | [17,  3000] loss: 1.691
2025-02-24T15:31:43.738303+0300 | INFO | [17,  3100] loss: 1.683
2025-02-24T15:31:59.832568+0300 | INFO | [17,  3200] loss: 1.684
2025-02-24T15:32:11.244397+0300 | INFO | [17,  3300] loss: 1.675
2025-02-24T15:32:22.941816+0300 | INFO | [17,  3400] loss: 1.697
2025-02-24T15:32:34.654330+0300 | INFO | [17,  3500] loss: 1.688
2025-02-24T15:32:47.299693+0300 | INFO | [17,  3600] loss: 1.672
2025-02-24T15:33:00.380517+0300 | INFO | [17,  3700] loss: 1.672
2025-02-24T15:33:11.832121+0300 | INFO | [17,  3800] loss: 1.704
2025-02-24T15:33:24.848651+0300 | INFO | [17,  3900] loss: 1.682
2025-02-24T15:33:37.481333+0300 | INFO | [17,  4000] loss: 1.678
2025-02-24T15:33:49.786897+0300 | INFO | [17,  4100] loss: 1.692
2025-02-24T15:34:03.014612+0300 | INFO | [17,  4200] loss: 1.688
2025-02-24T15:34:14.810946+0300 | INFO | [17,  4300] loss: 1.678
2025-02-24T15:34:25.904843+0300 | INFO | [17,  4400] loss: 1.661
2025-02-24T15:34:38.298890+0300 | INFO | [17,  4500] loss: 1.665
2025-02-24T15:34:50.092441+0300 | INFO | [17,  4600] loss: 1.681
2025-02-24T15:35:03.609591+0300 | INFO | [17,  4700] loss: 1.692
2025-02-24T15:35:17.190100+0300 | INFO | [17,  4800] loss: 1.675
2025-02-24T15:35:28.499284+0300 | INFO | [17,  4900] loss: 1.700
2025-02-24T15:35:41.428922+0300 | DEBUG | Saving model to flat file storage. Save #17
2025-02-24T15:35:41.455043+0300 | INFO | Averaging client parameters
2025-02-24T15:35:41.469419+0300 | INFO | Updating parameters on client #0
2025-02-24T15:36:02.984389+0300 | DEBUG | Test set: Accuracy: 7326/10000 (73%)
2025-02-24T15:36:02.985859+0300 | DEBUG | Test set: Loss: 1.7275283336639404
2025-02-24T15:36:03.098530+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.88      0.75      1000
           1       0.90      0.88      0.89      1000
           2       0.65      0.66      0.65      1000
           3       0.53      0.67      0.59      1200
           4       0.75      0.74      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.88      0.81      1000
           7       0.74      0.84      0.79      1000
           8       0.87      0.85      0.86      1000
           9       0.92      0.81      0.86      1000

    accuracy                           0.73     10000
   macro avg       0.68      0.72      0.69     10000
weighted avg       0.69      0.73      0.71     10000

2025-02-24T15:36:03.101040+0300 | DEBUG | Confusion Matrix:
[[878  11  29  10   8   0  12   7  36   9]
 [ 37 875   4   7   1   0  10   4  26  36]
 [ 92   1 657  61  74   0  70  36   6   3]
 [ 41   2  94 800  56   0  97  84  17   9]
 [ 34   3  57  57 736   0  63  45   4   1]
 [ 21   1  81 507  51   0  30  97  10   2]
 [ 12   0  43  34  16   0 884   5   6   0]
 [ 47   2  33  33  37   0   8 836   2   2]
 [100  13   7   5   1   0   6   5 854   9]
 [ 75  66   8   6   4   0   2   9  24 806]]
2025-02-24T15:36:03.102206+0300 | DEBUG | Class precision: [0.65669409 0.89835729 0.64856861 0.52631579 0.74796748        nan
 0.74788494 0.74113475 0.86700508 0.91904219]
2025-02-24T15:36:03.103219+0300 | DEBUG | Class recall: [0.878      0.875      0.657      0.66666667 0.736      0.
 0.884      0.836      0.854      0.806     ]
2025-02-24T15:36:03.172303+0300 | INFO | Training epoch #18 on client #0
2025-02-24T15:36:03.172303+0300 | DEBUG | Saving model to flat file storage. Save #18
2025-02-24T15:36:03.442629+0300 | INFO | [18,     0] loss: 0.016
2025-02-24T15:36:15.972651+0300 | INFO | [18,   100] loss: 1.664
2025-02-24T15:36:28.057848+0300 | INFO | [18,   200] loss: 1.660
2025-02-24T15:36:42.124445+0300 | INFO | [18,   300] loss: 1.660
2025-02-24T15:36:56.194739+0300 | INFO | [18,   400] loss: 1.671
2025-02-24T15:37:11.385061+0300 | INFO | [18,   500] loss: 1.667
2025-02-24T15:37:22.450605+0300 | INFO | [18,   600] loss: 1.680
2025-02-24T15:37:32.793933+0300 | INFO | [18,   700] loss: 1.670
2025-02-24T15:37:43.752387+0300 | INFO | [18,   800] loss: 1.660
2025-02-24T15:37:55.067006+0300 | INFO | [18,   900] loss: 1.664
2025-02-24T15:38:05.919075+0300 | INFO | [18,  1000] loss: 1.661
2025-02-24T15:38:16.622468+0300 | INFO | [18,  1100] loss: 1.666
2025-02-24T15:38:27.340221+0300 | INFO | [18,  1200] loss: 1.670
2025-02-24T15:38:37.743826+0300 | INFO | [18,  1300] loss: 1.657
2025-02-24T15:38:48.156719+0300 | INFO | [18,  1400] loss: 1.650
2025-02-24T15:38:58.191304+0300 | INFO | [18,  1500] loss: 1.676
2025-02-24T15:39:06.795498+0300 | INFO | [18,  1600] loss: 1.667
2025-02-24T15:39:15.820677+0300 | INFO | [18,  1700] loss: 1.663
2025-02-24T15:39:29.374412+0300 | INFO | [18,  1800] loss: 1.686
2025-02-24T15:39:42.671893+0300 | INFO | [18,  1900] loss: 1.671
2025-02-24T15:39:56.210120+0300 | INFO | [18,  2000] loss: 1.664
2025-02-24T15:40:09.654437+0300 | INFO | [18,  2100] loss: 1.668
2025-02-24T15:40:21.517356+0300 | INFO | [18,  2200] loss: 1.670
2025-02-24T15:40:35.767966+0300 | INFO | [18,  2300] loss: 1.679
2025-02-24T15:40:47.316939+0300 | INFO | [18,  2400] loss: 1.700
2025-02-24T15:40:59.055592+0300 | INFO | [18,  2500] loss: 1.677
2025-02-24T15:41:11.082838+0300 | INFO | [18,  2600] loss: 1.668
2025-02-24T15:41:22.076724+0300 | INFO | [18,  2700] loss: 1.679
2025-02-24T15:41:33.442574+0300 | INFO | [18,  2800] loss: 1.694
2025-02-24T15:41:44.582383+0300 | INFO | [18,  2900] loss: 1.699
2025-02-24T15:41:57.211600+0300 | INFO | [18,  3000] loss: 1.658
2025-02-24T15:42:09.114716+0300 | INFO | [18,  3100] loss: 1.679
2025-02-24T15:42:21.932713+0300 | INFO | [18,  3200] loss: 1.668
2025-02-24T15:42:35.585786+0300 | INFO | [18,  3300] loss: 1.675
2025-02-24T15:42:47.755846+0300 | INFO | [18,  3400] loss: 1.678
2025-02-24T15:43:01.817631+0300 | INFO | [18,  3500] loss: 1.660
2025-02-24T15:43:14.106045+0300 | INFO | [18,  3600] loss: 1.694
2025-02-24T15:43:24.876891+0300 | INFO | [18,  3700] loss: 1.718
2025-02-24T15:43:34.231423+0300 | INFO | [18,  3800] loss: 1.676
2025-02-24T15:43:43.738160+0300 | INFO | [18,  3900] loss: 1.674
2025-02-24T15:43:54.068091+0300 | INFO | [18,  4000] loss: 1.661
2025-02-24T15:44:03.802943+0300 | INFO | [18,  4100] loss: 1.691
2025-02-24T15:44:14.346550+0300 | INFO | [18,  4200] loss: 1.690
2025-02-24T15:44:24.018589+0300 | INFO | [18,  4300] loss: 1.647
2025-02-24T15:44:33.749008+0300 | INFO | [18,  4400] loss: 1.662
2025-02-24T15:44:44.577929+0300 | INFO | [18,  4500] loss: 1.664
2025-02-24T15:44:54.486617+0300 | INFO | [18,  4600] loss: 1.691
2025-02-24T15:45:04.351284+0300 | INFO | [18,  4700] loss: 1.694
2025-02-24T15:45:20.487584+0300 | INFO | [18,  4800] loss: 1.689
2025-02-24T15:45:30.341259+0300 | INFO | [18,  4900] loss: 1.669
2025-02-24T15:45:40.231191+0300 | DEBUG | Saving model to flat file storage. Save #18
2025-02-24T15:45:40.248121+0300 | INFO | Averaging client parameters
2025-02-24T15:45:40.256412+0300 | INFO | Updating parameters on client #0
2025-02-24T15:45:56.657393+0300 | DEBUG | Test set: Accuracy: 7398/10000 (74%)
2025-02-24T15:45:56.660413+0300 | DEBUG | Test set: Loss: 1.7208937406539917
2025-02-24T15:45:56.773585+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.85      0.78      1000
           1       0.89      0.87      0.88      1000
           2       0.66      0.68      0.67      1000
           3       0.50      0.74      0.60      1200
           4       0.80      0.71      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.83      0.82      1000
           7       0.79      0.82      0.81      1000
           8       0.88      0.86      0.87      1000
           9       0.80      0.89      0.84      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-24T15:45:56.777460+0300 | DEBUG | Confusion Matrix:
[[851  11  33  15  11   0   4  12  33  30]
 [ 11 871   2   4   0   0   1   1  18  92]
 [ 95   7 681  70  43   0  52  30   6  16]
 [ 36   7  84 885  44   0  59  49  13  23]
 [ 19   3  74  76 714   0  49  48  11   6]
 [ 15   2  70 580  26   0  23  67   9   8]
 [ 23   3  57  53  11   0 832   8  11   2]
 [ 30   5  12  52  41   0  13 822   4  21]
 [ 58  26   9  13   4   0   2   3 857  28]
 [ 37  39   7  13   3   0   2   2  12 885]]
2025-02-24T15:45:56.780601+0300 | DEBUG | Class precision: [0.72425532 0.89425051 0.66180758 0.50255537 0.79598662        nan
 0.80231437 0.78886756 0.8798768  0.79657966]
2025-02-24T15:45:56.784602+0300 | DEBUG | Class recall: [0.851  0.871  0.681  0.7375 0.714  0.     0.832  0.822  0.857  0.885 ]
2025-02-24T15:45:56.788593+0300 | INFO | Training epoch #19 on client #0
2025-02-24T15:45:56.791784+0300 | DEBUG | Saving model to flat file storage. Save #19
2025-02-24T15:45:56.975875+0300 | INFO | [19,     0] loss: 0.016
2025-02-24T15:46:06.854956+0300 | INFO | [19,   100] loss: 1.662
2025-02-24T15:46:17.244801+0300 | INFO | [19,   200] loss: 1.672
2025-02-24T15:46:26.735973+0300 | INFO | [19,   300] loss: 1.657
2025-02-24T15:46:36.887126+0300 | INFO | [19,   400] loss: 1.685
2025-02-24T15:46:46.714526+0300 | INFO | [19,   500] loss: 1.678
2025-02-24T15:46:58.307353+0300 | INFO | [19,   600] loss: 1.637
2025-02-24T15:47:09.019725+0300 | INFO | [19,   700] loss: 1.687
2025-02-24T15:47:20.143846+0300 | INFO | [19,   800] loss: 1.668
2025-02-24T15:47:33.572104+0300 | INFO | [19,   900] loss: 1.673
2025-02-24T15:47:44.661923+0300 | INFO | [19,  1000] loss: 1.669
2025-02-24T15:47:56.736171+0300 | INFO | [19,  1100] loss: 1.700
2025-02-24T15:48:08.976019+0300 | INFO | [19,  1200] loss: 1.650
2025-02-24T15:48:18.693296+0300 | INFO | [19,  1300] loss: 1.674
2025-02-24T15:48:29.353125+0300 | INFO | [19,  1400] loss: 1.681
2025-02-24T15:48:39.006388+0300 | INFO | [19,  1500] loss: 1.659
2025-02-24T15:48:49.167400+0300 | INFO | [19,  1600] loss: 1.665
2025-02-24T15:48:59.166836+0300 | INFO | [19,  1700] loss: 1.683
2025-02-24T15:49:09.094848+0300 | INFO | [19,  1800] loss: 1.644
2025-02-24T15:49:18.678927+0300 | INFO | [19,  1900] loss: 1.673
2025-02-24T15:49:29.111284+0300 | INFO | [19,  2000] loss: 1.661
2025-02-24T15:49:38.672959+0300 | INFO | [19,  2100] loss: 1.648
2025-02-24T15:49:48.214318+0300 | INFO | [19,  2200] loss: 1.673
2025-02-24T15:49:58.146018+0300 | INFO | [19,  2300] loss: 1.677
2025-02-24T15:50:09.465621+0300 | INFO | [19,  2400] loss: 1.654
2025-02-24T15:50:19.672155+0300 | INFO | [19,  2500] loss: 1.664
2025-02-24T15:50:29.473795+0300 | INFO | [19,  2600] loss: 1.667
2025-02-24T15:50:39.044099+0300 | INFO | [19,  2700] loss: 1.656
2025-02-24T15:50:49.695801+0300 | INFO | [19,  2800] loss: 1.656
2025-02-24T15:50:59.285588+0300 | INFO | [19,  2900] loss: 1.658
2025-02-24T15:51:09.862634+0300 | INFO | [19,  3000] loss: 1.665
2025-02-24T15:51:20.967974+0300 | INFO | [19,  3100] loss: 1.673
2025-02-24T15:51:31.897359+0300 | INFO | [19,  3200] loss: 1.681
2025-02-24T15:51:45.301357+0300 | INFO | [19,  3300] loss: 1.672
2025-02-24T15:51:59.897740+0300 | INFO | [19,  3400] loss: 1.665
2025-02-24T15:52:13.434593+0300 | INFO | [19,  3500] loss: 1.662
2025-02-24T15:52:25.263543+0300 | INFO | [19,  3600] loss: 1.660
2025-02-24T15:52:34.876290+0300 | INFO | [19,  3700] loss: 1.691
2025-02-24T15:52:45.365764+0300 | INFO | [19,  3800] loss: 1.662
2025-02-24T15:52:57.452322+0300 | INFO | [19,  3900] loss: 1.656
2025-02-24T15:53:12.776273+0300 | INFO | [19,  4000] loss: 1.653
2025-02-24T15:53:32.497200+0300 | INFO | [19,  4100] loss: 1.645
2025-02-24T15:53:44.578443+0300 | INFO | [19,  4200] loss: 1.685
2025-02-24T15:53:54.710213+0300 | INFO | [19,  4300] loss: 1.670
2025-02-24T15:54:06.514119+0300 | INFO | [19,  4400] loss: 1.665
2025-02-24T15:54:20.381739+0300 | INFO | [19,  4500] loss: 1.666
2025-02-24T15:54:35.524846+0300 | INFO | [19,  4600] loss: 1.703
2025-02-24T15:54:50.494321+0300 | INFO | [19,  4700] loss: 1.664
2025-02-24T15:55:05.695920+0300 | INFO | [19,  4800] loss: 1.675
2025-02-24T15:55:17.225703+0300 | INFO | [19,  4900] loss: 1.666
2025-02-24T15:55:27.464833+0300 | DEBUG | Saving model to flat file storage. Save #19
2025-02-24T15:55:27.490176+0300 | INFO | Averaging client parameters
2025-02-24T15:55:27.497093+0300 | INFO | Updating parameters on client #0
2025-02-24T15:55:45.218025+0300 | DEBUG | Test set: Accuracy: 7400/10000 (74%)
2025-02-24T15:55:45.219043+0300 | DEBUG | Test set: Loss: 1.7207220792770386
2025-02-24T15:55:45.344558+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.84      0.78      1000
           1       0.84      0.91      0.87      1000
           2       0.72      0.64      0.68      1000
           3       0.50      0.74      0.60      1200
           4       0.76      0.75      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.86      0.81      1000
           7       0.83      0.80      0.81      1000
           8       0.83      0.88      0.86      1000
           9       0.86      0.84      0.85      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-24T15:55:45.347547+0300 | DEBUG | Confusion Matrix:
[[836  23  20  21  12   0   7   5  46  30]
 [ 11 913   3   6   1   0   8   1  28  29]
 [ 97   7 638  76  73   0  59  26   9  15]
 [ 27  11  65 891  39   0  85  40  24  18]
 [ 27   2  48  76 746   0  55  30  10   6]
 [ 15   7  48 579  42   0  37  53  15   4]
 [ 16   3  43  41  20   0 858   4  12   3]
 [ 32   5  13  64  48   0  12 798   9  19]
 [ 60  20   4   9   4   0   3   2 884  14]
 [ 23  97   2  11   1   0   5   2  23 836]]
2025-02-24T15:55:45.351202+0300 | DEBUG | Class precision: [0.73076923 0.83915441 0.72171946 0.50225479 0.75659229        nan
 0.75996457 0.83038502 0.83396226 0.85831622]
2025-02-24T15:55:45.353233+0300 | DEBUG | Class recall: [0.836  0.913  0.638  0.7425 0.746  0.     0.858  0.798  0.884  0.836 ]
2025-02-24T15:55:45.355421+0300 | INFO | Training epoch #20 on client #0
2025-02-24T15:55:45.356861+0300 | DEBUG | Saving model to flat file storage. Save #20
2025-02-24T15:55:45.602923+0300 | INFO | [20,     0] loss: 0.017
2025-02-24T15:55:59.954478+0300 | INFO | [20,   100] loss: 1.632
2025-02-24T15:56:14.905702+0300 | INFO | [20,   200] loss: 1.648
2025-02-24T15:56:30.055909+0300 | INFO | [20,   300] loss: 1.649
2025-02-24T15:56:41.977342+0300 | INFO | [20,   400] loss: 1.661
2025-02-24T15:56:57.093683+0300 | INFO | [20,   500] loss: 1.660
2025-02-24T15:57:11.139188+0300 | INFO | [20,   600] loss: 1.655
2025-02-24T15:57:24.442732+0300 | INFO | [20,   700] loss: 1.655
2025-02-24T15:57:37.978119+0300 | INFO | [20,   800] loss: 1.652
2025-02-24T15:57:51.849935+0300 | INFO | [20,   900] loss: 1.675
2025-02-24T15:58:04.977855+0300 | INFO | [20,  1000] loss: 1.643
2025-02-24T15:58:16.296552+0300 | INFO | [20,  1100] loss: 1.642
2025-02-24T15:58:26.184644+0300 | INFO | [20,  1200] loss: 1.665
2025-02-24T15:58:38.512425+0300 | INFO | [20,  1300] loss: 1.657
2025-02-24T15:58:51.240136+0300 | INFO | [20,  1400] loss: 1.654
2025-02-24T15:59:05.048371+0300 | INFO | [20,  1500] loss: 1.670
2025-02-24T15:59:16.969092+0300 | INFO | [20,  1600] loss: 1.637
2025-02-24T15:59:27.461518+0300 | INFO | [20,  1700] loss: 1.683
2025-02-24T15:59:38.850124+0300 | INFO | [20,  1800] loss: 1.639
2025-02-24T15:59:50.122481+0300 | INFO | [20,  1900] loss: 1.668
2025-02-24T16:00:03.881334+0300 | INFO | [20,  2000] loss: 1.675
2025-02-24T16:00:18.709488+0300 | INFO | [20,  2100] loss: 1.664
2025-02-24T16:00:29.830157+0300 | INFO | [20,  2200] loss: 1.665
2025-02-24T16:00:40.466353+0300 | INFO | [20,  2300] loss: 1.658
2025-02-24T16:00:50.905358+0300 | INFO | [20,  2400] loss: 1.658
2025-02-24T16:01:02.287558+0300 | INFO | [20,  2500] loss: 1.651
2025-02-24T16:01:14.942826+0300 | INFO | [20,  2600] loss: 1.662
2025-02-24T16:01:28.959449+0300 | INFO | [20,  2700] loss: 1.682
2025-02-24T16:01:42.230269+0300 | INFO | [20,  2800] loss: 1.656
2025-02-24T16:01:54.926838+0300 | INFO | [20,  2900] loss: 1.682
2025-02-24T16:02:07.396066+0300 | INFO | [20,  3000] loss: 1.675
2025-02-24T16:02:20.978263+0300 | INFO | [20,  3100] loss: 1.668
2025-02-24T16:02:34.717774+0300 | INFO | [20,  3200] loss: 1.650
2025-02-24T16:02:50.873585+0300 | INFO | [20,  3300] loss: 1.658
2025-02-24T16:03:09.597058+0300 | INFO | [20,  3400] loss: 1.661
2025-02-24T16:03:22.883801+0300 | INFO | [20,  3500] loss: 1.686
2025-02-24T16:03:36.492848+0300 | INFO | [20,  3600] loss: 1.682
2025-02-24T16:03:50.350418+0300 | INFO | [20,  3700] loss: 1.647
2025-02-24T16:04:00.599734+0300 | INFO | [20,  3800] loss: 1.678
2025-02-24T16:04:13.052777+0300 | INFO | [20,  3900] loss: 1.654
2025-02-24T16:04:26.018211+0300 | INFO | [20,  4000] loss: 1.666
2025-02-24T16:04:38.732102+0300 | INFO | [20,  4100] loss: 1.659
2025-02-24T16:04:50.706300+0300 | INFO | [20,  4200] loss: 1.668
2025-02-24T16:05:03.522761+0300 | INFO | [20,  4300] loss: 1.673
2025-02-24T16:05:16.972479+0300 | INFO | [20,  4400] loss: 1.696
2025-02-24T16:05:27.318203+0300 | INFO | [20,  4500] loss: 1.689
2025-02-24T16:05:36.923977+0300 | INFO | [20,  4600] loss: 1.675
2025-02-24T16:05:49.864764+0300 | INFO | [20,  4700] loss: 1.667
2025-02-24T16:06:03.855345+0300 | INFO | [20,  4800] loss: 1.668
2025-02-24T16:06:15.959132+0300 | INFO | [20,  4900] loss: 1.659
2025-02-24T16:06:25.260838+0300 | DEBUG | Saving model to flat file storage. Save #20
2025-02-24T16:06:25.283918+0300 | INFO | Averaging client parameters
2025-02-24T16:06:25.291669+0300 | INFO | Updating parameters on client #0
2025-02-24T16:06:41.361494+0300 | DEBUG | Test set: Accuracy: 7367/10000 (74%)
2025-02-24T16:06:41.363502+0300 | DEBUG | Test set: Loss: 1.7226024866104126
2025-02-24T16:06:41.466064+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.85      0.77      1000
           1       0.89      0.89      0.89      1000
           2       0.60      0.72      0.65      1000
           3       0.54      0.66      0.59      1200
           4       0.72      0.77      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.87      0.81      1000
           7       0.83      0.78      0.80      1000
           8       0.90      0.83      0.86      1000
           9       0.84      0.86      0.85      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.72      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-24T16:06:41.467556+0300 | DEBUG | Confusion Matrix:
[[855  10  42  10  16   0   6   3  31  27]
 [ 14 894   4   2   2   0   8   1  13  62]
 [ 82   7 720  30  69   0  61  18   3  10]
 [ 36  16 127 794  71   0  81  47   6  22]
 [ 26   4  82  34 770   0  51  29   3   1]
 [ 19   4 126 501  52   0  38  52   6   2]
 [ 19   1  55  33  13   0 867   3   5   4]
 [ 37   4  32  53  68   0  14 777   3  12]
 [ 94  17  11  14   9   0   1   3 828  23]
 [ 40  52   5   9   3   0   6   6  17 862]]
2025-02-24T16:06:41.468568+0300 | DEBUG | Class precision: [0.69967267 0.88602577 0.59800664 0.53648649 0.71761417        nan
 0.76522507 0.82747604 0.90491803 0.84097561]
2025-02-24T16:06:41.470961+0300 | DEBUG | Class recall: [0.855      0.894      0.72       0.66166667 0.77       0.
 0.867      0.777      0.828      0.862     ]
2025-02-24T16:06:41.556902+0300 | INFO | Training epoch #21 on client #0
2025-02-24T16:06:41.560101+0300 | DEBUG | Saving model to flat file storage. Save #21
2025-02-24T16:06:41.871179+0300 | INFO | [21,     0] loss: 0.016
2025-02-24T16:06:55.157210+0300 | INFO | [21,   100] loss: 1.663
2025-02-24T16:07:07.537639+0300 | INFO | [21,   200] loss: 1.659
2025-02-24T16:07:17.943415+0300 | INFO | [21,   300] loss: 1.655
2025-02-24T16:07:30.162602+0300 | INFO | [21,   400] loss: 1.653
2025-02-24T16:07:44.093132+0300 | INFO | [21,   500] loss: 1.655
2025-02-24T16:07:56.220245+0300 | INFO | [21,   600] loss: 1.652
2025-02-24T16:08:09.168567+0300 | INFO | [21,   700] loss: 1.674
2025-02-24T16:08:18.840171+0300 | INFO | [21,   800] loss: 1.664
2025-02-24T16:08:29.491090+0300 | INFO | [21,   900] loss: 1.680
2025-02-24T16:08:39.708963+0300 | INFO | [21,  1000] loss: 1.657
2025-02-24T16:08:49.499662+0300 | INFO | [21,  1100] loss: 1.639
2025-02-24T16:08:59.730454+0300 | INFO | [21,  1200] loss: 1.652
2025-02-24T16:09:10.497634+0300 | INFO | [21,  1300] loss: 1.664
2025-02-24T16:09:20.559172+0300 | INFO | [21,  1400] loss: 1.647
2025-02-24T16:09:31.161923+0300 | INFO | [21,  1500] loss: 1.633
2025-02-24T16:09:41.519903+0300 | INFO | [21,  1600] loss: 1.653
2025-02-24T16:09:51.380879+0300 | INFO | [21,  1700] loss: 1.663
2025-02-24T16:10:01.830078+0300 | INFO | [21,  1800] loss: 1.667
2025-02-24T16:10:11.607553+0300 | INFO | [21,  1900] loss: 1.646
2025-02-24T16:10:21.824738+0300 | INFO | [21,  2000] loss: 1.647
2025-02-24T16:10:33.195040+0300 | INFO | [21,  2100] loss: 1.666
2025-02-24T16:10:43.413327+0300 | INFO | [21,  2200] loss: 1.663
2025-02-24T16:10:53.475310+0300 | INFO | [21,  2300] loss: 1.636
2025-02-24T16:11:03.609217+0300 | INFO | [21,  2400] loss: 1.662
2025-02-24T16:11:14.483316+0300 | INFO | [21,  2500] loss: 1.671
2025-02-24T16:11:26.368064+0300 | INFO | [21,  2600] loss: 1.654
2025-02-24T16:11:39.171916+0300 | INFO | [21,  2700] loss: 1.665
2025-02-24T16:11:49.282549+0300 | INFO | [21,  2800] loss: 1.653
2025-02-24T16:11:59.417962+0300 | INFO | [21,  2900] loss: 1.657
2025-02-24T16:12:09.725506+0300 | INFO | [21,  3000] loss: 1.646
2025-02-24T16:12:20.289322+0300 | INFO | [21,  3100] loss: 1.645
2025-02-24T16:12:30.071640+0300 | INFO | [21,  3200] loss: 1.652
2025-02-24T16:12:40.443390+0300 | INFO | [21,  3300] loss: 1.644
2025-02-24T16:12:50.813070+0300 | INFO | [21,  3400] loss: 1.661
2025-02-24T16:13:00.202693+0300 | INFO | [21,  3500] loss: 1.679
2025-02-24T16:13:12.445224+0300 | INFO | [21,  3600] loss: 1.661
2025-02-24T16:13:26.375242+0300 | INFO | [21,  3700] loss: 1.648
2025-02-24T16:13:39.661211+0300 | INFO | [21,  3800] loss: 1.674
2025-02-24T16:13:52.033149+0300 | INFO | [21,  3900] loss: 1.655
2025-02-24T16:14:02.564910+0300 | INFO | [21,  4000] loss: 1.656
2025-02-24T16:14:13.266884+0300 | INFO | [21,  4100] loss: 1.661
2025-02-24T16:14:23.782098+0300 | INFO | [21,  4200] loss: 1.677
2025-02-24T16:14:36.026268+0300 | INFO | [21,  4300] loss: 1.676
2025-02-24T16:14:49.808828+0300 | INFO | [21,  4400] loss: 1.653
2025-02-24T16:15:02.649305+0300 | INFO | [21,  4500] loss: 1.678
2025-02-24T16:15:14.921179+0300 | INFO | [21,  4600] loss: 1.676
2025-02-24T16:15:25.885663+0300 | INFO | [21,  4700] loss: 1.649
2025-02-24T16:15:36.933951+0300 | INFO | [21,  4800] loss: 1.663
2025-02-24T16:15:47.275598+0300 | INFO | [21,  4900] loss: 1.693
2025-02-24T16:15:58.113331+0300 | DEBUG | Saving model to flat file storage. Save #21
2025-02-24T16:15:58.132755+0300 | INFO | Averaging client parameters
2025-02-24T16:15:58.141310+0300 | INFO | Updating parameters on client #0
2025-02-24T16:16:17.285465+0300 | DEBUG | Test set: Accuracy: 7438/10000 (74%)
2025-02-24T16:16:17.286483+0300 | DEBUG | Test set: Loss: 1.7161051034927368
2025-02-24T16:16:17.396350+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.80      0.79      1000
           1       0.91      0.89      0.90      1000
           2       0.71      0.64      0.67      1000
           3       0.49      0.76      0.59      1200
           4       0.72      0.78      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.84      0.80      1000
           7       0.79      0.83      0.81      1000
           8       0.90      0.87      0.88      1000
           9       0.84      0.88      0.86      1000

    accuracy                           0.74     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.74      0.72     10000

2025-02-24T16:16:17.399709+0300 | DEBUG | Confusion Matrix:
[[796  11  47  28  20   0   9  14  42  33]
 [  4 891   3   4   1   0  11   2  16  68]
 [ 64   3 642  72  81   0  87  33   6  12]
 [ 21   7  68 906  66   0  57  43   8  24]
 [ 15   1  41  66 777   0  42  50   7   1]
 [ 13   1  46 604  43   0  29  58   4   2]
 [ 10   2  27  80  32   0 838   3   2   6]
 [ 13   4  21  64  46   0  13 830   1   8]
 [ 60  13   6  15   4   0   7   4 874  17]
 [ 24  44   2  14   2   0   6   8  16 884]]
2025-02-24T16:16:17.403411+0300 | DEBUG | Class precision: [0.78039216 0.91197544 0.71096346 0.48893686 0.72481343        nan
 0.76251137 0.79425837 0.8954918  0.83791469]
2025-02-24T16:16:17.405754+0300 | DEBUG | Class recall: [0.796 0.891 0.642 0.755 0.777 0.    0.838 0.83  0.874 0.884]
2025-02-24T16:16:17.472999+0300 | INFO | Training epoch #22 on client #0
2025-02-24T16:16:17.477030+0300 | DEBUG | Saving model to flat file storage. Save #22
2025-02-24T16:16:17.812488+0300 | INFO | [22,     0] loss: 0.017
2025-02-24T16:16:29.850085+0300 | INFO | [22,   100] loss: 1.657
2025-02-24T16:16:40.995386+0300 | INFO | [22,   200] loss: 1.661
2025-02-24T16:16:50.562216+0300 | INFO | [22,   300] loss: 1.663
2025-02-24T16:17:01.029339+0300 | INFO | [22,   400] loss: 1.647
2025-02-24T16:17:11.837783+0300 | INFO | [22,   500] loss: 1.645
2025-02-24T16:17:23.109909+0300 | INFO | [22,   600] loss: 1.665
2025-02-24T16:17:35.345541+0300 | INFO | [22,   700] loss: 1.648
2025-02-24T16:17:46.497556+0300 | INFO | [22,   800] loss: 1.639
2025-02-24T16:17:58.238626+0300 | INFO | [22,   900] loss: 1.648
2025-02-24T16:18:08.151923+0300 | INFO | [22,  1000] loss: 1.654
2025-02-24T16:18:18.431194+0300 | INFO | [22,  1100] loss: 1.648
2025-02-24T16:18:28.502433+0300 | INFO | [22,  1200] loss: 1.649
2025-02-24T16:18:38.833822+0300 | INFO | [22,  1300] loss: 1.661
2025-02-24T16:18:49.009690+0300 | INFO | [22,  1400] loss: 1.669
2025-02-24T16:18:58.848097+0300 | INFO | [22,  1500] loss: 1.651
2025-02-24T16:19:08.787757+0300 | INFO | [22,  1600] loss: 1.647
2025-02-24T16:19:18.660126+0300 | INFO | [22,  1700] loss: 1.654
2025-02-24T16:19:28.684038+0300 | INFO | [22,  1800] loss: 1.643
2025-02-24T16:19:41.399109+0300 | INFO | [22,  1900] loss: 1.657
2025-02-24T16:19:55.836614+0300 | INFO | [22,  2000] loss: 1.646
2025-02-24T16:20:08.555381+0300 | INFO | [22,  2100] loss: 1.660
2025-02-24T16:20:22.724981+0300 | INFO | [22,  2200] loss: 1.670
2025-02-24T16:20:36.821001+0300 | INFO | [22,  2300] loss: 1.642
2025-02-24T16:20:51.798714+0300 | INFO | [22,  2400] loss: 1.660
2025-02-24T16:21:06.718273+0300 | INFO | [22,  2500] loss: 1.652
2025-02-24T16:21:21.782453+0300 | INFO | [22,  2600] loss: 1.662
2025-02-24T16:21:36.939793+0300 | INFO | [22,  2700] loss: 1.643
2025-02-24T16:21:50.810947+0300 | INFO | [22,  2800] loss: 1.666
2025-02-24T16:22:02.709357+0300 | INFO | [22,  2900] loss: 1.636
2025-02-24T16:22:13.321508+0300 | INFO | [22,  3000] loss: 1.648
2025-02-24T16:22:23.061946+0300 | INFO | [22,  3100] loss: 1.647
2025-02-24T16:22:34.926861+0300 | INFO | [22,  3200] loss: 1.641
2025-02-24T16:22:46.909436+0300 | INFO | [22,  3300] loss: 1.656
2025-02-24T16:22:57.824080+0300 | INFO | [22,  3400] loss: 1.641
2025-02-24T16:23:08.458954+0300 | INFO | [22,  3500] loss: 1.655
2025-02-24T16:23:19.459969+0300 | INFO | [22,  3600] loss: 1.632
2025-02-24T16:23:30.070786+0300 | INFO | [22,  3700] loss: 1.645
2025-02-24T16:23:41.161246+0300 | INFO | [22,  3800] loss: 1.666
2025-02-24T16:23:51.825580+0300 | INFO | [22,  3900] loss: 1.654
2025-02-24T16:24:01.397261+0300 | INFO | [22,  4000] loss: 1.670
2025-02-24T16:24:12.341098+0300 | INFO | [22,  4100] loss: 1.660
2025-02-24T16:24:23.403519+0300 | INFO | [22,  4200] loss: 1.662
2025-02-24T16:24:35.068356+0300 | INFO | [22,  4300] loss: 1.652
2025-02-24T16:24:45.836368+0300 | INFO | [22,  4400] loss: 1.663
2025-02-24T16:24:58.306785+0300 | INFO | [22,  4500] loss: 1.645
2025-02-24T16:25:11.090546+0300 | INFO | [22,  4600] loss: 1.637
2025-02-24T16:25:21.367678+0300 | INFO | [22,  4700] loss: 1.684
2025-02-24T16:25:31.358858+0300 | INFO | [22,  4800] loss: 1.668
2025-02-24T16:25:41.941268+0300 | INFO | [22,  4900] loss: 1.681
2025-02-24T16:25:51.957200+0300 | DEBUG | Saving model to flat file storage. Save #22
2025-02-24T16:25:51.974073+0300 | INFO | Averaging client parameters
2025-02-24T16:25:51.984898+0300 | INFO | Updating parameters on client #0
2025-02-24T16:26:08.891393+0300 | DEBUG | Test set: Accuracy: 7445/10000 (74%)
2025-02-24T16:26:08.893762+0300 | DEBUG | Test set: Loss: 1.715838074684143
2025-02-24T16:26:08.997127+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.83      0.77      1000
           1       0.92      0.86      0.89      1000
           2       0.71      0.63      0.67      1000
           3       0.53      0.70      0.60      1200
           4       0.72      0.81      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.84      0.82      1000
           7       0.81      0.80      0.81      1000
           8       0.78      0.93      0.85      1000
           9       0.85      0.89      0.87      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.69      0.74      0.72     10000

2025-02-24T16:26:08.999153+0300 | DEBUG | Confusion Matrix:
[[835   9   6  10   9   0   3  11  86  31]
 [ 11 864   0   0   1   0   7   4  38  75]
 [114   4 632  55  89   0  64  21  14   7]
 [ 44  11  77 838  67   0  75  44  28  16]
 [ 22   1  42  38 814   0  27  37  15   4]
 [ 31   4  71 528  54   0  33  61  16   2]
 [ 17   0  35  48  38   0 844   5  11   2]
 [ 32   3  19  45  60   0  10 803  15  13]
 [ 45   8   1   2   2   0   1   4 927  10]
 [ 24  35   3   8   2   0   3   4  33 888]]
2025-02-24T16:26:09.000168+0300 | DEBUG | Class precision: [0.7106383  0.9201278  0.71331828 0.53307888 0.7165493         nan
 0.79100281 0.80784708 0.78360101 0.84732824]
2025-02-24T16:26:09.002176+0300 | DEBUG | Class recall: [0.835      0.864      0.632      0.69833333 0.814      0.
 0.844      0.803      0.927      0.888     ]
2025-02-24T16:26:09.066051+0300 | INFO | Training epoch #23 on client #0
2025-02-24T16:26:09.067049+0300 | DEBUG | Saving model to flat file storage. Save #23
2025-02-24T16:26:09.217196+0300 | INFO | [23,     0] loss: 0.018
2025-02-24T16:26:20.809486+0300 | INFO | [23,   100] loss: 1.650
2025-02-24T16:26:31.156537+0300 | INFO | [23,   200] loss: 1.659
2025-02-24T16:26:41.805262+0300 | INFO | [23,   300] loss: 1.640
2025-02-24T16:26:52.143020+0300 | INFO | [23,   400] loss: 1.650
2025-02-24T16:27:02.632971+0300 | INFO | [23,   500] loss: 1.663
2025-02-24T16:27:12.794576+0300 | INFO | [23,   600] loss: 1.651
2025-02-24T16:27:23.195636+0300 | INFO | [23,   700] loss: 1.631
2025-02-24T16:27:33.654180+0300 | INFO | [23,   800] loss: 1.643
2025-02-24T16:27:44.165033+0300 | INFO | [23,   900] loss: 1.644
2025-02-24T16:27:54.725255+0300 | INFO | [23,  1000] loss: 1.631
2025-02-24T16:28:05.074132+0300 | INFO | [23,  1100] loss: 1.648
2025-02-24T16:28:14.723313+0300 | INFO | [23,  1200] loss: 1.632
2025-02-24T16:28:29.343793+0300 | INFO | [23,  1300] loss: 1.649
2025-02-24T16:28:40.094585+0300 | INFO | [23,  1400] loss: 1.664
2025-02-24T16:28:50.382734+0300 | INFO | [23,  1500] loss: 1.656
2025-02-24T16:29:00.972408+0300 | INFO | [23,  1600] loss: 1.662
2025-02-24T16:29:11.631569+0300 | INFO | [23,  1700] loss: 1.643
2025-02-24T16:29:22.167128+0300 | INFO | [23,  1800] loss: 1.652
2025-02-24T16:29:32.280248+0300 | INFO | [23,  1900] loss: 1.650
2025-02-24T16:29:42.490028+0300 | INFO | [23,  2000] loss: 1.647
2025-02-24T16:29:52.867829+0300 | INFO | [23,  2100] loss: 1.664
2025-02-24T16:30:03.001742+0300 | INFO | [23,  2200] loss: 1.654
2025-02-24T16:30:13.327230+0300 | INFO | [23,  2300] loss: 1.663
2025-02-24T16:30:24.181550+0300 | INFO | [23,  2400] loss: 1.652
2025-02-24T16:30:34.011312+0300 | INFO | [23,  2500] loss: 1.655
2025-02-24T16:30:44.814259+0300 | INFO | [23,  2600] loss: 1.659
2025-02-24T16:30:56.208377+0300 | INFO | [23,  2700] loss: 1.635
2025-02-24T16:31:06.620244+0300 | INFO | [23,  2800] loss: 1.654
2025-02-24T16:31:16.876074+0300 | INFO | [23,  2900] loss: 1.667
2025-02-24T16:31:27.448586+0300 | INFO | [23,  3000] loss: 1.646
2025-02-24T16:31:37.933297+0300 | INFO | [23,  3100] loss: 1.650
2025-02-24T16:31:48.199603+0300 | INFO | [23,  3200] loss: 1.661
2025-02-24T16:31:57.564460+0300 | INFO | [23,  3300] loss: 1.641
2025-02-24T16:32:08.449504+0300 | INFO | [23,  3400] loss: 1.629
2025-02-24T16:32:18.549958+0300 | INFO | [23,  3500] loss: 1.655
2025-02-24T16:32:29.486936+0300 | INFO | [23,  3600] loss: 1.658
2025-02-24T16:32:39.325288+0300 | INFO | [23,  3700] loss: 1.663
2025-02-24T16:32:50.076925+0300 | INFO | [23,  3800] loss: 1.654
2025-02-24T16:33:00.545879+0300 | INFO | [23,  3900] loss: 1.646
2025-02-24T16:33:10.746886+0300 | INFO | [23,  4000] loss: 1.645
2025-02-24T16:33:21.403616+0300 | INFO | [23,  4100] loss: 1.686
2025-02-24T16:33:31.996022+0300 | INFO | [23,  4200] loss: 1.679
2025-02-24T16:33:42.435020+0300 | INFO | [23,  4300] loss: 1.640
2025-02-24T16:33:53.434543+0300 | INFO | [23,  4400] loss: 1.671
2025-02-24T16:34:03.811377+0300 | INFO | [23,  4500] loss: 1.669
2025-02-24T16:34:14.211519+0300 | INFO | [23,  4600] loss: 1.668
2025-02-24T16:34:24.334686+0300 | INFO | [23,  4700] loss: 1.652
2025-02-24T16:34:34.540873+0300 | INFO | [23,  4800] loss: 1.652
2025-02-24T16:34:44.810479+0300 | INFO | [23,  4900] loss: 1.646
2025-02-24T16:34:54.966427+0300 | DEBUG | Saving model to flat file storage. Save #23
2025-02-24T16:34:54.984961+0300 | INFO | Averaging client parameters
2025-02-24T16:34:54.991728+0300 | INFO | Updating parameters on client #0
2025-02-24T16:35:16.639552+0300 | DEBUG | Test set: Accuracy: 7486/10000 (75%)
2025-02-24T16:35:16.640563+0300 | DEBUG | Test set: Loss: 1.7129677534103394
2025-02-24T16:35:16.743706+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.81      0.80      1000
           1       0.92      0.88      0.90      1000
           2       0.59      0.73      0.65      1000
           3       0.53      0.69      0.60      1200
           4       0.75      0.79      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.86      0.82      1000
           7       0.79      0.85      0.82      1000
           8       0.88      0.88      0.88      1000
           9       0.87      0.86      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T16:35:16.746210+0300 | DEBUG | Confusion Matrix:
[[808  11  66  19   8   0  15  14  41  18]
 [ 13 876   6   5   0   0  13   5  21  61]
 [ 54   0 727  40  83   0  62  20   5   9]
 [ 22   2 140 832  61   0  66  53   9  15]
 [ 14   1  53  59 788   0  33  44   8   0]
 [  8   2 136 506  40   0  29  71   6   2]
 [  6   0  44  45  35   0 860   6   2   2]
 [ 10   2  30  46  41   0   7 855   2   7]
 [ 55  14  13  14   0   0   8   6 876  14]
 [ 37  43   9  10   1   0   4  12  20 864]]
2025-02-24T16:35:16.747706+0300 | DEBUG | Class precision: [0.78675755 0.92113565 0.59395425 0.52791878 0.74550615        nan
 0.78395624 0.78729282 0.88484848 0.87096774]
2025-02-24T16:35:16.748905+0300 | DEBUG | Class recall: [0.808      0.876      0.727      0.69333333 0.788      0.
 0.86       0.855      0.876      0.864     ]
2025-02-24T16:35:16.827577+0300 | INFO | Training epoch #24 on client #0
2025-02-24T16:35:16.829589+0300 | DEBUG | Saving model to flat file storage. Save #24
2025-02-24T16:35:17.049516+0300 | INFO | [24,     0] loss: 0.018
2025-02-24T16:35:31.001438+0300 | INFO | [24,   100] loss: 1.662
2025-02-24T16:35:47.993492+0300 | INFO | [24,   200] loss: 1.666
2025-02-24T16:35:59.643555+0300 | INFO | [24,   300] loss: 1.647
2025-02-24T16:36:10.356710+0300 | INFO | [24,   400] loss: 1.652
2025-02-24T16:36:20.866213+0300 | INFO | [24,   500] loss: 1.647
2025-02-24T16:36:32.106249+0300 | INFO | [24,   600] loss: 1.650
2025-02-24T16:36:46.360711+0300 | INFO | [24,   700] loss: 1.635
2025-02-24T16:36:56.881472+0300 | INFO | [24,   800] loss: 1.657
2025-02-24T16:37:08.343587+0300 | INFO | [24,   900] loss: 1.640
2025-02-24T16:37:19.099713+0300 | INFO | [24,  1000] loss: 1.634
2025-02-24T16:37:31.164294+0300 | INFO | [24,  1100] loss: 1.663
2025-02-24T16:37:42.744194+0300 | INFO | [24,  1200] loss: 1.635
2025-02-24T16:37:55.589519+0300 | INFO | [24,  1300] loss: 1.644
2025-02-24T16:38:08.273522+0300 | INFO | [24,  1400] loss: 1.656
2025-02-24T16:38:20.811304+0300 | INFO | [24,  1500] loss: 1.650
2025-02-24T16:38:32.598001+0300 | INFO | [24,  1600] loss: 1.655
2025-02-24T16:38:43.976091+0300 | INFO | [24,  1700] loss: 1.663
2025-02-24T16:38:55.338260+0300 | INFO | [24,  1800] loss: 1.652
2025-02-24T16:39:06.693701+0300 | INFO | [24,  1900] loss: 1.643
2025-02-24T16:39:17.922990+0300 | INFO | [24,  2000] loss: 1.664
2025-02-24T16:39:28.168912+0300 | INFO | [24,  2100] loss: 1.643
2025-02-24T16:39:39.128160+0300 | INFO | [24,  2200] loss: 1.633
2025-02-24T16:39:54.196857+0300 | INFO | [24,  2300] loss: 1.659
2025-02-24T16:40:10.906183+0300 | INFO | [24,  2400] loss: 1.636
2025-02-24T16:40:26.777563+0300 | INFO | [24,  2500] loss: 1.627
2025-02-24T16:40:41.756268+0300 | INFO | [24,  2600] loss: 1.658
2025-02-24T16:40:57.964280+0300 | INFO | [24,  2700] loss: 1.659
2025-02-24T16:41:16.562072+0300 | INFO | [24,  2800] loss: 1.667
2025-02-24T16:41:31.642617+0300 | INFO | [24,  2900] loss: 1.678
2025-02-24T16:41:46.487119+0300 | INFO | [24,  3000] loss: 1.628
2025-02-24T16:42:02.672784+0300 | INFO | [24,  3100] loss: 1.665
2025-02-24T16:42:18.861297+0300 | INFO | [24,  3200] loss: 1.634
2025-02-24T16:42:36.669514+0300 | INFO | [24,  3300] loss: 1.653
2025-02-24T16:42:51.567319+0300 | INFO | [24,  3400] loss: 1.653
2025-02-24T16:43:05.664191+0300 | INFO | [24,  3500] loss: 1.675
2025-02-24T16:43:16.354795+0300 | INFO | [24,  3600] loss: 1.633
2025-02-24T16:43:26.434950+0300 | INFO | [24,  3700] loss: 1.644
2025-02-24T16:43:37.321783+0300 | INFO | [24,  3800] loss: 1.645
2025-02-24T16:43:47.321527+0300 | INFO | [24,  3900] loss: 1.645
2025-02-24T16:43:58.001568+0300 | INFO | [24,  4000] loss: 1.660
2025-02-24T16:44:09.205645+0300 | INFO | [24,  4100] loss: 1.630
2025-02-24T16:44:18.917273+0300 | INFO | [24,  4200] loss: 1.634
2025-02-24T16:44:29.766713+0300 | INFO | [24,  4300] loss: 1.645
2025-02-24T16:44:40.468250+0300 | INFO | [24,  4400] loss: 1.643
2025-02-24T16:44:54.114766+0300 | INFO | [24,  4500] loss: 1.641
2025-02-24T16:45:07.873241+0300 | INFO | [24,  4600] loss: 1.639
2025-02-24T16:45:22.106183+0300 | INFO | [24,  4700] loss: 1.648
2025-02-24T16:45:37.281815+0300 | INFO | [24,  4800] loss: 1.648
2025-02-24T16:45:52.274236+0300 | INFO | [24,  4900] loss: 1.640
2025-02-24T16:46:06.438890+0300 | DEBUG | Saving model to flat file storage. Save #24
2025-02-24T16:46:06.454657+0300 | INFO | Averaging client parameters
2025-02-24T16:46:06.466981+0300 | INFO | Updating parameters on client #0
2025-02-24T16:46:31.219711+0300 | DEBUG | Test set: Accuracy: 7474/10000 (75%)
2025-02-24T16:46:31.222710+0300 | DEBUG | Test set: Loss: 1.7122992277145386
2025-02-24T16:46:31.376454+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.85      0.79      1000
           1       0.92      0.88      0.90      1000
           2       0.68      0.68      0.68      1000
           3       0.51      0.74      0.60      1200
           4       0.68      0.83      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.82      0.85      0.83      1000
           7       0.81      0.80      0.81      1000
           8       0.90      0.84      0.87      1000
           9       0.86      0.87      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T16:46:31.381445+0300 | DEBUG | Confusion Matrix:
[[848  10  48  23  16   0   6  11  23  15]
 [ 21 878   6   5   2   0  13   3  13  59]
 [ 67   2 681  71  92   0  49  23   8   7]
 [ 31   3  79 885  82   0  56  41   8  15]
 [ 15   2  47  49 832   0  25  25   5   0]
 [ 11   2  73 553  64   0  18  67   9   3]
 [ 10   0  33  52  43   0 846   6   5   5]
 [ 14   0  14  66  78   0   9 802   5  12]
 [ 88  18  11  15   5   0   2   4 836  21]
 [ 42  35   7  12   3   0   6   9  20 866]]
2025-02-24T16:46:31.386453+0300 | DEBUG | Class precision: [0.73931997 0.92421053 0.68168168 0.51126516 0.68364832        nan
 0.82135922 0.80928355 0.89699571 0.86340977]
2025-02-24T16:46:31.387539+0300 | DEBUG | Class recall: [0.848  0.878  0.681  0.7375 0.832  0.     0.846  0.802  0.836  0.866 ]
2025-02-24T16:46:31.389560+0300 | INFO | Training epoch #25 on client #0
2025-02-24T16:46:31.393556+0300 | DEBUG | Saving model to flat file storage. Save #25
2025-02-24T16:46:31.693571+0300 | INFO | [25,     0] loss: 0.015
2025-02-24T16:46:49.405082+0300 | INFO | [25,   100] loss: 1.641
2025-02-24T16:47:04.592182+0300 | INFO | [25,   200] loss: 1.647
2025-02-24T16:47:20.351149+0300 | INFO | [25,   300] loss: 1.636
2025-02-24T16:47:35.905054+0300 | INFO | [25,   400] loss: 1.645
2025-02-24T16:47:47.027959+0300 | INFO | [25,   500] loss: 1.635
2025-02-24T16:47:57.769705+0300 | INFO | [25,   600] loss: 1.645
2025-02-24T16:48:08.751192+0300 | INFO | [25,   700] loss: 1.630
2025-02-24T16:48:22.013662+0300 | INFO | [25,   800] loss: 1.670
2025-02-24T16:48:34.234939+0300 | INFO | [25,   900] loss: 1.645
2025-02-24T16:48:44.117655+0300 | INFO | [25,  1000] loss: 1.667
2025-02-24T16:48:58.971381+0300 | INFO | [25,  1100] loss: 1.640
2025-02-24T16:49:13.212883+0300 | INFO | [25,  1200] loss: 1.617
2025-02-24T16:49:25.833248+0300 | INFO | [25,  1300] loss: 1.646
2025-02-24T16:49:36.717034+0300 | INFO | [25,  1400] loss: 1.649
2025-02-24T16:49:52.825243+0300 | INFO | [25,  1500] loss: 1.655
2025-02-24T16:50:04.335915+0300 | INFO | [25,  1600] loss: 1.636
2025-02-24T16:50:15.259426+0300 | INFO | [25,  1700] loss: 1.664
2025-02-24T16:50:25.215858+0300 | INFO | [25,  1800] loss: 1.658
2025-02-24T16:50:36.569323+0300 | INFO | [25,  1900] loss: 1.630
2025-02-24T16:50:47.537186+0300 | INFO | [25,  2000] loss: 1.633
2025-02-24T16:50:57.979102+0300 | INFO | [25,  2100] loss: 1.637
2025-02-24T16:51:08.813548+0300 | INFO | [25,  2200] loss: 1.647
2025-02-24T16:51:19.542501+0300 | INFO | [25,  2300] loss: 1.644
2025-02-24T16:51:29.740118+0300 | INFO | [25,  2400] loss: 1.650
2025-02-24T16:51:41.135630+0300 | INFO | [25,  2500] loss: 1.636
2025-02-24T16:51:56.005563+0300 | INFO | [25,  2600] loss: 1.674
2025-02-24T16:52:11.245988+0300 | INFO | [25,  2700] loss: 1.638
2025-02-24T16:52:28.321080+0300 | INFO | [25,  2800] loss: 1.649
2025-02-24T16:52:43.197252+0300 | INFO | [25,  2900] loss: 1.655
2025-02-24T16:52:54.410802+0300 | INFO | [25,  3000] loss: 1.634
2025-02-24T16:53:06.199510+0300 | INFO | [25,  3100] loss: 1.648
2025-02-24T16:53:16.982241+0300 | INFO | [25,  3200] loss: 1.638
2025-02-24T16:53:29.250612+0300 | INFO | [25,  3300] loss: 1.651
2025-02-24T16:53:44.783179+0300 | INFO | [25,  3400] loss: 1.668
2025-02-24T16:53:59.718980+0300 | INFO | [25,  3500] loss: 1.643
2025-02-24T16:54:16.205135+0300 | INFO | [25,  3600] loss: 1.642
2025-02-24T16:54:29.866618+0300 | INFO | [25,  3700] loss: 1.644
2025-02-24T16:54:39.701612+0300 | INFO | [25,  3800] loss: 1.667
2025-02-24T16:54:50.611938+0300 | INFO | [25,  3900] loss: 1.651
2025-02-24T16:55:01.350514+0300 | INFO | [25,  4000] loss: 1.650
2025-02-24T16:55:11.094078+0300 | INFO | [25,  4100] loss: 1.654
2025-02-24T16:55:21.648250+0300 | INFO | [25,  4200] loss: 1.671
2025-02-24T16:55:31.889940+0300 | INFO | [25,  4300] loss: 1.648
2025-02-24T16:55:42.095132+0300 | INFO | [25,  4400] loss: 1.649
2025-02-24T16:56:04.031740+0300 | INFO | [25,  4500] loss: 1.642
2025-02-24T16:56:16.778433+0300 | INFO | [25,  4600] loss: 1.650
2025-02-24T16:56:29.847348+0300 | INFO | [25,  4700] loss: 1.637
2025-02-24T16:56:40.799642+0300 | INFO | [25,  4800] loss: 1.645
2025-02-24T16:56:50.865367+0300 | INFO | [25,  4900] loss: 1.643
2025-02-24T16:57:01.866067+0300 | DEBUG | Saving model to flat file storage. Save #25
2025-02-24T16:57:01.885918+0300 | INFO | Averaging client parameters
2025-02-24T16:57:01.893803+0300 | INFO | Updating parameters on client #0
2025-02-24T16:57:17.313547+0300 | DEBUG | Test set: Accuracy: 7541/10000 (75%)
2025-02-24T16:57:17.314550+0300 | DEBUG | Test set: Loss: 1.7066503763198853
2025-02-24T16:57:17.407036+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.86      0.81      1000
           1       0.93      0.88      0.90      1000
           2       0.70      0.70      0.70      1000
           3       0.50      0.78      0.61      1200
           4       0.76      0.80      0.78      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.89      0.82      1000
           7       0.84      0.76      0.80      1000
           8       0.89      0.86      0.87      1000
           9       0.86      0.86      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.75      0.73     10000

2025-02-24T16:57:17.409719+0300 | DEBUG | Confusion Matrix:
[[859   8  36  21   4   0   5  10  30  27]
 [  8 880   2   7   2   0  15   1  16  69]
 [ 74   1 696  71  62   0  68  15   7   6]
 [ 28   2  67 933  51   0  71  32   7   9]
 [ 19   1  39  60 800   0  42  31   7   1]
 [ 10   0  72 581  46   0  32  40  13   6]
 [ 10   0  39  43  14   0 886   3   5   0]
 [ 15   0  34  95  66   0  17 764   3   6]
 [ 75  15   9  15   2   0   4   4 859  17]
 [ 26  40   7  25   2   0   8   9  19 864]]
2025-02-24T16:57:17.411733+0300 | DEBUG | Class precision: [0.76423488 0.92925026 0.6953047  0.50405186 0.76263108        nan
 0.771777   0.84048405 0.88923395 0.85970149]
2025-02-24T16:57:17.411733+0300 | DEBUG | Class recall: [0.859  0.88   0.696  0.7775 0.8    0.     0.886  0.764  0.859  0.864 ]
2025-02-24T16:57:17.456135+0300 | INFO | Training epoch #26 on client #0
2025-02-24T16:57:17.457324+0300 | DEBUG | Saving model to flat file storage. Save #26
2025-02-24T16:57:17.587585+0300 | INFO | [26,     0] loss: 0.016
2025-02-24T16:57:31.504486+0300 | INFO | [26,   100] loss: 1.624
2025-02-24T16:57:44.225269+0300 | INFO | [26,   200] loss: 1.641
2025-02-24T16:57:57.226708+0300 | INFO | [26,   300] loss: 1.644
2025-02-24T16:58:07.806597+0300 | INFO | [26,   400] loss: 1.632
2025-02-24T16:58:18.983411+0300 | INFO | [26,   500] loss: 1.659
2025-02-24T16:58:30.183453+0300 | INFO | [26,   600] loss: 1.634
2025-02-24T16:58:43.008731+0300 | INFO | [26,   700] loss: 1.644
2025-02-24T16:58:57.274274+0300 | INFO | [26,   800] loss: 1.656
2025-02-24T16:59:15.399584+0300 | INFO | [26,   900] loss: 1.644
2025-02-24T16:59:32.070124+0300 | INFO | [26,  1000] loss: 1.641
2025-02-24T16:59:53.051837+0300 | INFO | [26,  1100] loss: 1.652
2025-02-24T17:00:12.269028+0300 | INFO | [26,  1200] loss: 1.644
2025-02-24T17:00:25.926926+0300 | INFO | [26,  1300] loss: 1.638
2025-02-24T17:00:38.183527+0300 | INFO | [26,  1400] loss: 1.641
2025-02-24T17:00:49.206744+0300 | INFO | [26,  1500] loss: 1.643
2025-02-24T17:01:01.818099+0300 | INFO | [26,  1600] loss: 1.629
2025-02-24T17:01:14.237331+0300 | INFO | [26,  1700] loss: 1.627
2025-02-24T17:01:25.855099+0300 | INFO | [26,  1800] loss: 1.643
2025-02-24T17:01:36.821721+0300 | INFO | [26,  1900] loss: 1.655
2025-02-24T17:01:47.888736+0300 | INFO | [26,  2000] loss: 1.629
2025-02-24T17:01:58.937285+0300 | INFO | [26,  2100] loss: 1.630
2025-02-24T17:02:09.255813+0300 | INFO | [26,  2200] loss: 1.650
2025-02-24T17:02:20.356954+0300 | INFO | [26,  2300] loss: 1.638
2025-02-24T17:02:34.158909+0300 | INFO | [26,  2400] loss: 1.669
2025-02-24T17:02:47.031855+0300 | INFO | [26,  2500] loss: 1.638
2025-02-24T17:03:00.599785+0300 | INFO | [26,  2600] loss: 1.645
2025-02-24T17:03:15.177740+0300 | INFO | [26,  2700] loss: 1.629
2025-02-24T17:03:28.914375+0300 | INFO | [26,  2800] loss: 1.645
2025-02-24T17:03:43.770606+0300 | INFO | [26,  2900] loss: 1.656
2025-02-24T17:03:55.643954+0300 | INFO | [26,  3000] loss: 1.656
2025-02-24T17:04:09.625693+0300 | INFO | [26,  3100] loss: 1.645
2025-02-24T17:04:23.175710+0300 | INFO | [26,  3200] loss: 1.673
2025-02-24T17:04:36.948740+0300 | INFO | [26,  3300] loss: 1.642
2025-02-24T17:04:50.464314+0300 | INFO | [26,  3400] loss: 1.638
2025-02-24T17:05:02.349009+0300 | INFO | [26,  3500] loss: 1.662
2025-02-24T17:05:13.466119+0300 | INFO | [26,  3600] loss: 1.631
2025-02-24T17:05:23.561188+0300 | INFO | [26,  3700] loss: 1.647
2025-02-24T17:05:41.322509+0300 | INFO | [26,  3800] loss: 1.662
2025-02-24T17:06:01.230698+0300 | INFO | [26,  3900] loss: 1.642
2025-02-24T17:06:16.401123+0300 | INFO | [26,  4000] loss: 1.658
2025-02-24T17:06:26.435858+0300 | INFO | [26,  4100] loss: 1.636
2025-02-24T17:06:37.485487+0300 | INFO | [26,  4200] loss: 1.665
2025-02-24T17:06:48.235026+0300 | INFO | [26,  4300] loss: 1.630
2025-02-24T17:06:58.334535+0300 | INFO | [26,  4400] loss: 1.655
2025-02-24T17:07:09.037503+0300 | INFO | [26,  4500] loss: 1.646
2025-02-24T17:07:20.156319+0300 | INFO | [26,  4600] loss: 1.645
2025-02-24T17:07:30.448950+0300 | INFO | [26,  4700] loss: 1.642
2025-02-24T17:07:42.258138+0300 | INFO | [26,  4800] loss: 1.644
2025-02-24T17:07:53.215362+0300 | INFO | [26,  4900] loss: 1.665
2025-02-24T17:08:03.156502+0300 | DEBUG | Saving model to flat file storage. Save #26
2025-02-24T17:08:03.185256+0300 | INFO | Averaging client parameters
2025-02-24T17:08:03.191245+0300 | INFO | Updating parameters on client #0
2025-02-24T17:08:19.062543+0300 | DEBUG | Test set: Accuracy: 7490/10000 (75%)
2025-02-24T17:08:19.065873+0300 | DEBUG | Test set: Loss: 1.7109806537628174
2025-02-24T17:08:19.164284+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.83      0.80      1000
           1       0.94      0.86      0.90      1000
           2       0.72      0.64      0.68      1000
           3       0.52      0.75      0.62      1200
           4       0.77      0.76      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.88      0.81      1000
           7       0.75      0.85      0.80      1000
           8       0.85      0.88      0.86      1000
           9       0.83      0.89      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T17:08:19.168719+0300 | DEBUG | Confusion Matrix:
[[826   8  32  22   7   0   7  16  50  32]
 [  7 857   3   1   1   0   6   8  20  97]
 [ 65   3 641  71  74   0  87  37  12  10]
 [ 26   6  60 905  43   0  70  62  14  14]
 [ 20   1  29  64 757   0  58  62   6   3]
 [ 12   2  68 541  39   0  41  76  15   6]
 [  9   1  31  41  19   0 881   6   8   4]
 [ 18   0  11  61  36   0   9 852   7   6]
 [ 67  13   9   9   1   0   3   5 877  16]
 [ 25  24   4  15   2   0   4   9  23 894]]
2025-02-24T17:08:19.171721+0300 | DEBUG | Class precision: [0.76837209 0.93661202 0.72184685 0.52312139 0.773238          nan
 0.75557461 0.75198588 0.8498062  0.82624769]
2025-02-24T17:08:19.174843+0300 | DEBUG | Class recall: [0.826      0.857      0.641      0.75416667 0.757      0.
 0.881      0.852      0.877      0.894     ]
2025-02-24T17:08:19.240566+0300 | INFO | Training epoch #27 on client #0
2025-02-24T17:08:19.241567+0300 | DEBUG | Saving model to flat file storage. Save #27
2025-02-24T17:08:19.443246+0300 | INFO | [27,     0] loss: 0.018
2025-02-24T17:08:30.233893+0300 | INFO | [27,   100] loss: 1.625
2025-02-24T17:08:40.958570+0300 | INFO | [27,   200] loss: 1.629
2025-02-24T17:08:50.644349+0300 | INFO | [27,   300] loss: 1.658
2025-02-24T17:09:01.478590+0300 | INFO | [27,   400] loss: 1.632
2025-02-24T17:09:13.283531+0300 | INFO | [27,   500] loss: 1.651
2025-02-24T17:09:25.248685+0300 | INFO | [27,   600] loss: 1.631
2025-02-24T17:09:39.892563+0300 | INFO | [27,   700] loss: 1.652
2025-02-24T17:09:53.268157+0300 | INFO | [27,   800] loss: 1.647
2025-02-24T17:10:06.149846+0300 | INFO | [27,   900] loss: 1.635
2025-02-24T17:10:17.596488+0300 | INFO | [27,  1000] loss: 1.633
2025-02-24T17:10:29.259949+0300 | INFO | [27,  1100] loss: 1.644
2025-02-24T17:10:40.286396+0300 | INFO | [27,  1200] loss: 1.639
2025-02-24T17:10:50.596941+0300 | INFO | [27,  1300] loss: 1.632
2025-02-24T17:11:00.895445+0300 | INFO | [27,  1400] loss: 1.633
2025-02-24T17:11:11.046816+0300 | INFO | [27,  1500] loss: 1.650
2025-02-24T17:11:22.202265+0300 | INFO | [27,  1600] loss: 1.662
2025-02-24T17:11:33.287916+0300 | INFO | [27,  1700] loss: 1.668
2025-02-24T17:11:43.686752+0300 | INFO | [27,  1800] loss: 1.646
2025-02-24T17:11:56.119605+0300 | INFO | [27,  1900] loss: 1.640
2025-02-24T17:12:09.677504+0300 | INFO | [27,  2000] loss: 1.655
2025-02-24T17:12:25.601766+0300 | INFO | [27,  2100] loss: 1.630
2025-02-24T17:12:42.172985+0300 | INFO | [27,  2200] loss: 1.652
2025-02-24T17:12:56.566091+0300 | INFO | [27,  2300] loss: 1.629
2025-02-24T17:13:06.179484+0300 | INFO | [27,  2400] loss: 1.628
2025-02-24T17:13:16.922686+0300 | INFO | [27,  2500] loss: 1.623
2025-02-24T17:13:27.531414+0300 | INFO | [27,  2600] loss: 1.636
2025-02-24T17:13:37.295636+0300 | INFO | [27,  2700] loss: 1.627
2025-02-24T17:13:47.771187+0300 | INFO | [27,  2800] loss: 1.633
2025-02-24T17:13:59.233975+0300 | INFO | [27,  2900] loss: 1.652
2025-02-24T17:14:09.909948+0300 | INFO | [27,  3000] loss: 1.639
2025-02-24T17:14:23.933297+0300 | INFO | [27,  3100] loss: 1.655
2025-02-24T17:14:47.945794+0300 | INFO | [27,  3200] loss: 1.638
2025-02-24T17:15:03.468472+0300 | INFO | [27,  3300] loss: 1.631
2025-02-24T17:15:14.874621+0300 | INFO | [27,  3400] loss: 1.625
2025-02-24T17:15:27.565537+0300 | INFO | [27,  3500] loss: 1.648
2025-02-24T17:15:39.236955+0300 | INFO | [27,  3600] loss: 1.640
2025-02-24T17:15:50.345859+0300 | INFO | [27,  3700] loss: 1.648
2025-02-24T17:16:01.450991+0300 | INFO | [27,  3800] loss: 1.649
2025-02-24T17:16:12.643773+0300 | INFO | [27,  3900] loss: 1.644
2025-02-24T17:16:23.822030+0300 | INFO | [27,  4000] loss: 1.653
2025-02-24T17:16:34.569612+0300 | INFO | [27,  4100] loss: 1.646
2025-02-24T17:16:45.198573+0300 | INFO | [27,  4200] loss: 1.646
2025-02-24T17:16:56.399802+0300 | INFO | [27,  4300] loss: 1.633
2025-02-24T17:17:06.112073+0300 | INFO | [27,  4400] loss: 1.654
2025-02-24T17:17:16.626812+0300 | INFO | [27,  4500] loss: 1.662
2025-02-24T17:17:27.421416+0300 | INFO | [27,  4600] loss: 1.634
2025-02-24T17:17:39.315763+0300 | INFO | [27,  4700] loss: 1.633
2025-02-24T17:17:52.657391+0300 | INFO | [27,  4800] loss: 1.637
2025-02-24T17:18:05.955080+0300 | INFO | [27,  4900] loss: 1.661
2025-02-24T17:18:17.415834+0300 | DEBUG | Saving model to flat file storage. Save #27
2025-02-24T17:18:17.442359+0300 | INFO | Averaging client parameters
2025-02-24T17:18:17.454373+0300 | INFO | Updating parameters on client #0
2025-02-24T17:18:36.400886+0300 | DEBUG | Test set: Accuracy: 7473/10000 (75%)
2025-02-24T17:18:36.400886+0300 | DEBUG | Test set: Loss: 1.7123585939407349
2025-02-24T17:18:36.521531+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.82      0.78      1000
           1       0.88      0.92      0.90      1000
           2       0.67      0.68      0.67      1000
           3       0.52      0.70      0.60      1200
           4       0.79      0.76      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.89      0.81      1000
           7       0.80      0.82      0.81      1000
           8       0.85      0.90      0.87      1000
           9       0.88      0.85      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T17:18:36.524018+0300 | DEBUG | Confusion Matrix:
[[822  13  28  20  10   0   9  13  61  24]
 [ 13 918   4   2   0   0   5   2  18  38]
 [ 80   2 682  65  51   0  75  24  11  10]
 [ 42   8  93 843  42   0  78  55  16  23]
 [ 25   1  46  61 760   0  62  36   8   1]
 [ 21   5  97 521  40   0  46  56   9   5]
 [ 15   0  36  32  13   0 887   9   6   2]
 [ 28   1  32  55  43   0  12 816   7   6]
 [ 44  19   5  15   1   0   3   4 897  12]
 [ 30  73   2   9   3   0   6   5  24 848]]
2025-02-24T17:18:36.525365+0300 | DEBUG | Class precision: [0.73392857 0.88269231 0.66536585 0.5194085  0.78920042        nan
 0.74978867 0.8        0.84862819 0.875129  ]
2025-02-24T17:18:36.526119+0300 | DEBUG | Class recall: [0.822  0.918  0.682  0.7025 0.76   0.     0.887  0.816  0.897  0.848 ]
2025-02-24T17:18:36.580041+0300 | INFO | Training epoch #28 on client #0
2025-02-24T17:18:36.581053+0300 | DEBUG | Saving model to flat file storage. Save #28
2025-02-24T17:18:36.756096+0300 | INFO | [28,     0] loss: 0.017
2025-02-24T17:18:49.340631+0300 | INFO | [28,   100] loss: 1.620
2025-02-24T17:19:00.370594+0300 | INFO | [28,   200] loss: 1.633
2025-02-24T17:19:13.182341+0300 | INFO | [28,   300] loss: 1.640
2025-02-24T17:19:24.042581+0300 | INFO | [28,   400] loss: 1.646
2025-02-24T17:19:36.065900+0300 | INFO | [28,   500] loss: 1.632
2025-02-24T17:19:46.326952+0300 | INFO | [28,   600] loss: 1.618
2025-02-24T17:20:00.164746+0300 | INFO | [28,   700] loss: 1.636
2025-02-24T17:20:16.008468+0300 | INFO | [28,   800] loss: 1.637
2025-02-24T17:20:31.333852+0300 | INFO | [28,   900] loss: 1.623
2025-02-24T17:20:44.249062+0300 | INFO | [28,  1000] loss: 1.644
2025-02-24T17:20:57.787903+0300 | INFO | [28,  1100] loss: 1.647
2025-02-24T17:21:11.241960+0300 | INFO | [28,  1200] loss: 1.641
2025-02-24T17:21:24.549126+0300 | INFO | [28,  1300] loss: 1.650
2025-02-24T17:21:34.673892+0300 | INFO | [28,  1400] loss: 1.631
2025-02-24T17:21:45.432823+0300 | INFO | [28,  1500] loss: 1.654
2025-02-24T17:21:56.209248+0300 | INFO | [28,  1600] loss: 1.634
2025-02-24T17:22:09.261808+0300 | INFO | [28,  1700] loss: 1.643
2025-02-24T17:22:22.060973+0300 | INFO | [28,  1800] loss: 1.635
2025-02-24T17:22:32.447929+0300 | INFO | [28,  1900] loss: 1.646
2025-02-24T17:22:43.550180+0300 | INFO | [28,  2000] loss: 1.634
2025-02-24T17:22:55.142311+0300 | INFO | [28,  2100] loss: 1.628
2025-02-24T17:23:06.889554+0300 | INFO | [28,  2200] loss: 1.658
2025-02-24T17:23:16.924033+0300 | INFO | [28,  2300] loss: 1.639
2025-02-24T17:23:28.590260+0300 | INFO | [28,  2400] loss: 1.637
2025-02-24T17:23:45.997613+0300 | INFO | [28,  2500] loss: 1.622
2025-02-24T17:24:07.396838+0300 | INFO | [28,  2600] loss: 1.645
2025-02-24T17:24:17.252312+0300 | INFO | [28,  2700] loss: 1.641
2025-02-24T17:24:27.136913+0300 | INFO | [28,  2800] loss: 1.642
2025-02-24T17:24:37.305378+0300 | INFO | [28,  2900] loss: 1.670
2025-02-24T17:24:48.034599+0300 | INFO | [28,  3000] loss: 1.649
2025-02-24T17:24:58.273998+0300 | INFO | [28,  3100] loss: 1.648
2025-02-24T17:25:08.528846+0300 | INFO | [28,  3200] loss: 1.645
2025-02-24T17:25:19.048266+0300 | INFO | [28,  3300] loss: 1.627
2025-02-24T17:25:29.262969+0300 | INFO | [28,  3400] loss: 1.631
2025-02-24T17:25:39.826370+0300 | INFO | [28,  3500] loss: 1.623
2025-02-24T17:25:49.335317+0300 | INFO | [28,  3600] loss: 1.637
2025-02-24T17:25:59.539444+0300 | INFO | [28,  3700] loss: 1.645
2025-02-24T17:26:09.768657+0300 | INFO | [28,  3800] loss: 1.655
2025-02-24T17:26:19.763927+0300 | INFO | [28,  3900] loss: 1.670
2025-02-24T17:26:31.067702+0300 | INFO | [28,  4000] loss: 1.658
2025-02-24T17:26:43.460660+0300 | INFO | [28,  4100] loss: 1.643
2025-02-24T17:26:54.545470+0300 | INFO | [28,  4200] loss: 1.632
2025-02-24T17:27:07.365218+0300 | INFO | [28,  4300] loss: 1.651
2025-02-24T17:27:21.091019+0300 | INFO | [28,  4400] loss: 1.640
2025-02-24T17:27:31.165422+0300 | INFO | [28,  4500] loss: 1.609
2025-02-24T17:27:43.959652+0300 | INFO | [28,  4600] loss: 1.630
2025-02-24T17:27:54.899223+0300 | INFO | [28,  4700] loss: 1.638
2025-02-24T17:28:06.413790+0300 | INFO | [28,  4800] loss: 1.642
2025-02-24T17:28:17.981980+0300 | INFO | [28,  4900] loss: 1.644
2025-02-24T17:28:28.375258+0300 | DEBUG | Saving model to flat file storage. Save #28
2025-02-24T17:28:28.392536+0300 | INFO | Averaging client parameters
2025-02-24T17:28:28.400545+0300 | INFO | Updating parameters on client #0
2025-02-24T17:28:44.506467+0300 | DEBUG | Test set: Accuracy: 7491/10000 (75%)
2025-02-24T17:28:44.507471+0300 | DEBUG | Test set: Loss: 1.711403489112854
2025-02-24T17:28:44.599740+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.84      0.78      1000
           1       0.91      0.90      0.90      1000
           2       0.72      0.67      0.69      1000
           3       0.51      0.75      0.61      1200
           4       0.82      0.70      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.74      0.89      0.81      1000
           7       0.77      0.84      0.80      1000
           8       0.89      0.89      0.89      1000
           9       0.84      0.88      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T17:28:44.601734+0300 | DEBUG | Confusion Matrix:
[[840  12  29  16   7   0   8   8  41  39]
 [ 12 899   2   1   1   0   8   3  12  62]
 [ 81   3 668  66  42   0  93  28   8  11]
 [ 45   7  62 897  38   0  68  57   9  17]
 [ 16   1  55  80 699   0  78  59   8   4]
 [ 21   4  62 568  26   0  37  74   4   4]
 [ 14   3  29  44  10   0 887   8   3   2]
 [ 25   1  17  68  25   0   9 836   4  15]
 [ 56  14   8  12   3   0   4   2 885  16]
 [ 35  45   2  11   2   0   4   5  16 880]]
2025-02-24T17:28:44.602739+0300 | DEBUG | Class precision: [0.73362445 0.90899899 0.71520343 0.50879183 0.81946073        nan
 0.7416388  0.77407407 0.89393939 0.83809524]
2025-02-24T17:28:44.603740+0300 | DEBUG | Class recall: [0.84   0.899  0.668  0.7475 0.699  0.     0.887  0.836  0.885  0.88  ]
2025-02-24T17:28:44.648545+0300 | INFO | Training epoch #29 on client #0
2025-02-24T17:28:44.650886+0300 | DEBUG | Saving model to flat file storage. Save #29
2025-02-24T17:28:44.765721+0300 | INFO | [29,     0] loss: 0.015
2025-02-24T17:28:55.905843+0300 | INFO | [29,   100] loss: 1.632
2025-02-24T17:29:06.859828+0300 | INFO | [29,   200] loss: 1.637
2025-02-24T17:29:19.162753+0300 | INFO | [29,   300] loss: 1.621
2025-02-24T17:29:31.084875+0300 | INFO | [29,   400] loss: 1.632
2025-02-24T17:29:44.424153+0300 | INFO | [29,   500] loss: 1.639
2025-02-24T17:29:55.909663+0300 | INFO | [29,   600] loss: 1.627
2025-02-24T17:30:07.623975+0300 | INFO | [29,   700] loss: 1.622
2025-02-24T17:30:19.211052+0300 | INFO | [29,   800] loss: 1.643
2025-02-24T17:30:30.917520+0300 | INFO | [29,   900] loss: 1.639
2025-02-24T17:30:42.444511+0300 | INFO | [29,  1000] loss: 1.651
2025-02-24T17:30:54.490077+0300 | INFO | [29,  1100] loss: 1.616
2025-02-24T17:31:06.783404+0300 | INFO | [29,  1200] loss: 1.651
2025-02-24T17:31:19.703775+0300 | INFO | [29,  1300] loss: 1.639
2025-02-24T17:31:31.409771+0300 | INFO | [29,  1400] loss: 1.632
2025-02-24T17:31:43.982849+0300 | INFO | [29,  1500] loss: 1.656
2025-02-24T17:31:56.147000+0300 | INFO | [29,  1600] loss: 1.629
2025-02-24T17:32:08.419642+0300 | INFO | [29,  1700] loss: 1.662
2025-02-24T17:32:20.381477+0300 | INFO | [29,  1800] loss: 1.632
2025-02-24T17:32:32.982983+0300 | INFO | [29,  1900] loss: 1.641
2025-02-24T17:32:53.059593+0300 | INFO | [29,  2000] loss: 1.613
2025-02-24T17:33:05.882499+0300 | INFO | [29,  2100] loss: 1.628
2025-02-24T17:33:18.591506+0300 | INFO | [29,  2200] loss: 1.614
2025-02-24T17:33:29.578689+0300 | INFO | [29,  2300] loss: 1.653
2025-02-24T17:33:40.430142+0300 | INFO | [29,  2400] loss: 1.647
2025-02-24T17:33:51.292199+0300 | INFO | [29,  2500] loss: 1.645
2025-02-24T17:34:02.518181+0300 | INFO | [29,  2600] loss: 1.633
2025-02-24T17:34:13.151362+0300 | INFO | [29,  2700] loss: 1.662
2025-02-24T17:34:24.904176+0300 | INFO | [29,  2800] loss: 1.637
2025-02-24T17:34:37.327551+0300 | INFO | [29,  2900] loss: 1.640
2025-02-24T17:34:50.911320+0300 | INFO | [29,  3000] loss: 1.628
2025-02-24T17:35:03.812372+0300 | INFO | [29,  3100] loss: 1.646
2025-02-24T17:35:15.813612+0300 | INFO | [29,  3200] loss: 1.642
2025-02-24T17:35:28.125827+0300 | INFO | [29,  3300] loss: 1.620
2025-02-24T17:35:40.067132+0300 | INFO | [29,  3400] loss: 1.633
2025-02-24T17:35:54.507893+0300 | INFO | [29,  3500] loss: 1.647
2025-02-24T17:36:11.820238+0300 | INFO | [29,  3600] loss: 1.633
2025-02-24T17:36:24.768897+0300 | INFO | [29,  3700] loss: 1.643
2025-02-24T17:36:37.990913+0300 | INFO | [29,  3800] loss: 1.632
2025-02-24T17:36:48.880443+0300 | INFO | [29,  3900] loss: 1.631
2025-02-24T17:37:01.912408+0300 | INFO | [29,  4000] loss: 1.638
2025-02-24T17:37:12.964743+0300 | INFO | [29,  4100] loss: 1.617
2025-02-24T17:37:26.303655+0300 | INFO | [29,  4200] loss: 1.642
2025-02-24T17:37:39.150592+0300 | INFO | [29,  4300] loss: 1.674
2025-02-24T17:37:52.717535+0300 | INFO | [29,  4400] loss: 1.671
2025-02-24T17:38:04.802763+0300 | INFO | [29,  4500] loss: 1.634
2025-02-24T17:38:16.890374+0300 | INFO | [29,  4600] loss: 1.635
2025-02-24T17:38:31.563325+0300 | INFO | [29,  4700] loss: 1.655
2025-02-24T17:38:44.863108+0300 | INFO | [29,  4800] loss: 1.630
2025-02-24T17:38:57.694304+0300 | INFO | [29,  4900] loss: 1.652
2025-02-24T17:39:09.648480+0300 | DEBUG | Saving model to flat file storage. Save #29
2025-02-24T17:39:09.677190+0300 | INFO | Averaging client parameters
2025-02-24T17:39:09.689766+0300 | INFO | Updating parameters on client #0
2025-02-24T17:39:29.127284+0300 | DEBUG | Test set: Accuracy: 7534/10000 (75%)
2025-02-24T17:39:29.128323+0300 | DEBUG | Test set: Loss: 1.7082419395446777
2025-02-24T17:39:29.228782+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.80      0.79      1000
           1       0.91      0.91      0.91      1000
           2       0.68      0.70      0.69      1000
           3       0.51      0.79      0.62      1200
           4       0.73      0.78      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.82      0.85      0.83      1000
           7       0.83      0.81      0.82      1000
           8       0.85      0.89      0.87      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.75      0.73     10000

2025-02-24T17:39:29.232289+0300 | DEBUG | Confusion Matrix:
[[803   9  55  25  20   0   5   8  54  21]
 [ 11 906   5   7   1   0   2   1  24  43]
 [ 60   2 701  70  74   0  57  19  10   7]
 [ 21   4  68 942  56   0  49  37  10  13]
 [ 15   2  45  69 779   0  44  39   7   0]
 [ 12   5  80 577  49   0  18  45  11   3]
 [ 14   2  37  57  28   0 848   7   5   2]
 [ 16   2  24  74  58   0   7 805   6   8]
 [ 54  14   8  15   4   0   3   3 886  13]
 [ 28  51   7  15   3   0   5   2  25 864]]
2025-02-24T17:39:29.234434+0300 | DEBUG | Class precision: [0.77659574 0.90872618 0.68058252 0.5089141  0.7266791         nan
 0.81695568 0.83333333 0.85356455 0.88706366]
2025-02-24T17:39:29.235450+0300 | DEBUG | Class recall: [0.803 0.906 0.701 0.785 0.779 0.    0.848 0.805 0.886 0.864]
2025-02-24T17:39:29.290445+0300 | INFO | Training epoch #30 on client #0
2025-02-24T17:39:29.293620+0300 | DEBUG | Saving model to flat file storage. Save #30
2025-02-24T17:39:29.449018+0300 | INFO | [30,     0] loss: 0.016
2025-02-24T17:39:41.307388+0300 | INFO | [30,   100] loss: 1.624
2025-02-24T17:39:53.069895+0300 | INFO | [30,   200] loss: 1.618
2025-02-24T17:40:04.731610+0300 | INFO | [30,   300] loss: 1.617
2025-02-24T17:40:16.311887+0300 | INFO | [30,   400] loss: 1.633
2025-02-24T17:40:27.784791+0300 | INFO | [30,   500] loss: 1.646
2025-02-24T17:40:39.615344+0300 | INFO | [30,   600] loss: 1.608
2025-02-24T17:40:52.806126+0300 | INFO | [30,   700] loss: 1.634
2025-02-24T17:41:05.905763+0300 | INFO | [30,   800] loss: 1.629
2025-02-24T17:41:19.254913+0300 | INFO | [30,   900] loss: 1.620
2025-02-24T17:41:31.852828+0300 | INFO | [30,  1000] loss: 1.624
2025-02-24T17:41:44.865184+0300 | INFO | [30,  1100] loss: 1.636
2025-02-24T17:41:59.335448+0300 | INFO | [30,  1200] loss: 1.637
2025-02-24T17:42:18.404794+0300 | INFO | [30,  1300] loss: 1.622
2025-02-24T17:42:35.186974+0300 | INFO | [30,  1400] loss: 1.669
2025-02-24T17:42:46.789210+0300 | INFO | [30,  1500] loss: 1.621
2025-02-24T17:42:58.979403+0300 | INFO | [30,  1600] loss: 1.635
2025-02-24T17:43:12.364644+0300 | INFO | [30,  1700] loss: 1.626
2025-02-24T17:43:25.466212+0300 | INFO | [30,  1800] loss: 1.635
2025-02-24T17:43:38.014773+0300 | INFO | [30,  1900] loss: 1.621
2025-02-24T17:43:56.726466+0300 | INFO | [30,  2000] loss: 1.631
2025-02-24T17:44:18.359474+0300 | INFO | [30,  2100] loss: 1.645
2025-02-24T17:44:28.838105+0300 | INFO | [30,  2200] loss: 1.644
2025-02-24T17:44:39.141666+0300 | INFO | [30,  2300] loss: 1.626
2025-02-24T17:44:54.068218+0300 | INFO | [30,  2400] loss: 1.654
2025-02-24T17:45:05.238722+0300 | INFO | [30,  2500] loss: 1.627
2025-02-24T17:45:19.674874+0300 | INFO | [30,  2600] loss: 1.648
2025-02-24T17:45:33.044433+0300 | INFO | [30,  2700] loss: 1.623
2025-02-24T17:45:45.520951+0300 | INFO | [30,  2800] loss: 1.637
2025-02-24T17:45:55.483354+0300 | INFO | [30,  2900] loss: 1.628
2025-02-24T17:46:07.832622+0300 | INFO | [30,  3000] loss: 1.667
2025-02-24T17:46:20.685730+0300 | INFO | [30,  3100] loss: 1.641
2025-02-24T17:46:33.891683+0300 | INFO | [30,  3200] loss: 1.631
2025-02-24T17:46:47.278219+0300 | INFO | [30,  3300] loss: 1.627
2025-02-24T17:47:03.142743+0300 | INFO | [30,  3400] loss: 1.632
2025-02-24T17:47:16.290208+0300 | INFO | [30,  3500] loss: 1.618
2025-02-24T17:47:29.099566+0300 | INFO | [30,  3600] loss: 1.639
2025-02-24T17:47:42.421298+0300 | INFO | [30,  3700] loss: 1.651
2025-02-24T17:47:56.800590+0300 | INFO | [30,  3800] loss: 1.655
2025-02-24T17:48:10.940760+0300 | INFO | [30,  3900] loss: 1.641
2025-02-24T17:48:24.511698+0300 | INFO | [30,  4000] loss: 1.644
2025-02-24T17:48:36.902428+0300 | INFO | [30,  4100] loss: 1.661
2025-02-24T17:48:48.944001+0300 | INFO | [30,  4200] loss: 1.622
2025-02-24T17:49:01.886332+0300 | INFO | [30,  4300] loss: 1.639
2025-02-24T17:49:15.148359+0300 | INFO | [30,  4400] loss: 1.631
2025-02-24T17:49:27.872732+0300 | INFO | [30,  4500] loss: 1.642
2025-02-24T17:49:39.280351+0300 | INFO | [30,  4600] loss: 1.608
2025-02-24T17:49:51.111591+0300 | INFO | [30,  4700] loss: 1.627
2025-02-24T17:50:03.924273+0300 | INFO | [30,  4800] loss: 1.627
2025-02-24T17:50:16.255744+0300 | INFO | [30,  4900] loss: 1.618
2025-02-24T17:50:28.771773+0300 | DEBUG | Saving model to flat file storage. Save #30
2025-02-24T17:50:28.800688+0300 | INFO | Averaging client parameters
2025-02-24T17:50:28.819476+0300 | INFO | Updating parameters on client #0
2025-02-24T17:50:51.582972+0300 | DEBUG | Test set: Accuracy: 7519/10000 (75%)
2025-02-24T17:50:51.584344+0300 | DEBUG | Test set: Loss: 1.7078710794448853
2025-02-24T17:50:51.689526+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.85      0.80      1000
           1       0.90      0.89      0.90      1000
           2       0.66      0.70      0.68      1000
           3       0.53      0.75      0.62      1200
           4       0.82      0.70      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.86      0.83      1000
           7       0.72      0.88      0.80      1000
           8       0.89      0.85      0.87      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-24T17:50:51.694083+0300 | DEBUG | Confusion Matrix:
[[850  11  31  25   8   0   3  10  40  22]
 [  9 893   7   5   0   0  12   3  19  52]
 [ 79   0 705  58  47   0  53  45   3  10]
 [ 22   6  87 901  37   0  57  68   7  15]
 [ 19   2  55  79 705   0  43  84  10   3]
 [ 11   4  93 528  26   0  28  97   9   4]
 [ 10   1  50  48  12   0 860  12   3   4]
 [ 20   2  20  43  20   0   6 882   2   5]
 [ 70  19  12  16   2   0   6   6 846  23]
 [ 29  49   5  13   2   0   4  11  10 877]]
2025-02-24T17:50:51.695086+0300 | DEBUG | Class precision: [0.75960679 0.9047619  0.66197183 0.52505828 0.82072177        nan
 0.80223881 0.72413793 0.8914647  0.86403941]
2025-02-24T17:50:51.696085+0300 | DEBUG | Class recall: [0.85       0.893      0.705      0.75083333 0.705      0.
 0.86       0.882      0.846      0.877     ]
2025-02-24T17:50:51.746486+0300 | INFO | Training epoch #31 on client #0
2025-02-24T17:50:51.749983+0300 | DEBUG | Saving model to flat file storage. Save #31
2025-02-24T17:50:51.898400+0300 | INFO | [31,     0] loss: 0.016
2025-02-24T17:51:04.593369+0300 | INFO | [31,   100] loss: 1.628
2025-02-24T17:51:19.345488+0300 | INFO | [31,   200] loss: 1.602
2025-02-24T17:51:31.939353+0300 | INFO | [31,   300] loss: 1.648
2025-02-24T17:51:43.709664+0300 | INFO | [31,   400] loss: 1.621
2025-02-24T17:51:58.710984+0300 | INFO | [31,   500] loss: 1.603
2025-02-24T17:52:08.447210+0300 | INFO | [31,   600] loss: 1.628
2025-02-24T17:52:21.616658+0300 | INFO | [31,   700] loss: 1.611
2025-02-24T17:52:35.096417+0300 | INFO | [31,   800] loss: 1.633
2025-02-24T17:52:44.825005+0300 | INFO | [31,   900] loss: 1.627
2025-02-24T17:52:54.744755+0300 | INFO | [31,  1000] loss: 1.630
2025-02-24T17:53:04.759214+0300 | INFO | [31,  1100] loss: 1.643
2025-02-24T17:53:15.884701+0300 | INFO | [31,  1200] loss: 1.645
2025-02-24T17:53:25.569012+0300 | INFO | [31,  1300] loss: 1.632
2025-02-24T17:53:34.412569+0300 | INFO | [31,  1400] loss: 1.636
2025-02-24T17:53:43.033223+0300 | INFO | [31,  1500] loss: 1.636
2025-02-24T17:53:52.140891+0300 | INFO | [31,  1600] loss: 1.630
2025-02-24T17:54:01.242337+0300 | INFO | [31,  1700] loss: 1.646
2025-02-24T17:54:10.006099+0300 | INFO | [31,  1800] loss: 1.626
2025-02-24T17:54:18.432304+0300 | INFO | [31,  1900] loss: 1.631
2025-02-24T17:54:27.036713+0300 | INFO | [31,  2000] loss: 1.644
2025-02-24T17:54:37.239738+0300 | INFO | [31,  2100] loss: 1.635
2025-02-24T17:54:45.959461+0300 | INFO | [31,  2200] loss: 1.640
2025-02-24T17:54:54.535197+0300 | INFO | [31,  2300] loss: 1.630
2025-02-24T17:55:03.024347+0300 | INFO | [31,  2400] loss: 1.643
2025-02-24T17:55:11.381490+0300 | INFO | [31,  2500] loss: 1.636
2025-02-24T17:55:19.846243+0300 | INFO | [31,  2600] loss: 1.646
2025-02-24T17:55:29.527452+0300 | INFO | [31,  2700] loss: 1.629
2025-02-24T17:55:38.003720+0300 | INFO | [31,  2800] loss: 1.658
2025-02-24T17:55:46.399818+0300 | INFO | [31,  2900] loss: 1.648
2025-02-24T17:55:55.095840+0300 | INFO | [31,  3000] loss: 1.636
2025-02-24T17:56:04.132513+0300 | INFO | [31,  3100] loss: 1.627
2025-02-24T17:56:12.659399+0300 | INFO | [31,  3200] loss: 1.642
2025-02-24T17:56:22.130241+0300 | INFO | [31,  3300] loss: 1.644
2025-02-24T17:56:30.665483+0300 | INFO | [31,  3400] loss: 1.654
2025-02-24T17:56:39.192918+0300 | INFO | [31,  3500] loss: 1.618
2025-02-24T17:56:49.790308+0300 | INFO | [31,  3600] loss: 1.627
2025-02-24T17:56:59.915449+0300 | INFO | [31,  3700] loss: 1.634
2025-02-24T17:57:09.194868+0300 | INFO | [31,  3800] loss: 1.630
2025-02-24T17:57:17.535320+0300 | INFO | [31,  3900] loss: 1.628
2025-02-24T17:57:28.972108+0300 | INFO | [31,  4000] loss: 1.635
2025-02-24T17:57:41.012784+0300 | INFO | [31,  4100] loss: 1.629
2025-02-24T17:57:54.420781+0300 | INFO | [31,  4200] loss: 1.648
2025-02-24T17:58:07.784241+0300 | INFO | [31,  4300] loss: 1.610
2025-02-24T17:58:20.053206+0300 | INFO | [31,  4400] loss: 1.658
2025-02-24T17:58:29.112050+0300 | INFO | [31,  4500] loss: 1.632
2025-02-24T17:58:38.554694+0300 | INFO | [31,  4600] loss: 1.633
2025-02-24T17:58:47.462891+0300 | INFO | [31,  4700] loss: 1.621
2025-02-24T17:59:00.273501+0300 | INFO | [31,  4800] loss: 1.625
2025-02-24T17:59:13.265837+0300 | INFO | [31,  4900] loss: 1.632
2025-02-24T17:59:27.024545+0300 | DEBUG | Saving model to flat file storage. Save #31
2025-02-24T17:59:27.048565+0300 | INFO | Averaging client parameters
2025-02-24T17:59:27.055758+0300 | INFO | Updating parameters on client #0
2025-02-24T17:59:48.560436+0300 | DEBUG | Test set: Accuracy: 7508/10000 (75%)
2025-02-24T17:59:48.561428+0300 | DEBUG | Test set: Loss: 1.7101573944091797
2025-02-24T17:59:48.685629+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.83      0.80      1000
           1       0.86      0.92      0.89      1000
           2       0.66      0.70      0.68      1000
           3       0.53      0.73      0.62      1200
           4       0.69      0.81      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.83      0.84      0.84      1000
           7       0.83      0.80      0.81      1000
           8       0.83      0.91      0.87      1000
           9       0.89      0.83      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T17:59:48.687629+0300 | DEBUG | Confusion Matrix:
[[834  16  32  14   9   0   5   6  65  19]
 [  8 916   2   3   1   0   5   1  32  32]
 [ 77   4 698  55  88   0  43  17  11   7]
 [ 29   7  91 873  83   0  47  37  18  15]
 [ 13   1  39  43 814   0  35  43  10   2]
 [ 14   8 106 509  76   0  21  48  17   1]
 [ 12   2  45  49  35   0 842   4  10   1]
 [ 24   3  26  66  66   0   7 796   3   9]
 [ 35  17   8  10   2   0   3   3 907  15]
 [ 30  93   5  12   1   0   5   6  20 828]]
2025-02-24T17:59:48.690014+0300 | DEBUG | Class precision: [0.77509294 0.85848172 0.6634981  0.53427173 0.69276596        nan
 0.83119447 0.82830385 0.82982617 0.89128095]
2025-02-24T17:59:48.690014+0300 | DEBUG | Class recall: [0.834  0.916  0.698  0.7275 0.814  0.     0.842  0.796  0.907  0.828 ]
2025-02-24T17:59:48.737044+0300 | INFO | Training epoch #32 on client #0
2025-02-24T17:59:48.737044+0300 | DEBUG | Saving model to flat file storage. Save #32
2025-02-24T17:59:48.920894+0300 | INFO | [32,     0] loss: 0.015
2025-02-24T18:00:04.393668+0300 | INFO | [32,   100] loss: 1.641
2025-02-24T18:00:23.773908+0300 | INFO | [32,   200] loss: 1.637
2025-02-24T18:00:43.686100+0300 | INFO | [32,   300] loss: 1.620
2025-02-24T18:00:54.871300+0300 | INFO | [32,   400] loss: 1.646
2025-02-24T18:01:04.789104+0300 | INFO | [32,   500] loss: 1.614
2025-02-24T18:01:15.802773+0300 | INFO | [32,   600] loss: 1.631
2025-02-24T18:01:26.064603+0300 | INFO | [32,   700] loss: 1.655
2025-02-24T18:01:36.870529+0300 | INFO | [32,   800] loss: 1.617
2025-02-24T18:01:48.215941+0300 | INFO | [32,   900] loss: 1.627
2025-02-24T18:02:01.662056+0300 | INFO | [32,  1000] loss: 1.629
2025-02-24T18:02:15.783652+0300 | INFO | [32,  1100] loss: 1.627
2025-02-24T18:02:30.224028+0300 | INFO | [32,  1200] loss: 1.641
2025-02-24T18:02:41.263642+0300 | INFO | [32,  1300] loss: 1.651
2025-02-24T18:02:56.530972+0300 | INFO | [32,  1400] loss: 1.644
2025-02-24T18:03:09.423364+0300 | INFO | [32,  1500] loss: 1.603
2025-02-24T18:03:23.011501+0300 | INFO | [32,  1600] loss: 1.622
2025-02-24T18:03:36.637370+0300 | INFO | [32,  1700] loss: 1.630
2025-02-24T18:03:51.353158+0300 | INFO | [32,  1800] loss: 1.647
2025-02-24T18:04:07.127891+0300 | INFO | [32,  1900] loss: 1.643
2025-02-24T18:04:17.182298+0300 | INFO | [32,  2000] loss: 1.623
2025-02-24T18:04:32.160417+0300 | INFO | [32,  2100] loss: 1.617
2025-02-24T18:04:43.919170+0300 | INFO | [32,  2200] loss: 1.629
2025-02-24T18:04:55.913047+0300 | INFO | [32,  2300] loss: 1.638
2025-02-24T18:05:06.544760+0300 | INFO | [32,  2400] loss: 1.603
2025-02-24T18:05:18.472011+0300 | INFO | [32,  2500] loss: 1.629
2025-02-24T18:05:29.042181+0300 | INFO | [32,  2600] loss: 1.629
2025-02-24T18:05:39.906419+0300 | INFO | [32,  2700] loss: 1.644
2025-02-24T18:05:50.454881+0300 | INFO | [32,  2800] loss: 1.617
2025-02-24T18:06:00.024428+0300 | INFO | [32,  2900] loss: 1.651
2025-02-24T18:06:10.288670+0300 | INFO | [32,  3000] loss: 1.616
2025-02-24T18:06:21.019371+0300 | INFO | [32,  3100] loss: 1.630
2025-02-24T18:06:32.650215+0300 | INFO | [32,  3200] loss: 1.626
2025-02-24T18:06:44.361498+0300 | INFO | [32,  3300] loss: 1.654
2025-02-24T18:06:57.156546+0300 | INFO | [32,  3400] loss: 1.619
2025-02-24T18:07:09.504685+0300 | INFO | [32,  3500] loss: 1.633
2025-02-24T18:07:22.629093+0300 | INFO | [32,  3600] loss: 1.635
2025-02-24T18:07:34.923293+0300 | INFO | [32,  3700] loss: 1.630
2025-02-24T18:07:51.537271+0300 | INFO | [32,  3800] loss: 1.631
2025-02-24T18:08:05.430272+0300 | INFO | [32,  3900] loss: 1.625
2025-02-24T18:08:20.374927+0300 | INFO | [32,  4000] loss: 1.627
2025-02-24T18:08:34.153473+0300 | INFO | [32,  4100] loss: 1.632
2025-02-24T18:08:46.162229+0300 | INFO | [32,  4200] loss: 1.640
2025-02-24T18:09:00.647023+0300 | INFO | [32,  4300] loss: 1.631
2025-02-24T18:09:13.004521+0300 | INFO | [32,  4400] loss: 1.624
2025-02-24T18:09:25.360977+0300 | INFO | [32,  4500] loss: 1.608
2025-02-24T18:09:40.757031+0300 | INFO | [32,  4600] loss: 1.634
2025-02-24T18:09:53.903008+0300 | INFO | [32,  4700] loss: 1.632
2025-02-24T18:10:05.309172+0300 | INFO | [32,  4800] loss: 1.632
2025-02-24T18:10:17.254755+0300 | INFO | [32,  4900] loss: 1.616
2025-02-24T18:10:27.699431+0300 | DEBUG | Saving model to flat file storage. Save #32
2025-02-24T18:10:27.728542+0300 | INFO | Averaging client parameters
2025-02-24T18:10:27.738319+0300 | INFO | Updating parameters on client #0
2025-02-24T18:10:47.000470+0300 | DEBUG | Test set: Accuracy: 7437/10000 (74%)
2025-02-24T18:10:47.001995+0300 | DEBUG | Test set: Loss: 1.7168214321136475
2025-02-24T18:10:47.113253+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.87      0.78      1000
           1       0.94      0.86      0.90      1000
           2       0.64      0.73      0.68      1000
           3       0.51      0.74      0.60      1200
           4       0.81      0.71      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.87      0.82      1000
           7       0.84      0.80      0.82      1000
           8       0.91      0.80      0.85      1000
           9       0.80      0.91      0.85      1000

    accuracy                           0.74     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.74      0.72     10000

2025-02-24T18:10:47.116141+0300 | DEBUG | Confusion Matrix:
[[869   4  45  15   4   0   6   8  19  30]
 [ 19 862   5   2   1   0   7   0  15  89]
 [ 69   5 729  61  44   0  55  18   5  14]
 [ 39   4  97 885  36   0  75  32  14  18]
 [ 30   1  60  89 711   0  60  35   8   6]
 [ 22   3 103 548  28   0  34  50   5   7]
 [ 16   1  44  37  15   0 874   6   3   4]
 [ 26   1  42  73  33   0   7 795   2  21]
 [112  13  12  13   2   0   7   2 803  36]
 [ 36  23   6   8   2   0   5   4   7 909]]
2025-02-24T18:10:47.120569+0300 | DEBUG | Class precision: [0.70193861 0.94002181 0.63779528 0.51126516 0.81164384        nan
 0.77345133 0.83684211 0.91146425 0.8015873 ]
2025-02-24T18:10:47.122335+0300 | DEBUG | Class recall: [0.869  0.862  0.729  0.7375 0.711  0.     0.874  0.795  0.803  0.909 ]
2025-02-24T18:10:47.177507+0300 | INFO | Training epoch #33 on client #0
2025-02-24T18:10:47.180362+0300 | DEBUG | Saving model to flat file storage. Save #33
2025-02-24T18:10:47.335846+0300 | INFO | [33,     0] loss: 0.016
2025-02-24T18:10:58.563595+0300 | INFO | [33,   100] loss: 1.623
2025-02-24T18:11:09.800413+0300 | INFO | [33,   200] loss: 1.616
2025-02-24T18:11:21.428757+0300 | INFO | [33,   300] loss: 1.637
2025-02-24T18:11:31.967747+0300 | INFO | [33,   400] loss: 1.617
2025-02-24T18:11:42.788483+0300 | INFO | [33,   500] loss: 1.650
2025-02-24T18:11:53.835000+0300 | INFO | [33,   600] loss: 1.637
2025-02-24T18:12:04.518635+0300 | INFO | [33,   700] loss: 1.609
2025-02-24T18:12:15.397375+0300 | INFO | [33,   800] loss: 1.624
2025-02-24T18:12:26.457352+0300 | INFO | [33,   900] loss: 1.615
2025-02-24T18:12:36.721871+0300 | INFO | [33,  1000] loss: 1.631
2025-02-24T18:12:47.355895+0300 | INFO | [33,  1100] loss: 1.629
2025-02-24T18:12:58.972798+0300 | INFO | [33,  1200] loss: 1.596
2025-02-24T18:13:09.686759+0300 | INFO | [33,  1300] loss: 1.641
2025-02-24T18:13:20.408404+0300 | INFO | [33,  1400] loss: 1.624
2025-02-24T18:13:32.021462+0300 | INFO | [33,  1500] loss: 1.622
2025-02-24T18:13:42.880327+0300 | INFO | [33,  1600] loss: 1.632
2025-02-24T18:13:53.357217+0300 | INFO | [33,  1700] loss: 1.642
2025-02-24T18:14:04.278135+0300 | INFO | [33,  1800] loss: 1.624
2025-02-24T18:14:14.867343+0300 | INFO | [33,  1900] loss: 1.631
2025-02-24T18:14:25.127850+0300 | INFO | [33,  2000] loss: 1.642
2025-02-24T18:14:35.903990+0300 | INFO | [33,  2100] loss: 1.635
2025-02-24T18:14:46.771921+0300 | INFO | [33,  2200] loss: 1.615
2025-02-24T18:14:57.430902+0300 | INFO | [33,  2300] loss: 1.636
2025-02-24T18:15:08.553991+0300 | INFO | [33,  2400] loss: 1.631
2025-02-24T18:15:19.808057+0300 | INFO | [33,  2500] loss: 1.623
2025-02-24T18:15:31.204937+0300 | INFO | [33,  2600] loss: 1.628
2025-02-24T18:15:44.718225+0300 | INFO | [33,  2700] loss: 1.617
2025-02-24T18:15:56.214449+0300 | INFO | [33,  2800] loss: 1.625
2025-02-24T18:16:07.782815+0300 | INFO | [33,  2900] loss: 1.642
2025-02-24T18:16:18.331268+0300 | INFO | [33,  3000] loss: 1.629
2025-02-24T18:16:29.048054+0300 | INFO | [33,  3100] loss: 1.629
2025-02-24T18:16:40.742842+0300 | INFO | [33,  3200] loss: 1.621
2025-02-24T18:16:51.411473+0300 | INFO | [33,  3300] loss: 1.619
2025-02-24T18:17:02.315996+0300 | INFO | [33,  3400] loss: 1.620
2025-02-24T18:17:12.987555+0300 | INFO | [33,  3500] loss: 1.634
2025-02-24T18:17:23.096568+0300 | INFO | [33,  3600] loss: 1.649
2025-02-24T18:17:33.702808+0300 | INFO | [33,  3700] loss: 1.617
2025-02-24T18:17:44.679571+0300 | INFO | [33,  3800] loss: 1.629
2025-02-24T18:17:55.019274+0300 | INFO | [33,  3900] loss: 1.614
2025-02-24T18:18:08.176666+0300 | INFO | [33,  4000] loss: 1.635
2025-02-24T18:18:22.829066+0300 | INFO | [33,  4100] loss: 1.628
2025-02-24T18:18:33.556477+0300 | INFO | [33,  4200] loss: 1.621
2025-02-24T18:18:44.913870+0300 | INFO | [33,  4300] loss: 1.631
2025-02-24T18:18:56.114372+0300 | INFO | [33,  4400] loss: 1.623
2025-02-24T18:19:07.728422+0300 | INFO | [33,  4500] loss: 1.637
2025-02-24T18:19:18.881851+0300 | INFO | [33,  4600] loss: 1.648
2025-02-24T18:19:30.628070+0300 | INFO | [33,  4700] loss: 1.633
2025-02-24T18:19:41.670006+0300 | INFO | [33,  4800] loss: 1.630
2025-02-24T18:19:53.798784+0300 | INFO | [33,  4900] loss: 1.616
2025-02-24T18:20:04.782386+0300 | DEBUG | Saving model to flat file storage. Save #33
2025-02-24T18:20:04.803924+0300 | INFO | Averaging client parameters
2025-02-24T18:20:04.813922+0300 | INFO | Updating parameters on client #0
2025-02-24T18:20:22.673521+0300 | DEBUG | Test set: Accuracy: 7441/10000 (74%)
2025-02-24T18:20:22.676623+0300 | DEBUG | Test set: Loss: 1.7157530784606934
2025-02-24T18:20:22.778244+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.72      0.77      1000
           1       0.89      0.91      0.90      1000
           2       0.65      0.71      0.68      1000
           3       0.52      0.72      0.60      1200
           4       0.68      0.81      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.87      0.82      1000
           7       0.82      0.83      0.82      1000
           8       0.83      0.89      0.86      1000
           9       0.89      0.84      0.87      1000

    accuracy                           0.74     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.74      0.72     10000

2025-02-24T18:20:22.780313+0300 | DEBUG | Confusion Matrix:
[[718  12  85  23  62   0   9   6  61  24]
 [ 11 913   1   2   1   0   8   0  29  35]
 [ 35   4 715  65  80   0  58  29   7   7]
 [ 13   7  89 861  89   0  75  38  16  12]
 [  2   1  48  52 808   0  49  31   6   3]
 [ 10   5  73 554  56   0  33  60   9   0]
 [  5   1  46  39  25   0 866   7  10   1]
 [ 15   4  21  43  62   0  11 826   9   9]
 [ 33  17  19  11   7   0   6   5 892  10]
 [ 29  61   8  12   0   0   9   9  30 842]]
2025-02-24T18:20:22.782276+0300 | DEBUG | Class precision: [0.82433984 0.89073171 0.64705882 0.51805054 0.6789916         nan
 0.77046263 0.81701286 0.8344247  0.89289502]
2025-02-24T18:20:22.783245+0300 | DEBUG | Class recall: [0.718  0.913  0.715  0.7175 0.808  0.     0.866  0.826  0.892  0.842 ]
2025-02-24T18:20:22.836267+0300 | INFO | Training epoch #34 on client #0
2025-02-24T18:20:22.839279+0300 | DEBUG | Saving model to flat file storage. Save #34
2025-02-24T18:20:22.981553+0300 | INFO | [34,     0] loss: 0.016
2025-02-24T18:20:34.219633+0300 | INFO | [34,   100] loss: 1.633
2025-02-24T18:20:44.370399+0300 | INFO | [34,   200] loss: 1.622
2025-02-24T18:20:55.490132+0300 | INFO | [34,   300] loss: 1.630
2025-02-24T18:21:07.300010+0300 | INFO | [34,   400] loss: 1.643
2025-02-24T18:21:18.613853+0300 | INFO | [34,   500] loss: 1.630
2025-02-24T18:21:30.273570+0300 | INFO | [34,   600] loss: 1.645
2025-02-24T18:21:41.339146+0300 | INFO | [34,   700] loss: 1.629
2025-02-24T18:21:52.787606+0300 | INFO | [34,   800] loss: 1.635
2025-02-24T18:22:04.284396+0300 | INFO | [34,   900] loss: 1.623
2025-02-24T18:22:15.746813+0300 | INFO | [34,  1000] loss: 1.623
2025-02-24T18:22:27.885075+0300 | INFO | [34,  1100] loss: 1.620
2025-02-24T18:22:37.020054+0300 | INFO | [34,  1200] loss: 1.617
2025-02-24T18:22:47.731807+0300 | INFO | [34,  1300] loss: 1.639
2025-02-24T18:22:58.299455+0300 | INFO | [34,  1400] loss: 1.622
2025-02-24T18:23:08.921353+0300 | INFO | [34,  1500] loss: 1.634
2025-02-24T18:23:19.507541+0300 | INFO | [34,  1600] loss: 1.622
2025-02-24T18:23:29.810861+0300 | INFO | [34,  1700] loss: 1.624
2025-02-24T18:23:40.553869+0300 | INFO | [34,  1800] loss: 1.594
2025-02-24T18:23:50.256980+0300 | INFO | [34,  1900] loss: 1.624
2025-02-24T18:24:00.874673+0300 | INFO | [34,  2000] loss: 1.654
2025-02-24T18:24:12.266382+0300 | INFO | [34,  2100] loss: 1.629
2025-02-24T18:24:25.222408+0300 | INFO | [34,  2200] loss: 1.625
2025-02-24T18:24:36.275352+0300 | INFO | [34,  2300] loss: 1.630
2025-02-24T18:24:46.250285+0300 | INFO | [34,  2400] loss: 1.630
2025-02-24T18:24:56.171033+0300 | INFO | [34,  2500] loss: 1.641
2025-02-24T18:25:09.239000+0300 | INFO | [34,  2600] loss: 1.618
2025-02-24T18:25:21.386056+0300 | INFO | [34,  2700] loss: 1.632
2025-02-24T18:25:32.691351+0300 | INFO | [34,  2800] loss: 1.626
2025-02-24T18:25:42.606885+0300 | INFO | [34,  2900] loss: 1.619
2025-02-24T18:25:52.500317+0300 | INFO | [34,  3000] loss: 1.610
2025-02-24T18:26:03.446398+0300 | INFO | [34,  3100] loss: 1.641
2025-02-24T18:26:14.220525+0300 | INFO | [34,  3200] loss: 1.625
2025-02-24T18:26:24.578440+0300 | INFO | [34,  3300] loss: 1.629
2025-02-24T18:26:38.760192+0300 | INFO | [34,  3400] loss: 1.639
2025-02-24T18:26:50.369716+0300 | INFO | [34,  3500] loss: 1.646
2025-02-24T18:27:01.220299+0300 | INFO | [34,  3600] loss: 1.612
2025-02-24T18:27:11.485630+0300 | INFO | [34,  3700] loss: 1.622
2025-02-24T18:27:20.711634+0300 | INFO | [34,  3800] loss: 1.643
2025-02-24T18:27:30.546784+0300 | INFO | [34,  3900] loss: 1.616
2025-02-24T18:27:42.110970+0300 | INFO | [34,  4000] loss: 1.635
2025-02-24T18:27:55.799464+0300 | INFO | [34,  4100] loss: 1.638
2025-02-24T18:28:07.457005+0300 | INFO | [34,  4200] loss: 1.625
2025-02-24T18:28:18.413130+0300 | INFO | [34,  4300] loss: 1.617
2025-02-24T18:28:28.479623+0300 | INFO | [34,  4400] loss: 1.645
2025-02-24T18:28:39.342235+0300 | INFO | [34,  4500] loss: 1.637
2025-02-24T18:28:50.056976+0300 | INFO | [34,  4600] loss: 1.628
2025-02-24T18:29:02.308647+0300 | INFO | [34,  4700] loss: 1.610
2025-02-24T18:29:13.713541+0300 | INFO | [34,  4800] loss: 1.628
2025-02-24T18:29:24.168338+0300 | INFO | [34,  4900] loss: 1.633
2025-02-24T18:29:34.279314+0300 | DEBUG | Saving model to flat file storage. Save #34
2025-02-24T18:29:34.311580+0300 | INFO | Averaging client parameters
2025-02-24T18:29:34.319504+0300 | INFO | Updating parameters on client #0
2025-02-24T18:29:50.857466+0300 | DEBUG | Test set: Accuracy: 7517/10000 (75%)
2025-02-24T18:29:50.859981+0300 | DEBUG | Test set: Loss: 1.708722710609436
2025-02-24T18:29:50.955189+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1000
           1       0.89      0.91      0.90      1000
           2       0.75      0.66      0.70      1000
           3       0.50      0.75      0.60      1200
           4       0.73      0.77      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.72      0.90      0.80      1000
           7       0.85      0.81      0.83      1000
           8       0.88      0.86      0.87      1000
           9       0.84      0.89      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-24T18:29:50.957192+0300 | DEBUG | Confusion Matrix:
[[814  21  34  18  10   0  14  11  46  32]
 [  5 909   2   2   0   0   7   0  10  65]
 [ 54   1 661  68  85   0  89  19  11  12]
 [ 20   6  56 897  69   0  88  29  15  20]
 [ 10   1  26  70 772   0  83  30   6   2]
 [ 10   2  51 587  49   0  49  43   6   3]
 [  8   2  24  39  14   0 900   3   4   6]
 [ 12   3  17  77  54   0  16 811   3   7]
 [ 51  33   4  11   5   0   5   6 860  25]
 [ 17  44   4  12   3   0   7   5  15 893]]
2025-02-24T18:29:50.959723+0300 | DEBUG | Class precision: [0.81318681 0.88943249 0.7519909  0.50364964 0.72761546        nan
 0.7154213  0.84743992 0.88114754 0.83849765]
2025-02-24T18:29:50.961721+0300 | DEBUG | Class recall: [0.814  0.909  0.661  0.7475 0.772  0.     0.9    0.811  0.86   0.893 ]
2025-02-24T18:29:51.019178+0300 | INFO | Training epoch #35 on client #0
2025-02-24T18:29:51.020189+0300 | DEBUG | Saving model to flat file storage. Save #35
2025-02-24T18:29:51.164615+0300 | INFO | [35,     0] loss: 0.017
2025-02-24T18:30:02.168576+0300 | INFO | [35,   100] loss: 1.629
2025-02-24T18:30:12.033599+0300 | INFO | [35,   200] loss: 1.627
2025-02-24T18:30:23.226619+0300 | INFO | [35,   300] loss: 1.636
2025-02-24T18:30:33.005962+0300 | INFO | [35,   400] loss: 1.628
2025-02-24T18:30:45.074687+0300 | INFO | [35,   500] loss: 1.614
2025-02-24T18:30:58.184348+0300 | INFO | [35,   600] loss: 1.641
2025-02-24T18:31:09.962452+0300 | INFO | [35,   700] loss: 1.624
2025-02-24T18:31:20.276874+0300 | INFO | [35,   800] loss: 1.617
2025-02-24T18:31:30.907721+0300 | INFO | [35,   900] loss: 1.615
2025-02-24T18:31:40.304577+0300 | INFO | [35,  1000] loss: 1.616
2025-02-24T18:31:51.308320+0300 | INFO | [35,  1100] loss: 1.627
2025-02-24T18:32:02.073394+0300 | INFO | [35,  1200] loss: 1.643
2025-02-24T18:32:12.712315+0300 | INFO | [35,  1300] loss: 1.618
2025-02-24T18:32:25.006094+0300 | INFO | [35,  1400] loss: 1.627
2025-02-24T18:32:36.170664+0300 | INFO | [35,  1500] loss: 1.622
2025-02-24T18:32:49.460734+0300 | INFO | [35,  1600] loss: 1.633
2025-02-24T18:33:03.161485+0300 | INFO | [35,  1700] loss: 1.617
2025-02-24T18:33:13.934152+0300 | INFO | [35,  1800] loss: 1.629
2025-02-24T18:33:26.173636+0300 | INFO | [35,  1900] loss: 1.617
2025-02-24T18:33:38.740815+0300 | INFO | [35,  2000] loss: 1.626
2025-02-24T18:33:51.301654+0300 | INFO | [35,  2100] loss: 1.633
2025-02-24T18:34:03.220252+0300 | INFO | [35,  2200] loss: 1.626
2025-02-24T18:34:15.121429+0300 | INFO | [35,  2300] loss: 1.642
2025-02-24T18:34:26.306432+0300 | INFO | [35,  2400] loss: 1.623
2025-02-24T18:34:39.126983+0300 | INFO | [35,  2500] loss: 1.619
2025-02-24T18:34:51.548236+0300 | INFO | [35,  2600] loss: 1.631
2025-02-24T18:35:04.148692+0300 | INFO | [35,  2700] loss: 1.631
2025-02-24T18:35:20.230825+0300 | INFO | [35,  2800] loss: 1.638
2025-02-24T18:35:35.411305+0300 | INFO | [35,  2900] loss: 1.646
2025-02-24T18:35:47.776585+0300 | INFO | [35,  3000] loss: 1.613
2025-02-24T18:36:01.648323+0300 | INFO | [35,  3100] loss: 1.640
2025-02-24T18:36:13.740701+0300 | INFO | [35,  3200] loss: 1.626
2025-02-24T18:36:28.059761+0300 | INFO | [35,  3300] loss: 1.625
2025-02-24T18:36:40.360074+0300 | INFO | [35,  3400] loss: 1.628
2025-02-24T18:36:50.857058+0300 | INFO | [35,  3500] loss: 1.615
2025-02-24T18:37:00.651313+0300 | INFO | [35,  3600] loss: 1.625
2025-02-24T18:37:11.924440+0300 | INFO | [35,  3700] loss: 1.645
2025-02-24T18:37:23.707639+0300 | INFO | [35,  3800] loss: 1.631
2025-02-24T18:37:37.780357+0300 | INFO | [35,  3900] loss: 1.643
2025-02-24T18:37:49.731366+0300 | INFO | [35,  4000] loss: 1.635
2025-02-24T18:38:00.376452+0300 | INFO | [35,  4100] loss: 1.623
2025-02-24T18:38:10.928459+0300 | INFO | [35,  4200] loss: 1.622
2025-02-24T18:38:20.698301+0300 | INFO | [35,  4300] loss: 1.614
2025-02-24T18:38:32.007405+0300 | INFO | [35,  4400] loss: 1.625
2025-02-24T18:38:42.154571+0300 | INFO | [35,  4500] loss: 1.620
2025-02-24T18:38:54.578232+0300 | INFO | [35,  4600] loss: 1.638
2025-02-24T18:39:09.048486+0300 | INFO | [35,  4700] loss: 1.615
2025-02-24T18:39:20.592376+0300 | INFO | [35,  4800] loss: 1.631
2025-02-24T18:39:30.806222+0300 | INFO | [35,  4900] loss: 1.614
2025-02-24T18:39:42.242561+0300 | DEBUG | Saving model to flat file storage. Save #35
2025-02-24T18:39:42.274219+0300 | INFO | Averaging client parameters
2025-02-24T18:39:42.285328+0300 | INFO | Updating parameters on client #0
2025-02-24T18:40:02.325303+0300 | DEBUG | Test set: Accuracy: 7462/10000 (75%)
2025-02-24T18:40:02.326305+0300 | DEBUG | Test set: Loss: 1.7130259275436401
2025-02-24T18:40:02.438640+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.82      0.80      1000
           1       0.89      0.91      0.90      1000
           2       0.68      0.68      0.68      1000
           3       0.50      0.72      0.59      1200
           4       0.78      0.74      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.67      0.91      0.77      1000
           7       0.85      0.80      0.82      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.85      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T18:40:02.444193+0300 | DEBUG | Confusion Matrix:
[[822  14  31  24  11   0  12   5  50  31]
 [  6 913   3   5   0   0  17   2  14  40]
 [ 75   1 680  76  49   0  96  14   3   6]
 [ 26   3  74 865  48   0 128  35  10  11]
 [ 16   1  64  72 742   0  80  21   4   0]
 [ 12   4  81 546  32   0  70  48   6   1]
 [ 12   0  29  33  11   0 909   4   2   0]
 [ 14   1  29  74  48   0  24 796   4  10]
 [ 43  20   6  12   2   0   6   3 889  19]
 [ 28  71   4  15   3   0  12   3  18 846]]
2025-02-24T18:40:02.451858+0300 | DEBUG | Class precision: [0.77988615 0.8881323  0.67932068 0.50232288 0.78435518        nan
 0.67134417 0.85499463 0.889      0.87759336]
2025-02-24T18:40:02.453813+0300 | DEBUG | Class recall: [0.822      0.913      0.68       0.72083333 0.742      0.
 0.909      0.796      0.889      0.846     ]
2025-02-24T18:40:02.530569+0300 | INFO | Training epoch #36 on client #0
2025-02-24T18:40:02.531578+0300 | DEBUG | Saving model to flat file storage. Save #36
2025-02-24T18:40:02.748519+0300 | INFO | [36,     0] loss: 0.015
2025-02-24T18:40:14.250276+0300 | INFO | [36,   100] loss: 1.632
2025-02-24T18:40:26.731092+0300 | INFO | [36,   200] loss: 1.619
2025-02-24T18:40:39.752213+0300 | INFO | [36,   300] loss: 1.625
2025-02-24T18:40:51.128348+0300 | INFO | [36,   400] loss: 1.624
2025-02-24T18:41:03.263164+0300 | INFO | [36,   500] loss: 1.605
2025-02-24T18:41:15.168249+0300 | INFO | [36,   600] loss: 1.620
2025-02-24T18:41:26.469731+0300 | INFO | [36,   700] loss: 1.600
2025-02-24T18:41:37.621646+0300 | INFO | [36,   800] loss: 1.625
2025-02-24T18:41:50.800896+0300 | INFO | [36,   900] loss: 1.622
2025-02-24T18:42:02.907476+0300 | INFO | [36,  1000] loss: 1.614
2025-02-24T18:42:12.869682+0300 | INFO | [36,  1100] loss: 1.625
2025-02-24T18:42:24.844201+0300 | INFO | [36,  1200] loss: 1.626
2025-02-24T18:42:36.363116+0300 | INFO | [36,  1300] loss: 1.624
2025-02-24T18:42:48.700790+0300 | INFO | [36,  1400] loss: 1.598
2025-02-24T18:42:59.839991+0300 | INFO | [36,  1500] loss: 1.623
2025-02-24T18:43:13.228243+0300 | INFO | [36,  1600] loss: 1.617
2025-02-24T18:43:25.859344+0300 | INFO | [36,  1700] loss: 1.623
2025-02-24T18:43:39.327865+0300 | INFO | [36,  1800] loss: 1.643
2025-02-24T18:43:51.173833+0300 | INFO | [36,  1900] loss: 1.634
2025-02-24T18:44:01.390212+0300 | INFO | [36,  2000] loss: 1.631
2025-02-24T18:44:14.366468+0300 | INFO | [36,  2100] loss: 1.647
2025-02-24T18:44:28.357603+0300 | INFO | [36,  2200] loss: 1.626
2025-02-24T18:44:41.625419+0300 | INFO | [36,  2300] loss: 1.636
2025-02-24T18:44:51.598495+0300 | INFO | [36,  2400] loss: 1.650
2025-02-24T18:45:02.240270+0300 | INFO | [36,  2500] loss: 1.658
2025-02-24T18:45:13.703583+0300 | INFO | [36,  2600] loss: 1.622
2025-02-24T18:45:26.890166+0300 | INFO | [36,  2700] loss: 1.614
2025-02-24T18:45:38.705711+0300 | INFO | [36,  2800] loss: 1.620
2025-02-24T18:45:51.501773+0300 | INFO | [36,  2900] loss: 1.631
2025-02-24T18:46:06.759957+0300 | INFO | [36,  3000] loss: 1.612
2025-02-24T18:46:20.199534+0300 | INFO | [36,  3100] loss: 1.656
2025-02-24T18:46:33.893743+0300 | INFO | [36,  3200] loss: 1.650
2025-02-24T18:46:47.800302+0300 | INFO | [36,  3300] loss: 1.636
2025-02-24T18:46:58.395292+0300 | INFO | [36,  3400] loss: 1.629
2025-02-24T18:47:09.637751+0300 | INFO | [36,  3500] loss: 1.618
2025-02-24T18:47:20.308647+0300 | INFO | [36,  3600] loss: 1.626
2025-02-24T18:47:33.439782+0300 | INFO | [36,  3700] loss: 1.625
2025-02-24T18:47:46.760121+0300 | INFO | [36,  3800] loss: 1.608
2025-02-24T18:47:58.916504+0300 | INFO | [36,  3900] loss: 1.607
2025-02-24T18:48:12.737520+0300 | INFO | [36,  4000] loss: 1.616
2025-02-24T18:48:25.360811+0300 | INFO | [36,  4100] loss: 1.630
2025-02-24T18:48:36.792666+0300 | INFO | [36,  4200] loss: 1.640
2025-02-24T18:48:47.911061+0300 | INFO | [36,  4300] loss: 1.639
2025-02-24T18:48:58.268977+0300 | INFO | [36,  4400] loss: 1.631
2025-02-24T18:49:08.625011+0300 | INFO | [36,  4500] loss: 1.632
2025-02-24T18:49:19.008221+0300 | INFO | [36,  4600] loss: 1.612
2025-02-24T18:49:29.444796+0300 | INFO | [36,  4700] loss: 1.632
2025-02-24T18:49:44.054512+0300 | INFO | [36,  4800] loss: 1.621
2025-02-24T18:49:57.800615+0300 | INFO | [36,  4900] loss: 1.644
2025-02-24T18:50:12.017117+0300 | DEBUG | Saving model to flat file storage. Save #36
2025-02-24T18:50:12.077333+0300 | INFO | Averaging client parameters
2025-02-24T18:50:12.094538+0300 | INFO | Updating parameters on client #0
2025-02-24T18:50:36.085693+0300 | DEBUG | Test set: Accuracy: 7522/10000 (75%)
2025-02-24T18:50:36.086706+0300 | DEBUG | Test set: Loss: 1.7080976963043213
2025-02-24T18:50:36.180244+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.80      1000
           1       0.87      0.94      0.90      1000
           2       0.70      0.67      0.69      1000
           3       0.50      0.77      0.61      1200
           4       0.73      0.81      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.85      0.82      1000
           7       0.81      0.83      0.82      1000
           8       0.90      0.84      0.87      1000
           9       0.92      0.81      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.71     10000
weighted avg       0.71      0.75      0.73     10000

2025-02-24T18:50:36.181289+0300 | DEBUG | Confusion Matrix:
[[847  14  41  23  16   0   6   6  32  15]
 [ 11 936   2   6   0   0   6   3  10  26]
 [ 70   5 674  83  80   0  59  25   1   3]
 [ 16   7  73 927  67   0  55  40   8   7]
 [ 12   1  36  61 807   0  48  30   5   0]
 [  7   3  74 579  43   0  24  64   5   1]
 [ 18   2  33  60  25   0 851   7   4   0]
 [ 15   1  14  72  55   0  10 828   3   2]
 [ 76  24  12  21   8   0   3   5 838  13]
 [ 34  85   6  19   5   0   7   8  22 814]]
2025-02-24T18:50:36.182681+0300 | DEBUG | Class precision: [0.76582278 0.86827458 0.6984456  0.50081037 0.72965642        nan
 0.79607109 0.81496063 0.90301724 0.92395006]
2025-02-24T18:50:36.184693+0300 | DEBUG | Class recall: [0.847  0.936  0.674  0.7725 0.807  0.     0.851  0.828  0.838  0.814 ]
2025-02-24T18:50:36.251252+0300 | INFO | Training epoch #37 on client #0
2025-02-24T18:50:36.252253+0300 | DEBUG | Saving model to flat file storage. Save #37
2025-02-24T18:50:36.459551+0300 | INFO | [37,     0] loss: 0.018
2025-02-24T18:50:50.431116+0300 | INFO | [37,   100] loss: 1.630
2025-02-24T18:51:03.698051+0300 | INFO | [37,   200] loss: 1.613
2025-02-24T18:51:17.453387+0300 | INFO | [37,   300] loss: 1.616
2025-02-24T18:51:30.887603+0300 | INFO | [37,   400] loss: 1.621
2025-02-24T18:51:42.666101+0300 | INFO | [37,   500] loss: 1.621
2025-02-24T18:51:53.799732+0300 | INFO | [37,   600] loss: 1.632
2025-02-24T18:52:04.025866+0300 | INFO | [37,   700] loss: 1.637
2025-02-24T18:52:14.668270+0300 | INFO | [37,   800] loss: 1.609
2025-02-24T18:52:24.638071+0300 | INFO | [37,   900] loss: 1.646
2025-02-24T18:52:34.574108+0300 | INFO | [37,  1000] loss: 1.619
2025-02-24T18:52:44.884779+0300 | INFO | [37,  1100] loss: 1.616
2025-02-24T18:52:55.033646+0300 | INFO | [37,  1200] loss: 1.624
2025-02-24T18:53:05.209237+0300 | INFO | [37,  1300] loss: 1.620
2025-02-24T18:53:15.711048+0300 | INFO | [37,  1400] loss: 1.606
2025-02-24T18:53:25.681515+0300 | INFO | [37,  1500] loss: 1.616
2025-02-24T18:53:40.123212+0300 | INFO | [37,  1600] loss: 1.634
2025-02-24T18:53:52.082267+0300 | INFO | [37,  1700] loss: 1.626
2025-02-24T18:54:02.338031+0300 | INFO | [37,  1800] loss: 1.648
2025-02-24T18:54:13.052117+0300 | INFO | [37,  1900] loss: 1.599
2025-02-24T18:54:23.338706+0300 | INFO | [37,  2000] loss: 1.624
2025-02-24T18:54:33.757778+0300 | INFO | [37,  2100] loss: 1.625
2025-02-24T18:54:44.352824+0300 | INFO | [37,  2200] loss: 1.640
2025-02-24T18:54:55.039588+0300 | INFO | [37,  2300] loss: 1.635
2025-02-24T18:55:05.693434+0300 | INFO | [37,  2400] loss: 1.633
2025-02-24T18:55:16.395187+0300 | INFO | [37,  2500] loss: 1.629
2025-02-24T18:55:26.914662+0300 | INFO | [37,  2600] loss: 1.618
2025-02-24T18:55:37.556317+0300 | INFO | [37,  2700] loss: 1.615
2025-02-24T18:55:48.180011+0300 | INFO | [37,  2800] loss: 1.625
2025-02-24T18:55:58.634884+0300 | INFO | [37,  2900] loss: 1.614
2025-02-24T18:56:09.287150+0300 | INFO | [37,  3000] loss: 1.632
2025-02-24T18:56:20.068755+0300 | INFO | [37,  3100] loss: 1.617
2025-02-24T18:56:30.646924+0300 | INFO | [37,  3200] loss: 1.631
2025-02-24T18:56:41.267539+0300 | INFO | [37,  3300] loss: 1.626
2025-02-24T18:56:52.319675+0300 | INFO | [37,  3400] loss: 1.625
2025-02-24T18:57:02.937159+0300 | INFO | [37,  3500] loss: 1.616
2025-02-24T18:57:13.549138+0300 | INFO | [37,  3600] loss: 1.628
2025-02-24T18:57:24.326241+0300 | INFO | [37,  3700] loss: 1.629
2025-02-24T18:57:35.061376+0300 | INFO | [37,  3800] loss: 1.630
2025-02-24T18:57:45.652321+0300 | INFO | [37,  3900] loss: 1.627
2025-02-24T18:57:56.400157+0300 | INFO | [37,  4000] loss: 1.636
2025-02-24T18:58:07.126033+0300 | INFO | [37,  4100] loss: 1.604
2025-02-24T18:58:17.575074+0300 | INFO | [37,  4200] loss: 1.627
2025-02-24T18:58:28.269523+0300 | INFO | [37,  4300] loss: 1.628
2025-02-24T18:58:38.931875+0300 | INFO | [37,  4400] loss: 1.639
2025-02-24T18:58:49.647100+0300 | INFO | [37,  4500] loss: 1.611
2025-02-24T18:59:00.296095+0300 | INFO | [37,  4600] loss: 1.648
2025-02-24T18:59:11.018431+0300 | INFO | [37,  4700] loss: 1.614
2025-02-24T18:59:21.612621+0300 | INFO | [37,  4800] loss: 1.619
2025-02-24T18:59:32.279912+0300 | INFO | [37,  4900] loss: 1.620
2025-02-24T18:59:42.678761+0300 | DEBUG | Saving model to flat file storage. Save #37
2025-02-24T18:59:42.698716+0300 | INFO | Averaging client parameters
2025-02-24T18:59:42.707425+0300 | INFO | Updating parameters on client #0
2025-02-24T18:59:59.117505+0300 | DEBUG | Test set: Accuracy: 7520/10000 (75%)
2025-02-24T18:59:59.119941+0300 | DEBUG | Test set: Loss: 1.708060383796692
2025-02-24T18:59:59.218434+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.81      0.81      1000
           1       0.91      0.87      0.89      1000
           2       0.77      0.62      0.68      1000
           3       0.51      0.76      0.61      1200
           4       0.72      0.81      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.88      0.82      1000
           7       0.80      0.84      0.82      1000
           8       0.89      0.86      0.88      1000
           9       0.80      0.92      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-24T18:59:59.220430+0300 | DEBUG | Confusion Matrix:
[[812  13  37  13  16   0  13  14  41  41]
 [  9 872   4   2   1   0   7   2  10  93]
 [ 72   6 616  83  87   0  76  30   9  21]
 [ 16  10  45 906  79   0  76  40   7  21]
 [ 14   3  21  59 812   0  37  42  10   2]
 [  8   4  48 574  45   0  42  66  10   3]
 [  9   2  20  43  31   0 880   5   5   5]
 [ 10   3   6  62  51   0  14 838   3  13]
 [ 49  22   6  11   7   0   6   5 864  30]
 [ 16  25   2   8   2   0   8   7  12 920]]
2025-02-24T18:59:59.221433+0300 | DEBUG | Class precision: [0.8        0.90833333 0.76521739 0.51448041 0.71794872        nan
 0.75927524 0.79885605 0.88980433 0.80069626]
2025-02-24T18:59:59.222432+0300 | DEBUG | Class recall: [0.812 0.872 0.616 0.755 0.812 0.    0.88  0.838 0.864 0.92 ]
2025-02-24T18:59:59.271934+0300 | INFO | Training epoch #38 on client #0
2025-02-24T18:59:59.272934+0300 | DEBUG | Saving model to flat file storage. Save #38
2025-02-24T18:59:59.412038+0300 | INFO | [38,     0] loss: 0.019
2025-02-24T19:00:10.198492+0300 | INFO | [38,   100] loss: 1.621
2025-02-24T19:00:20.970183+0300 | INFO | [38,   200] loss: 1.621
2025-02-24T19:00:31.560209+0300 | INFO | [38,   300] loss: 1.613
2025-02-24T19:00:41.813973+0300 | INFO | [38,   400] loss: 1.606
2025-02-24T19:00:52.625026+0300 | INFO | [38,   500] loss: 1.627
2025-02-24T19:01:02.967728+0300 | INFO | [38,   600] loss: 1.613
2025-02-24T19:01:13.586948+0300 | INFO | [38,   700] loss: 1.601
2025-02-24T19:01:24.212778+0300 | INFO | [38,   800] loss: 1.620
2025-02-24T19:01:34.719927+0300 | INFO | [38,   900] loss: 1.603
2025-02-24T19:01:49.420896+0300 | INFO | [38,  1000] loss: 1.608
2025-02-24T19:02:00.382324+0300 | INFO | [38,  1100] loss: 1.608
2025-02-24T19:02:11.158552+0300 | INFO | [38,  1200] loss: 1.619
2025-02-24T19:02:21.698486+0300 | INFO | [38,  1300] loss: 1.621
2025-02-24T19:02:32.204146+0300 | INFO | [38,  1400] loss: 1.621
2025-02-24T19:02:42.977737+0300 | INFO | [38,  1500] loss: 1.617
2025-02-24T19:02:53.501414+0300 | INFO | [38,  1600] loss: 1.631
2025-02-24T19:03:04.706151+0300 | INFO | [38,  1700] loss: 1.631
2025-02-24T19:03:15.407028+0300 | INFO | [38,  1800] loss: 1.633
2025-02-24T19:03:25.907059+0300 | INFO | [38,  1900] loss: 1.617
2025-02-24T19:03:36.283305+0300 | INFO | [38,  2000] loss: 1.641
2025-02-24T19:03:46.966690+0300 | INFO | [38,  2100] loss: 1.602
2025-02-24T19:03:57.306178+0300 | INFO | [38,  2200] loss: 1.624
2025-02-24T19:04:07.871987+0300 | INFO | [38,  2300] loss: 1.628
2025-02-24T19:04:18.504512+0300 | INFO | [38,  2400] loss: 1.630
2025-02-24T19:04:28.975573+0300 | INFO | [38,  2500] loss: 1.627
2025-02-24T19:04:39.456008+0300 | INFO | [38,  2600] loss: 1.611
2025-02-24T19:04:50.092430+0300 | INFO | [38,  2700] loss: 1.632
2025-02-24T19:05:00.581696+0300 | INFO | [38,  2800] loss: 1.622
2025-02-24T19:05:11.197269+0300 | INFO | [38,  2900] loss: 1.636
2025-02-24T19:05:22.269886+0300 | INFO | [38,  3000] loss: 1.622
2025-02-24T19:05:33.545339+0300 | INFO | [38,  3100] loss: 1.637
2025-02-24T19:05:44.551127+0300 | INFO | [38,  3200] loss: 1.616
2025-02-24T19:05:55.770511+0300 | INFO | [38,  3300] loss: 1.619
2025-02-24T19:06:07.086169+0300 | INFO | [38,  3400] loss: 1.631
2025-02-24T19:06:18.542620+0300 | INFO | [38,  3500] loss: 1.638
2025-02-24T19:06:29.566736+0300 | INFO | [38,  3600] loss: 1.625
2025-02-24T19:06:40.733430+0300 | INFO | [38,  3700] loss: 1.604
2025-02-24T19:06:51.378506+0300 | INFO | [38,  3800] loss: 1.626
2025-02-24T19:07:02.582918+0300 | INFO | [38,  3900] loss: 1.621
2025-02-24T19:07:13.866541+0300 | INFO | [38,  4000] loss: 1.619
2025-02-24T19:07:25.126628+0300 | INFO | [38,  4100] loss: 1.615
2025-02-24T19:07:36.427601+0300 | INFO | [38,  4200] loss: 1.616
2025-02-24T19:07:48.286771+0300 | INFO | [38,  4300] loss: 1.623
2025-02-24T19:07:59.551257+0300 | INFO | [38,  4400] loss: 1.619
2025-02-24T19:08:10.591922+0300 | INFO | [38,  4500] loss: 1.640
2025-02-24T19:08:21.616417+0300 | INFO | [38,  4600] loss: 1.618
2025-02-24T19:08:32.370253+0300 | INFO | [38,  4700] loss: 1.615
2025-02-24T19:08:42.805017+0300 | INFO | [38,  4800] loss: 1.648
2025-02-24T19:08:53.426529+0300 | INFO | [38,  4900] loss: 1.602
2025-02-24T19:09:04.144638+0300 | DEBUG | Saving model to flat file storage. Save #38
2025-02-24T19:09:04.175529+0300 | INFO | Averaging client parameters
2025-02-24T19:09:04.183346+0300 | INFO | Updating parameters on client #0
2025-02-24T19:09:19.942523+0300 | DEBUG | Test set: Accuracy: 7573/10000 (76%)
2025-02-24T19:09:19.944525+0300 | DEBUG | Test set: Loss: 1.7032052278518677
2025-02-24T19:09:20.042025+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.79      0.80      1000
           1       0.88      0.93      0.91      1000
           2       0.66      0.70      0.68      1000
           3       0.52      0.77      0.62      1200
           4       0.76      0.79      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.88      0.83      1000
           7       0.80      0.83      0.82      1000
           8       0.88      0.89      0.88      1000
           9       0.91      0.84      0.87      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T19:09:20.044025+0300 | DEBUG | Confusion Matrix:
[[788  18  60  18  23   0  12  10  52  19]
 [  7 931   3   3   1   0  11   1  13  30]
 [ 50   4 705  79  65   0  64  24   6   3]
 [ 17   9  89 920  45   0  59  41  12   8]
 [ 11   0  53  71 785   0  42  32   5   1]
 [ 10   5  83 549  39   0  26  81   6   1]
 [  6   1  36  47  18   0 879   8   2   3]
 [ 16   2  22  70  47   0   6 834   1   2]
 [ 33  18  15  11   6   0   5   4 892  16]
 [ 28  65   9  16   2   0   4   9  28 839]]
2025-02-24T19:09:20.045023+0300 | DEBUG | Class precision: [0.81573499 0.88414055 0.65581395 0.51569507 0.7613967         nan
 0.7933213  0.79885057 0.87708948 0.90997831]
2025-02-24T19:09:20.047033+0300 | DEBUG | Class recall: [0.788      0.931      0.705      0.76666667 0.785      0.
 0.879      0.834      0.892      0.839     ]
2025-02-24T19:09:20.104833+0300 | INFO | Training epoch #39 on client #0
2025-02-24T19:09:20.107831+0300 | DEBUG | Saving model to flat file storage. Save #39
2025-02-24T19:09:20.237427+0300 | INFO | [39,     0] loss: 0.016
2025-02-24T19:09:31.034771+0300 | INFO | [39,   100] loss: 1.608
2025-02-24T19:09:41.564070+0300 | INFO | [39,   200] loss: 1.611
2025-02-24T19:09:52.471194+0300 | INFO | [39,   300] loss: 1.619
2025-02-24T19:10:07.674793+0300 | INFO | [39,   400] loss: 1.605
2025-02-24T19:10:17.834074+0300 | INFO | [39,   500] loss: 1.613
2025-02-24T19:10:31.041079+0300 | INFO | [39,   600] loss: 1.621
2025-02-24T19:10:41.725426+0300 | INFO | [39,   700] loss: 1.615
2025-02-24T19:10:52.255402+0300 | INFO | [39,   800] loss: 1.620
2025-02-24T19:11:02.888980+0300 | INFO | [39,   900] loss: 1.628
2025-02-24T19:11:13.433782+0300 | INFO | [39,  1000] loss: 1.637
2025-02-24T19:11:23.909782+0300 | INFO | [39,  1100] loss: 1.623
2025-02-24T19:11:34.430694+0300 | INFO | [39,  1200] loss: 1.635
2025-02-24T19:11:45.261902+0300 | INFO | [39,  1300] loss: 1.613
2025-02-24T19:11:55.756697+0300 | INFO | [39,  1400] loss: 1.627
2025-02-24T19:12:06.305483+0300 | INFO | [39,  1500] loss: 1.602
2025-02-24T19:12:17.020188+0300 | INFO | [39,  1600] loss: 1.632
2025-02-24T19:12:27.578014+0300 | INFO | [39,  1700] loss: 1.616
2025-02-24T19:12:38.735001+0300 | INFO | [39,  1800] loss: 1.602
2025-02-24T19:12:49.449506+0300 | INFO | [39,  1900] loss: 1.616
2025-02-24T19:12:59.392784+0300 | INFO | [39,  2000] loss: 1.632
2025-02-24T19:13:08.967819+0300 | INFO | [39,  2100] loss: 1.633
2025-02-24T19:13:19.552489+0300 | INFO | [39,  2200] loss: 1.591
2025-02-24T19:13:30.155501+0300 | INFO | [39,  2300] loss: 1.614
2025-02-24T19:13:40.940110+0300 | INFO | [39,  2400] loss: 1.637
2025-02-24T19:13:51.772624+0300 | INFO | [39,  2500] loss: 1.614
2025-02-24T19:14:02.260302+0300 | INFO | [39,  2600] loss: 1.620
2025-02-24T19:14:12.958618+0300 | INFO | [39,  2700] loss: 1.604
2025-02-24T19:14:23.586311+0300 | INFO | [39,  2800] loss: 1.618
2025-02-24T19:14:34.321663+0300 | INFO | [39,  2900] loss: 1.616
2025-02-24T19:14:44.809921+0300 | INFO | [39,  3000] loss: 1.618
2025-02-24T19:14:55.086755+0300 | INFO | [39,  3100] loss: 1.635
2025-02-24T19:15:05.499510+0300 | INFO | [39,  3200] loss: 1.621
2025-02-24T19:15:16.157674+0300 | INFO | [39,  3300] loss: 1.620
2025-02-24T19:15:26.293362+0300 | INFO | [39,  3400] loss: 1.612
2025-02-24T19:15:36.839673+0300 | INFO | [39,  3500] loss: 1.615
2025-02-24T19:15:49.026852+0300 | INFO | [39,  3600] loss: 1.633
2025-02-24T19:16:01.198235+0300 | INFO | [39,  3700] loss: 1.623
2025-02-24T19:16:12.526973+0300 | INFO | [39,  3800] loss: 1.609
2025-02-24T19:16:23.325262+0300 | INFO | [39,  3900] loss: 1.627
2025-02-24T19:16:37.742823+0300 | INFO | [39,  4000] loss: 1.620
2025-02-24T19:16:52.854378+0300 | INFO | [39,  4100] loss: 1.615
2025-02-24T19:17:07.492013+0300 | INFO | [39,  4200] loss: 1.624
2025-02-24T19:17:22.068635+0300 | INFO | [39,  4300] loss: 1.609
2025-02-24T19:17:36.722860+0300 | INFO | [39,  4400] loss: 1.622
2025-02-24T19:17:51.763166+0300 | INFO | [39,  4500] loss: 1.615
2025-02-24T19:18:06.996348+0300 | INFO | [39,  4600] loss: 1.610
2025-02-24T19:18:22.417396+0300 | INFO | [39,  4700] loss: 1.617
2025-02-24T19:18:38.051144+0300 | INFO | [39,  4800] loss: 1.626
2025-02-24T19:19:01.326321+0300 | INFO | [39,  4900] loss: 1.625
2025-02-24T19:19:16.111020+0300 | DEBUG | Saving model to flat file storage. Save #39
2025-02-24T19:19:16.136020+0300 | INFO | Averaging client parameters
2025-02-24T19:19:16.151400+0300 | INFO | Updating parameters on client #0
2025-02-24T19:19:33.505525+0300 | DEBUG | Test set: Accuracy: 7569/10000 (76%)
2025-02-24T19:19:33.507521+0300 | DEBUG | Test set: Loss: 1.7034132480621338
2025-02-24T19:19:33.604761+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.86      0.80      1000
           1       0.89      0.92      0.90      1000
           2       0.81      0.60      0.69      1000
           3       0.52      0.72      0.60      1200
           4       0.73      0.80      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.89      0.82      1000
           7       0.76      0.88      0.81      1000
           8       0.89      0.87      0.88      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T19:19:33.608212+0300 | DEBUG | Confusion Matrix:
[[861  15  18  13  12   0   5  13  39  24]
 [  9 917   1   3   1   0   5   0  15  49]
 [ 84   4 597  78 100   0  83  38   9   7]
 [ 35  12  42 867  73   0  84  60  10  17]
 [ 22   1  18  53 804   0  39  53   4   6]
 [ 12   5  38 564  50   0  35  88   7   1]
 [ 14   5  14  37  25   0 890  11   2   2]
 [ 22   2   2  42  37   0   8 876   2   9]
 [ 61  23   7  10   3   0   5   6 872  13]
 [ 25  51   2   8   1   0   4   9  15 885]]
2025-02-24T19:19:33.609208+0300 | DEBUG | Class precision: [0.75196507 0.88599034 0.80784844 0.51761194 0.72694394        nan
 0.76856649 0.75909879 0.89435897 0.87364265]
2025-02-24T19:19:33.609208+0300 | DEBUG | Class recall: [0.861  0.917  0.597  0.7225 0.804  0.     0.89   0.876  0.872  0.885 ]
2025-02-24T19:19:33.660561+0300 | INFO | Training epoch #40 on client #0
2025-02-24T19:19:33.662596+0300 | DEBUG | Saving model to flat file storage. Save #40
2025-02-24T19:19:33.787166+0300 | INFO | [40,     0] loss: 0.017
2025-02-24T19:19:45.126226+0300 | INFO | [40,   100] loss: 1.620
2025-02-24T19:19:55.703938+0300 | INFO | [40,   200] loss: 1.599
2025-02-24T19:20:06.040393+0300 | INFO | [40,   300] loss: 1.622
2025-02-24T19:20:16.763144+0300 | INFO | [40,   400] loss: 1.634
2025-02-24T19:20:27.469386+0300 | INFO | [40,   500] loss: 1.588
2025-02-24T19:20:37.946580+0300 | INFO | [40,   600] loss: 1.615
2025-02-24T19:20:48.596508+0300 | INFO | [40,   700] loss: 1.591
2025-02-24T19:20:59.451849+0300 | INFO | [40,   800] loss: 1.605
2025-02-24T19:21:10.255822+0300 | INFO | [40,   900] loss: 1.628
2025-02-24T19:21:20.714169+0300 | INFO | [40,  1000] loss: 1.611
2025-02-24T19:21:31.305141+0300 | INFO | [40,  1100] loss: 1.598
2025-02-24T19:21:41.946219+0300 | INFO | [40,  1200] loss: 1.612
2025-02-24T19:21:52.846201+0300 | INFO | [40,  1300] loss: 1.630
2025-02-24T19:22:03.674160+0300 | INFO | [40,  1400] loss: 1.629
2025-02-24T19:22:14.455074+0300 | INFO | [40,  1500] loss: 1.603
2025-02-24T19:22:25.283047+0300 | INFO | [40,  1600] loss: 1.602
2025-02-24T19:22:36.072154+0300 | INFO | [40,  1700] loss: 1.629
2025-02-24T19:22:47.719297+0300 | INFO | [40,  1800] loss: 1.606
2025-02-24T19:22:58.555401+0300 | INFO | [40,  1900] loss: 1.621
2025-02-24T19:23:09.536225+0300 | INFO | [40,  2000] loss: 1.619
2025-02-24T19:23:20.158362+0300 | INFO | [40,  2100] loss: 1.623
2025-02-24T19:23:30.960627+0300 | INFO | [40,  2200] loss: 1.607
2025-02-24T19:23:41.602315+0300 | INFO | [40,  2300] loss: 1.611
2025-02-24T19:23:52.146543+0300 | INFO | [40,  2400] loss: 1.630
2025-02-24T19:24:02.876642+0300 | INFO | [40,  2500] loss: 1.619
2025-02-24T19:24:12.771741+0300 | INFO | [40,  2600] loss: 1.646
2025-02-24T19:24:22.960257+0300 | INFO | [40,  2700] loss: 1.620
2025-02-24T19:24:33.055882+0300 | INFO | [40,  2800] loss: 1.623
2025-02-24T19:24:43.582323+0300 | INFO | [40,  2900] loss: 1.602
2025-02-24T19:24:54.127739+0300 | INFO | [40,  3000] loss: 1.615
2025-02-24T19:25:05.134286+0300 | INFO | [40,  3100] loss: 1.619
2025-02-24T19:25:15.972853+0300 | INFO | [40,  3200] loss: 1.642
2025-02-24T19:25:26.640387+0300 | INFO | [40,  3300] loss: 1.617
2025-02-24T19:25:37.384595+0300 | INFO | [40,  3400] loss: 1.613
2025-02-24T19:25:48.015848+0300 | INFO | [40,  3500] loss: 1.613
2025-02-24T19:25:59.364436+0300 | INFO | [40,  3600] loss: 1.628
2025-02-24T19:26:10.407702+0300 | INFO | [40,  3700] loss: 1.632
2025-02-24T19:26:21.098704+0300 | INFO | [40,  3800] loss: 1.619
2025-02-24T19:26:31.709734+0300 | INFO | [40,  3900] loss: 1.620
2025-02-24T19:26:42.917239+0300 | INFO | [40,  4000] loss: 1.620
2025-02-24T19:26:53.655860+0300 | INFO | [40,  4100] loss: 1.618
2025-02-24T19:27:04.410687+0300 | INFO | [40,  4200] loss: 1.607
2025-02-24T19:27:19.348143+0300 | INFO | [40,  4300] loss: 1.639
2025-02-24T19:27:29.971881+0300 | INFO | [40,  4400] loss: 1.627
2025-02-24T19:27:40.623248+0300 | INFO | [40,  4500] loss: 1.630
2025-02-24T19:27:51.319783+0300 | INFO | [40,  4600] loss: 1.639
2025-02-24T19:28:02.118600+0300 | INFO | [40,  4700] loss: 1.615
2025-02-24T19:28:12.603554+0300 | INFO | [40,  4800] loss: 1.618
2025-02-24T19:28:23.236595+0300 | INFO | [40,  4900] loss: 1.638
2025-02-24T19:28:33.969908+0300 | DEBUG | Saving model to flat file storage. Save #40
2025-02-24T19:28:33.988006+0300 | INFO | Averaging client parameters
2025-02-24T19:28:33.999545+0300 | INFO | Updating parameters on client #0
2025-02-24T19:28:48.993854+0300 | DEBUG | Test set: Accuracy: 7469/10000 (75%)
2025-02-24T19:28:48.994870+0300 | DEBUG | Test set: Loss: 1.7128441333770752
2025-02-24T19:28:49.078741+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.80      0.80      1000
           1       0.92      0.89      0.90      1000
           2       0.68      0.68      0.68      1000
           3       0.49      0.75      0.60      1200
           4       0.75      0.75      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.71      0.91      0.79      1000
           7       0.86      0.79      0.82      1000
           8       0.86      0.92      0.89      1000
           9       0.89      0.83      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.73      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-24T19:28:49.081951+0300 | DEBUG | Confusion Matrix:
[[804  10  53  18  24   0  16   7  56  12]
 [ 15 888   6   5   1   0  13   2  23  47]
 [ 51   4 684  75  64   0  96  12   9   5]
 [ 19   4  73 897  56   0 100  26  10  15]
 [ 16   1  35  80 749   0  86  26   5   2]
 [  5   1  81 586  41   0  38  39   9   0]
 [  7   1  23  48   6   0 909   2   2   2]
 [ 15   3  37  78  51   0  15 786   6   9]
 [ 30   8   9  11   4   0   5   4 917  12]
 [ 43  50   9  15   3   0   9   9  27 835]]
2025-02-24T19:28:49.085952+0300 | DEBUG | Class precision: [0.8        0.91546392 0.67722772 0.49476007 0.74974975        nan
 0.70629371 0.86089814 0.86184211 0.88924388]
2025-02-24T19:28:49.086972+0300 | DEBUG | Class recall: [0.804  0.888  0.684  0.7475 0.749  0.     0.909  0.786  0.917  0.835 ]
2025-02-24T19:28:49.146558+0300 | INFO | Training epoch #41 on client #0
2025-02-24T19:28:49.148451+0300 | DEBUG | Saving model to flat file storage. Save #41
2025-02-24T19:28:49.260709+0300 | INFO | [41,     0] loss: 0.015
2025-02-24T19:29:02.622113+0300 | INFO | [41,   100] loss: 1.608
2025-02-24T19:29:16.520038+0300 | INFO | [41,   200] loss: 1.628
2025-02-24T19:29:27.084593+0300 | INFO | [41,   300] loss: 1.628
2025-02-24T19:29:37.356293+0300 | INFO | [41,   400] loss: 1.621
2025-02-24T19:29:48.213674+0300 | INFO | [41,   500] loss: 1.621
2025-02-24T19:29:59.290002+0300 | INFO | [41,   600] loss: 1.606
2025-02-24T19:30:09.527072+0300 | INFO | [41,   700] loss: 1.601
2025-02-24T19:30:20.076826+0300 | INFO | [41,   800] loss: 1.616
2025-02-24T19:30:30.842048+0300 | INFO | [41,   900] loss: 1.624
2025-02-24T19:30:42.248279+0300 | INFO | [41,  1000] loss: 1.619
2025-02-24T19:30:57.814996+0300 | INFO | [41,  1100] loss: 1.609
2025-02-24T19:31:14.496137+0300 | INFO | [41,  1200] loss: 1.621
2025-02-24T19:31:28.849237+0300 | INFO | [41,  1300] loss: 1.623
2025-02-24T19:31:42.559849+0300 | INFO | [41,  1400] loss: 1.622
2025-02-24T19:31:53.457652+0300 | INFO | [41,  1500] loss: 1.618
2025-02-24T19:32:04.551607+0300 | INFO | [41,  1600] loss: 1.633
2025-02-24T19:32:15.174836+0300 | INFO | [41,  1700] loss: 1.615
2025-02-24T19:32:25.936051+0300 | INFO | [41,  1800] loss: 1.622
2025-02-24T19:32:37.252146+0300 | INFO | [41,  1900] loss: 1.631
2025-02-24T19:32:47.540463+0300 | INFO | [41,  2000] loss: 1.616
2025-02-24T19:32:57.664288+0300 | INFO | [41,  2100] loss: 1.618
2025-02-24T19:33:08.780543+0300 | INFO | [41,  2200] loss: 1.620
2025-02-24T19:33:19.832779+0300 | INFO | [41,  2300] loss: 1.603
2025-02-24T19:33:30.686033+0300 | INFO | [41,  2400] loss: 1.604
2025-02-24T19:33:41.472729+0300 | INFO | [41,  2500] loss: 1.612
2025-02-24T19:33:52.250434+0300 | INFO | [41,  2600] loss: 1.620
2025-02-24T19:34:03.163965+0300 | INFO | [41,  2700] loss: 1.622
2025-02-24T19:34:13.933218+0300 | INFO | [41,  2800] loss: 1.615
2025-02-24T19:34:25.106777+0300 | INFO | [41,  2900] loss: 1.613
2025-02-24T19:34:35.753553+0300 | INFO | [41,  3000] loss: 1.612
2025-02-24T19:34:46.339282+0300 | INFO | [41,  3100] loss: 1.608
2025-02-24T19:34:56.960985+0300 | INFO | [41,  3200] loss: 1.633
2025-02-24T19:35:10.433297+0300 | INFO | [41,  3300] loss: 1.625
2025-02-24T19:35:21.119327+0300 | INFO | [41,  3400] loss: 1.635
2025-02-24T19:35:31.830613+0300 | INFO | [41,  3500] loss: 1.612
2025-02-24T19:35:44.384918+0300 | INFO | [41,  3600] loss: 1.605
2025-02-24T19:35:58.515082+0300 | INFO | [41,  3700] loss: 1.626
2025-02-24T19:36:09.236431+0300 | INFO | [41,  3800] loss: 1.619
2025-02-24T19:36:20.149785+0300 | INFO | [41,  3900] loss: 1.622
2025-02-24T19:36:30.922621+0300 | INFO | [41,  4000] loss: 1.625
2025-02-24T19:36:41.574793+0300 | INFO | [41,  4100] loss: 1.608
2025-02-24T19:36:51.012636+0300 | INFO | [41,  4200] loss: 1.638
2025-02-24T19:37:03.247932+0300 | INFO | [41,  4300] loss: 1.606
2025-02-24T19:37:13.961378+0300 | INFO | [41,  4400] loss: 1.618
2025-02-24T19:37:27.218638+0300 | INFO | [41,  4500] loss: 1.624
2025-02-24T19:37:41.598811+0300 | INFO | [41,  4600] loss: 1.615
2025-02-24T19:37:51.988418+0300 | INFO | [41,  4700] loss: 1.610
2025-02-24T19:38:02.960119+0300 | INFO | [41,  4800] loss: 1.600
2025-02-24T19:38:13.160622+0300 | INFO | [41,  4900] loss: 1.632
2025-02-24T19:38:23.411418+0300 | DEBUG | Saving model to flat file storage. Save #41
2025-02-24T19:38:23.443022+0300 | INFO | Averaging client parameters
2025-02-24T19:38:23.448937+0300 | INFO | Updating parameters on client #0
2025-02-24T19:38:38.963212+0300 | DEBUG | Test set: Accuracy: 7550/10000 (76%)
2025-02-24T19:38:38.964213+0300 | DEBUG | Test set: Loss: 1.7052451372146606
2025-02-24T19:38:39.059907+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.83      0.80      1000
           1       0.92      0.90      0.91      1000
           2       0.71      0.69      0.70      1000
           3       0.52      0.74      0.61      1200
           4       0.74      0.78      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.77      0.88      0.82      1000
           7       0.79      0.84      0.82      1000
           8       0.85      0.89      0.87      1000
           9       0.89      0.85      0.87      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T19:38:39.062893+0300 | DEBUG | Confusion Matrix:
[[827  10  42  17  19   0   8  15  51  11]
 [ 14 895   4   5   1   0   4   3  22  52]
 [ 72   2 689  69  71   0  63  20  10   4]
 [ 20   5  60 894  61   0  81  55  14  10]
 [ 13   1  41  65 776   0  53  41   8   2]
 [  9   0  75 547  49   0  36  67  15   2]
 [ 14   3  34  39  18   0 880   7   4   1]
 [ 22   2  21  56  38   0   8 845   4   4]
 [ 41  17   7  11   7   0   2   6 889  20]
 [ 40  41   3  15   4   0   6   9  27 855]]
2025-02-24T19:38:39.064892+0300 | DEBUG | Class precision: [0.77145522 0.9170082  0.70594262 0.52037253 0.74329502        nan
 0.77125329 0.7911985  0.85153257 0.88969823]
2025-02-24T19:38:39.065882+0300 | DEBUG | Class recall: [0.827 0.895 0.689 0.745 0.776 0.    0.88  0.845 0.889 0.855]
2025-02-24T19:38:39.126258+0300 | INFO | Training epoch #42 on client #0
2025-02-24T19:38:39.131248+0300 | DEBUG | Saving model to flat file storage. Save #42
2025-02-24T19:38:39.275432+0300 | INFO | [42,     0] loss: 0.016
2025-02-24T19:38:50.109552+0300 | INFO | [42,   100] loss: 1.625
2025-02-24T19:39:01.122120+0300 | INFO | [42,   200] loss: 1.597
2025-02-24T19:39:11.978194+0300 | INFO | [42,   300] loss: 1.592
2025-02-24T19:39:22.779299+0300 | INFO | [42,   400] loss: 1.601
2025-02-24T19:39:33.551196+0300 | INFO | [42,   500] loss: 1.632
2025-02-24T19:39:43.551741+0300 | INFO | [42,   600] loss: 1.621
2025-02-24T19:39:54.241315+0300 | INFO | [42,   700] loss: 1.609
2025-02-24T19:40:04.697590+0300 | INFO | [42,   800] loss: 1.599
2025-02-24T19:40:15.841407+0300 | INFO | [42,   900] loss: 1.617
2025-02-24T19:40:26.376367+0300 | INFO | [42,  1000] loss: 1.625
2025-02-24T19:40:36.829563+0300 | INFO | [42,  1100] loss: 1.612
2025-02-24T19:40:47.485895+0300 | INFO | [42,  1200] loss: 1.614
2025-02-24T19:40:58.014702+0300 | INFO | [42,  1300] loss: 1.615
2025-02-24T19:41:08.008442+0300 | INFO | [42,  1400] loss: 1.610
2025-02-24T19:41:20.651386+0300 | INFO | [42,  1500] loss: 1.626
2025-02-24T19:41:35.044931+0300 | INFO | [42,  1600] loss: 1.601
2025-02-24T19:41:45.734425+0300 | INFO | [42,  1700] loss: 1.617
2025-02-24T19:41:56.041095+0300 | INFO | [42,  1800] loss: 1.617
2025-02-24T19:42:06.946897+0300 | INFO | [42,  1900] loss: 1.607
2025-02-24T19:42:17.359760+0300 | INFO | [42,  2000] loss: 1.621
2025-02-24T19:42:27.325692+0300 | INFO | [42,  2100] loss: 1.604
2025-02-24T19:42:37.569760+0300 | INFO | [42,  2200] loss: 1.639
2025-02-24T19:42:50.599443+0300 | INFO | [42,  2300] loss: 1.600
2025-02-24T19:43:03.799817+0300 | INFO | [42,  2400] loss: 1.614
2025-02-24T19:43:16.904548+0300 | INFO | [42,  2500] loss: 1.624
2025-02-24T19:43:29.922782+0300 | INFO | [42,  2600] loss: 1.615
2025-02-24T19:43:41.637909+0300 | INFO | [42,  2700] loss: 1.618
2025-02-24T19:43:55.001557+0300 | INFO | [42,  2800] loss: 1.635
2025-02-24T19:44:07.208946+0300 | INFO | [42,  2900] loss: 1.625
2025-02-24T19:44:22.368281+0300 | INFO | [42,  3000] loss: 1.610
2025-02-24T19:44:41.126107+0300 | INFO | [42,  3100] loss: 1.622
2025-02-24T19:44:53.323879+0300 | INFO | [42,  3200] loss: 1.613
2025-02-24T19:45:03.770128+0300 | INFO | [42,  3300] loss: 1.615
2025-02-24T19:45:14.026370+0300 | INFO | [42,  3400] loss: 1.599
2025-02-24T19:45:24.186499+0300 | INFO | [42,  3500] loss: 1.622
2025-02-24T19:45:35.364355+0300 | INFO | [42,  3600] loss: 1.635
2025-02-24T19:45:48.726959+0300 | INFO | [42,  3700] loss: 1.600
2025-02-24T19:46:03.562472+0300 | INFO | [42,  3800] loss: 1.610
2025-02-24T19:46:18.113360+0300 | INFO | [42,  3900] loss: 1.618
2025-02-24T19:46:31.917380+0300 | INFO | [42,  4000] loss: 1.617
2025-02-24T19:46:43.080525+0300 | INFO | [42,  4100] loss: 1.621
2025-02-24T19:46:54.524068+0300 | INFO | [42,  4200] loss: 1.632
2025-02-24T19:47:04.731783+0300 | INFO | [42,  4300] loss: 1.610
2025-02-24T19:47:15.534905+0300 | INFO | [42,  4400] loss: 1.580
2025-02-24T19:47:26.209120+0300 | INFO | [42,  4500] loss: 1.612
2025-02-24T19:47:37.515170+0300 | INFO | [42,  4600] loss: 1.618
2025-02-24T19:47:47.640488+0300 | INFO | [42,  4700] loss: 1.613
2025-02-24T19:47:57.910741+0300 | INFO | [42,  4800] loss: 1.628
2025-02-24T19:48:08.395832+0300 | INFO | [42,  4900] loss: 1.625
2025-02-24T19:48:18.747412+0300 | DEBUG | Saving model to flat file storage. Save #42
2025-02-24T19:48:18.774870+0300 | INFO | Averaging client parameters
2025-02-24T19:48:18.785239+0300 | INFO | Updating parameters on client #0
2025-02-24T19:48:34.456269+0300 | DEBUG | Test set: Accuracy: 7579/10000 (76%)
2025-02-24T19:48:34.460274+0300 | DEBUG | Test set: Loss: 1.7026453018188477
2025-02-24T19:48:34.561264+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.86      0.79      1000
           1       0.88      0.92      0.90      1000
           2       0.71      0.67      0.69      1000
           3       0.51      0.78      0.62      1200
           4       0.78      0.78      0.78      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.87      0.84      1000
           7       0.82      0.84      0.83      1000
           8       0.90      0.84      0.87      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T19:48:34.564263+0300 | DEBUG | Confusion Matrix:
[[856  11  35  15   9   0   7   8  35  24]
 [ 15 915   4   5   0   0   7   2   5  47]
 [ 85   5 669  91  59   0  57  20   5   9]
 [ 36  11  55 935  47   0  56  38   9  13]
 [ 19   3  34  80 780   0  33  42   9   0]
 [ 15   8  66 567  41   0  32  61   9   1]
 [ 16   1  29  54  19   0 869   6   5   1]
 [ 25   5  22  56  41   0   4 838   3   6]
 [ 70  32  16  10   3   0   4   5 837  23]
 [ 28  44   8  12   2   0   7   6  13 880]]
2025-02-24T19:48:34.566807+0300 | DEBUG | Class precision: [0.73476395 0.88405797 0.71321962 0.51232877 0.77922078        nan
 0.80762082 0.81676413 0.9        0.87649402]
2025-02-24T19:48:34.568104+0300 | DEBUG | Class recall: [0.856      0.915      0.669      0.77916667 0.78       0.
 0.869      0.838      0.837      0.88      ]
2025-02-24T19:48:34.617677+0300 | INFO | Training epoch #43 on client #0
2025-02-24T19:48:34.619747+0300 | DEBUG | Saving model to flat file storage. Save #43
2025-02-24T19:48:34.757623+0300 | INFO | [43,     0] loss: 0.015
2025-02-24T19:48:45.229293+0300 | INFO | [43,   100] loss: 1.605
2025-02-24T19:48:56.510535+0300 | INFO | [43,   200] loss: 1.613
2025-02-24T19:49:09.249099+0300 | INFO | [43,   300] loss: 1.608
2025-02-24T19:49:23.876656+0300 | INFO | [43,   400] loss: 1.611
2025-02-24T19:49:40.687911+0300 | INFO | [43,   500] loss: 1.627
2025-02-24T19:49:56.321348+0300 | INFO | [43,   600] loss: 1.613
2025-02-24T19:50:09.632114+0300 | INFO | [43,   700] loss: 1.626
2025-02-24T19:50:20.705203+0300 | INFO | [43,   800] loss: 1.611
2025-02-24T19:50:31.725886+0300 | INFO | [43,   900] loss: 1.608
2025-02-24T19:50:41.711232+0300 | INFO | [43,  1000] loss: 1.613
2025-02-24T19:50:53.409793+0300 | INFO | [43,  1100] loss: 1.616
2025-02-24T19:51:04.576915+0300 | INFO | [43,  1200] loss: 1.612
2025-02-24T19:51:14.565110+0300 | INFO | [43,  1300] loss: 1.627
2025-02-24T19:51:25.472046+0300 | INFO | [43,  1400] loss: 1.599
2025-02-24T19:51:36.301928+0300 | INFO | [43,  1500] loss: 1.616
2025-02-24T19:51:46.266734+0300 | INFO | [43,  1600] loss: 1.627
2025-02-24T19:51:58.487948+0300 | INFO | [43,  1700] loss: 1.618
2025-02-24T19:52:11.507186+0300 | INFO | [43,  1800] loss: 1.619
2025-02-24T19:52:22.590367+0300 | INFO | [43,  1900] loss: 1.620
2025-02-24T19:52:32.274608+0300 | INFO | [43,  2000] loss: 1.604
2025-02-24T19:52:42.781654+0300 | INFO | [43,  2100] loss: 1.606
2025-02-24T19:52:53.195641+0300 | INFO | [43,  2200] loss: 1.631
2025-02-24T19:53:06.162787+0300 | INFO | [43,  2300] loss: 1.618
2025-02-24T19:53:16.686236+0300 | INFO | [43,  2400] loss: 1.589
2025-02-24T19:53:30.945685+0300 | INFO | [43,  2500] loss: 1.627
2025-02-24T19:53:41.314429+0300 | INFO | [43,  2600] loss: 1.593
2025-02-24T19:53:51.677326+0300 | INFO | [43,  2700] loss: 1.615
2025-02-24T19:54:02.001222+0300 | INFO | [43,  2800] loss: 1.640
2025-02-24T19:54:12.652732+0300 | INFO | [43,  2900] loss: 1.610
2025-02-24T19:54:23.163529+0300 | INFO | [43,  3000] loss: 1.612
2025-02-24T19:54:33.461188+0300 | INFO | [43,  3100] loss: 1.621
2025-02-24T19:54:42.901824+0300 | INFO | [43,  3200] loss: 1.613
2025-02-24T19:54:53.410642+0300 | INFO | [43,  3300] loss: 1.611
2025-02-24T19:55:03.761754+0300 | INFO | [43,  3400] loss: 1.617
2025-02-24T19:55:14.366491+0300 | INFO | [43,  3500] loss: 1.600
2025-02-24T19:55:24.241766+0300 | INFO | [43,  3600] loss: 1.629
2025-02-24T19:55:34.513726+0300 | INFO | [43,  3700] loss: 1.619
2025-02-24T19:55:44.613571+0300 | INFO | [43,  3800] loss: 1.618
2025-02-24T19:55:55.220722+0300 | INFO | [43,  3900] loss: 1.619
2025-02-24T19:56:06.006377+0300 | INFO | [43,  4000] loss: 1.606
2025-02-24T19:56:16.565232+0300 | INFO | [43,  4100] loss: 1.610
2025-02-24T19:56:27.071617+0300 | INFO | [43,  4200] loss: 1.589
2025-02-24T19:56:37.267658+0300 | INFO | [43,  4300] loss: 1.618
2025-02-24T19:56:47.838382+0300 | INFO | [43,  4400] loss: 1.630
2025-02-24T19:56:58.062452+0300 | INFO | [43,  4500] loss: 1.613
2025-02-24T19:57:08.552374+0300 | INFO | [43,  4600] loss: 1.622
2025-02-24T19:57:19.209103+0300 | INFO | [43,  4700] loss: 1.625
2025-02-24T19:57:29.755369+0300 | INFO | [43,  4800] loss: 1.612
2025-02-24T19:57:40.021287+0300 | INFO | [43,  4900] loss: 1.612
2025-02-24T19:57:50.294329+0300 | DEBUG | Saving model to flat file storage. Save #43
2025-02-24T19:57:50.318837+0300 | INFO | Averaging client parameters
2025-02-24T19:57:50.332106+0300 | INFO | Updating parameters on client #0
2025-02-24T19:58:06.119963+0300 | DEBUG | Test set: Accuracy: 7571/10000 (76%)
2025-02-24T19:58:06.121984+0300 | DEBUG | Test set: Loss: 1.7024593353271484
2025-02-24T19:58:06.226179+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.82      0.80      1000
           1       0.89      0.92      0.91      1000
           2       0.72      0.63      0.67      1000
           3       0.53      0.74      0.61      1200
           4       0.70      0.83      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.88      0.83      1000
           7       0.82      0.83      0.82      1000
           8       0.88      0.88      0.88      1000
           9       0.86      0.89      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T19:58:06.229177+0300 | DEBUG | Confusion Matrix:
[[822  13  33  14  22   0  11   9  51  25]
 [ 10 922   4   2   1   0   7   1   9  44]
 [ 74   4 629  74 105   0  78  24   7   5]
 [ 33   6  63 887  81   0  56  40  10  24]
 [ 11   2  17  64 834   0  29  33   8   2]
 [ 10   7  76 540  59   0  32  63  11   2]
 [ 13   2  15  49  33   0 878   6   2   2]
 [ 17   2  23  42  56   1  10 830   4  15]
 [ 46  26   9   7   1   0   7   4 879  21]
 [ 16  47   2   9   1   0   8   5  22 890]]
2025-02-24T19:58:06.230176+0300 | DEBUG | Class precision: [0.78136882 0.8942774  0.72215844 0.52547393 0.69907795 0.
 0.78673835 0.81773399 0.87637089 0.86407767]
2025-02-24T19:58:06.231394+0300 | DEBUG | Class recall: [0.822      0.922      0.629      0.73916667 0.834      0.
 0.878      0.83       0.879      0.89      ]
2025-02-24T19:58:06.287379+0300 | INFO | Training epoch #44 on client #0
2025-02-24T19:58:06.288465+0300 | DEBUG | Saving model to flat file storage. Save #44
2025-02-24T19:58:06.418152+0300 | INFO | [44,     0] loss: 0.016
2025-02-24T19:58:16.574408+0300 | INFO | [44,   100] loss: 1.607
2025-02-24T19:58:26.942375+0300 | INFO | [44,   200] loss: 1.608
2025-02-24T19:58:38.249363+0300 | INFO | [44,   300] loss: 1.620
2025-02-24T19:58:48.564522+0300 | INFO | [44,   400] loss: 1.608
2025-02-24T19:58:59.166427+0300 | INFO | [44,   500] loss: 1.614
2025-02-24T19:59:09.487251+0300 | INFO | [44,   600] loss: 1.631
2025-02-24T19:59:19.890919+0300 | INFO | [44,   700] loss: 1.623
2025-02-24T19:59:30.654197+0300 | INFO | [44,   800] loss: 1.600
2025-02-24T19:59:40.805618+0300 | INFO | [44,   900] loss: 1.582
2025-02-24T19:59:50.965890+0300 | INFO | [44,  1000] loss: 1.624
2025-02-24T20:00:01.538554+0300 | INFO | [44,  1100] loss: 1.609
2025-02-24T20:00:11.863445+0300 | INFO | [44,  1200] loss: 1.599
2025-02-24T20:00:22.655020+0300 | INFO | [44,  1300] loss: 1.622
2025-02-24T20:00:33.176389+0300 | INFO | [44,  1400] loss: 1.608
2025-02-24T20:00:43.278214+0300 | INFO | [44,  1500] loss: 1.603
2025-02-24T20:00:53.691936+0300 | INFO | [44,  1600] loss: 1.600
2025-02-24T20:01:04.577701+0300 | INFO | [44,  1700] loss: 1.612
2025-02-24T20:01:16.623365+0300 | INFO | [44,  1800] loss: 1.598
2025-02-24T20:01:28.603438+0300 | INFO | [44,  1900] loss: 1.627
2025-02-24T20:01:43.491889+0300 | INFO | [44,  2000] loss: 1.604
2025-02-24T20:01:56.177087+0300 | INFO | [44,  2100] loss: 1.632
2025-02-24T20:02:10.987017+0300 | INFO | [44,  2200] loss: 1.609
2025-02-24T20:02:22.466672+0300 | INFO | [44,  2300] loss: 1.616
2025-02-24T20:02:34.724052+0300 | INFO | [44,  2400] loss: 1.606
2025-02-24T20:02:47.893654+0300 | INFO | [44,  2500] loss: 1.611
2025-02-24T20:03:02.939595+0300 | INFO | [44,  2600] loss: 1.617
2025-02-24T20:03:17.003534+0300 | INFO | [44,  2700] loss: 1.637
2025-02-24T20:03:29.078935+0300 | INFO | [44,  2800] loss: 1.618
2025-02-24T20:03:40.574299+0300 | INFO | [44,  2900] loss: 1.601
2025-02-24T20:03:51.908682+0300 | INFO | [44,  3000] loss: 1.622
2025-02-24T20:04:04.307318+0300 | INFO | [44,  3100] loss: 1.589
2025-02-24T20:04:16.512316+0300 | INFO | [44,  3200] loss: 1.619
2025-02-24T20:04:27.833070+0300 | INFO | [44,  3300] loss: 1.606
2025-02-24T20:04:39.674018+0300 | INFO | [44,  3400] loss: 1.628
2025-02-24T20:04:51.556110+0300 | INFO | [44,  3500] loss: 1.611
2025-02-24T20:05:06.582938+0300 | INFO | [44,  3600] loss: 1.608
2025-02-24T20:05:19.002795+0300 | INFO | [44,  3700] loss: 1.617
2025-02-24T20:05:30.464033+0300 | INFO | [44,  3800] loss: 1.611
2025-02-24T20:05:43.060913+0300 | INFO | [44,  3900] loss: 1.642
2025-02-24T20:05:53.827787+0300 | INFO | [44,  4000] loss: 1.605
2025-02-24T20:06:06.554536+0300 | INFO | [44,  4100] loss: 1.623
2025-02-24T20:06:16.956930+0300 | INFO | [44,  4200] loss: 1.625
2025-02-24T20:06:27.539871+0300 | INFO | [44,  4300] loss: 1.620
2025-02-24T20:06:38.074867+0300 | INFO | [44,  4400] loss: 1.626
2025-02-24T20:06:48.626358+0300 | INFO | [44,  4500] loss: 1.596
2025-02-24T20:06:59.201720+0300 | INFO | [44,  4600] loss: 1.611
2025-02-24T20:07:09.363767+0300 | INFO | [44,  4700] loss: 1.614
2025-02-24T20:07:18.680250+0300 | INFO | [44,  4800] loss: 1.611
2025-02-24T20:07:28.865588+0300 | INFO | [44,  4900] loss: 1.622
2025-02-24T20:07:40.662386+0300 | DEBUG | Saving model to flat file storage. Save #44
2025-02-24T20:07:40.691637+0300 | INFO | Averaging client parameters
2025-02-24T20:07:40.697922+0300 | INFO | Updating parameters on client #0
2025-02-24T20:07:58.062242+0300 | DEBUG | Test set: Accuracy: 7462/10000 (75%)
2025-02-24T20:07:58.063428+0300 | DEBUG | Test set: Loss: 1.714264988899231
2025-02-24T20:07:58.169639+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.90      0.91      0.90      1000
           2       0.66      0.70      0.68      1000
           3       0.51      0.75      0.60      1200
           4       0.73      0.77      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.72      0.90      0.80      1000
           7       0.86      0.77      0.81      1000
           8       0.85      0.90      0.87      1000
           9       0.93      0.79      0.85      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-24T20:07:58.170639+0300 | DEBUG | Confusion Matrix:
[[832  11  41  13  13   0  15   8  51  16]
 [ 14 907   4   6   0   0  16   2  26  25]
 [ 63   4 699  61  64   0  82  13  12   2]
 [ 23   3  98 896  57   0  80  28   9   6]
 [ 10   1  44  77 766   0  69  25   8   0]
 [ 14   1  96 551  54   0  41  33   8   2]
 [  9   0  28  42  11   0 903   3   3   1]
 [ 20   2  35  81  71   0  20 765   4   2]
 [ 41  10  12  13   6   0   6   3 901   8]
 [ 29  72   8  27   4   0  19   6  42 793]]
2025-02-24T20:07:58.172643+0300 | DEBUG | Class precision: [0.78862559 0.89713155 0.65633803 0.50707414 0.73231358        nan
 0.72182254 0.86343115 0.84680451 0.92748538]
2025-02-24T20:07:58.175640+0300 | DEBUG | Class recall: [0.832      0.907      0.699      0.74666667 0.766      0.
 0.903      0.765      0.901      0.793     ]
2025-02-24T20:07:58.224423+0300 | INFO | Training epoch #45 on client #0
2025-02-24T20:07:58.227416+0300 | DEBUG | Saving model to flat file storage. Save #45
2025-02-24T20:07:58.394114+0300 | INFO | [45,     0] loss: 0.015
2025-02-24T20:08:09.154279+0300 | INFO | [45,   100] loss: 1.613
2025-02-24T20:08:19.196598+0300 | INFO | [45,   200] loss: 1.616
2025-02-24T20:08:29.875138+0300 | INFO | [45,   300] loss: 1.614
2025-02-24T20:08:41.330691+0300 | INFO | [45,   400] loss: 1.599
2025-02-24T20:08:52.240009+0300 | INFO | [45,   500] loss: 1.611
2025-02-24T20:09:03.147949+0300 | INFO | [45,   600] loss: 1.608
2025-02-24T20:09:13.835673+0300 | INFO | [45,   700] loss: 1.602
2025-02-24T20:09:24.625715+0300 | INFO | [45,   800] loss: 1.609
2025-02-24T20:09:35.356627+0300 | INFO | [45,   900] loss: 1.612
2025-02-24T20:09:47.946407+0300 | INFO | [45,  1000] loss: 1.625
2025-02-24T20:10:00.314514+0300 | INFO | [45,  1100] loss: 1.610
2025-02-24T20:10:16.818062+0300 | INFO | [45,  1200] loss: 1.596
2025-02-24T20:10:27.516211+0300 | INFO | [45,  1300] loss: 1.591
2025-02-24T20:10:39.205565+0300 | INFO | [45,  1400] loss: 1.610
2025-02-24T20:10:50.535849+0300 | INFO | [45,  1500] loss: 1.619
2025-02-24T20:11:01.491705+0300 | INFO | [45,  1600] loss: 1.632
2025-02-24T20:11:13.133032+0300 | INFO | [45,  1700] loss: 1.607
2025-02-24T20:11:24.414012+0300 | INFO | [45,  1800] loss: 1.622
2025-02-24T20:11:35.359438+0300 | INFO | [45,  1900] loss: 1.610
2025-02-24T20:11:50.165453+0300 | INFO | [45,  2000] loss: 1.617
2025-02-24T20:12:00.518680+0300 | INFO | [45,  2100] loss: 1.610
2025-02-24T20:12:11.551028+0300 | INFO | [45,  2200] loss: 1.626
2025-02-24T20:12:22.189455+0300 | INFO | [45,  2300] loss: 1.615
2025-02-24T20:12:32.287742+0300 | INFO | [45,  2400] loss: 1.621
2025-02-24T20:12:43.059560+0300 | INFO | [45,  2500] loss: 1.609
2025-02-24T20:12:55.409163+0300 | INFO | [45,  2600] loss: 1.606
2025-02-24T20:13:05.850225+0300 | INFO | [45,  2700] loss: 1.597
2025-02-24T20:13:16.061436+0300 | INFO | [45,  2800] loss: 1.614
2025-02-24T20:13:26.275877+0300 | INFO | [45,  2900] loss: 1.590
2025-02-24T20:13:36.670303+0300 | INFO | [45,  3000] loss: 1.628
2025-02-24T20:13:46.730952+0300 | INFO | [45,  3100] loss: 1.593
2025-02-24T20:13:56.723839+0300 | INFO | [45,  3200] loss: 1.625
2025-02-24T20:14:07.434417+0300 | INFO | [45,  3300] loss: 1.609
2025-02-24T20:14:17.790012+0300 | INFO | [45,  3400] loss: 1.624
2025-02-24T20:14:27.896533+0300 | INFO | [45,  3500] loss: 1.620
2025-02-24T20:14:38.289229+0300 | INFO | [45,  3600] loss: 1.634
2025-02-24T20:14:48.978120+0300 | INFO | [45,  3700] loss: 1.615
2025-02-24T20:14:59.183752+0300 | INFO | [45,  3800] loss: 1.609
2025-02-24T20:15:09.575791+0300 | INFO | [45,  3900] loss: 1.602
2025-02-24T20:15:19.934195+0300 | INFO | [45,  4000] loss: 1.627
2025-02-24T20:15:29.986443+0300 | INFO | [45,  4100] loss: 1.624
2025-02-24T20:15:40.889751+0300 | INFO | [45,  4200] loss: 1.641
2025-02-24T20:15:51.688709+0300 | INFO | [45,  4300] loss: 1.624
2025-02-24T20:16:01.757828+0300 | INFO | [45,  4400] loss: 1.605
2025-02-24T20:16:12.574007+0300 | INFO | [45,  4500] loss: 1.609
2025-02-24T20:16:22.909127+0300 | INFO | [45,  4600] loss: 1.615
2025-02-24T20:16:33.314848+0300 | INFO | [45,  4700] loss: 1.617
2025-02-24T20:16:43.456073+0300 | INFO | [45,  4800] loss: 1.631
2025-02-24T20:16:55.525078+0300 | INFO | [45,  4900] loss: 1.620
2025-02-24T20:17:05.581082+0300 | DEBUG | Saving model to flat file storage. Save #45
2025-02-24T20:17:05.603534+0300 | INFO | Averaging client parameters
2025-02-24T20:17:05.611963+0300 | INFO | Updating parameters on client #0
2025-02-24T20:17:21.014970+0300 | DEBUG | Test set: Accuracy: 7563/10000 (76%)
2025-02-24T20:17:21.015968+0300 | DEBUG | Test set: Loss: 1.7041007280349731
2025-02-24T20:17:21.085216+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.83      0.79      1000
           1       0.90      0.92      0.91      1000
           2       0.65      0.74      0.69      1000
           3       0.52      0.76      0.61      1200
           4       0.81      0.76      0.78      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.85      0.82      1000
           7       0.83      0.80      0.82      1000
           8       0.86      0.88      0.87      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T20:17:21.088218+0300 | DEBUG | Confusion Matrix:
[[829  16  42  14   8   0   3   7  55  26]
 [  8 919   5   3   1   0   2   1  17  44]
 [ 74   4 739  53  45   0  50  16  13   6]
 [ 35   5  82 906  43   0  61  39  13  16]
 [ 15   3  51  81 759   0  45  35  10   1]
 [ 17   2 100 561  28   0  32  50   8   2]
 [ 16   3  53  51  11   0 849   8   8   1]
 [ 25   4  42  61  40   0   8 803   4  13]
 [ 50  17  14  10   1   0   2   5 880  21]
 [ 27  45   6  11   1   0   7   5  19 879]]
2025-02-24T20:17:21.092108+0300 | DEBUG | Class precision: [0.75638686 0.90275049 0.65167549 0.51741862 0.81003202        nan
 0.80169972 0.82868937 0.85686465 0.87115956]
2025-02-24T20:17:21.094103+0300 | DEBUG | Class recall: [0.829 0.919 0.739 0.755 0.759 0.    0.849 0.803 0.88  0.879]
2025-02-24T20:17:21.135835+0300 | INFO | Training epoch #46 on client #0
2025-02-24T20:17:21.136844+0300 | DEBUG | Saving model to flat file storage. Save #46
2025-02-24T20:17:21.260346+0300 | INFO | [46,     0] loss: 0.016
2025-02-24T20:17:31.992882+0300 | INFO | [46,   100] loss: 1.603
2025-02-24T20:17:42.830757+0300 | INFO | [46,   200] loss: 1.614
2025-02-24T20:17:58.873240+0300 | INFO | [46,   300] loss: 1.612
2025-02-24T20:18:09.861852+0300 | INFO | [46,   400] loss: 1.600
2025-02-24T20:18:24.660396+0300 | INFO | [46,   500] loss: 1.632
2025-02-24T20:18:41.049370+0300 | INFO | [46,   600] loss: 1.596
2025-02-24T20:18:51.991139+0300 | INFO | [46,   700] loss: 1.606
2025-02-24T20:19:02.973436+0300 | INFO | [46,   800] loss: 1.609
2025-02-24T20:19:15.855739+0300 | INFO | [46,   900] loss: 1.603
2025-02-24T20:19:29.596044+0300 | INFO | [46,  1000] loss: 1.626
2025-02-24T20:19:44.649788+0300 | INFO | [46,  1100] loss: 1.617
2025-02-24T20:19:57.769789+0300 | INFO | [46,  1200] loss: 1.609
2025-02-24T20:20:07.519974+0300 | INFO | [46,  1300] loss: 1.611
2025-02-24T20:20:19.207614+0300 | INFO | [46,  1400] loss: 1.613
2025-02-24T20:20:31.128350+0300 | INFO | [46,  1500] loss: 1.612
2025-02-24T20:20:43.201192+0300 | INFO | [46,  1600] loss: 1.617
2025-02-24T20:20:55.321278+0300 | INFO | [46,  1700] loss: 1.601
2025-02-24T20:21:08.389044+0300 | INFO | [46,  1800] loss: 1.599
2025-02-24T20:21:21.561891+0300 | INFO | [46,  1900] loss: 1.612
2025-02-24T20:21:37.431810+0300 | INFO | [46,  2000] loss: 1.618
2025-02-24T20:21:50.934046+0300 | INFO | [46,  2100] loss: 1.599
2025-02-24T20:22:04.931888+0300 | INFO | [46,  2200] loss: 1.613
2025-02-24T20:22:16.984654+0300 | INFO | [46,  2300] loss: 1.592
2025-02-24T20:22:28.162042+0300 | INFO | [46,  2400] loss: 1.613
2025-02-24T20:22:41.320156+0300 | INFO | [46,  2500] loss: 1.612
2025-02-24T20:22:53.537073+0300 | INFO | [46,  2600] loss: 1.614
2025-02-24T20:23:06.622375+0300 | INFO | [46,  2700] loss: 1.627
2025-02-24T20:23:18.836212+0300 | INFO | [46,  2800] loss: 1.601
2025-02-24T20:23:29.983294+0300 | INFO | [46,  2900] loss: 1.609
2025-02-24T20:23:41.768911+0300 | INFO | [46,  3000] loss: 1.615
2025-02-24T20:23:54.217199+0300 | INFO | [46,  3100] loss: 1.617
2025-02-24T20:24:06.822155+0300 | INFO | [46,  3200] loss: 1.602
2025-02-24T20:24:19.202179+0300 | INFO | [46,  3300] loss: 1.606
2025-02-24T20:24:32.377343+0300 | INFO | [46,  3400] loss: 1.601
2025-02-24T20:24:44.512574+0300 | INFO | [46,  3500] loss: 1.627
2025-02-24T20:24:56.647163+0300 | INFO | [46,  3600] loss: 1.613
2025-02-24T20:25:08.824805+0300 | INFO | [46,  3700] loss: 1.618
2025-02-24T20:25:20.518351+0300 | INFO | [46,  3800] loss: 1.609
2025-02-24T20:25:33.227727+0300 | INFO | [46,  3900] loss: 1.614
2025-02-24T20:25:45.408481+0300 | INFO | [46,  4000] loss: 1.640
2025-02-24T20:25:56.481298+0300 | INFO | [46,  4100] loss: 1.592
2025-02-24T20:26:09.655644+0300 | INFO | [46,  4200] loss: 1.617
2025-02-24T20:26:21.866626+0300 | INFO | [46,  4300] loss: 1.637
2025-02-24T20:26:33.243059+0300 | INFO | [46,  4400] loss: 1.619
2025-02-24T20:26:44.094802+0300 | INFO | [46,  4500] loss: 1.612
2025-02-24T20:26:57.007415+0300 | INFO | [46,  4600] loss: 1.616
2025-02-24T20:27:11.932311+0300 | INFO | [46,  4700] loss: 1.624
2025-02-24T20:27:24.142505+0300 | INFO | [46,  4800] loss: 1.611
2025-02-24T20:27:36.259041+0300 | INFO | [46,  4900] loss: 1.623
2025-02-24T20:27:48.607005+0300 | DEBUG | Saving model to flat file storage. Save #46
2025-02-24T20:27:48.628659+0300 | INFO | Averaging client parameters
2025-02-24T20:27:48.645157+0300 | INFO | Updating parameters on client #0
2025-02-24T20:28:12.440439+0300 | DEBUG | Test set: Accuracy: 7566/10000 (76%)
2025-02-24T20:28:12.441449+0300 | DEBUG | Test set: Loss: 1.703607439994812
2025-02-24T20:28:12.542301+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.81      0.80      1000
           1       0.93      0.90      0.91      1000
           2       0.64      0.74      0.68      1000
           3       0.54      0.71      0.61      1200
           4       0.72      0.81      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.82      0.86      0.84      1000
           7       0.78      0.85      0.81      1000
           8       0.89      0.88      0.88      1000
           9       0.86      0.89      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-24T20:28:12.554433+0300 | DEBUG | Confusion Matrix:
[[806  11  64   9  25   0   4  18  41  22]
 [ 14 895   6   2   3   0   5   8  11  56]
 [ 45   1 737  47  72   0  52  29   8   9]
 [ 27   6 120 847  58   0  58  52  12  20]
 [  8   2  45  50 808   0  41  35   5   6]
 [ 16   1 105 509  61   0  26  73   6   3]
 [ 13   2  40  43  28   0 857   8   6   3]
 [ 13   1  23  47  56   0   3 846   3   8]
 [ 52  18  11   8   3   0   2   9 876  21]
 [ 27  30   6   5   4   0   1  12  21 894]]
2025-02-24T20:28:12.557630+0300 | DEBUG | Class precision: [0.78942214 0.92554292 0.63699222 0.54052329 0.72271914        nan
 0.81696854 0.77614679 0.88574317 0.85796545]
2025-02-24T20:28:12.558629+0300 | DEBUG | Class recall: [0.806      0.895      0.737      0.70583333 0.808      0.
 0.857      0.846      0.876      0.894     ]
2025-02-24T20:28:12.559747+0300 | INFO | Training epoch #47 on client #0
2025-02-24T20:28:12.561068+0300 | DEBUG | Saving model to flat file storage. Save #47
2025-02-24T20:28:12.773175+0300 | INFO | [47,     0] loss: 0.016
2025-02-24T20:28:27.504827+0300 | INFO | [47,   100] loss: 1.596
2025-02-24T20:28:39.616451+0300 | INFO | [47,   200] loss: 1.608
2025-02-24T20:28:51.613311+0300 | INFO | [47,   300] loss: 1.594
2025-02-24T20:29:03.619633+0300 | INFO | [47,   400] loss: 1.621
2025-02-24T20:29:16.794618+0300 | INFO | [47,   500] loss: 1.612
2025-02-24T20:29:30.054739+0300 | INFO | [47,   600] loss: 1.603
2025-02-24T20:29:42.135018+0300 | INFO | [47,   700] loss: 1.627
2025-02-24T20:29:55.077036+0300 | INFO | [47,   800] loss: 1.603
2025-02-24T20:30:06.984064+0300 | INFO | [47,   900] loss: 1.602
2025-02-24T20:30:20.364133+0300 | INFO | [47,  1000] loss: 1.625
2025-02-24T20:30:32.786736+0300 | INFO | [47,  1100] loss: 1.602
2025-02-24T20:30:45.342141+0300 | INFO | [47,  1200] loss: 1.605
2025-02-24T20:30:58.296987+0300 | INFO | [47,  1300] loss: 1.629
2025-02-24T20:31:08.921262+0300 | INFO | [47,  1400] loss: 1.612
2025-02-24T20:31:19.484319+0300 | INFO | [47,  1500] loss: 1.601
2025-02-24T20:31:30.058674+0300 | INFO | [47,  1600] loss: 1.613
2025-02-24T20:31:40.592727+0300 | INFO | [47,  1700] loss: 1.600
2025-02-24T20:31:51.286141+0300 | INFO | [47,  1800] loss: 1.595
2025-02-24T20:32:01.886895+0300 | INFO | [47,  1900] loss: 1.601
2025-02-24T20:32:12.879975+0300 | INFO | [47,  2000] loss: 1.618
2025-02-24T20:32:23.477704+0300 | INFO | [47,  2100] loss: 1.614
2025-02-24T20:32:34.156972+0300 | INFO | [47,  2200] loss: 1.617
2025-02-24T20:32:44.534549+0300 | INFO | [47,  2300] loss: 1.621
2025-02-24T20:32:55.983255+0300 | INFO | [47,  2400] loss: 1.592
2025-02-24T20:33:07.360885+0300 | INFO | [47,  2500] loss: 1.601
2025-02-24T20:33:18.199400+0300 | INFO | [47,  2600] loss: 1.616
2025-02-24T20:33:30.283502+0300 | INFO | [47,  2700] loss: 1.617
2025-02-24T20:33:41.122967+0300 | INFO | [47,  2800] loss: 1.618
2025-02-24T20:33:51.653595+0300 | INFO | [47,  2900] loss: 1.623
2025-02-24T20:34:02.396524+0300 | INFO | [47,  3000] loss: 1.629
2025-02-24T20:34:13.193457+0300 | INFO | [47,  3100] loss: 1.615
2025-02-24T20:34:23.642220+0300 | INFO | [47,  3200] loss: 1.608
2025-02-24T20:34:34.286124+0300 | INFO | [47,  3300] loss: 1.611
2025-02-24T20:34:44.970577+0300 | INFO | [47,  3400] loss: 1.609
2025-02-24T20:34:54.471768+0300 | INFO | [47,  3500] loss: 1.623
2025-02-24T20:35:06.439913+0300 | INFO | [47,  3600] loss: 1.615
2025-02-24T20:35:17.575768+0300 | INFO | [47,  3700] loss: 1.618
2025-02-24T20:35:28.030635+0300 | INFO | [47,  3800] loss: 1.595
2025-02-24T20:35:38.600581+0300 | INFO | [47,  3900] loss: 1.616
2025-02-24T20:35:49.333756+0300 | INFO | [47,  4000] loss: 1.602
2025-02-24T20:35:59.664781+0300 | INFO | [47,  4100] loss: 1.613
2025-02-24T20:36:09.912342+0300 | INFO | [47,  4200] loss: 1.622
2025-02-24T20:36:20.640946+0300 | INFO | [47,  4300] loss: 1.606
2025-02-24T20:36:31.219508+0300 | INFO | [47,  4400] loss: 1.604
2025-02-24T20:36:45.633067+0300 | INFO | [47,  4500] loss: 1.606
2025-02-24T20:36:56.070600+0300 | INFO | [47,  4600] loss: 1.614
2025-02-24T20:37:05.772987+0300 | INFO | [47,  4700] loss: 1.622
2025-02-24T20:37:17.452077+0300 | INFO | [47,  4800] loss: 1.627
2025-02-24T20:37:28.690313+0300 | INFO | [47,  4900] loss: 1.619
2025-02-24T20:37:39.862659+0300 | DEBUG | Saving model to flat file storage. Save #47
2025-02-24T20:37:39.889814+0300 | INFO | Averaging client parameters
2025-02-24T20:37:39.899773+0300 | INFO | Updating parameters on client #0
2025-02-24T20:37:55.173289+0300 | DEBUG | Test set: Accuracy: 7604/10000 (76%)
2025-02-24T20:37:55.175306+0300 | DEBUG | Test set: Loss: 1.6999986171722412
2025-02-24T20:37:55.279063+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.86      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.71      0.67      0.69      1000
           3       0.52      0.77      0.62      1200
           4       0.69      0.82      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.83      0.85      0.84      1000
           7       0.81      0.83      0.82      1000
           8       0.89      0.88      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.71      0.74      0.72     10000
weighted avg       0.72      0.76      0.73     10000

2025-02-24T20:37:55.281061+0300 | DEBUG | Confusion Matrix:
[[857   8  30  25  14   0   7  11  32  16]
 [ 11 912   2   6   1   0   7   2  16  43]
 [ 68   4 669  74  94   0  51  23  13   4]
 [ 23   2  69 924  80   0  49  36  11   6]
 [ 15   1  31  68 821   0  31  26   6   1]
 [  8   0  73 557  68   0  22  67   5   0]
 [  9   3  40  45  45   0 847   6   5   0]
 [ 17   1  19  60  67   0   2 828   1   5]
 [ 59  17   4   9   1   0   4   6 882  18]
 [ 43  40   4  16   0   0   6  12  15 864]]
2025-02-24T20:37:55.282061+0300 | DEBUG | Class precision: [0.77207207 0.92307692 0.7109458  0.51793722 0.68933669        nan
 0.82553606 0.81415929 0.89452333 0.90282132]
2025-02-24T20:37:55.285058+0300 | DEBUG | Class recall: [0.857 0.912 0.669 0.77  0.821 0.    0.847 0.828 0.882 0.864]
2025-02-24T20:37:55.341485+0300 | INFO | Training epoch #48 on client #0
2025-02-24T20:37:55.342492+0300 | DEBUG | Saving model to flat file storage. Save #48
2025-02-24T20:37:55.477885+0300 | INFO | [48,     0] loss: 0.018
2025-02-24T20:38:07.160438+0300 | INFO | [48,   100] loss: 1.603
2025-02-24T20:38:21.147158+0300 | INFO | [48,   200] loss: 1.606
2025-02-24T20:39:02.053017+0300 | INFO | [48,   300] loss: 1.588
2025-02-24T20:39:46.797509+0300 | INFO | [48,   400] loss: 1.610
2025-02-24T20:40:30.772638+0300 | INFO | [48,   500] loss: 1.605
2025-02-24T20:41:15.883853+0300 | INFO | [48,   600] loss: 1.590
2025-02-24T20:41:59.859016+0300 | INFO | [48,   700] loss: 1.612
2025-02-24T20:42:44.083600+0300 | INFO | [48,   800] loss: 1.649
2025-02-24T20:43:28.689884+0300 | INFO | [48,   900] loss: 1.609
2025-02-24T20:44:15.136785+0300 | INFO | [48,  1000] loss: 1.602
2025-02-24T20:44:59.238395+0300 | INFO | [48,  1100] loss: 1.629
2025-02-24T20:45:44.725840+0300 | INFO | [48,  1200] loss: 1.614
2025-02-24T20:46:30.090119+0300 | INFO | [48,  1300] loss: 1.594
2025-02-24T20:47:15.015009+0300 | INFO | [48,  1400] loss: 1.601
2025-02-24T20:48:00.544225+0300 | INFO | [48,  1500] loss: 1.599
2025-02-24T20:48:44.986346+0300 | INFO | [48,  1600] loss: 1.610
2025-02-24T20:49:33.994447+0300 | INFO | [48,  1700] loss: 1.604
2025-02-24T20:50:18.433999+0300 | INFO | [48,  1800] loss: 1.619
2025-02-24T20:51:03.464672+0300 | INFO | [48,  1900] loss: 1.609
2025-02-24T20:51:51.312407+0300 | INFO | [48,  2000] loss: 1.617
2025-02-24T20:52:34.934075+0300 | INFO | [48,  2100] loss: 1.612
2025-02-24T20:53:22.383856+0300 | INFO | [48,  2200] loss: 1.620
2025-02-24T20:54:06.378065+0300 | INFO | [48,  2300] loss: 1.602
2025-02-24T20:54:51.082288+0300 | INFO | [48,  2400] loss: 1.613
2025-02-24T20:55:35.866123+0300 | INFO | [48,  2500] loss: 1.603
2025-02-24T20:56:20.884064+0300 | INFO | [48,  2600] loss: 1.595
2025-02-24T20:57:05.435391+0300 | INFO | [48,  2700] loss: 1.603
2025-02-24T20:57:50.391400+0300 | INFO | [48,  2800] loss: 1.602
2025-02-24T20:58:34.135466+0300 | INFO | [48,  2900] loss: 1.628
2025-02-24T20:59:18.010365+0300 | INFO | [48,  3000] loss: 1.593
2025-02-24T21:00:01.436313+0300 | INFO | [48,  3100] loss: 1.633
2025-02-24T21:00:44.726600+0300 | INFO | [48,  3200] loss: 1.618
2025-02-24T21:01:29.064081+0300 | INFO | [48,  3300] loss: 1.603
2025-02-24T21:02:12.922518+0300 | INFO | [48,  3400] loss: 1.614
2025-02-24T21:02:55.844462+0300 | INFO | [48,  3500] loss: 1.623
2025-02-24T21:03:39.108624+0300 | INFO | [48,  3600] loss: 1.611
2025-02-24T21:04:27.429208+0300 | INFO | [48,  3700] loss: 1.594
2025-02-24T21:05:35.166102+0300 | INFO | [48,  3800] loss: 1.600
2025-02-24T21:06:21.293273+0300 | INFO | [48,  3900] loss: 1.602
2025-02-24T21:07:06.289427+0300 | INFO | [48,  4000] loss: 1.607
2025-02-24T21:07:53.344073+0300 | INFO | [48,  4100] loss: 1.622
2025-02-24T21:08:36.134754+0300 | INFO | [48,  4200] loss: 1.625
2025-02-24T21:09:20.243638+0300 | INFO | [48,  4300] loss: 1.596
2025-02-24T21:10:03.761070+0300 | INFO | [48,  4400] loss: 1.616
2025-02-24T21:10:47.424639+0300 | INFO | [48,  4500] loss: 1.616
2025-02-24T21:11:31.970199+0300 | INFO | [48,  4600] loss: 1.619
2025-02-24T21:12:19.150247+0300 | INFO | [48,  4700] loss: 1.618
2025-02-24T21:13:09.294994+0300 | INFO | [48,  4800] loss: 1.614
2025-02-24T21:13:59.724445+0300 | INFO | [48,  4900] loss: 1.611
2025-02-24T21:14:49.696852+0300 | DEBUG | Saving model to flat file storage. Save #48
2025-02-24T21:14:49.715735+0300 | INFO | Averaging client parameters
2025-02-24T21:14:49.725117+0300 | INFO | Updating parameters on client #0
2025-02-24T21:15:37.088207+0300 | DEBUG | Test set: Accuracy: 7501/10000 (75%)
2025-02-24T21:15:37.090701+0300 | DEBUG | Test set: Loss: 1.710440993309021
2025-02-24T21:15:37.254774+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.87      0.78      1000
           1       0.92      0.90      0.91      1000
           2       0.61      0.74      0.67      1000
           3       0.53      0.71      0.61      1200
           4       0.78      0.77      0.78      1000
           5       0.00      0.00      0.00       800
           6       0.74      0.89      0.81      1000
           7       0.85      0.78      0.82      1000
           8       0.90      0.86      0.88      1000
           9       0.90      0.85      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-24T21:15:37.256784+0300 | DEBUG | Confusion Matrix:
[[868   7  49  14   9   0  11   5  29   8]
 [ 25 897   5   8   0   0  10   1  14  40]
 [ 68   2 736  45  51   0  71  16   7   4]
 [ 45   4 109 847  51   0  86  36  11  11]
 [ 16   1  47  63 772   0  71  22   4   4]
 [ 17   2 125 520  40   0  42  44   8   2]
 [ 13   1  47  31  12   0 889   3   4   0]
 [ 35   1  60  53  49   0  10 781   2   9]
 [ 77  11  15   8   3   0   4   2 862  18]
 [ 55  46   9   9   0   0   7   4  21 849]]
2025-02-24T21:15:37.257786+0300 | DEBUG | Class precision: [0.71205906 0.92283951 0.61231281 0.53003755 0.78216819        nan
 0.74021649 0.85448578 0.8960499  0.8984127 ]
2025-02-24T21:15:37.260065+0300 | DEBUG | Class recall: [0.868      0.897      0.736      0.70583333 0.772      0.
 0.889      0.781      0.862      0.849     ]
2025-02-24T21:15:37.263345+0300 | INFO | Training epoch #49 on client #0
2025-02-24T21:15:37.264361+0300 | DEBUG | Saving model to flat file storage. Save #49
2025-02-24T21:15:37.860226+0300 | INFO | [49,     0] loss: 0.016
2025-02-24T21:16:29.494277+0300 | INFO | [49,   100] loss: 1.588
2025-02-24T21:17:21.340818+0300 | INFO | [49,   200] loss: 1.612
2025-02-24T21:18:15.589414+0300 | INFO | [49,   300] loss: 1.601
2025-02-24T21:19:06.417606+0300 | INFO | [49,   400] loss: 1.605
2025-02-24T21:19:57.488112+0300 | INFO | [49,   500] loss: 1.602
2025-02-24T21:20:45.564743+0300 | INFO | [49,   600] loss: 1.621
2025-02-24T21:21:31.160111+0300 | INFO | [49,   700] loss: 1.623
2025-02-24T21:22:17.088722+0300 | INFO | [49,   800] loss: 1.626
2025-02-24T21:23:03.166740+0300 | INFO | [49,   900] loss: 1.612
2025-02-24T21:23:51.175394+0300 | INFO | [49,  1000] loss: 1.607
2025-02-24T21:24:35.105276+0300 | INFO | [49,  1100] loss: 1.622
2025-02-24T21:25:19.354382+0300 | INFO | [49,  1200] loss: 1.622
2025-02-24T21:26:04.184935+0300 | INFO | [49,  1300] loss: 1.601
2025-02-24T21:26:48.098261+0300 | INFO | [49,  1400] loss: 1.613
2025-02-24T21:27:32.294244+0300 | INFO | [49,  1500] loss: 1.607
2025-02-24T21:28:17.124571+0300 | INFO | [49,  1600] loss: 1.595
2025-02-24T21:29:00.658450+0300 | INFO | [49,  1700] loss: 1.613
2025-02-24T21:29:45.197168+0300 | INFO | [49,  1800] loss: 1.603
2025-02-24T21:30:33.755915+0300 | INFO | [49,  1900] loss: 1.617
2025-02-24T21:31:19.774595+0300 | INFO | [49,  2000] loss: 1.620
2025-02-24T21:32:06.701432+0300 | INFO | [49,  2100] loss: 1.616
2025-02-24T21:32:50.615221+0300 | INFO | [49,  2200] loss: 1.588
2025-02-24T21:33:36.480466+0300 | INFO | [49,  2300] loss: 1.603
2025-02-24T21:34:22.212052+0300 | INFO | [49,  2400] loss: 1.613
2025-02-24T21:35:07.720128+0300 | INFO | [49,  2500] loss: 1.594
2025-02-24T21:35:52.950522+0300 | INFO | [49,  2600] loss: 1.618
2025-02-24T21:36:37.860862+0300 | INFO | [49,  2700] loss: 1.624
2025-02-24T21:37:24.458913+0300 | INFO | [49,  2800] loss: 1.604
2025-02-24T21:38:14.108656+0300 | INFO | [49,  2900] loss: 1.600
2025-02-24T21:38:59.363596+0300 | INFO | [49,  3000] loss: 1.584
2025-02-24T21:39:46.033308+0300 | INFO | [49,  3100] loss: 1.606
2025-02-24T21:40:48.597200+0300 | INFO | [49,  3200] loss: 1.606
2025-02-24T21:41:39.609953+0300 | INFO | [49,  3300] loss: 1.591
2025-02-24T21:42:25.468947+0300 | INFO | [49,  3400] loss: 1.599
2025-02-24T21:43:11.617808+0300 | INFO | [49,  3500] loss: 1.594
2025-02-24T21:44:00.625397+0300 | INFO | [49,  3600] loss: 1.632
2025-02-24T21:45:43.335521+0300 | INFO | [49,  3700] loss: 1.649
2025-02-24T21:46:44.680915+0300 | INFO | [49,  3800] loss: 1.610
2025-02-24T21:47:36.202686+0300 | INFO | [49,  3900] loss: 1.591
2025-02-24T21:48:25.598131+0300 | INFO | [49,  4000] loss: 1.607
2025-02-24T21:49:13.795566+0300 | INFO | [49,  4100] loss: 1.603
2025-02-24T21:50:02.633793+0300 | INFO | [49,  4200] loss: 1.614
2025-02-24T21:50:50.896094+0300 | INFO | [49,  4300] loss: 1.602
2025-02-24T21:51:42.012747+0300 | INFO | [49,  4400] loss: 1.611
2025-02-24T21:52:28.853866+0300 | INFO | [49,  4500] loss: 1.602
2025-02-24T21:53:20.168688+0300 | INFO | [49,  4600] loss: 1.604
2025-02-24T21:54:08.327244+0300 | INFO | [49,  4700] loss: 1.618
2025-02-24T21:54:55.923733+0300 | INFO | [49,  4800] loss: 1.611
2025-02-24T21:55:44.531710+0300 | INFO | [49,  4900] loss: 1.639
2025-02-24T21:56:32.751559+0300 | DEBUG | Saving model to flat file storage. Save #49
2025-02-24T21:56:32.788053+0300 | INFO | Averaging client parameters
2025-02-24T21:56:32.877966+0300 | INFO | Updating parameters on client #0
2025-02-24T21:57:20.831504+0300 | DEBUG | Test set: Accuracy: 7546/10000 (75%)
2025-02-24T21:57:20.832508+0300 | DEBUG | Test set: Loss: 1.7061595916748047
2025-02-24T21:57:20.994438+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.83      0.80      1000
           1       0.92      0.89      0.90      1000
           2       0.70      0.68      0.69      1000
           3       0.52      0.73      0.61      1200
           4       0.71      0.82      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.74      0.90      0.81      1000
           7       0.84      0.82      0.83      1000
           8       0.86      0.90      0.88      1000
           9       0.90      0.84      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.75      0.73     10000

2025-02-24T21:57:20.994947+0300 | DEBUG | Confusion Matrix:
[[827  10  49  16  22   0  10   7  48  11]
 [ 11 891   2   8   0   0  11   2  29  46]
 [ 62   1 679  61  90   0  86  15   3   3]
 [ 27   5  74 882  78   0  78  32  13  11]
 [ 10   1  26  57 816   0  54  29   5   2]
 [ 12   2  80 545  57   0  36  58   9   1]
 [  7   0  22  40  28   0 895   4   3   1]
 [ 21   2  25  61  48   0  18 817   4   4]
 [ 47  14  10   7   3   0   7   4 896  12]
 [ 43  46   6  14   2   0  11   9  26 843]]
2025-02-24T21:57:20.995963+0300 | DEBUG | Class precision: [0.77507029 0.91666667 0.69784173 0.52158486 0.71328671        nan
 0.74212272 0.83623337 0.86486486 0.90256959]
2025-02-24T21:57:21.009974+0300 | DEBUG | Class recall: [0.827 0.891 0.679 0.735 0.816 0.    0.895 0.817 0.896 0.843]
2025-02-24T21:57:21.011974+0300 | INFO | Training epoch #50 on client #0
2025-02-24T21:57:21.030978+0300 | DEBUG | Saving model to flat file storage. Save #50
2025-02-24T21:57:21.673796+0300 | INFO | [50,     0] loss: 0.016
2025-02-24T21:58:09.358098+0300 | INFO | [50,   100] loss: 1.611
2025-02-24T21:58:59.501867+0300 | INFO | [50,   200] loss: 1.614
2025-02-24T21:59:49.443941+0300 | INFO | [50,   300] loss: 1.619
2025-02-24T22:00:40.138095+0300 | INFO | [50,   400] loss: 1.600
2025-02-24T22:01:26.859321+0300 | INFO | [50,   500] loss: 1.598
2025-02-24T22:02:14.804951+0300 | INFO | [50,   600] loss: 1.618
2025-02-24T22:03:02.136959+0300 | INFO | [50,   700] loss: 1.588
2025-02-24T22:03:51.591393+0300 | INFO | [50,   800] loss: 1.597
2025-02-24T22:04:42.130091+0300 | INFO | [50,   900] loss: 1.602
2025-02-24T22:05:32.363395+0300 | INFO | [50,  1000] loss: 1.618
2025-02-24T22:06:23.674882+0300 | INFO | [50,  1100] loss: 1.601
2025-02-24T22:07:10.819981+0300 | INFO | [50,  1200] loss: 1.611
2025-02-24T22:07:58.629489+0300 | INFO | [50,  1300] loss: 1.601
2025-02-24T22:08:49.581491+0300 | INFO | [50,  1400] loss: 1.590
2025-02-24T22:09:36.947923+0300 | INFO | [50,  1500] loss: 1.616
2025-02-24T22:10:25.066471+0300 | INFO | [50,  1600] loss: 1.618
2025-02-24T22:11:14.339612+0300 | INFO | [50,  1700] loss: 1.589
2025-02-24T22:12:06.930885+0300 | INFO | [50,  1800] loss: 1.618
2025-02-24T22:13:11.024650+0300 | INFO | [50,  1900] loss: 1.618
2025-02-24T22:13:46.969949+0300 | INFO | [50,  2000] loss: 1.601
2025-02-24T22:13:58.464485+0300 | INFO | [50,  2100] loss: 1.577
2025-02-24T22:14:08.929449+0300 | INFO | [50,  2200] loss: 1.622
2025-02-24T22:14:19.565392+0300 | INFO | [50,  2300] loss: 1.600
2025-02-24T22:14:30.210132+0300 | INFO | [50,  2400] loss: 1.626
2025-02-24T22:14:40.805219+0300 | INFO | [50,  2500] loss: 1.611
2025-02-24T22:14:54.754499+0300 | INFO | [50,  2600] loss: 1.611
2025-02-24T22:15:06.311319+0300 | INFO | [50,  2700] loss: 1.611
2025-02-24T22:15:16.697967+0300 | INFO | [50,  2800] loss: 1.612
2025-02-24T22:15:27.044704+0300 | INFO | [50,  2900] loss: 1.599
2025-02-24T22:15:38.067076+0300 | INFO | [50,  3000] loss: 1.604
2025-02-24T22:15:48.955000+0300 | INFO | [50,  3100] loss: 1.618
2025-02-24T22:15:59.556170+0300 | INFO | [50,  3200] loss: 1.601
2025-02-24T22:16:09.505767+0300 | INFO | [50,  3300] loss: 1.606
2025-02-24T22:16:20.012613+0300 | INFO | [50,  3400] loss: 1.628
2025-02-24T22:16:31.187344+0300 | INFO | [50,  3500] loss: 1.604
2025-02-24T22:16:41.608262+0300 | INFO | [50,  3600] loss: 1.622
2025-02-24T22:16:52.110144+0300 | INFO | [50,  3700] loss: 1.600
2025-02-24T22:17:02.711116+0300 | INFO | [50,  3800] loss: 1.598
2025-02-24T22:17:13.258817+0300 | INFO | [50,  3900] loss: 1.597
2025-02-24T22:17:24.106261+0300 | INFO | [50,  4000] loss: 1.597
2025-02-24T22:17:34.786156+0300 | INFO | [50,  4100] loss: 1.621
2025-02-24T22:17:46.931339+0300 | INFO | [50,  4200] loss: 1.631
2025-02-24T22:17:57.686898+0300 | INFO | [50,  4300] loss: 1.613
2025-02-24T22:18:08.208557+0300 | INFO | [50,  4400] loss: 1.621
2025-02-24T22:18:19.110893+0300 | INFO | [50,  4500] loss: 1.616
2025-02-24T22:18:29.965999+0300 | INFO | [50,  4600] loss: 1.599
2025-02-24T22:18:40.810217+0300 | INFO | [50,  4700] loss: 1.618
2025-02-24T22:18:51.209728+0300 | INFO | [50,  4800] loss: 1.599
2025-02-24T22:19:02.058050+0300 | INFO | [50,  4900] loss: 1.589
2025-02-24T22:19:12.681277+0300 | DEBUG | Updating LR for optimizer
2025-02-24T22:19:12.683278+0300 | DEBUG | New LR: 5e-05
2025-02-24T22:19:12.685838+0300 | DEBUG | Saving model to flat file storage. Save #50
2025-02-24T22:19:12.710828+0300 | INFO | Averaging client parameters
2025-02-24T22:19:12.722823+0300 | INFO | Updating parameters on client #0
2025-02-24T22:19:27.858806+0300 | DEBUG | Test set: Accuracy: 7525/10000 (75%)
2025-02-24T22:19:27.860801+0300 | DEBUG | Test set: Loss: 1.7072778940200806
2025-02-24T22:19:27.959753+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.82      0.79      1000
           1       0.92      0.90      0.91      1000
           2       0.70      0.70      0.70      1000
           3       0.49      0.78      0.61      1200
           4       0.71      0.80      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.83      0.84      0.83      1000
           7       0.86      0.78      0.82      1000
           8       0.87      0.88      0.87      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.75      0.73     10000

2025-02-24T22:19:27.964650+0300 | DEBUG | Confusion Matrix:
[[817  11  43  30  18   0   3  11  43  24]
 [  7 901   3   6   1   0   9   3  25  45]
 [ 61   1 701  82  81   0  47  11  10   6]
 [ 25   5  65 938  77   0  47  20  10  13]
 [ 19   1  39  69 804   0  31  27   8   2]
 [ 14   0  70 596  52   0  20  36   9   3]
 [ 12   3  39  57  39   0 843   3   2   2]
 [ 31   4  25  94  56   0   5 777   4   4]
 [ 53  11   9  12   4   0   5   5 880  21]
 [ 30  44   5  15   2   0  11   7  22 864]]
2025-02-24T22:19:27.965642+0300 | DEBUG | Class precision: [0.76426567 0.91845056 0.7017017  0.49394418 0.70899471        nan
 0.82566112 0.86333333 0.86870681 0.87804878]
2025-02-24T22:19:27.967644+0300 | DEBUG | Class recall: [0.817      0.901      0.701      0.78166667 0.804      0.
 0.843      0.777      0.88       0.864     ]
2025-02-24T22:19:28.013527+0300 | INFO | Training epoch #51 on client #0
2025-02-24T22:19:28.016526+0300 | DEBUG | Saving model to flat file storage. Save #51
2025-02-24T22:19:28.155264+0300 | INFO | [51,     0] loss: 0.017
2025-02-24T22:19:38.726003+0300 | INFO | [51,   100] loss: 1.603
2025-02-24T22:19:49.682637+0300 | INFO | [51,   200] loss: 1.584
2025-02-24T22:20:00.463291+0300 | INFO | [51,   300] loss: 1.611
2025-02-24T22:20:11.432207+0300 | INFO | [51,   400] loss: 1.597
2025-02-24T22:20:21.852661+0300 | INFO | [51,   500] loss: 1.603
2025-02-24T22:20:32.472561+0300 | INFO | [51,   600] loss: 1.619
2025-02-24T22:20:43.210511+0300 | INFO | [51,   700] loss: 1.596
2025-02-24T22:20:53.923292+0300 | INFO | [51,   800] loss: 1.622
2025-02-24T22:21:04.972654+0300 | INFO | [51,   900] loss: 1.589
2025-02-24T22:21:16.293029+0300 | INFO | [51,  1000] loss: 1.598
2025-02-24T22:21:27.669457+0300 | INFO | [51,  1100] loss: 1.613
2025-02-24T22:21:38.855906+0300 | INFO | [51,  1200] loss: 1.601
2025-02-24T22:21:50.126513+0300 | INFO | [51,  1300] loss: 1.590
2025-02-24T22:22:01.343885+0300 | INFO | [51,  1400] loss: 1.603
2025-02-24T22:22:12.201538+0300 | INFO | [51,  1500] loss: 1.588
2025-02-24T22:22:23.635829+0300 | INFO | [51,  1600] loss: 1.604
2025-02-24T22:22:35.194213+0300 | INFO | [51,  1700] loss: 1.612
2025-02-24T22:22:46.566444+0300 | INFO | [51,  1800] loss: 1.592
2025-02-24T22:22:59.148846+0300 | INFO | [51,  1900] loss: 1.625
2025-02-24T22:23:16.153032+0300 | INFO | [51,  2000] loss: 1.587
2025-02-24T22:23:27.542345+0300 | INFO | [51,  2100] loss: 1.613
2025-02-24T22:23:38.656166+0300 | INFO | [51,  2200] loss: 1.581
2025-02-24T22:23:49.692951+0300 | INFO | [51,  2300] loss: 1.582
2025-02-24T22:24:00.537732+0300 | INFO | [51,  2400] loss: 1.607
2025-02-24T22:24:11.108583+0300 | INFO | [51,  2500] loss: 1.587
2025-02-24T22:24:21.894991+0300 | INFO | [51,  2600] loss: 1.591
2025-02-24T22:24:32.596852+0300 | INFO | [51,  2700] loss: 1.604
2025-02-24T22:24:43.345628+0300 | INFO | [51,  2800] loss: 1.604
2025-02-24T22:24:53.855303+0300 | INFO | [51,  2900] loss: 1.591
2025-02-24T22:25:04.481330+0300 | INFO | [51,  3000] loss: 1.591
2025-02-24T22:25:17.817354+0300 | INFO | [51,  3100] loss: 1.612
2025-02-24T22:25:28.745129+0300 | INFO | [51,  3200] loss: 1.604
2025-02-24T22:25:39.309875+0300 | INFO | [51,  3300] loss: 1.578
2025-02-24T22:25:50.270760+0300 | INFO | [51,  3400] loss: 1.593
2025-02-24T22:26:00.768253+0300 | INFO | [51,  3500] loss: 1.583
2025-02-24T22:26:11.789871+0300 | INFO | [51,  3600] loss: 1.615
2025-02-24T22:26:22.813419+0300 | INFO | [51,  3700] loss: 1.592
2025-02-24T22:26:33.619983+0300 | INFO | [51,  3800] loss: 1.587
2025-02-24T22:26:44.312345+0300 | INFO | [51,  3900] loss: 1.597
2025-02-24T22:26:55.075028+0300 | INFO | [51,  4000] loss: 1.591
2025-02-24T22:27:05.773686+0300 | INFO | [51,  4100] loss: 1.590
2025-02-24T22:27:16.184718+0300 | INFO | [51,  4200] loss: 1.593
2025-02-24T22:27:27.024866+0300 | INFO | [51,  4300] loss: 1.589
2025-02-24T22:27:37.811364+0300 | INFO | [51,  4400] loss: 1.586
2025-02-24T22:27:48.450872+0300 | INFO | [51,  4500] loss: 1.583
2025-02-24T22:27:58.805624+0300 | INFO | [51,  4600] loss: 1.603
2025-02-24T22:28:09.686774+0300 | INFO | [51,  4700] loss: 1.594
2025-02-24T22:28:20.490986+0300 | INFO | [51,  4800] loss: 1.583
2025-02-24T22:28:31.225878+0300 | INFO | [51,  4900] loss: 1.589
2025-02-24T22:28:42.054508+0300 | DEBUG | Saving model to flat file storage. Save #51
2025-02-24T22:28:42.082618+0300 | INFO | Averaging client parameters
2025-02-24T22:28:42.091629+0300 | INFO | Updating parameters on client #0
2025-02-24T22:28:57.342738+0300 | DEBUG | Test set: Accuracy: 7647/10000 (76%)
2025-02-24T22:28:57.342738+0300 | DEBUG | Test set: Loss: 1.694893717765808
2025-02-24T22:28:57.434502+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.83      0.81      1000
           1       0.92      0.90      0.91      1000
           2       0.73      0.70      0.71      1000
           3       0.53      0.77      0.62      1200
           4       0.74      0.81      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.86      0.83      1000
           7       0.82      0.84      0.83      1000
           8       0.86      0.90      0.88      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.71      0.75      0.72     10000
weighted avg       0.72      0.76      0.74     10000

2025-02-24T22:28:57.437546+0300 | DEBUG | Confusion Matrix:
[[834  11  39  13  15   0   5   8  52  23]
 [ 14 904   4   4   1   0   4   1  21  47]
 [ 58   4 699  65  81   0  59  17   8   9]
 [ 32   5  59 921  62   0  58  38  11  14]
 [ 18   1  33  58 808   0  36  31   9   6]
 [ 10   1  62 567  52   0  25  70  10   3]
 [ 12   2  29  50  30   0 860   6   8   3]
 [ 20   2  18  57  43   0   8 842   5   5]
 [ 43   9  10   9   1   0   3   7 897  21]
 [ 27  39   4   9   2   0   4   9  24 882]]
2025-02-24T22:28:57.439611+0300 | DEBUG | Class precision: [0.78089888 0.92433538 0.73040752 0.52538505 0.73789954        nan
 0.80979284 0.81827017 0.85837321 0.87068115]
2025-02-24T22:28:57.440609+0300 | DEBUG | Class recall: [0.834  0.904  0.699  0.7675 0.808  0.     0.86   0.842  0.897  0.882 ]
2025-02-24T22:28:57.483251+0300 | INFO | Training epoch #52 on client #0
2025-02-24T22:28:57.484251+0300 | DEBUG | Saving model to flat file storage. Save #52
2025-02-24T22:28:57.628892+0300 | INFO | [52,     0] loss: 0.017
2025-02-24T22:29:07.911091+0300 | INFO | [52,   100] loss: 1.590
2025-02-24T22:29:19.359297+0300 | INFO | [52,   200] loss: 1.592
2025-02-24T22:29:33.117420+0300 | INFO | [52,   300] loss: 1.590
2025-02-24T22:29:44.008433+0300 | INFO | [52,   400] loss: 1.579
2025-02-24T22:29:54.637591+0300 | INFO | [52,   500] loss: 1.579
2025-02-24T22:30:05.262311+0300 | INFO | [52,   600] loss: 1.599
2025-02-24T22:30:15.983587+0300 | INFO | [52,   700] loss: 1.574
2025-02-24T22:30:26.753144+0300 | INFO | [52,   800] loss: 1.583
2025-02-24T22:30:37.622552+0300 | INFO | [52,   900] loss: 1.585
2025-02-24T22:30:48.151293+0300 | INFO | [52,  1000] loss: 1.602
2025-02-24T22:30:58.892563+0300 | INFO | [52,  1100] loss: 1.598
2025-02-24T22:31:09.484330+0300 | INFO | [52,  1200] loss: 1.591
2025-02-24T22:31:22.888228+0300 | INFO | [52,  1300] loss: 1.583
2025-02-24T22:31:33.539687+0300 | INFO | [52,  1400] loss: 1.593
2025-02-24T22:31:48.546985+0300 | INFO | [52,  1500] loss: 1.584
2025-02-24T22:31:59.028389+0300 | INFO | [52,  1600] loss: 1.614
2025-02-24T22:32:09.689803+0300 | INFO | [52,  1700] loss: 1.572
2025-02-24T22:32:20.664800+0300 | INFO | [52,  1800] loss: 1.588
2025-02-24T22:32:31.949587+0300 | INFO | [52,  1900] loss: 1.594
2025-02-24T22:32:42.910965+0300 | INFO | [52,  2000] loss: 1.578
2025-02-24T22:32:53.537610+0300 | INFO | [52,  2100] loss: 1.589
2025-02-24T22:33:04.097329+0300 | INFO | [52,  2200] loss: 1.593
2025-02-24T22:33:14.843023+0300 | INFO | [52,  2300] loss: 1.587
2025-02-24T22:33:25.659436+0300 | INFO | [52,  2400] loss: 1.599
2025-02-24T22:33:36.488094+0300 | INFO | [52,  2500] loss: 1.589
2025-02-24T22:33:47.249954+0300 | INFO | [52,  2600] loss: 1.612
2025-02-24T22:33:58.121287+0300 | INFO | [52,  2700] loss: 1.601
2025-02-24T22:34:08.967049+0300 | INFO | [52,  2800] loss: 1.585
2025-02-24T22:34:19.980925+0300 | INFO | [52,  2900] loss: 1.594
2025-02-24T22:34:30.887533+0300 | INFO | [52,  3000] loss: 1.623
2025-02-24T22:34:41.631502+0300 | INFO | [52,  3100] loss: 1.594
2025-02-24T22:34:52.431305+0300 | INFO | [52,  3200] loss: 1.606
2025-02-24T22:35:03.237856+0300 | INFO | [52,  3300] loss: 1.573
2025-02-24T22:35:16.148208+0300 | INFO | [52,  3400] loss: 1.599
2025-02-24T22:35:27.473552+0300 | INFO | [52,  3500] loss: 1.599
2025-02-24T22:35:38.943259+0300 | INFO | [52,  3600] loss: 1.605
2025-02-24T22:35:49.621714+0300 | INFO | [52,  3700] loss: 1.596
2025-02-24T22:36:00.219018+0300 | INFO | [52,  3800] loss: 1.569
2025-02-24T22:36:10.471259+0300 | INFO | [52,  3900] loss: 1.596
2025-02-24T22:36:21.123361+0300 | INFO | [52,  4000] loss: 1.583
2025-02-24T22:36:33.023069+0300 | INFO | [52,  4100] loss: 1.619
2025-02-24T22:36:45.466354+0300 | INFO | [52,  4200] loss: 1.605
2025-02-24T22:36:57.279520+0300 | INFO | [52,  4300] loss: 1.590
2025-02-24T22:37:08.027363+0300 | INFO | [52,  4400] loss: 1.600
2025-02-24T22:37:21.767603+0300 | INFO | [52,  4500] loss: 1.576
2025-02-24T22:37:32.632585+0300 | INFO | [52,  4600] loss: 1.594
2025-02-24T22:37:43.455920+0300 | INFO | [52,  4700] loss: 1.571
2025-02-24T22:37:54.059286+0300 | INFO | [52,  4800] loss: 1.591
2025-02-24T22:38:04.779269+0300 | INFO | [52,  4900] loss: 1.588
2025-02-24T22:38:17.553529+0300 | DEBUG | Saving model to flat file storage. Save #52
2025-02-24T22:38:17.581431+0300 | INFO | Averaging client parameters
2025-02-24T22:38:17.590538+0300 | INFO | Updating parameters on client #0
2025-02-24T22:38:33.059967+0300 | DEBUG | Test set: Accuracy: 7645/10000 (76%)
2025-02-24T22:38:33.061962+0300 | DEBUG | Test set: Loss: 1.6961181163787842
2025-02-24T22:38:33.155806+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.81      0.81      1000
           1       0.89      0.91      0.90      1000
           2       0.77      0.69      0.73      1000
           3       0.51      0.77      0.62      1200
           4       0.76      0.80      0.78      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.89      0.85      1000
           7       0.79      0.85      0.82      1000
           8       0.88      0.88      0.88      1000
           9       0.84      0.89      0.86      1000

    accuracy                           0.76     10000
   macro avg       0.71      0.75      0.72     10000
weighted avg       0.72      0.76      0.74     10000

2025-02-24T22:38:33.157706+0300 | DEBUG | Confusion Matrix:
[[809  17  38  26  18   0   7   7  50  28]
 [  8 913   0   3   0   0   4   2   7  63]
 [ 50   5 686  77  76   0  65  28   5   8]
 [ 25  11  40 924  54   0  64  52  13  17]
 [ 11   2  30  71 802   0  35  36   8   5]
 [ 12   2  55 573  39   0  29  76  11   3]
 [  9   3  19  39  21   0 892   9   6   2]
 [ 16   3  10  64  38   0   4 854   2   9]
 [ 41  23   6  10   2   0   4   4 878  32]
 [ 26  46   2  11   2   0   5   7  14 887]]
2025-02-24T22:38:33.159740+0300 | DEBUG | Class precision: [0.80337637 0.89073171 0.77426637 0.51390434 0.76235741        nan
 0.80432822 0.7944186  0.8832998  0.84155598]
2025-02-24T22:38:33.161735+0300 | DEBUG | Class recall: [0.809 0.913 0.686 0.77  0.802 0.    0.892 0.854 0.878 0.887]
2025-02-24T22:38:33.220268+0300 | INFO | Training epoch #53 on client #0
2025-02-24T22:38:33.222395+0300 | DEBUG | Saving model to flat file storage. Save #53
2025-02-24T22:38:33.359232+0300 | INFO | [53,     0] loss: 0.016
2025-02-24T22:38:43.809560+0300 | INFO | [53,   100] loss: 1.598
2025-02-24T22:38:54.529556+0300 | INFO | [53,   200] loss: 1.588
2025-02-24T22:39:06.076107+0300 | INFO | [53,   300] loss: 1.585
2025-02-24T22:39:16.718778+0300 | INFO | [53,   400] loss: 1.582
2025-02-24T22:39:27.415775+0300 | INFO | [53,   500] loss: 1.590
2025-02-24T22:39:41.030769+0300 | INFO | [53,   600] loss: 1.574
2025-02-24T22:39:51.786838+0300 | INFO | [53,   700] loss: 1.603
2025-02-24T22:40:02.573219+0300 | INFO | [53,   800] loss: 1.576
2025-02-24T22:40:13.031624+0300 | INFO | [53,   900] loss: 1.604
2025-02-24T22:40:23.695781+0300 | INFO | [53,  1000] loss: 1.593
2025-02-24T22:40:36.023255+0300 | INFO | [53,  1100] loss: 1.564
2025-02-24T22:40:49.241931+0300 | INFO | [53,  1200] loss: 1.594
2025-02-24T22:41:00.033894+0300 | INFO | [53,  1300] loss: 1.603
2025-02-24T22:41:10.337310+0300 | INFO | [53,  1400] loss: 1.591
2025-02-24T22:41:21.168489+0300 | INFO | [53,  1500] loss: 1.587
2025-02-24T22:41:32.080700+0300 | INFO | [53,  1600] loss: 1.584
2025-02-24T22:41:42.787947+0300 | INFO | [53,  1700] loss: 1.586
2025-02-24T22:41:53.491291+0300 | INFO | [53,  1800] loss: 1.577
2025-02-24T22:42:04.375055+0300 | INFO | [53,  1900] loss: 1.602
2025-02-24T22:42:17.459934+0300 | INFO | [53,  2000] loss: 1.570
2025-02-24T22:42:28.510689+0300 | INFO | [53,  2100] loss: 1.581
2025-02-24T22:42:39.264543+0300 | INFO | [53,  2200] loss: 1.585
2025-02-24T22:42:50.207145+0300 | INFO | [53,  2300] loss: 1.583
2025-02-24T22:43:01.013734+0300 | INFO | [53,  2400] loss: 1.598
2025-02-24T22:43:11.351163+0300 | INFO | [53,  2500] loss: 1.590
2025-02-24T22:43:22.069631+0300 | INFO | [53,  2600] loss: 1.602
2025-02-24T22:43:32.803559+0300 | INFO | [53,  2700] loss: 1.597
2025-02-24T22:43:43.667577+0300 | INFO | [53,  2800] loss: 1.587
2025-02-24T22:43:54.449919+0300 | INFO | [53,  2900] loss: 1.582
2025-02-24T22:44:04.200470+0300 | INFO | [53,  3000] loss: 1.579
2025-02-24T22:44:16.956877+0300 | INFO | [53,  3100] loss: 1.564
2025-02-24T22:44:27.717882+0300 | INFO | [53,  3200] loss: 1.585
2025-02-24T22:44:38.156586+0300 | INFO | [53,  3300] loss: 1.595
2025-02-24T22:44:48.177771+0300 | INFO | [53,  3400] loss: 1.590
2025-02-24T22:44:59.042412+0300 | INFO | [53,  3500] loss: 1.576
2025-02-24T22:45:09.513363+0300 | INFO | [53,  3600] loss: 1.596
2025-02-24T22:45:23.874128+0300 | INFO | [53,  3700] loss: 1.597
2025-02-24T22:45:34.281193+0300 | INFO | [53,  3800] loss: 1.582
2025-02-24T22:45:44.988412+0300 | INFO | [53,  3900] loss: 1.611
2025-02-24T22:45:55.551927+0300 | INFO | [53,  4000] loss: 1.575
2025-02-24T22:46:05.805875+0300 | INFO | [53,  4100] loss: 1.596
2025-02-24T22:46:15.991614+0300 | INFO | [53,  4200] loss: 1.585
2025-02-24T22:46:27.202304+0300 | INFO | [53,  4300] loss: 1.586
2025-02-24T22:46:37.750591+0300 | INFO | [53,  4400] loss: 1.559
2025-02-24T22:46:48.592431+0300 | INFO | [53,  4500] loss: 1.602
2025-02-24T22:46:59.159932+0300 | INFO | [53,  4600] loss: 1.582
2025-02-24T22:47:09.572095+0300 | INFO | [53,  4700] loss: 1.582
2025-02-24T22:47:20.497236+0300 | INFO | [53,  4800] loss: 1.602
2025-02-24T22:47:31.068134+0300 | INFO | [53,  4900] loss: 1.584
2025-02-24T22:47:41.881711+0300 | DEBUG | Saving model to flat file storage. Save #53
2025-02-24T22:47:41.910267+0300 | INFO | Averaging client parameters
2025-02-24T22:47:41.917267+0300 | INFO | Updating parameters on client #0
2025-02-24T22:47:56.804453+0300 | DEBUG | Test set: Accuracy: 7653/10000 (77%)
2025-02-24T22:47:56.805456+0300 | DEBUG | Test set: Loss: 1.6951810121536255
2025-02-24T22:47:56.906292+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.92      0.92      0.92      1000
           2       0.68      0.74      0.71      1000
           3       0.52      0.73      0.61      1200
           4       0.78      0.78      0.78      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.89      0.82      1000
           7       0.83      0.83      0.83      1000
           8       0.89      0.88      0.89      1000
           9       0.90      0.89      0.89      1000

    accuracy                           0.77     10000
   macro avg       0.71      0.75      0.73     10000
weighted avg       0.72      0.77      0.74     10000

2025-02-24T22:47:56.910337+0300 | DEBUG | Confusion Matrix:
[[850   9  45  19  13   0   5   7  38  14]
 [ 16 919   0   5   0   0   8   0  10  42]
 [ 58   4 740  59  55   0  61  15   5   3]
 [ 28   4  83 875  54   0  92  38  14  12]
 [ 21   2  44  73 775   0  45  34   6   0]
 [ 11   1 106 527  46   0  37  60   9   3]
 [ 13   3  34  35  13   1 894   3   3   1]
 [ 25   1  24  56  40   0   9 835   3   7]
 [ 53  13   9  12   2   0  11   3 880  17]
 [ 30  38   4  10   2   0   7   7  17 885]]
2025-02-24T22:47:56.912337+0300 | DEBUG | Class precision: [0.76923077 0.92454728 0.6795225  0.52363854 0.775      0.
 0.7647562  0.83333333 0.89340102 0.89939024]
2025-02-24T22:47:56.913326+0300 | DEBUG | Class recall: [0.85       0.919      0.74       0.72916667 0.775      0.
 0.894      0.835      0.88       0.885     ]
2025-02-24T22:47:56.967964+0300 | INFO | Training epoch #54 on client #0
2025-02-24T22:47:56.970963+0300 | DEBUG | Saving model to flat file storage. Save #54
2025-02-24T22:47:57.127235+0300 | INFO | [54,     0] loss: 0.017
2025-02-24T22:48:07.415400+0300 | INFO | [54,   100] loss: 1.592
2025-02-24T22:48:17.828566+0300 | INFO | [54,   200] loss: 1.580
2025-02-24T22:48:29.615434+0300 | INFO | [54,   300] loss: 1.589
2025-02-24T22:48:40.146342+0300 | INFO | [54,   400] loss: 1.584
2025-02-24T22:48:50.807166+0300 | INFO | [54,   500] loss: 1.581
2025-02-24T22:49:03.473490+0300 | INFO | [54,   600] loss: 1.584
2025-02-24T22:49:16.251465+0300 | INFO | [54,   700] loss: 1.573
2025-02-24T22:49:27.020195+0300 | INFO | [54,   800] loss: 1.586
2025-02-24T22:49:37.754443+0300 | INFO | [54,   900] loss: 1.588
2025-02-24T22:49:48.706435+0300 | INFO | [54,  1000] loss: 1.589
2025-02-24T22:49:59.566572+0300 | INFO | [54,  1100] loss: 1.584
2025-02-24T22:50:10.531180+0300 | INFO | [54,  1200] loss: 1.570
2025-02-24T22:50:21.363044+0300 | INFO | [54,  1300] loss: 1.581
2025-02-24T22:50:33.304086+0300 | INFO | [54,  1400] loss: 1.578
2025-02-24T22:50:45.561147+0300 | INFO | [54,  1500] loss: 1.580
2025-02-24T22:50:55.603493+0300 | INFO | [54,  1600] loss: 1.588
2025-02-24T22:51:06.538903+0300 | INFO | [54,  1700] loss: 1.588
2025-02-24T22:51:17.154404+0300 | INFO | [54,  1800] loss: 1.585
2025-02-24T22:51:27.948218+0300 | INFO | [54,  1900] loss: 1.580
2025-02-24T22:51:39.353039+0300 | INFO | [54,  2000] loss: 1.576
2025-02-24T22:51:50.898557+0300 | INFO | [54,  2100] loss: 1.591
2025-02-24T22:52:03.224810+0300 | INFO | [54,  2200] loss: 1.569
2025-02-24T22:52:14.418953+0300 | INFO | [54,  2300] loss: 1.568
2025-02-24T22:52:25.483091+0300 | INFO | [54,  2400] loss: 1.580
2025-02-24T22:52:36.184155+0300 | INFO | [54,  2500] loss: 1.595
2025-02-24T22:52:47.127211+0300 | INFO | [54,  2600] loss: 1.581
2025-02-24T22:53:00.742681+0300 | INFO | [54,  2700] loss: 1.566
2025-02-24T22:53:12.638327+0300 | INFO | [54,  2800] loss: 1.590
2025-02-24T22:53:23.405765+0300 | INFO | [54,  2900] loss: 1.592
2025-02-24T22:53:34.343351+0300 | INFO | [54,  3000] loss: 1.573
2025-02-24T22:53:44.845862+0300 | INFO | [54,  3100] loss: 1.599
2025-02-24T22:53:55.774518+0300 | INFO | [54,  3200] loss: 1.585
2025-02-24T22:54:06.450667+0300 | INFO | [54,  3300] loss: 1.587
2025-02-24T22:54:17.530518+0300 | INFO | [54,  3400] loss: 1.608
2025-02-24T22:54:30.543375+0300 | INFO | [54,  3500] loss: 1.587
2025-02-24T22:54:41.244059+0300 | INFO | [54,  3600] loss: 1.599
2025-02-24T22:54:52.865408+0300 | INFO | [54,  3700] loss: 1.584
2025-02-24T22:55:03.764587+0300 | INFO | [54,  3800] loss: 1.581
2025-02-24T22:55:14.247484+0300 | INFO | [54,  3900] loss: 1.571
2025-02-24T22:55:25.228439+0300 | INFO | [54,  4000] loss: 1.577
2025-02-24T22:55:35.816202+0300 | INFO | [54,  4100] loss: 1.593
2025-02-24T22:55:46.407740+0300 | INFO | [54,  4200] loss: 1.600
2025-02-24T22:55:57.064621+0300 | INFO | [54,  4300] loss: 1.592
2025-02-24T22:56:06.938976+0300 | INFO | [54,  4400] loss: 1.615
2025-02-24T22:56:18.227908+0300 | INFO | [54,  4500] loss: 1.595
2025-02-24T22:56:31.803377+0300 | INFO | [54,  4600] loss: 1.579
2025-02-24T22:56:44.469187+0300 | INFO | [54,  4700] loss: 1.579
2025-02-24T22:56:55.068295+0300 | INFO | [54,  4800] loss: 1.589
2025-02-24T22:57:05.467060+0300 | INFO | [54,  4900] loss: 1.586
2025-02-24T22:57:16.394626+0300 | DEBUG | Saving model to flat file storage. Save #54
2025-02-24T22:57:16.432751+0300 | INFO | Averaging client parameters
2025-02-24T22:57:16.445752+0300 | INFO | Updating parameters on client #0
2025-02-24T22:57:31.829101+0300 | DEBUG | Test set: Accuracy: 7623/10000 (76%)
2025-02-24T22:57:31.831108+0300 | DEBUG | Test set: Loss: 1.697872519493103
2025-02-24T22:57:31.929091+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.85      0.79      1000
           1       0.90      0.92      0.91      1000
           2       0.71      0.72      0.71      1000
           3       0.50      0.79      0.62      1200
           4       0.80      0.76      0.78      1000
           5       0.67      0.00      0.00       800
           6       0.81      0.88      0.84      1000
           7       0.83      0.83      0.83      1000
           8       0.90      0.87      0.88      1000
           9       0.92      0.84      0.88      1000

    accuracy                           0.76     10000
   macro avg       0.78      0.75      0.72     10000
weighted avg       0.77      0.76      0.74     10000

2025-02-24T22:57:31.932082+0300 | DEBUG | Confusion Matrix:
[[855  14  44  25   9   0   3   8  32  10]
 [ 16 916   3   6   0   0   7   1  18  33]
 [ 60   3 718  79  54   0  59  16   6   5]
 [ 31   6  65 948  45   0  56  32   9   8]
 [ 23   2  37  94 759   0  44  35   5   1]
 [ 15   0  82 575  36   2  23  58   8   1]
 [ 16   1  29  59  11   1 877   4   2   0]
 [ 26   2  21  72  36   0   6 830   2   5]
 [ 64  13  12  13   0   0   6   5 873  14]
 [ 46  60   6   8   2   0   7   6  20 845]]
2025-02-24T22:57:31.933077+0300 | DEBUG | Class precision: [0.7421875  0.9006883  0.70599803 0.50452368 0.79726891 0.66666667
 0.80606618 0.83417085 0.89538462 0.9164859 ]
2025-02-24T22:57:31.934072+0300 | DEBUG | Class recall: [0.855  0.916  0.718  0.79   0.759  0.0025 0.877  0.83   0.873  0.845 ]
2025-02-24T22:57:31.987901+0300 | INFO | Training epoch #55 on client #0
2025-02-24T22:57:31.990902+0300 | DEBUG | Saving model to flat file storage. Save #55
2025-02-24T22:57:32.112653+0300 | INFO | [55,     0] loss: 0.017
2025-02-24T22:57:42.813453+0300 | INFO | [55,   100] loss: 1.593
2025-02-24T22:57:53.459586+0300 | INFO | [55,   200] loss: 1.567
2025-02-24T22:58:08.823566+0300 | INFO | [55,   300] loss: 1.595
2025-02-24T22:58:21.733860+0300 | INFO | [55,   400] loss: 1.579
2025-02-24T22:58:32.330005+0300 | INFO | [55,   500] loss: 1.576
2025-02-24T22:58:43.116114+0300 | INFO | [55,   600] loss: 1.585
2025-02-24T22:58:54.122911+0300 | INFO | [55,   700] loss: 1.594
2025-02-24T22:59:04.648460+0300 | INFO | [55,   800] loss: 1.583
2025-02-24T22:59:15.294695+0300 | INFO | [55,   900] loss: 1.586
2025-02-24T22:59:26.496374+0300 | INFO | [55,  1000] loss: 1.565
2025-02-24T22:59:37.260740+0300 | INFO | [55,  1100] loss: 1.580
2025-02-24T22:59:48.287834+0300 | INFO | [55,  1200] loss: 1.592
2025-02-24T22:59:58.920145+0300 | INFO | [55,  1300] loss: 1.591
2025-02-24T23:00:09.498510+0300 | INFO | [55,  1400] loss: 1.583
2025-02-24T23:00:20.217722+0300 | INFO | [55,  1500] loss: 1.594
2025-02-24T23:00:31.059619+0300 | INFO | [55,  1600] loss: 1.570
2025-02-24T23:00:41.269622+0300 | INFO | [55,  1700] loss: 1.590
2025-02-24T23:00:51.756248+0300 | INFO | [55,  1800] loss: 1.597
2025-02-24T23:01:01.765854+0300 | INFO | [55,  1900] loss: 1.570
2025-02-24T23:01:11.826493+0300 | INFO | [55,  2000] loss: 1.576
2025-02-24T23:01:22.552068+0300 | INFO | [55,  2100] loss: 1.573
2025-02-24T23:01:33.659394+0300 | INFO | [55,  2200] loss: 1.596
2025-02-24T23:01:44.309084+0300 | INFO | [55,  2300] loss: 1.609
2025-02-24T23:01:57.320734+0300 | INFO | [55,  2400] loss: 1.592
2025-02-24T23:02:07.659290+0300 | INFO | [55,  2500] loss: 1.573
2025-02-24T23:02:19.766520+0300 | INFO | [55,  2600] loss: 1.578
2025-02-24T23:02:31.574190+0300 | INFO | [55,  2700] loss: 1.590
2025-02-24T23:02:43.387150+0300 | INFO | [55,  2800] loss: 1.580
2025-02-24T23:02:58.158833+0300 | INFO | [55,  2900] loss: 1.576
2025-02-24T23:03:08.954892+0300 | INFO | [55,  3000] loss: 1.576
2025-02-24T23:03:19.606687+0300 | INFO | [55,  3100] loss: 1.590
2025-02-24T23:03:30.269695+0300 | INFO | [55,  3200] loss: 1.589
2025-02-24T23:03:41.235579+0300 | INFO | [55,  3300] loss: 1.578
2025-02-24T23:03:51.973940+0300 | INFO | [55,  3400] loss: 1.585
2025-02-24T23:04:02.467997+0300 | INFO | [55,  3500] loss: 1.589
2025-02-24T23:04:12.743784+0300 | INFO | [55,  3600] loss: 1.598
2025-02-24T23:04:24.091256+0300 | INFO | [55,  3700] loss: 1.577
2025-02-24T23:04:34.785652+0300 | INFO | [55,  3800] loss: 1.602
2025-02-24T23:04:45.825483+0300 | INFO | [55,  3900] loss: 1.576
2025-02-24T23:04:56.397244+0300 | INFO | [55,  4000] loss: 1.593
2025-02-24T23:05:06.615069+0300 | INFO | [55,  4100] loss: 1.580
2025-02-24T23:05:17.437853+0300 | INFO | [55,  4200] loss: 1.578
2025-02-24T23:05:28.131241+0300 | INFO | [55,  4300] loss: 1.584
2025-02-24T23:05:38.914424+0300 | INFO | [55,  4400] loss: 1.585
2025-02-24T23:05:52.597047+0300 | INFO | [55,  4500] loss: 1.582
2025-02-24T23:06:03.469182+0300 | INFO | [55,  4600] loss: 1.589
2025-02-24T23:06:14.029801+0300 | INFO | [55,  4700] loss: 1.579
2025-02-24T23:06:24.579556+0300 | INFO | [55,  4800] loss: 1.597
2025-02-24T23:06:35.293432+0300 | INFO | [55,  4900] loss: 1.557
2025-02-24T23:06:48.966679+0300 | DEBUG | Saving model to flat file storage. Save #55
2025-02-24T23:06:48.975688+0300 | INFO | Averaging client parameters
2025-02-24T23:06:48.984691+0300 | INFO | Updating parameters on client #0
2025-02-24T23:07:04.921925+0300 | DEBUG | Test set: Accuracy: 7597/10000 (76%)
2025-02-24T23:07:04.925927+0300 | DEBUG | Test set: Loss: 1.6998612880706787
2025-02-24T23:07:05.034885+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.83      0.79      1000
           1       0.88      0.92      0.90      1000
           2       0.68      0.72      0.70      1000
           3       0.56      0.64      0.60      1200
           4       0.76      0.81      0.78      1000
           5       0.39      0.10      0.16       800
           6       0.76      0.88      0.82      1000
           7       0.85      0.81      0.83      1000
           8       0.87      0.89      0.88      1000
           9       0.86      0.89      0.87      1000

    accuracy                           0.76     10000
   macro avg       0.74      0.75      0.73     10000
weighted avg       0.74      0.76      0.74     10000

2025-02-24T23:07:05.037781+0300 | DEBUG | Confusion Matrix:
[[827  16  44  19  14   2   2   7  40  29]
 [  9 921   1   2   0   1   3   0  11  52]
 [ 62   5 722  33  63  20  66  14   9   6]
 [ 34  19  88 765  57  68  96  34  16  23]
 [ 20   2  46  48 809   2  38  22  10   3]
 [ 21   5  99 427  48  80  45  57  15   3]
 [ 17   2  34  25  21   5 883   5   6   2]
 [ 32   3  24  37  50  22  10 811   5   6]
 [ 46  18   3   3   3   3   6   2 893  23]
 [ 19  52   6   4   1   0   7   6  19 886]]
2025-02-24T23:07:05.038860+0300 | DEBUG | Class precision: [0.76080957 0.88302972 0.67666354 0.56126192 0.75891182 0.39408867
 0.76384083 0.84655532 0.87207031 0.85769603]
2025-02-24T23:07:05.040897+0300 | DEBUG | Class recall: [0.827  0.921  0.722  0.6375 0.809  0.1    0.883  0.811  0.893  0.886 ]
2025-02-24T23:07:05.094629+0300 | INFO | Training epoch #56 on client #0
2025-02-24T23:07:05.095642+0300 | DEBUG | Saving model to flat file storage. Save #56
2025-02-24T23:07:05.244504+0300 | INFO | [56,     0] loss: 0.017
2025-02-24T23:07:15.676480+0300 | INFO | [56,   100] loss: 1.597
2025-02-24T23:07:26.627463+0300 | INFO | [56,   200] loss: 1.588
2025-02-24T23:07:40.580424+0300 | INFO | [56,   300] loss: 1.569
2025-02-24T23:07:51.768611+0300 | INFO | [56,   400] loss: 1.583
2025-02-24T23:08:06.062579+0300 | INFO | [56,   500] loss: 1.584
2025-02-24T23:08:16.503225+0300 | INFO | [56,   600] loss: 1.589
2025-02-24T23:08:27.274148+0300 | INFO | [56,   700] loss: 1.560
2025-02-24T23:08:37.882206+0300 | INFO | [56,   800] loss: 1.579
2025-02-24T23:08:48.514343+0300 | INFO | [56,   900] loss: 1.582
2025-02-24T23:09:02.089370+0300 | INFO | [56,  1000] loss: 1.577
2025-02-24T23:09:14.309818+0300 | INFO | [56,  1100] loss: 1.586
2025-02-24T23:09:25.042825+0300 | INFO | [56,  1200] loss: 1.574
2025-02-24T23:09:35.870128+0300 | INFO | [56,  1300] loss: 1.581
2025-02-24T23:09:46.643533+0300 | INFO | [56,  1400] loss: 1.548
2025-02-24T23:09:57.316283+0300 | INFO | [56,  1500] loss: 1.570
2025-02-24T23:10:07.526322+0300 | INFO | [56,  1600] loss: 1.579
2025-02-24T23:10:18.610856+0300 | INFO | [56,  1700] loss: 1.590
2025-02-24T23:10:29.568738+0300 | INFO | [56,  1800] loss: 1.593
2025-02-24T23:10:40.403246+0300 | INFO | [56,  1900] loss: 1.581
2025-02-24T23:10:51.433304+0300 | INFO | [56,  2000] loss: 1.571
2025-02-24T23:11:05.520553+0300 | INFO | [56,  2100] loss: 1.574
2025-02-24T23:11:15.503726+0300 | INFO | [56,  2200] loss: 1.572
2025-02-24T23:11:26.408364+0300 | INFO | [56,  2300] loss: 1.576
2025-02-24T23:11:37.157572+0300 | INFO | [56,  2400] loss: 1.571
2025-02-24T23:11:49.210476+0300 | INFO | [56,  2500] loss: 1.570
2025-02-24T23:12:00.117668+0300 | INFO | [56,  2600] loss: 1.574
2025-02-24T23:12:10.991505+0300 | INFO | [56,  2700] loss: 1.571
2025-02-24T23:12:21.668146+0300 | INFO | [56,  2800] loss: 1.600
2025-02-24T23:12:32.515035+0300 | INFO | [56,  2900] loss: 1.570
2025-02-24T23:12:43.200639+0300 | INFO | [56,  3000] loss: 1.561
2025-02-24T23:12:53.665329+0300 | INFO | [56,  3100] loss: 1.583
2025-02-24T23:13:04.066928+0300 | INFO | [56,  3200] loss: 1.570
2025-02-24T23:13:14.436570+0300 | INFO | [56,  3300] loss: 1.568
2025-02-24T23:13:25.211673+0300 | INFO | [56,  3400] loss: 1.568
2025-02-24T23:13:36.098887+0300 | INFO | [56,  3500] loss: 1.583
2025-02-24T23:13:47.081690+0300 | INFO | [56,  3600] loss: 1.562
2025-02-24T23:13:57.710147+0300 | INFO | [56,  3700] loss: 1.586
2025-02-24T23:14:09.084431+0300 | INFO | [56,  3800] loss: 1.572
2025-02-24T23:14:19.649636+0300 | INFO | [56,  3900] loss: 1.575
2025-02-24T23:14:30.483371+0300 | INFO | [56,  4000] loss: 1.583
2025-02-24T23:14:41.123814+0300 | INFO | [56,  4100] loss: 1.579
2025-02-24T23:14:51.964043+0300 | INFO | [56,  4200] loss: 1.580
2025-02-24T23:15:02.739399+0300 | INFO | [56,  4300] loss: 1.571
2025-02-24T23:15:13.136507+0300 | INFO | [56,  4400] loss: 1.576
2025-02-24T23:15:24.999137+0300 | INFO | [56,  4500] loss: 1.566
2025-02-24T23:15:35.548207+0300 | INFO | [56,  4600] loss: 1.578
2025-02-24T23:15:49.961487+0300 | INFO | [56,  4700] loss: 1.581
2025-02-24T23:16:01.197276+0300 | INFO | [56,  4800] loss: 1.575
2025-02-24T23:16:11.613408+0300 | INFO | [56,  4900] loss: 1.600
2025-02-24T23:16:21.533630+0300 | DEBUG | Saving model to flat file storage. Save #56
2025-02-24T23:16:21.561858+0300 | INFO | Averaging client parameters
2025-02-24T23:16:21.572865+0300 | INFO | Updating parameters on client #0
2025-02-24T23:16:36.581692+0300 | DEBUG | Test set: Accuracy: 7739/10000 (77%)
2025-02-24T23:16:36.583644+0300 | DEBUG | Test set: Loss: 1.6860402822494507
2025-02-24T23:16:36.685318+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.82      0.81      1000
           1       0.88      0.92      0.90      1000
           2       0.78      0.67      0.72      1000
           3       0.60      0.64      0.62      1200
           4       0.80      0.78      0.79      1000
           5       0.45      0.38      0.41       800
           6       0.81      0.88      0.84      1000
           7       0.84      0.83      0.84      1000
           8       0.86      0.89      0.87      1000
           9       0.86      0.89      0.87      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000

2025-02-24T23:16:36.690311+0300 | DEBUG | Confusion Matrix:
[[819  18  30  14  14   9   8   9  46  33]
 [  8 917   2   1   0   1   3   0  17  51]
 [ 55   5 671  44  60  62  63  15  15  10]
 [ 26  11  36 767  46 192  61  27  14  20]
 [ 12   2  31  69 779  12  41  42   9   3]
 [ 13   3  47 311  30 307  23  48  15   3]
 [ 11   2  21  43  15  22 877   4   4   1]
 [ 14   3  11  26  30  70   6 830   3   7]
 [ 48  22   5   5   2   7   4   3 887  17]
 [ 16  55   3   5   2   6   2   5  21 885]]
2025-02-24T23:16:36.694313+0300 | DEBUG | Class precision: [0.80136986 0.88342967 0.78296383 0.59688716 0.79652352 0.44622093
 0.80606618 0.84435402 0.86032978 0.8592233 ]
2025-02-24T23:16:36.697312+0300 | DEBUG | Class recall: [0.819      0.917      0.671      0.63916667 0.779      0.38375
 0.877      0.83       0.887      0.885     ]
2025-02-24T23:16:36.750942+0300 | INFO | Training epoch #57 on client #0
2025-02-24T23:16:36.751940+0300 | DEBUG | Saving model to flat file storage. Save #57
2025-02-24T23:16:36.886720+0300 | INFO | [57,     0] loss: 0.016
2025-02-24T23:16:47.421552+0300 | INFO | [57,   100] loss: 1.554
2025-02-24T23:16:57.588517+0300 | INFO | [57,   200] loss: 1.556
2025-02-24T23:17:07.834826+0300 | INFO | [57,   300] loss: 1.566
2025-02-24T23:17:20.311198+0300 | INFO | [57,   400] loss: 1.567
2025-02-24T23:17:31.156029+0300 | INFO | [57,   500] loss: 1.573
2025-02-24T23:17:43.324757+0300 | INFO | [57,   600] loss: 1.551
2025-02-24T23:17:54.959669+0300 | INFO | [57,   700] loss: 1.570
2025-02-24T23:18:05.617056+0300 | INFO | [57,   800] loss: 1.561
2025-02-24T23:18:16.117893+0300 | INFO | [57,   900] loss: 1.556
2025-02-24T23:18:26.740268+0300 | INFO | [57,  1000] loss: 1.561
2025-02-24T23:18:37.668320+0300 | INFO | [57,  1100] loss: 1.565
2025-02-24T23:18:48.377143+0300 | INFO | [57,  1200] loss: 1.559
2025-02-24T23:18:59.144443+0300 | INFO | [57,  1300] loss: 1.571
2025-02-24T23:19:10.247504+0300 | INFO | [57,  1400] loss: 1.574
2025-02-24T23:19:20.999140+0300 | INFO | [57,  1500] loss: 1.581
2025-02-24T23:19:31.593885+0300 | INFO | [57,  1600] loss: 1.576
2025-02-24T23:19:43.914774+0300 | INFO | [57,  1700] loss: 1.551
2025-02-24T23:19:54.892171+0300 | INFO | [57,  1800] loss: 1.559
2025-02-24T23:20:05.435625+0300 | INFO | [57,  1900] loss: 1.562
2025-02-24T23:20:16.199732+0300 | INFO | [57,  2000] loss: 1.559
2025-02-24T23:20:26.956168+0300 | INFO | [57,  2100] loss: 1.583
2025-02-24T23:20:38.066732+0300 | INFO | [57,  2200] loss: 1.575
2025-02-24T23:20:48.816847+0300 | INFO | [57,  2300] loss: 1.542
2025-02-24T23:20:59.585970+0300 | INFO | [57,  2400] loss: 1.560
2025-02-24T23:21:10.163422+0300 | INFO | [57,  2500] loss: 1.558
2025-02-24T23:21:20.894652+0300 | INFO | [57,  2600] loss: 1.567
2025-02-24T23:21:31.595701+0300 | INFO | [57,  2700] loss: 1.554
2025-02-24T23:21:41.942653+0300 | INFO | [57,  2800] loss: 1.572
2025-02-24T23:21:52.269398+0300 | INFO | [57,  2900] loss: 1.580
2025-02-24T23:22:02.507467+0300 | INFO | [57,  3000] loss: 1.557
2025-02-24T23:22:13.086878+0300 | INFO | [57,  3100] loss: 1.566
2025-02-24T23:22:23.839988+0300 | INFO | [57,  3200] loss: 1.589
2025-02-24T23:22:34.715627+0300 | INFO | [57,  3300] loss: 1.569
2025-02-24T23:22:45.200712+0300 | INFO | [57,  3400] loss: 1.558
2025-02-24T23:22:55.943014+0300 | INFO | [57,  3500] loss: 1.572
2025-02-24T23:23:06.944367+0300 | INFO | [57,  3600] loss: 1.561
2025-02-24T23:23:17.308127+0300 | INFO | [57,  3700] loss: 1.582
2025-02-24T23:23:31.081009+0300 | INFO | [57,  3800] loss: 1.577
2025-02-24T23:23:42.292407+0300 | INFO | [57,  3900] loss: 1.552
2025-02-24T23:23:52.845634+0300 | INFO | [57,  4000] loss: 1.573
2025-02-24T23:24:03.407126+0300 | INFO | [57,  4100] loss: 1.572
2025-02-24T23:24:15.448054+0300 | INFO | [57,  4200] loss: 1.561
2025-02-24T23:24:30.798295+0300 | INFO | [57,  4300] loss: 1.571
2025-02-24T23:24:42.614798+0300 | INFO | [57,  4400] loss: 1.570
2025-02-24T23:24:53.825751+0300 | INFO | [57,  4500] loss: 1.559
2025-02-24T23:25:05.054229+0300 | INFO | [57,  4600] loss: 1.562
2025-02-24T23:25:18.655590+0300 | INFO | [57,  4700] loss: 1.572
2025-02-24T23:25:30.937912+0300 | INFO | [57,  4800] loss: 1.567
2025-02-24T23:25:42.320808+0300 | INFO | [57,  4900] loss: 1.560
2025-02-24T23:25:53.657956+0300 | DEBUG | Saving model to flat file storage. Save #57
2025-02-24T23:25:53.683642+0300 | INFO | Averaging client parameters
2025-02-24T23:25:53.694718+0300 | INFO | Updating parameters on client #0
2025-02-24T23:26:09.254555+0300 | DEBUG | Test set: Accuracy: 7756/10000 (78%)
2025-02-24T23:26:09.257551+0300 | DEBUG | Test set: Loss: 1.6841362714767456
2025-02-24T23:26:09.375241+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.83      0.80      1000
           1       0.91      0.91      0.91      1000
           2       0.70      0.74      0.72      1000
           3       0.65      0.54      0.59      1200
           4       0.76      0.82      0.79      1000
           5       0.46      0.54      0.50       800
           6       0.85      0.83      0.84      1000
           7       0.90      0.78      0.84      1000
           8       0.85      0.90      0.87      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.77     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-24T23:26:09.377237+0300 | DEBUG | Confusion Matrix:
[[827   9  46  10  19   8   3   4  55  19]
 [ 11 913   2   1   1   3   5   0  17  47]
 [ 53   6 738  31  54  56  40   6   9   7]
 [ 32   6  73 653  59 277  52  15  20  13]
 [ 13   2  46  50 817  21  22  15  10   4]
 [ 15   1  69 187  38 429  16  33  12   0]
 [ 14   1  38  41  32  30 831   3   9   1]
 [ 20   2  21  20  57  86   3 780   4   7]
 [ 48  17   9   4   1   8   4   0 896  13]
 [ 31  44   6   3   3  10   3   6  22 872]]
2025-02-24T23:26:09.379238+0300 | DEBUG | Class precision: [0.77725564 0.91208791 0.70419847 0.653      0.75578168 0.46228448
 0.84882533 0.90487239 0.85009488 0.88708037]
2025-02-24T23:26:09.381247+0300 | DEBUG | Class recall: [0.827      0.913      0.738      0.54416667 0.817      0.53625
 0.831      0.78       0.896      0.872     ]
2025-02-24T23:26:09.431091+0300 | INFO | Training epoch #58 on client #0
2025-02-24T23:26:09.433096+0300 | DEBUG | Saving model to flat file storage. Save #58
2025-02-24T23:26:09.580936+0300 | INFO | [58,     0] loss: 0.016
2025-02-24T23:26:20.748851+0300 | INFO | [58,   100] loss: 1.552
2025-02-24T23:26:32.112066+0300 | INFO | [58,   200] loss: 1.566
2025-02-24T23:26:43.139994+0300 | INFO | [58,   300] loss: 1.556
2025-02-24T23:26:54.572847+0300 | INFO | [58,   400] loss: 1.563
2025-02-24T23:27:06.220433+0300 | INFO | [58,   500] loss: 1.560
2025-02-24T23:27:17.137660+0300 | INFO | [58,   600] loss: 1.563
2025-02-24T23:27:27.743990+0300 | INFO | [58,   700] loss: 1.547
2025-02-24T23:27:40.757298+0300 | INFO | [58,   800] loss: 1.550
2025-02-24T23:27:56.022278+0300 | INFO | [58,   900] loss: 1.561
2025-02-24T23:28:07.061243+0300 | INFO | [58,  1000] loss: 1.572
2025-02-24T23:28:17.726827+0300 | INFO | [58,  1100] loss: 1.558
2025-02-24T23:28:29.046137+0300 | INFO | [58,  1200] loss: 1.546
2025-02-24T23:28:41.572473+0300 | INFO | [58,  1300] loss: 1.567
2025-02-24T23:28:55.586206+0300 | INFO | [58,  1400] loss: 1.564
2025-02-24T23:29:05.914934+0300 | INFO | [58,  1500] loss: 1.559
2025-02-24T23:29:16.465554+0300 | INFO | [58,  1600] loss: 1.558
2025-02-24T23:29:27.000010+0300 | INFO | [58,  1700] loss: 1.549
2025-02-24T23:29:37.637370+0300 | INFO | [58,  1800] loss: 1.567
2025-02-24T23:29:48.366548+0300 | INFO | [58,  1900] loss: 1.549
2025-02-24T23:29:59.040879+0300 | INFO | [58,  2000] loss: 1.556
2025-02-24T23:30:09.575279+0300 | INFO | [58,  2100] loss: 1.554
2025-02-24T23:30:20.966731+0300 | INFO | [58,  2200] loss: 1.562
2025-02-24T23:30:31.729987+0300 | INFO | [58,  2300] loss: 1.558
2025-02-24T23:30:42.243084+0300 | INFO | [58,  2400] loss: 1.554
2025-02-24T23:30:53.183637+0300 | INFO | [58,  2500] loss: 1.547
2025-02-24T23:31:03.767793+0300 | INFO | [58,  2600] loss: 1.563
2025-02-24T23:31:13.784253+0300 | INFO | [58,  2700] loss: 1.567
2025-02-24T23:31:24.797352+0300 | INFO | [58,  2800] loss: 1.560
2025-02-24T23:31:35.445282+0300 | INFO | [58,  2900] loss: 1.554
2025-02-24T23:31:45.965908+0300 | INFO | [58,  3000] loss: 1.561
2025-02-24T23:31:56.868240+0300 | INFO | [58,  3100] loss: 1.561
2025-02-24T23:32:07.233538+0300 | INFO | [58,  3200] loss: 1.561
2025-02-24T23:32:17.596094+0300 | INFO | [58,  3300] loss: 1.559
2025-02-24T23:32:28.308062+0300 | INFO | [58,  3400] loss: 1.562
2025-02-24T23:32:39.742425+0300 | INFO | [58,  3500] loss: 1.549
2025-02-24T23:32:50.677206+0300 | INFO | [58,  3600] loss: 1.551
2025-02-24T23:33:04.233872+0300 | INFO | [58,  3700] loss: 1.556
2025-02-24T23:33:15.211303+0300 | INFO | [58,  3800] loss: 1.576
2025-02-24T23:33:25.836586+0300 | INFO | [58,  3900] loss: 1.569
2025-02-24T23:33:41.488420+0300 | INFO | [58,  4000] loss: 1.556
2025-02-24T23:33:52.283036+0300 | INFO | [58,  4100] loss: 1.558
2025-02-24T23:34:03.206999+0300 | INFO | [58,  4200] loss: 1.547
2025-02-24T23:34:13.522942+0300 | INFO | [58,  4300] loss: 1.568
2025-02-24T23:34:24.284360+0300 | INFO | [58,  4400] loss: 1.552
2025-02-24T23:34:35.068205+0300 | INFO | [58,  4500] loss: 1.560
2025-02-24T23:34:45.648186+0300 | INFO | [58,  4600] loss: 1.568
2025-02-24T23:34:56.836971+0300 | INFO | [58,  4700] loss: 1.548
2025-02-24T23:35:07.216131+0300 | INFO | [58,  4800] loss: 1.554
2025-02-24T23:35:17.752696+0300 | INFO | [58,  4900] loss: 1.554
2025-02-24T23:35:28.475700+0300 | DEBUG | Saving model to flat file storage. Save #58
2025-02-24T23:35:28.499714+0300 | INFO | Averaging client parameters
2025-02-24T23:35:28.508706+0300 | INFO | Updating parameters on client #0
2025-02-24T23:35:43.429721+0300 | DEBUG | Test set: Accuracy: 7829/10000 (78%)
2025-02-24T23:35:43.429721+0300 | DEBUG | Test set: Loss: 1.6779531240463257
2025-02-24T23:35:43.529371+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.81      1000
           1       0.91      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.66      0.55      0.60      1200
           4       0.76      0.80      0.78      1000
           5       0.51      0.54      0.53       800
           6       0.82      0.86      0.84      1000
           7       0.83      0.83      0.83      1000
           8       0.86      0.91      0.88      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-24T23:35:43.532369+0300 | DEBUG | Confusion Matrix:
[[826   9  43  15  16   6   2   7  50  26]
 [  7 917   0   1   1   2   4   1  18  49]
 [ 51   4 706  26  68  60  47  22  10   6]
 [ 29  12  53 655  66 245  69  35  16  20]
 [ 17   2  42  44 798  14  37  33   8   5]
 [ 13   3  42 183  33 434  20  59  11   2]
 [ 16   2  33  34  20  19 864   4   5   3]
 [ 12   2   9  22  50  53   7 834   4   7]
 [ 38  16   4   3   1   6   4   5 905  18]
 [ 19  44   5   2   2   7   0   6  25 890]]
2025-02-24T23:35:43.535372+0300 | DEBUG | Class precision: [0.80350195 0.90702275 0.75346852 0.66497462 0.7563981  0.51300236
 0.81973435 0.82902584 0.86026616 0.86744639]
2025-02-24T23:35:43.537371+0300 | DEBUG | Class recall: [0.826      0.917      0.706      0.54583333 0.798      0.5425
 0.864      0.834      0.905      0.89      ]
2025-02-24T23:35:43.590321+0300 | INFO | Training epoch #59 on client #0
2025-02-24T23:35:43.592325+0300 | DEBUG | Saving model to flat file storage. Save #59
2025-02-24T23:35:43.711972+0300 | INFO | [59,     0] loss: 0.016
2025-02-24T23:35:54.354850+0300 | INFO | [59,   100] loss: 1.545
2025-02-24T23:36:04.507842+0300 | INFO | [59,   200] loss: 1.551
2025-02-24T23:36:14.898616+0300 | INFO | [59,   300] loss: 1.540
2025-02-24T23:36:25.814301+0300 | INFO | [59,   400] loss: 1.542
2025-02-24T23:36:36.462478+0300 | INFO | [59,   500] loss: 1.554
2025-02-24T23:36:47.610338+0300 | INFO | [59,   600] loss: 1.549
2025-02-24T23:36:58.438155+0300 | INFO | [59,   700] loss: 1.565
2025-02-24T23:37:09.036503+0300 | INFO | [59,   800] loss: 1.547
2025-02-24T23:37:19.438275+0300 | INFO | [59,   900] loss: 1.560
2025-02-24T23:37:29.441553+0300 | INFO | [59,  1000] loss: 1.546
2025-02-24T23:37:39.428816+0300 | INFO | [59,  1100] loss: 1.555
2025-02-24T23:37:49.279264+0300 | INFO | [59,  1200] loss: 1.564
2025-02-24T23:37:59.611405+0300 | INFO | [59,  1300] loss: 1.557
2025-02-24T23:38:13.395077+0300 | INFO | [59,  1400] loss: 1.572
2025-02-24T23:38:24.088972+0300 | INFO | [59,  1500] loss: 1.556
2025-02-24T23:38:34.111635+0300 | INFO | [59,  1600] loss: 1.559
2025-02-24T23:38:44.530945+0300 | INFO | [59,  1700] loss: 1.540
2025-02-24T23:38:54.428972+0300 | INFO | [59,  1800] loss: 1.552
2025-02-24T23:39:04.956338+0300 | INFO | [59,  1900] loss: 1.557
2025-02-24T23:39:15.868959+0300 | INFO | [59,  2000] loss: 1.536
2025-02-24T23:39:25.877749+0300 | INFO | [59,  2100] loss: 1.552
2025-02-24T23:39:36.072744+0300 | INFO | [59,  2200] loss: 1.548
2025-02-24T23:39:47.223863+0300 | INFO | [59,  2300] loss: 1.550
2025-02-24T23:39:57.500499+0300 | INFO | [59,  2400] loss: 1.548
2025-02-24T23:40:08.378158+0300 | INFO | [59,  2500] loss: 1.544
2025-02-24T23:40:18.634731+0300 | INFO | [59,  2600] loss: 1.546
2025-02-24T23:40:28.388499+0300 | INFO | [59,  2700] loss: 1.568
2025-02-24T23:40:38.639635+0300 | INFO | [59,  2800] loss: 1.552
2025-02-24T23:40:48.639301+0300 | INFO | [59,  2900] loss: 1.544
2025-02-24T23:40:59.679006+0300 | INFO | [59,  3000] loss: 1.564
2025-02-24T23:41:09.935359+0300 | INFO | [59,  3100] loss: 1.555
2025-02-24T23:41:20.487277+0300 | INFO | [59,  3200] loss: 1.565
2025-02-24T23:41:31.336414+0300 | INFO | [59,  3300] loss: 1.551
2025-02-24T23:41:42.010782+0300 | INFO | [59,  3400] loss: 1.571
2025-02-24T23:41:54.662726+0300 | INFO | [59,  3500] loss: 1.547
2025-02-24T23:42:09.256711+0300 | INFO | [59,  3600] loss: 1.559
2025-02-24T23:42:21.586406+0300 | INFO | [59,  3700] loss: 1.562
2025-02-24T23:42:33.342899+0300 | INFO | [59,  3800] loss: 1.538
2025-02-24T23:42:43.823466+0300 | INFO | [59,  3900] loss: 1.568
2025-02-24T23:42:55.207630+0300 | INFO | [59,  4000] loss: 1.570
2025-02-24T23:43:08.903115+0300 | INFO | [59,  4100] loss: 1.560
2025-02-24T23:43:19.575248+0300 | INFO | [59,  4200] loss: 1.570
2025-02-24T23:43:30.370339+0300 | INFO | [59,  4300] loss: 1.551
2025-02-24T23:43:41.400958+0300 | INFO | [59,  4400] loss: 1.547
2025-02-24T23:43:52.192907+0300 | INFO | [59,  4500] loss: 1.550
2025-02-24T23:44:02.314411+0300 | INFO | [59,  4600] loss: 1.549
2025-02-24T23:44:12.211560+0300 | INFO | [59,  4700] loss: 1.547
2025-02-24T23:44:22.949633+0300 | INFO | [59,  4800] loss: 1.549
2025-02-24T23:44:33.608023+0300 | INFO | [59,  4900] loss: 1.554
2025-02-24T23:44:44.263427+0300 | DEBUG | Saving model to flat file storage. Save #59
2025-02-24T23:44:44.288415+0300 | INFO | Averaging client parameters
2025-02-24T23:44:44.296540+0300 | INFO | Updating parameters on client #0
2025-02-24T23:44:59.642973+0300 | DEBUG | Test set: Accuracy: 7847/10000 (78%)
2025-02-24T23:44:59.644969+0300 | DEBUG | Test set: Loss: 1.676209568977356
2025-02-24T23:44:59.750598+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.79      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.61      0.66      0.63      1200
           4       0.75      0.83      0.79      1000
           5       0.52      0.47      0.49       800
           6       0.80      0.88      0.84      1000
           7       0.88      0.78      0.83      1000
           8       0.88      0.89      0.88      1000
           9       0.88      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-24T23:44:59.752615+0300 | DEBUG | Confusion Matrix:
[[791  14  58  25  24   8   7  10  43  20]
 [  6 907   0   2   1   4   8   3  15  54]
 [ 36   2 720  47  68  47  59   9   6   6]
 [ 14   6  54 786  56 177  63  20  11  13]
 [  7   2  31  60 829  13  34  17   7   0]
 [  8   1  48 265  35 373  28  31   9   2]
 [  4   1  26  41  25  14 880   3   5   1]
 [  9   2  19  38  56  71  11 784   4   6]
 [ 41  18   9  11   5   6   4   3 886  17]
 [ 21  37   5   5   4   4   6   7  20 891]]
2025-02-24T23:44:59.754710+0300 | DEBUG | Class precision: [0.84418356 0.91616162 0.74226804 0.6140625  0.75158658 0.52022315
 0.8        0.88387824 0.88071571 0.88217822]
2025-02-24T23:44:59.756711+0300 | DEBUG | Class recall: [0.791   0.907   0.72    0.655   0.829   0.46625 0.88    0.784   0.886
 0.891  ]
2025-02-24T23:44:59.808704+0300 | INFO | Training epoch #60 on client #0
2025-02-24T23:44:59.809705+0300 | DEBUG | Saving model to flat file storage. Save #60
2025-02-24T23:44:59.943101+0300 | INFO | [60,     0] loss: 0.016
2025-02-24T23:45:10.198488+0300 | INFO | [60,   100] loss: 1.546
2025-02-24T23:45:20.837390+0300 | INFO | [60,   200] loss: 1.551
2025-02-24T23:45:31.668786+0300 | INFO | [60,   300] loss: 1.546
2025-02-24T23:45:42.406710+0300 | INFO | [60,   400] loss: 1.549
2025-02-24T23:45:53.222613+0300 | INFO | [60,   500] loss: 1.548
2025-02-24T23:46:03.579935+0300 | INFO | [60,   600] loss: 1.552
2025-02-24T23:46:14.370623+0300 | INFO | [60,   700] loss: 1.551
2025-02-24T23:46:24.852389+0300 | INFO | [60,   800] loss: 1.555
2025-02-24T23:46:35.522893+0300 | INFO | [60,   900] loss: 1.559
2025-02-24T23:46:46.208076+0300 | INFO | [60,  1000] loss: 1.536
2025-02-24T23:46:57.157974+0300 | INFO | [60,  1100] loss: 1.546
2025-02-24T23:47:07.364084+0300 | INFO | [60,  1200] loss: 1.549
2025-02-24T23:47:20.098613+0300 | INFO | [60,  1300] loss: 1.571
2025-02-24T23:47:30.644254+0300 | INFO | [60,  1400] loss: 1.557
2025-02-24T23:47:41.434725+0300 | INFO | [60,  1500] loss: 1.552
2025-02-24T23:47:51.799436+0300 | INFO | [60,  1600] loss: 1.547
2025-02-24T23:48:02.188226+0300 | INFO | [60,  1700] loss: 1.548
2025-02-24T23:48:12.898853+0300 | INFO | [60,  1800] loss: 1.548
2025-02-24T23:48:26.108578+0300 | INFO | [60,  1900] loss: 1.546
2025-02-24T23:48:36.768324+0300 | INFO | [60,  2000] loss: 1.537
2025-02-24T23:48:48.543286+0300 | INFO | [60,  2100] loss: 1.551
2025-02-24T23:48:59.375192+0300 | INFO | [60,  2200] loss: 1.553
2025-02-24T23:49:10.025438+0300 | INFO | [60,  2300] loss: 1.556
2025-02-24T23:49:21.192971+0300 | INFO | [60,  2400] loss: 1.540
2025-02-24T23:49:32.069672+0300 | INFO | [60,  2500] loss: 1.540
2025-02-24T23:49:42.868281+0300 | INFO | [60,  2600] loss: 1.556
2025-02-24T23:49:53.500964+0300 | INFO | [60,  2700] loss: 1.545
2025-02-24T23:50:06.995036+0300 | INFO | [60,  2800] loss: 1.550
2025-02-24T23:50:17.432847+0300 | INFO | [60,  2900] loss: 1.555
2025-02-24T23:50:28.222074+0300 | INFO | [60,  3000] loss: 1.541
2025-02-24T23:50:39.007477+0300 | INFO | [60,  3100] loss: 1.547
2025-02-24T23:50:53.033691+0300 | INFO | [60,  3200] loss: 1.547
2025-02-24T23:51:06.775038+0300 | INFO | [60,  3300] loss: 1.545
2025-02-24T23:51:16.988885+0300 | INFO | [60,  3400] loss: 1.542
2025-02-24T23:51:27.654855+0300 | INFO | [60,  3500] loss: 1.538
2025-02-24T23:51:39.929207+0300 | INFO | [60,  3600] loss: 1.545
2025-02-24T23:51:50.524256+0300 | INFO | [60,  3700] loss: 1.551
2025-02-24T23:52:01.119594+0300 | INFO | [60,  3800] loss: 1.534
2025-02-24T23:52:11.482563+0300 | INFO | [60,  3900] loss: 1.540
2025-02-24T23:52:22.339200+0300 | INFO | [60,  4000] loss: 1.558
2025-02-24T23:52:35.662250+0300 | INFO | [60,  4100] loss: 1.566
2025-02-24T23:52:46.385029+0300 | INFO | [60,  4200] loss: 1.560
2025-02-24T23:52:57.304663+0300 | INFO | [60,  4300] loss: 1.543
2025-02-24T23:53:07.970425+0300 | INFO | [60,  4400] loss: 1.546
2025-02-24T23:53:18.532804+0300 | INFO | [60,  4500] loss: 1.536
2025-02-24T23:53:31.928961+0300 | INFO | [60,  4600] loss: 1.553
2025-02-24T23:53:42.703520+0300 | INFO | [60,  4700] loss: 1.556
2025-02-24T23:53:53.344286+0300 | INFO | [60,  4800] loss: 1.550
2025-02-24T23:54:04.252440+0300 | INFO | [60,  4900] loss: 1.542
2025-02-24T23:54:14.485988+0300 | DEBUG | Saving model to flat file storage. Save #60
2025-02-24T23:54:14.510183+0300 | INFO | Averaging client parameters
2025-02-24T23:54:14.522814+0300 | INFO | Updating parameters on client #0
2025-02-24T23:54:29.961491+0300 | DEBUG | Test set: Accuracy: 7804/10000 (78%)
2025-02-24T23:54:29.962460+0300 | DEBUG | Test set: Loss: 1.6790728569030762
2025-02-24T23:54:30.071291+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.91      0.91      0.91      1000
           2       0.73      0.72      0.73      1000
           3       0.66      0.55      0.60      1200
           4       0.77      0.80      0.78      1000
           5       0.50      0.58      0.53       800
           6       0.82      0.86      0.84      1000
           7       0.86      0.80      0.83      1000
           8       0.87      0.89      0.88      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-24T23:54:30.075304+0300 | DEBUG | Confusion Matrix:
[[838  10  42  11  19   7   3   5  45  20]
 [ 17 906   2   2   0   3   7   1  17  45]
 [ 58   2 722  29  55  58  52  13   6   5]
 [ 31   7  62 660  53 272  60  29  11  15]
 [ 16   2  46  43 795  16  41  34   6   1]
 [ 13   0  42 183  29 461  21  38  11   2]
 [ 16   1  35  33  21  24 862   1   6   1]
 [ 18   1  19  27  49  76   5 798   3   4]
 [ 48  17   9   2   1   7   3   4 891  18]
 [ 25  47   6   4   4   6   3   9  25 871]]
2025-02-24T23:54:30.079292+0300 | DEBUG | Class precision: [0.77592593 0.91238671 0.73299492 0.6639839  0.7748538  0.49569892
 0.81551561 0.85622318 0.87267385 0.88696538]
2025-02-24T23:54:30.085289+0300 | DEBUG | Class recall: [0.838   0.906   0.722   0.55    0.795   0.57625 0.862   0.798   0.891
 0.871  ]
2025-02-24T23:54:30.141203+0300 | INFO | Training epoch #61 on client #0
2025-02-24T23:54:30.143201+0300 | DEBUG | Saving model to flat file storage. Save #61
2025-02-24T23:54:30.281358+0300 | INFO | [61,     0] loss: 0.015
2025-02-24T23:54:40.746465+0300 | INFO | [61,   100] loss: 1.542
2025-02-24T23:54:51.652993+0300 | INFO | [61,   200] loss: 1.545
2025-02-24T23:55:02.707852+0300 | INFO | [61,   300] loss: 1.530
2025-02-24T23:55:16.291949+0300 | INFO | [61,   400] loss: 1.536
2025-02-24T23:55:27.094340+0300 | INFO | [61,   500] loss: 1.549
2025-02-24T23:55:37.885378+0300 | INFO | [61,   600] loss: 1.534
2025-02-24T23:55:49.225958+0300 | INFO | [61,   700] loss: 1.540
2025-02-24T23:55:59.856128+0300 | INFO | [61,   800] loss: 1.548
2025-02-24T23:56:10.282082+0300 | INFO | [61,   900] loss: 1.551
2025-02-24T23:56:23.909894+0300 | INFO | [61,  1000] loss: 1.546
2025-02-24T23:56:34.665645+0300 | INFO | [61,  1100] loss: 1.526
2025-02-24T23:56:45.728628+0300 | INFO | [61,  1200] loss: 1.552
2025-02-24T23:56:56.390853+0300 | INFO | [61,  1300] loss: 1.549
2025-02-24T23:57:08.372196+0300 | INFO | [61,  1400] loss: 1.553
2025-02-24T23:57:19.235699+0300 | INFO | [61,  1500] loss: 1.538
2025-02-24T23:57:30.173427+0300 | INFO | [61,  1600] loss: 1.552
2025-02-24T23:57:41.028101+0300 | INFO | [61,  1700] loss: 1.532
2025-02-24T23:57:51.527294+0300 | INFO | [61,  1800] loss: 1.546
2025-02-24T23:58:02.425154+0300 | INFO | [61,  1900] loss: 1.542
2025-02-24T23:58:12.752155+0300 | INFO | [61,  2000] loss: 1.543
2025-02-24T23:58:23.569729+0300 | INFO | [61,  2100] loss: 1.546
2025-02-24T23:58:34.404638+0300 | INFO | [61,  2200] loss: 1.537
2025-02-24T23:58:45.101802+0300 | INFO | [61,  2300] loss: 1.533
2025-02-24T23:58:58.373094+0300 | INFO | [61,  2400] loss: 1.561
2025-02-24T23:59:09.018708+0300 | INFO | [61,  2500] loss: 1.551
2025-02-24T23:59:19.546640+0300 | INFO | [61,  2600] loss: 1.530
2025-02-24T23:59:31.743160+0300 | INFO | [61,  2700] loss: 1.540
2025-02-24T23:59:42.447576+0300 | INFO | [61,  2800] loss: 1.545
2025-02-24T23:59:53.117114+0300 | INFO | [61,  2900] loss: 1.562
2025-02-25T00:00:08.792654+0300 | INFO | [61,  3000] loss: 1.543
2025-02-25T00:00:18.545257+0300 | INFO | [61,  3100] loss: 1.541
2025-02-25T00:00:29.657993+0300 | INFO | [61,  3200] loss: 1.562
2025-02-25T00:00:40.251422+0300 | INFO | [61,  3300] loss: 1.546
2025-02-25T00:00:51.129602+0300 | INFO | [61,  3400] loss: 1.548
2025-02-25T00:01:01.607845+0300 | INFO | [61,  3500] loss: 1.539
2025-02-25T00:01:13.899545+0300 | INFO | [61,  3600] loss: 1.539
2025-02-25T00:01:27.680504+0300 | INFO | [61,  3700] loss: 1.544
2025-02-25T00:01:39.363987+0300 | INFO | [61,  3800] loss: 1.548
2025-02-25T00:01:50.505846+0300 | INFO | [61,  3900] loss: 1.539
2025-02-25T00:02:01.693859+0300 | INFO | [61,  4000] loss: 1.549
2025-02-25T00:02:12.189824+0300 | INFO | [61,  4100] loss: 1.526
2025-02-25T00:02:23.703855+0300 | INFO | [61,  4200] loss: 1.562
2025-02-25T00:02:34.569276+0300 | INFO | [61,  4300] loss: 1.531
2025-02-25T00:02:48.237865+0300 | INFO | [61,  4400] loss: 1.540
2025-02-25T00:02:59.391247+0300 | INFO | [61,  4500] loss: 1.555
2025-02-25T00:03:10.348483+0300 | INFO | [61,  4600] loss: 1.547
2025-02-25T00:03:21.231831+0300 | INFO | [61,  4700] loss: 1.547
2025-02-25T00:03:31.930163+0300 | INFO | [61,  4800] loss: 1.548
2025-02-25T00:03:42.851870+0300 | INFO | [61,  4900] loss: 1.542
2025-02-25T00:03:53.749273+0300 | DEBUG | Saving model to flat file storage. Save #61
2025-02-25T00:03:53.763292+0300 | INFO | Averaging client parameters
2025-02-25T00:03:53.771272+0300 | INFO | Updating parameters on client #0
2025-02-25T00:04:08.802572+0300 | DEBUG | Test set: Accuracy: 7800/10000 (78%)
2025-02-25T00:04:08.803560+0300 | DEBUG | Test set: Loss: 1.679687261581421
2025-02-25T00:04:08.898095+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.79      0.80      1000
           1       0.91      0.91      0.91      1000
           2       0.77      0.70      0.73      1000
           3       0.62      0.61      0.62      1200
           4       0.77      0.79      0.78      1000
           5       0.52      0.53      0.52       800
           6       0.79      0.88      0.83      1000
           7       0.86      0.81      0.83      1000
           8       0.84      0.90      0.87      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T00:04:08.900096+0300 | DEBUG | Confusion Matrix:
[[788  14  41  27  23   9   6  10  61  21]
 [  9 912   1   3   0   2   6   1  30  36]
 [ 45   3 701  40  64  62  57  13   6   9]
 [ 19   8  43 735  45 214  77  28  15  16]
 [ 13   2  41  53 791  15  45  29   9   2]
 [  8   1  34 236  27 420  23  36  10   5]
 [  8   0  24  40  18  16 881   6   6   1]
 [ 12   1  10  38  51  64   5 806   4   9]
 [ 40  11  11   6   4   4   5   1 900  18]
 [ 19  53   5   7   5   5   7   7  26 866]]
2025-02-25T00:04:08.903090+0300 | DEBUG | Class precision: [0.81997919 0.90746269 0.76948408 0.62025316 0.76945525 0.51787916
 0.79226619 0.8601921  0.84348641 0.8809766 ]
2025-02-25T00:04:08.905093+0300 | DEBUG | Class recall: [0.788  0.912  0.701  0.6125 0.791  0.525  0.881  0.806  0.9    0.866 ]
2025-02-25T00:04:08.953866+0300 | INFO | Training epoch #62 on client #0
2025-02-25T00:04:08.954873+0300 | DEBUG | Saving model to flat file storage. Save #62
2025-02-25T00:04:09.091722+0300 | INFO | [62,     0] loss: 0.015
2025-02-25T00:04:20.178345+0300 | INFO | [62,   100] loss: 1.558
2025-02-25T00:04:30.013943+0300 | INFO | [62,   200] loss: 1.540
2025-02-25T00:04:41.319235+0300 | INFO | [62,   300] loss: 1.548
2025-02-25T00:04:52.758315+0300 | INFO | [62,   400] loss: 1.547
2025-02-25T00:05:03.542680+0300 | INFO | [62,   500] loss: 1.528
2025-02-25T00:05:15.960248+0300 | INFO | [62,   600] loss: 1.540
2025-02-25T00:05:31.385093+0300 | INFO | [62,   700] loss: 1.533
2025-02-25T00:05:45.635615+0300 | INFO | [62,   800] loss: 1.531
2025-02-25T00:05:56.319235+0300 | INFO | [62,   900] loss: 1.548
2025-02-25T00:06:07.324340+0300 | INFO | [62,  1000] loss: 1.538
2025-02-25T00:06:18.635268+0300 | INFO | [62,  1100] loss: 1.537
2025-02-25T00:06:29.182440+0300 | INFO | [62,  1200] loss: 1.539
2025-02-25T00:06:39.732476+0300 | INFO | [62,  1300] loss: 1.531
2025-02-25T00:06:50.589291+0300 | INFO | [62,  1400] loss: 1.551
2025-02-25T00:07:01.392356+0300 | INFO | [62,  1500] loss: 1.540
2025-02-25T00:07:11.768746+0300 | INFO | [62,  1600] loss: 1.543
2025-02-25T00:07:22.494479+0300 | INFO | [62,  1700] loss: 1.538
2025-02-25T00:07:33.155024+0300 | INFO | [62,  1800] loss: 1.536
2025-02-25T00:07:43.901273+0300 | INFO | [62,  1900] loss: 1.546
2025-02-25T00:07:54.222836+0300 | INFO | [62,  2000] loss: 1.543
2025-02-25T00:08:05.061612+0300 | INFO | [62,  2100] loss: 1.538
2025-02-25T00:08:16.802456+0300 | INFO | [62,  2200] loss: 1.538
2025-02-25T00:08:27.541863+0300 | INFO | [62,  2300] loss: 1.532
2025-02-25T00:08:38.396914+0300 | INFO | [62,  2400] loss: 1.538
2025-02-25T00:08:49.477082+0300 | INFO | [62,  2500] loss: 1.546
2025-02-25T00:08:59.906850+0300 | INFO | [62,  2600] loss: 1.550
2025-02-25T00:09:17.938278+0300 | INFO | [62,  2700] loss: 1.541
2025-02-25T00:09:30.279155+0300 | INFO | [62,  2800] loss: 1.541
2025-02-25T00:09:40.773414+0300 | INFO | [62,  2900] loss: 1.536
2025-02-25T00:09:51.372439+0300 | INFO | [62,  3000] loss: 1.526
2025-02-25T00:10:02.081062+0300 | INFO | [62,  3100] loss: 1.535
2025-02-25T00:10:12.591865+0300 | INFO | [62,  3200] loss: 1.536
2025-02-25T00:10:23.715768+0300 | INFO | [62,  3300] loss: 1.539
2025-02-25T00:10:34.671473+0300 | INFO | [62,  3400] loss: 1.524
2025-02-25T00:10:45.558602+0300 | INFO | [62,  3500] loss: 1.551
2025-02-25T00:10:56.330762+0300 | INFO | [62,  3600] loss: 1.541
2025-02-25T00:11:07.025118+0300 | INFO | [62,  3700] loss: 1.538
2025-02-25T00:11:17.684669+0300 | INFO | [62,  3800] loss: 1.547
2025-02-25T00:11:28.459838+0300 | INFO | [62,  3900] loss: 1.543
2025-02-25T00:11:39.447433+0300 | INFO | [62,  4000] loss: 1.535
2025-02-25T00:11:50.948854+0300 | INFO | [62,  4100] loss: 1.543
2025-02-25T00:12:01.978781+0300 | INFO | [62,  4200] loss: 1.552
2025-02-25T00:12:12.723632+0300 | INFO | [62,  4300] loss: 1.537
2025-02-25T00:12:23.055564+0300 | INFO | [62,  4400] loss: 1.540
2025-02-25T00:12:33.617675+0300 | INFO | [62,  4500] loss: 1.556
2025-02-25T00:12:44.422464+0300 | INFO | [62,  4600] loss: 1.544
2025-02-25T00:12:55.068137+0300 | INFO | [62,  4700] loss: 1.539
2025-02-25T00:13:05.658548+0300 | INFO | [62,  4800] loss: 1.570
2025-02-25T00:13:16.058250+0300 | INFO | [62,  4900] loss: 1.549
2025-02-25T00:13:26.851426+0300 | DEBUG | Saving model to flat file storage. Save #62
2025-02-25T00:13:26.879528+0300 | INFO | Averaging client parameters
2025-02-25T00:13:26.888527+0300 | INFO | Updating parameters on client #0
2025-02-25T00:13:42.260077+0300 | DEBUG | Test set: Accuracy: 7820/10000 (78%)
2025-02-25T00:13:42.262091+0300 | DEBUG | Test set: Loss: 1.678118348121643
2025-02-25T00:13:42.362943+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.62      0.63      0.62      1200
           4       0.74      0.82      0.78      1000
           5       0.50      0.51      0.51       800
           6       0.85      0.83      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.88      0.88      0.88      1000
           9       0.87      0.90      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T00:13:42.365952+0300 | DEBUG | Confusion Matrix:
[[831  11  31  16  23   5   1   9  43  30]
 [  9 908   1   3   1   3   3   0  21  51]
 [ 65   3 686  43  65  64  47  14   6   7]
 [ 28   6  49 755  63 205  47  23  11  13]
 [ 14   2  37  55 823  18  28  16   5   2]
 [ 12   2  40 249  35 410  10  30   8   4]
 [ 12   5  33  51  30  22 833   6   5   3]
 [ 16   0  11  32  62  71   4 795   2   7]
 [ 49  13   8   8   5   6   3   3 883  22]
 [ 13  42   4   5   5   9   2   6  18 896]]
2025-02-25T00:13:42.369934+0300 | DEBUG | Class precision: [0.79218303 0.91532258 0.76222222 0.62037798 0.74010791 0.50430504
 0.85173824 0.88137472 0.88123752 0.86570048]
2025-02-25T00:13:42.370896+0300 | DEBUG | Class recall: [0.831      0.908      0.686      0.62916667 0.823      0.5125
 0.833      0.795      0.883      0.896     ]
2025-02-25T00:13:42.424637+0300 | INFO | Training epoch #63 on client #0
2025-02-25T00:13:42.427636+0300 | DEBUG | Saving model to flat file storage. Save #63
2025-02-25T00:13:42.563578+0300 | INFO | [63,     0] loss: 0.015
2025-02-25T00:13:55.046396+0300 | INFO | [63,   100] loss: 1.557
2025-02-25T00:14:05.899722+0300 | INFO | [63,   200] loss: 1.537
2025-02-25T00:14:16.782766+0300 | INFO | [63,   300] loss: 1.530
2025-02-25T00:14:27.459945+0300 | INFO | [63,   400] loss: 1.538
2025-02-25T00:14:38.525288+0300 | INFO | [63,   500] loss: 1.528
2025-02-25T00:14:49.210601+0300 | INFO | [63,   600] loss: 1.557
2025-02-25T00:14:59.961556+0300 | INFO | [63,   700] loss: 1.534
2025-02-25T00:15:10.947811+0300 | INFO | [63,   800] loss: 1.546
2025-02-25T00:15:21.903503+0300 | INFO | [63,   900] loss: 1.527
2025-02-25T00:15:32.706739+0300 | INFO | [63,  1000] loss: 1.536
2025-02-25T00:15:43.467423+0300 | INFO | [63,  1100] loss: 1.539
2025-02-25T00:15:54.270802+0300 | INFO | [63,  1200] loss: 1.548
2025-02-25T00:16:04.711287+0300 | INFO | [63,  1300] loss: 1.532
2025-02-25T00:16:14.903132+0300 | INFO | [63,  1400] loss: 1.540
2025-02-25T00:16:25.846000+0300 | INFO | [63,  1500] loss: 1.540
2025-02-25T00:16:36.466141+0300 | INFO | [63,  1600] loss: 1.547
2025-02-25T00:16:47.092790+0300 | INFO | [63,  1700] loss: 1.526
2025-02-25T00:16:57.446589+0300 | INFO | [63,  1800] loss: 1.536
2025-02-25T00:17:07.735738+0300 | INFO | [63,  1900] loss: 1.527
2025-02-25T00:17:19.797405+0300 | INFO | [63,  2000] loss: 1.546
2025-02-25T00:17:30.825184+0300 | INFO | [63,  2100] loss: 1.530
2025-02-25T00:17:42.870658+0300 | INFO | [63,  2200] loss: 1.542
2025-02-25T00:17:58.267833+0300 | INFO | [63,  2300] loss: 1.548
2025-02-25T00:18:08.716309+0300 | INFO | [63,  2400] loss: 1.539
2025-02-25T00:18:19.593264+0300 | INFO | [63,  2500] loss: 1.540
2025-02-25T00:18:30.832746+0300 | INFO | [63,  2600] loss: 1.546
2025-02-25T00:18:44.469264+0300 | INFO | [63,  2700] loss: 1.545
2025-02-25T00:18:55.280356+0300 | INFO | [63,  2800] loss: 1.544
2025-02-25T00:19:06.255605+0300 | INFO | [63,  2900] loss: 1.537
2025-02-25T00:19:16.766033+0300 | INFO | [63,  3000] loss: 1.538
2025-02-25T00:19:27.512409+0300 | INFO | [63,  3100] loss: 1.537
2025-02-25T00:19:38.637708+0300 | INFO | [63,  3200] loss: 1.528
2025-02-25T00:19:49.508366+0300 | INFO | [63,  3300] loss: 1.550
2025-02-25T00:20:00.053757+0300 | INFO | [63,  3400] loss: 1.539
2025-02-25T00:20:10.792314+0300 | INFO | [63,  3500] loss: 1.554
2025-02-25T00:20:21.308154+0300 | INFO | [63,  3600] loss: 1.534
2025-02-25T00:20:31.732601+0300 | INFO | [63,  3700] loss: 1.542
2025-02-25T00:20:42.371987+0300 | INFO | [63,  3800] loss: 1.534
2025-02-25T00:20:52.937264+0300 | INFO | [63,  3900] loss: 1.540
2025-02-25T00:21:04.794433+0300 | INFO | [63,  4000] loss: 1.539
2025-02-25T00:21:15.341023+0300 | INFO | [63,  4100] loss: 1.535
2025-02-25T00:21:28.649254+0300 | INFO | [63,  4200] loss: 1.534
2025-02-25T00:21:40.015752+0300 | INFO | [63,  4300] loss: 1.531
2025-02-25T00:21:49.999561+0300 | INFO | [63,  4400] loss: 1.514
2025-02-25T00:22:00.461934+0300 | INFO | [63,  4500] loss: 1.529
2025-02-25T00:22:10.989381+0300 | INFO | [63,  4600] loss: 1.535
2025-02-25T00:22:21.762048+0300 | INFO | [63,  4700] loss: 1.539
2025-02-25T00:22:32.300760+0300 | INFO | [63,  4800] loss: 1.532
2025-02-25T00:22:43.130352+0300 | INFO | [63,  4900] loss: 1.533
2025-02-25T00:22:58.777706+0300 | DEBUG | Saving model to flat file storage. Save #63
2025-02-25T00:22:58.804716+0300 | INFO | Averaging client parameters
2025-02-25T00:22:58.813267+0300 | INFO | Updating parameters on client #0
2025-02-25T00:23:14.683532+0300 | DEBUG | Test set: Accuracy: 7823/10000 (78%)
2025-02-25T00:23:14.685526+0300 | DEBUG | Test set: Loss: 1.6773130893707275
2025-02-25T00:23:14.781101+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.85      0.80      1000
           1       0.91      0.92      0.91      1000
           2       0.79      0.66      0.72      1000
           3       0.60      0.63      0.62      1200
           4       0.78      0.79      0.79      1000
           5       0.52      0.47      0.50       800
           6       0.85      0.85      0.85      1000
           7       0.83      0.84      0.84      1000
           8       0.91      0.87      0.89      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T00:23:14.783219+0300 | DEBUG | Confusion Matrix:
[[851  11  26  19  14   7   3   5  35  29]
 [ 15 916   1   5   0   1   3   1   9  49]
 [ 72   5 660  60  62  60  51  18   4   8]
 [ 30   6  45 761  54 193  53  34   8  16]
 [ 22   2  29  65 793  14  28  38   5   4]
 [ 14   3  35 270  25 380  10  55   4   4]
 [ 14   3  25  47  21  20 853   9   5   3]
 [ 17   1   5  32  42  51   1 842   2   7]
 [ 60  17   7   6   4   4   4   4 866  28]
 [ 22  40   4   5   4   3   3   6  12 901]]
2025-02-25T00:23:14.784209+0300 | DEBUG | Class precision: [0.76186213 0.9123506  0.78853047 0.5992126  0.77821394 0.51841746
 0.84539148 0.83201581 0.91157895 0.85891325]
2025-02-25T00:23:14.786215+0300 | DEBUG | Class recall: [0.851      0.916      0.66       0.63416667 0.793      0.475
 0.853      0.842      0.866      0.901     ]
2025-02-25T00:23:14.840773+0300 | INFO | Training epoch #64 on client #0
2025-02-25T00:23:14.841773+0300 | DEBUG | Saving model to flat file storage. Save #64
2025-02-25T00:23:14.987742+0300 | INFO | [64,     0] loss: 0.016
2025-02-25T00:23:25.642520+0300 | INFO | [64,   100] loss: 1.549
2025-02-25T00:23:36.239618+0300 | INFO | [64,   200] loss: 1.541
2025-02-25T00:23:46.917645+0300 | INFO | [64,   300] loss: 1.545
2025-02-25T00:23:57.703582+0300 | INFO | [64,   400] loss: 1.524
2025-02-25T00:24:09.604762+0300 | INFO | [64,   500] loss: 1.530
2025-02-25T00:24:20.649837+0300 | INFO | [64,   600] loss: 1.540
2025-02-25T00:24:31.377365+0300 | INFO | [64,   700] loss: 1.537
2025-02-25T00:24:42.245411+0300 | INFO | [64,   800] loss: 1.534
2025-02-25T00:24:53.441303+0300 | INFO | [64,   900] loss: 1.532
2025-02-25T00:25:03.938998+0300 | INFO | [64,  1000] loss: 1.532
2025-02-25T00:25:14.667044+0300 | INFO | [64,  1100] loss: 1.537
2025-02-25T00:25:25.113999+0300 | INFO | [64,  1200] loss: 1.526
2025-02-25T00:25:35.603404+0300 | INFO | [64,  1300] loss: 1.535
2025-02-25T00:25:46.336004+0300 | INFO | [64,  1400] loss: 1.535
2025-02-25T00:25:57.006649+0300 | INFO | [64,  1500] loss: 1.531
2025-02-25T00:26:07.285896+0300 | INFO | [64,  1600] loss: 1.522
2025-02-25T00:26:17.889552+0300 | INFO | [64,  1700] loss: 1.533
2025-02-25T00:26:28.700823+0300 | INFO | [64,  1800] loss: 1.525
2025-02-25T00:26:39.859769+0300 | INFO | [64,  1900] loss: 1.533
2025-02-25T00:26:54.581999+0300 | INFO | [64,  2000] loss: 1.541
2025-02-25T00:27:04.780658+0300 | INFO | [64,  2100] loss: 1.524
2025-02-25T00:27:15.269160+0300 | INFO | [64,  2200] loss: 1.527
2025-02-25T00:27:26.293098+0300 | INFO | [64,  2300] loss: 1.533
2025-02-25T00:27:37.612867+0300 | INFO | [64,  2400] loss: 1.518
2025-02-25T00:27:48.842793+0300 | INFO | [64,  2500] loss: 1.523
2025-02-25T00:28:00.341332+0300 | INFO | [64,  2600] loss: 1.543
2025-02-25T00:28:12.000577+0300 | INFO | [64,  2700] loss: 1.539
2025-02-25T00:28:23.193029+0300 | INFO | [64,  2800] loss: 1.532
2025-02-25T00:28:34.572829+0300 | INFO | [64,  2900] loss: 1.541
2025-02-25T00:28:47.843249+0300 | INFO | [64,  3000] loss: 1.536
2025-02-25T00:29:00.749293+0300 | INFO | [64,  3100] loss: 1.540
2025-02-25T00:29:11.612735+0300 | INFO | [64,  3200] loss: 1.542
2025-02-25T00:29:22.670726+0300 | INFO | [64,  3300] loss: 1.542
2025-02-25T00:29:33.826333+0300 | INFO | [64,  3400] loss: 1.539
2025-02-25T00:29:45.204736+0300 | INFO | [64,  3500] loss: 1.529
2025-02-25T00:29:58.865972+0300 | INFO | [64,  3600] loss: 1.537
2025-02-25T00:30:10.044107+0300 | INFO | [64,  3700] loss: 1.527
2025-02-25T00:30:21.376565+0300 | INFO | [64,  3800] loss: 1.527
2025-02-25T00:30:32.269794+0300 | INFO | [64,  3900] loss: 1.538
2025-02-25T00:30:42.732883+0300 | INFO | [64,  4000] loss: 1.533
2025-02-25T00:30:54.172117+0300 | INFO | [64,  4100] loss: 1.539
2025-02-25T00:31:04.823230+0300 | INFO | [64,  4200] loss: 1.534
2025-02-25T00:31:15.290030+0300 | INFO | [64,  4300] loss: 1.534
2025-02-25T00:31:26.850471+0300 | INFO | [64,  4400] loss: 1.546
2025-02-25T00:31:37.685365+0300 | INFO | [64,  4500] loss: 1.527
2025-02-25T00:31:48.156502+0300 | INFO | [64,  4600] loss: 1.529
2025-02-25T00:31:58.993796+0300 | INFO | [64,  4700] loss: 1.549
2025-02-25T00:32:09.367060+0300 | INFO | [64,  4800] loss: 1.532
2025-02-25T00:32:19.992749+0300 | INFO | [64,  4900] loss: 1.548
2025-02-25T00:32:30.824299+0300 | DEBUG | Saving model to flat file storage. Save #64
2025-02-25T00:32:30.850309+0300 | INFO | Averaging client parameters
2025-02-25T00:32:30.862202+0300 | INFO | Updating parameters on client #0
2025-02-25T00:32:45.971303+0300 | DEBUG | Test set: Accuracy: 7804/10000 (78%)
2025-02-25T00:32:45.974377+0300 | DEBUG | Test set: Loss: 1.6791845560073853
2025-02-25T00:32:46.081190+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.92      0.92      0.92      1000
           2       0.79      0.68      0.73      1000
           3       0.63      0.58      0.61      1200
           4       0.78      0.79      0.79      1000
           5       0.47      0.58      0.52       800
           6       0.84      0.84      0.84      1000
           7       0.86      0.80      0.83      1000
           8       0.86      0.90      0.88      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T00:32:46.085176+0300 | DEBUG | Confusion Matrix:
[[842   9  31  18  16  10   2   8  45  19]
 [ 12 916   1   2   0   2   3   3  22  39]
 [ 58   5 678  48  58  76  49  13   7   8]
 [ 25   6  39 701  42 281  46  32  14  14]
 [ 20   1  37  53 790  29  36  22   8   4]
 [ 12   0  28 209  23 461  17  35  11   4]
 [ 12   3  27  45  22  30 844   4  11   2]
 [ 20   0  11  27  54  81   2 798   1   6]
 [ 44  13   5   6   4   4   4   4 898  18]
 [ 25  48   4   4   2   5   3   8  25 876]]
2025-02-25T00:32:46.087191+0300 | DEBUG | Class precision: [0.78691589 0.91508492 0.78745645 0.62982929 0.78140455 0.47088866
 0.8389662  0.86084142 0.86180422 0.88484848]
2025-02-25T00:32:46.087191+0300 | DEBUG | Class recall: [0.842      0.916      0.678      0.58416667 0.79       0.57625
 0.844      0.798      0.898      0.876     ]
2025-02-25T00:32:46.148929+0300 | INFO | Training epoch #65 on client #0
2025-02-25T00:32:46.150931+0300 | DEBUG | Saving model to flat file storage. Save #65
2025-02-25T00:32:46.306612+0300 | INFO | [65,     0] loss: 0.015
2025-02-25T00:32:56.724084+0300 | INFO | [65,   100] loss: 1.535
2025-02-25T00:33:07.503459+0300 | INFO | [65,   200] loss: 1.529
2025-02-25T00:33:20.323951+0300 | INFO | [65,   300] loss: 1.539
2025-02-25T00:33:31.265582+0300 | INFO | [65,   400] loss: 1.527
2025-02-25T00:33:42.011092+0300 | INFO | [65,   500] loss: 1.517
2025-02-25T00:33:55.129322+0300 | INFO | [65,   600] loss: 1.533
2025-02-25T00:34:05.850004+0300 | INFO | [65,   700] loss: 1.542
2025-02-25T00:34:16.401355+0300 | INFO | [65,   800] loss: 1.542
2025-02-25T00:34:27.307260+0300 | INFO | [65,   900] loss: 1.526
2025-02-25T00:34:38.946848+0300 | INFO | [65,  1000] loss: 1.529
2025-02-25T00:34:49.915579+0300 | INFO | [65,  1100] loss: 1.558
2025-02-25T00:35:02.642457+0300 | INFO | [65,  1200] loss: 1.523
2025-02-25T00:35:12.812636+0300 | INFO | [65,  1300] loss: 1.526
2025-02-25T00:35:23.607176+0300 | INFO | [65,  1400] loss: 1.523
2025-02-25T00:35:37.179737+0300 | INFO | [65,  1500] loss: 1.534
2025-02-25T00:35:49.701221+0300 | INFO | [65,  1600] loss: 1.532
2025-02-25T00:36:02.526592+0300 | INFO | [65,  1700] loss: 1.544
2025-02-25T00:36:12.942105+0300 | INFO | [65,  1800] loss: 1.532
2025-02-25T00:36:23.850383+0300 | INFO | [65,  1900] loss: 1.529
2025-02-25T00:36:34.474322+0300 | INFO | [65,  2000] loss: 1.527
2025-02-25T00:36:45.252789+0300 | INFO | [65,  2100] loss: 1.529
2025-02-25T00:36:55.944241+0300 | INFO | [65,  2200] loss: 1.530
2025-02-25T00:37:06.461087+0300 | INFO | [65,  2300] loss: 1.529
2025-02-25T00:37:17.197673+0300 | INFO | [65,  2400] loss: 1.528
2025-02-25T00:37:27.829766+0300 | INFO | [65,  2500] loss: 1.532
2025-02-25T00:37:41.360436+0300 | INFO | [65,  2600] loss: 1.531
2025-02-25T00:37:51.977987+0300 | INFO | [65,  2700] loss: 1.530
2025-02-25T00:38:02.952735+0300 | INFO | [65,  2800] loss: 1.531
2025-02-25T00:38:14.127690+0300 | INFO | [65,  2900] loss: 1.536
2025-02-25T00:38:24.923169+0300 | INFO | [65,  3000] loss: 1.528
2025-02-25T00:38:35.832288+0300 | INFO | [65,  3100] loss: 1.516
2025-02-25T00:38:46.305174+0300 | INFO | [65,  3200] loss: 1.533
2025-02-25T00:38:56.929634+0300 | INFO | [65,  3300] loss: 1.543
2025-02-25T00:39:07.850177+0300 | INFO | [65,  3400] loss: 1.523
2025-02-25T00:39:18.432541+0300 | INFO | [65,  3500] loss: 1.527
2025-02-25T00:39:28.868535+0300 | INFO | [65,  3600] loss: 1.522
2025-02-25T00:39:39.827480+0300 | INFO | [65,  3700] loss: 1.527
2025-02-25T00:39:49.912528+0300 | INFO | [65,  3800] loss: 1.538
2025-02-25T00:40:00.490028+0300 | INFO | [65,  3900] loss: 1.535
2025-02-25T00:40:11.161815+0300 | INFO | [65,  4000] loss: 1.542
2025-02-25T00:40:23.051759+0300 | INFO | [65,  4100] loss: 1.534
2025-02-25T00:40:33.659036+0300 | INFO | [65,  4200] loss: 1.524
2025-02-25T00:40:44.663565+0300 | INFO | [65,  4300] loss: 1.530
2025-02-25T00:40:55.394230+0300 | INFO | [65,  4400] loss: 1.518
2025-02-25T00:41:06.382133+0300 | INFO | [65,  4500] loss: 1.532
2025-02-25T00:41:17.063698+0300 | INFO | [65,  4600] loss: 1.531
2025-02-25T00:41:28.170551+0300 | INFO | [65,  4700] loss: 1.554
2025-02-25T00:41:41.815050+0300 | INFO | [65,  4800] loss: 1.550
2025-02-25T00:41:52.371332+0300 | INFO | [65,  4900] loss: 1.530
2025-02-25T00:42:03.110779+0300 | DEBUG | Saving model to flat file storage. Save #65
2025-02-25T00:42:03.136602+0300 | INFO | Averaging client parameters
2025-02-25T00:42:03.144545+0300 | INFO | Updating parameters on client #0
2025-02-25T00:42:18.524477+0300 | DEBUG | Test set: Accuracy: 7854/10000 (79%)
2025-02-25T00:42:18.526430+0300 | DEBUG | Test set: Loss: 1.674994945526123
2025-02-25T00:42:18.635378+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.85      0.80      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.72      0.73      1000
           3       0.66      0.57      0.61      1200
           4       0.80      0.77      0.78      1000
           5       0.53      0.57      0.55       800
           6       0.81      0.88      0.84      1000
           7       0.85      0.82      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T00:42:18.639333+0300 | DEBUG | Confusion Matrix:
[[848  14  36  10  12   6   6   7  42  19]
 [ 14 923   0   2   0   1   5   1  15  39]
 [ 69   5 720  35  44  48  53  14   5   7]
 [ 36  11  53 682  44 260  60  29  11  14]
 [ 22   1  49  50 766  15  51  37   7   2]
 [ 14   2  50 185  24 460  18  38   8   1]
 [ 13   3  32  33  14  15 877   4   8   1]
 [ 26   1   9  32  43  61   6 816   1   5]
 [ 47  13   9   6   3   6   7   4 887  18]
 [ 30  54   5   5   2   1   5   7  16 875]]
2025-02-25T00:42:18.643333+0300 | DEBUG | Class precision: [0.75781948 0.89873418 0.74766355 0.65576923 0.80462185 0.52691867
 0.80606618 0.85266458 0.887      0.89194699]
2025-02-25T00:42:18.644339+0300 | DEBUG | Class recall: [0.848      0.923      0.72       0.56833333 0.766      0.575
 0.877      0.816      0.887      0.875     ]
2025-02-25T00:42:18.708064+0300 | INFO | Training epoch #66 on client #0
2025-02-25T00:42:18.711027+0300 | DEBUG | Saving model to flat file storage. Save #66
2025-02-25T00:42:18.899789+0300 | INFO | [66,     0] loss: 0.016
2025-02-25T00:42:29.654666+0300 | INFO | [66,   100] loss: 1.525
2025-02-25T00:42:40.488768+0300 | INFO | [66,   200] loss: 1.522
2025-02-25T00:42:51.251162+0300 | INFO | [66,   300] loss: 1.519
2025-02-25T00:43:01.954300+0300 | INFO | [66,   400] loss: 1.526
2025-02-25T00:43:12.715855+0300 | INFO | [66,   500] loss: 1.529
2025-02-25T00:43:23.603849+0300 | INFO | [66,   600] loss: 1.520
2025-02-25T00:43:34.346058+0300 | INFO | [66,   700] loss: 1.528
2025-02-25T00:43:44.939220+0300 | INFO | [66,   800] loss: 1.547
2025-02-25T00:43:55.847863+0300 | INFO | [66,   900] loss: 1.528
2025-02-25T00:44:05.225587+0300 | INFO | [66,  1000] loss: 1.529
2025-02-25T00:44:17.566889+0300 | INFO | [66,  1100] loss: 1.533
2025-02-25T00:44:31.523321+0300 | INFO | [66,  1200] loss: 1.529
2025-02-25T00:44:42.381752+0300 | INFO | [66,  1300] loss: 1.522
2025-02-25T00:44:52.956210+0300 | INFO | [66,  1400] loss: 1.533
2025-02-25T00:45:03.757737+0300 | INFO | [66,  1500] loss: 1.522
2025-02-25T00:45:14.557784+0300 | INFO | [66,  1600] loss: 1.522
2025-02-25T00:45:25.387862+0300 | INFO | [66,  1700] loss: 1.526
2025-02-25T00:45:35.779550+0300 | INFO | [66,  1800] loss: 1.529
2025-02-25T00:45:46.538831+0300 | INFO | [66,  1900] loss: 1.519
2025-02-25T00:45:56.667061+0300 | INFO | [66,  2000] loss: 1.527
2025-02-25T00:46:06.981907+0300 | INFO | [66,  2100] loss: 1.528
2025-02-25T00:46:17.297834+0300 | INFO | [66,  2200] loss: 1.523
2025-02-25T00:46:27.850948+0300 | INFO | [66,  2300] loss: 1.531
2025-02-25T00:46:38.658787+0300 | INFO | [66,  2400] loss: 1.536
2025-02-25T00:46:49.107907+0300 | INFO | [66,  2500] loss: 1.526
2025-02-25T00:47:02.393262+0300 | INFO | [66,  2600] loss: 1.530
2025-02-25T00:47:12.840593+0300 | INFO | [66,  2700] loss: 1.521
2025-02-25T00:47:24.045706+0300 | INFO | [66,  2800] loss: 1.538
2025-02-25T00:47:35.253550+0300 | INFO | [66,  2900] loss: 1.527
2025-02-25T00:47:45.979469+0300 | INFO | [66,  3000] loss: 1.543
2025-02-25T00:47:56.727588+0300 | INFO | [66,  3100] loss: 1.531
2025-02-25T00:48:07.544874+0300 | INFO | [66,  3200] loss: 1.522
2025-02-25T00:48:18.100286+0300 | INFO | [66,  3300] loss: 1.527
2025-02-25T00:48:29.169309+0300 | INFO | [66,  3400] loss: 1.535
2025-02-25T00:48:39.870399+0300 | INFO | [66,  3500] loss: 1.527
2025-02-25T00:48:50.584284+0300 | INFO | [66,  3600] loss: 1.534
2025-02-25T00:49:01.565313+0300 | INFO | [66,  3700] loss: 1.531
2025-02-25T00:49:14.070442+0300 | INFO | [66,  3800] loss: 1.523
2025-02-25T00:49:24.929254+0300 | INFO | [66,  3900] loss: 1.536
2025-02-25T00:49:35.758971+0300 | INFO | [66,  4000] loss: 1.535
2025-02-25T00:49:46.837377+0300 | INFO | [66,  4100] loss: 1.531
2025-02-25T00:49:57.461130+0300 | INFO | [66,  4200] loss: 1.541
2025-02-25T00:50:08.401604+0300 | INFO | [66,  4300] loss: 1.528
2025-02-25T00:50:19.263802+0300 | INFO | [66,  4400] loss: 1.519
2025-02-25T00:50:29.696997+0300 | INFO | [66,  4500] loss: 1.526
2025-02-25T00:50:40.944270+0300 | INFO | [66,  4600] loss: 1.538
2025-02-25T00:50:51.577398+0300 | INFO | [66,  4700] loss: 1.528
2025-02-25T00:51:02.054454+0300 | INFO | [66,  4800] loss: 1.537
2025-02-25T00:51:12.711059+0300 | INFO | [66,  4900] loss: 1.526
2025-02-25T00:51:23.404584+0300 | DEBUG | Saving model to flat file storage. Save #66
2025-02-25T00:51:23.430581+0300 | INFO | Averaging client parameters
2025-02-25T00:51:23.438492+0300 | INFO | Updating parameters on client #0
2025-02-25T00:51:38.621343+0300 | DEBUG | Test set: Accuracy: 7876/10000 (79%)
2025-02-25T00:51:38.623349+0300 | DEBUG | Test set: Loss: 1.6726527214050293
2025-02-25T00:51:38.752550+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.81      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.78      0.71      0.74      1000
           3       0.65      0.58      0.61      1200
           4       0.73      0.84      0.78      1000
           5       0.53      0.58      0.55       800
           6       0.81      0.86      0.84      1000
           7       0.89      0.80      0.84      1000
           8       0.87      0.90      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T00:51:38.755552+0300 | DEBUG | Confusion Matrix:
[[811  16  36  16  26   8   5   5  57  20]
 [ 10 922   1   1   1   3   4   1  18  39]
 [ 44   3 714  39  75  49  55  11   4   6]
 [ 20  10  49 694  63 252  60  26  12  14]
 [ 12   2  33  49 838  13  32  15   6   0]
 [ 10   3  38 195  34 462  20  30   6   2]
 [  9   0  26  40  37  17 861   3   6   1]
 [ 16   2  12  25  69  66  10 795   2   3]
 [ 36  14   5   5   6   4   4   4 903  19]
 [ 22  53   5   6   2   2   7   7  20 876]]
2025-02-25T00:51:38.757548+0300 | DEBUG | Class precision: [0.81919192 0.8995122  0.77693145 0.64859813 0.72806255 0.52739726
 0.81379962 0.88628763 0.87330754 0.89387755]
2025-02-25T00:51:38.758666+0300 | DEBUG | Class recall: [0.811      0.922      0.714      0.57833333 0.838      0.5775
 0.861      0.795      0.903      0.876     ]
2025-02-25T00:51:38.817046+0300 | INFO | Training epoch #67 on client #0
2025-02-25T00:51:38.819046+0300 | DEBUG | Saving model to flat file storage. Save #67
2025-02-25T00:51:38.971798+0300 | INFO | [67,     0] loss: 0.016
2025-02-25T00:51:49.496743+0300 | INFO | [67,   100] loss: 1.530
2025-02-25T00:52:00.145043+0300 | INFO | [67,   200] loss: 1.522
2025-02-25T00:52:13.525009+0300 | INFO | [67,   300] loss: 1.529
2025-02-25T00:52:24.424226+0300 | INFO | [67,   400] loss: 1.531
2025-02-25T00:52:35.539924+0300 | INFO | [67,   500] loss: 1.518
2025-02-25T00:52:46.591160+0300 | INFO | [67,   600] loss: 1.513
2025-02-25T00:53:00.990250+0300 | INFO | [67,   700] loss: 1.541
2025-02-25T00:53:12.245276+0300 | INFO | [67,   800] loss: 1.517
2025-02-25T00:53:22.992537+0300 | INFO | [67,   900] loss: 1.520
2025-02-25T00:53:33.835540+0300 | INFO | [67,  1000] loss: 1.537
2025-02-25T00:53:44.529231+0300 | INFO | [67,  1100] loss: 1.525
2025-02-25T00:53:55.806689+0300 | INFO | [67,  1200] loss: 1.526
2025-02-25T00:54:06.784486+0300 | INFO | [67,  1300] loss: 1.539
2025-02-25T00:54:18.261251+0300 | INFO | [67,  1400] loss: 1.532
2025-02-25T00:54:32.098512+0300 | INFO | [67,  1500] loss: 1.527
2025-02-25T00:54:44.947514+0300 | INFO | [67,  1600] loss: 1.519
2025-02-25T00:54:55.743805+0300 | INFO | [67,  1700] loss: 1.538
2025-02-25T00:55:06.504793+0300 | INFO | [67,  1800] loss: 1.530
2025-02-25T00:55:16.902808+0300 | INFO | [67,  1900] loss: 1.531
2025-02-25T00:55:27.633417+0300 | INFO | [67,  2000] loss: 1.530
2025-02-25T00:55:38.521483+0300 | INFO | [67,  2100] loss: 1.534
2025-02-25T00:55:49.495602+0300 | INFO | [67,  2200] loss: 1.525
2025-02-25T00:56:00.212599+0300 | INFO | [67,  2300] loss: 1.516
2025-02-25T00:56:10.282433+0300 | INFO | [67,  2400] loss: 1.522
2025-02-25T00:56:20.819514+0300 | INFO | [67,  2500] loss: 1.536
2025-02-25T00:56:31.514470+0300 | INFO | [67,  2600] loss: 1.532
2025-02-25T00:56:42.284218+0300 | INFO | [67,  2700] loss: 1.521
2025-02-25T00:56:52.854708+0300 | INFO | [67,  2800] loss: 1.522
2025-02-25T00:57:03.988806+0300 | INFO | [67,  2900] loss: 1.527
2025-02-25T00:57:15.230988+0300 | INFO | [67,  3000] loss: 1.527
2025-02-25T00:57:25.965017+0300 | INFO | [67,  3100] loss: 1.533
2025-02-25T00:57:36.394923+0300 | INFO | [67,  3200] loss: 1.525
2025-02-25T00:57:47.430200+0300 | INFO | [67,  3300] loss: 1.536
2025-02-25T00:57:58.653657+0300 | INFO | [67,  3400] loss: 1.525
2025-02-25T00:58:09.354218+0300 | INFO | [67,  3500] loss: 1.532
2025-02-25T00:58:20.221738+0300 | INFO | [67,  3600] loss: 1.526
2025-02-25T00:58:31.120391+0300 | INFO | [67,  3700] loss: 1.516
2025-02-25T00:58:41.910060+0300 | INFO | [67,  3800] loss: 1.526
2025-02-25T00:58:52.965918+0300 | INFO | [67,  3900] loss: 1.523
2025-02-25T00:59:03.598309+0300 | INFO | [67,  4000] loss: 1.533
2025-02-25T00:59:13.981833+0300 | INFO | [67,  4100] loss: 1.528
2025-02-25T00:59:25.711095+0300 | INFO | [67,  4200] loss: 1.518
2025-02-25T00:59:36.380178+0300 | INFO | [67,  4300] loss: 1.523
2025-02-25T00:59:47.187860+0300 | INFO | [67,  4400] loss: 1.515
2025-02-25T00:59:58.025043+0300 | INFO | [67,  4500] loss: 1.532
2025-02-25T01:00:07.848623+0300 | INFO | [67,  4600] loss: 1.528
2025-02-25T01:00:18.776430+0300 | INFO | [67,  4700] loss: 1.530
2025-02-25T01:00:30.040129+0300 | INFO | [67,  4800] loss: 1.527
2025-02-25T01:00:44.225144+0300 | INFO | [67,  4900] loss: 1.522
2025-02-25T01:00:55.034951+0300 | DEBUG | Saving model to flat file storage. Save #67
2025-02-25T01:00:55.058764+0300 | INFO | Averaging client parameters
2025-02-25T01:00:55.066821+0300 | INFO | Updating parameters on client #0
2025-02-25T01:01:10.805643+0300 | DEBUG | Test set: Accuracy: 7826/10000 (78%)
2025-02-25T01:01:10.806652+0300 | DEBUG | Test set: Loss: 1.677321434020996
2025-02-25T01:01:10.925392+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.93      0.88      0.90      1000
           2       0.79      0.69      0.74      1000
           3       0.64      0.60      0.62      1200
           4       0.75      0.82      0.78      1000
           5       0.51      0.56      0.53       800
           6       0.81      0.86      0.84      1000
           7       0.90      0.77      0.83      1000
           8       0.87      0.90      0.88      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T01:01:10.929383+0300 | DEBUG | Confusion Matrix:
[[846  13  30  11  14  12   5   8  46  15]
 [ 11 875   1   3   0   2   4   0  23  81]
 [ 59   3 689  39  71  59  60   9   6   5]
 [ 28   6  40 715  55 250  62  20  12  12]
 [ 18   2  36  42 821  16  40  15  10   0]
 [ 11   1  38 221  30 449  14  26   7   3]
 [ 14   3  24  37  24  21 865   4   7   1]
 [ 24   1   7  36  78  71   8 766   3   6]
 [ 45  10   4   6   2   3   6   1 901  22]
 [ 25  29   5   7   2   5   2   4  22 899]]
2025-02-25T01:01:10.931275+0300 | DEBUG | Class precision: [0.7826087  0.92788971 0.78832952 0.64010743 0.74840474 0.50563063
 0.81144465 0.89800703 0.86885246 0.86111111]
2025-02-25T01:01:10.932305+0300 | DEBUG | Class recall: [0.846      0.875      0.689      0.59583333 0.821      0.56125
 0.865      0.766      0.901      0.899     ]
2025-02-25T01:01:10.984251+0300 | INFO | Training epoch #68 on client #0
2025-02-25T01:01:10.986242+0300 | DEBUG | Saving model to flat file storage. Save #68
2025-02-25T01:01:11.126275+0300 | INFO | [68,     0] loss: 0.015
2025-02-25T01:01:21.859408+0300 | INFO | [68,   100] loss: 1.518
2025-02-25T01:01:33.092501+0300 | INFO | [68,   200] loss: 1.526
2025-02-25T01:01:50.526917+0300 | INFO | [68,   300] loss: 1.513
2025-02-25T01:02:02.180564+0300 | INFO | [68,   400] loss: 1.525
2025-02-25T01:02:12.334369+0300 | INFO | [68,   500] loss: 1.525
2025-02-25T01:02:26.072641+0300 | INFO | [68,   600] loss: 1.519
2025-02-25T01:02:36.448162+0300 | INFO | [68,   700] loss: 1.523
2025-02-25T01:02:46.633064+0300 | INFO | [68,   800] loss: 1.524
2025-02-25T01:02:57.007619+0300 | INFO | [68,   900] loss: 1.520
2025-02-25T01:03:07.431626+0300 | INFO | [68,  1000] loss: 1.528
2025-02-25T01:03:17.640044+0300 | INFO | [68,  1100] loss: 1.527
2025-02-25T01:03:28.147236+0300 | INFO | [68,  1200] loss: 1.523
2025-02-25T01:03:39.083062+0300 | INFO | [68,  1300] loss: 1.529
2025-02-25T01:03:49.573633+0300 | INFO | [68,  1400] loss: 1.505
2025-02-25T01:04:00.139890+0300 | INFO | [68,  1500] loss: 1.519
2025-02-25T01:04:13.724348+0300 | INFO | [68,  1600] loss: 1.525
2025-02-25T01:04:26.299889+0300 | INFO | [68,  1700] loss: 1.527
2025-02-25T01:04:37.262536+0300 | INFO | [68,  1800] loss: 1.527
2025-02-25T01:04:47.700666+0300 | INFO | [68,  1900] loss: 1.516
2025-02-25T01:04:57.977022+0300 | INFO | [68,  2000] loss: 1.519
2025-02-25T01:05:08.681163+0300 | INFO | [68,  2100] loss: 1.520
2025-02-25T01:05:21.568257+0300 | INFO | [68,  2200] loss: 1.510
2025-02-25T01:05:32.739847+0300 | INFO | [68,  2300] loss: 1.521
2025-02-25T01:05:44.639219+0300 | INFO | [68,  2400] loss: 1.531
2025-02-25T01:05:56.204009+0300 | INFO | [68,  2500] loss: 1.532
2025-02-25T01:06:08.925411+0300 | INFO | [68,  2600] loss: 1.533
2025-02-25T01:06:20.461527+0300 | INFO | [68,  2700] loss: 1.531
2025-02-25T01:06:31.714221+0300 | INFO | [68,  2800] loss: 1.526
2025-02-25T01:06:42.394677+0300 | INFO | [68,  2900] loss: 1.530
2025-02-25T01:06:53.704824+0300 | INFO | [68,  3000] loss: 1.542
2025-02-25T01:07:06.163900+0300 | INFO | [68,  3100] loss: 1.537
2025-02-25T01:07:19.519790+0300 | INFO | [68,  3200] loss: 1.515
2025-02-25T01:07:35.070265+0300 | INFO | [68,  3300] loss: 1.539
2025-02-25T01:07:46.969290+0300 | INFO | [68,  3400] loss: 1.528
2025-02-25T01:07:57.786713+0300 | INFO | [68,  3500] loss: 1.521
2025-02-25T01:08:08.762726+0300 | INFO | [68,  3600] loss: 1.516
2025-02-25T01:08:19.308605+0300 | INFO | [68,  3700] loss: 1.523
2025-02-25T01:08:33.138151+0300 | INFO | [68,  3800] loss: 1.537
2025-02-25T01:08:47.184108+0300 | INFO | [68,  3900] loss: 1.521
2025-02-25T01:08:58.665450+0300 | INFO | [68,  4000] loss: 1.518
2025-02-25T01:09:09.578753+0300 | INFO | [68,  4100] loss: 1.526
2025-02-25T01:09:20.249505+0300 | INFO | [68,  4200] loss: 1.527
2025-02-25T01:09:31.325251+0300 | INFO | [68,  4300] loss: 1.534
2025-02-25T01:09:42.190747+0300 | INFO | [68,  4400] loss: 1.533
2025-02-25T01:09:52.842678+0300 | INFO | [68,  4500] loss: 1.533
2025-02-25T01:10:03.814894+0300 | INFO | [68,  4600] loss: 1.535
2025-02-25T01:10:14.629148+0300 | INFO | [68,  4700] loss: 1.532
2025-02-25T01:10:25.474381+0300 | INFO | [68,  4800] loss: 1.529
2025-02-25T01:10:36.418394+0300 | INFO | [68,  4900] loss: 1.533
2025-02-25T01:10:47.281291+0300 | DEBUG | Saving model to flat file storage. Save #68
2025-02-25T01:10:47.307144+0300 | INFO | Averaging client parameters
2025-02-25T01:10:47.317373+0300 | INFO | Updating parameters on client #0
2025-02-25T01:11:03.902688+0300 | DEBUG | Test set: Accuracy: 7833/10000 (78%)
2025-02-25T01:11:03.902688+0300 | DEBUG | Test set: Loss: 1.6769214868545532
2025-02-25T01:11:03.983803+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.84      0.81      1000
           1       0.89      0.93      0.91      1000
           2       0.80      0.67      0.73      1000
           3       0.64      0.58      0.61      1200
           4       0.77      0.80      0.78      1000
           5       0.50      0.59      0.54       800
           6       0.87      0.83      0.85      1000
           7       0.85      0.81      0.83      1000
           8       0.84      0.91      0.87      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T01:11:03.985540+0300 | DEBUG | Confusion Matrix:
[[843  15  20  12  12   6   2   8  62  20]
 [ 12 927   2   1   0   4   3   1  18  32]
 [ 79   5 666  48  66  61  34  18  14   9]
 [ 31   7  40 692  52 268  43  30  24  13]
 [ 18   2  31  54 795  26  28  32  10   4]
 [ 12   3  31 196  25 470   8  39  12   4]
 [ 17   3  30  43  26  25 835   6  13   2]
 [ 24   3   7  28  48  64   4 813   2   7]
 [ 34  18   2   5   3   3   3   3 911  18]
 [ 19  58   2   5   2   4   2   4  23 881]]
2025-02-25T01:11:03.987555+0300 | DEBUG | Class precision: [0.77410468 0.89048991 0.80144404 0.63837638 0.77259475 0.50483351
 0.86798337 0.85220126 0.83654729 0.88989899]
2025-02-25T01:11:03.988783+0300 | DEBUG | Class recall: [0.843      0.927      0.666      0.57666667 0.795      0.5875
 0.835      0.813      0.911      0.881     ]
2025-02-25T01:11:04.035912+0300 | INFO | Training epoch #69 on client #0
2025-02-25T01:11:04.037920+0300 | DEBUG | Saving model to flat file storage. Save #69
2025-02-25T01:11:04.170084+0300 | INFO | [69,     0] loss: 0.017
2025-02-25T01:11:14.443376+0300 | INFO | [69,   100] loss: 1.524
2025-02-25T01:11:26.085452+0300 | INFO | [69,   200] loss: 1.520
2025-02-25T01:11:40.087326+0300 | INFO | [69,   300] loss: 1.531
2025-02-25T01:11:50.776937+0300 | INFO | [69,   400] loss: 1.529
2025-02-25T01:12:01.672371+0300 | INFO | [69,   500] loss: 1.519
2025-02-25T01:12:12.731751+0300 | INFO | [69,   600] loss: 1.528
2025-02-25T01:12:23.404635+0300 | INFO | [69,   700] loss: 1.526
2025-02-25T01:12:34.229155+0300 | INFO | [69,   800] loss: 1.529
2025-02-25T01:12:46.267039+0300 | INFO | [69,   900] loss: 1.521
2025-02-25T01:12:56.917358+0300 | INFO | [69,  1000] loss: 1.536
2025-02-25T01:13:07.793022+0300 | INFO | [69,  1100] loss: 1.526
2025-02-25T01:13:18.022374+0300 | INFO | [69,  1200] loss: 1.520
2025-02-25T01:13:29.433874+0300 | INFO | [69,  1300] loss: 1.523
2025-02-25T01:13:42.745027+0300 | INFO | [69,  1400] loss: 1.531
2025-02-25T01:13:53.456173+0300 | INFO | [69,  1500] loss: 1.510
2025-02-25T01:14:04.115048+0300 | INFO | [69,  1600] loss: 1.525
2025-02-25T01:14:14.840960+0300 | INFO | [69,  1700] loss: 1.516
2025-02-25T01:14:25.576879+0300 | INFO | [69,  1800] loss: 1.528
2025-02-25T01:14:37.694152+0300 | INFO | [69,  1900] loss: 1.527
2025-02-25T01:14:49.166796+0300 | INFO | [69,  2000] loss: 1.519
2025-02-25T01:14:59.735124+0300 | INFO | [69,  2100] loss: 1.520
2025-02-25T01:15:10.599777+0300 | INFO | [69,  2200] loss: 1.528
2025-02-25T01:15:21.287983+0300 | INFO | [69,  2300] loss: 1.515
2025-02-25T01:15:33.937738+0300 | INFO | [69,  2400] loss: 1.524
2025-02-25T01:15:44.344222+0300 | INFO | [69,  2500] loss: 1.521
2025-02-25T01:15:55.136572+0300 | INFO | [69,  2600] loss: 1.513
2025-02-25T01:16:05.486269+0300 | INFO | [69,  2700] loss: 1.511
2025-02-25T01:16:15.817975+0300 | INFO | [69,  2800] loss: 1.527
2025-02-25T01:16:26.547007+0300 | INFO | [69,  2900] loss: 1.528
2025-02-25T01:16:37.124290+0300 | INFO | [69,  3000] loss: 1.535
2025-02-25T01:16:47.269876+0300 | INFO | [69,  3100] loss: 1.525
2025-02-25T01:16:58.248498+0300 | INFO | [69,  3200] loss: 1.523
2025-02-25T01:17:08.598864+0300 | INFO | [69,  3300] loss: 1.526
2025-02-25T01:17:19.615716+0300 | INFO | [69,  3400] loss: 1.525
2025-02-25T01:17:30.722270+0300 | INFO | [69,  3500] loss: 1.525
2025-02-25T01:17:41.439181+0300 | INFO | [69,  3600] loss: 1.527
2025-02-25T01:17:52.211008+0300 | INFO | [69,  3700] loss: 1.524
2025-02-25T01:18:03.009391+0300 | INFO | [69,  3800] loss: 1.520
2025-02-25T01:18:13.534506+0300 | INFO | [69,  3900] loss: 1.533
2025-02-25T01:18:27.242299+0300 | INFO | [69,  4000] loss: 1.534
2025-02-25T01:18:38.494028+0300 | INFO | [69,  4100] loss: 1.515
2025-02-25T01:18:49.261928+0300 | INFO | [69,  4200] loss: 1.527
2025-02-25T01:18:59.882715+0300 | INFO | [69,  4300] loss: 1.517
2025-02-25T01:19:10.867519+0300 | INFO | [69,  4400] loss: 1.531
2025-02-25T01:19:23.966957+0300 | INFO | [69,  4500] loss: 1.520
2025-02-25T01:19:35.024877+0300 | INFO | [69,  4600] loss: 1.513
2025-02-25T01:19:45.547053+0300 | INFO | [69,  4700] loss: 1.526
2025-02-25T01:19:56.273170+0300 | INFO | [69,  4800] loss: 1.522
2025-02-25T01:20:07.460771+0300 | INFO | [69,  4900] loss: 1.529
2025-02-25T01:20:19.507010+0300 | DEBUG | Saving model to flat file storage. Save #69
2025-02-25T01:20:19.522021+0300 | INFO | Averaging client parameters
2025-02-25T01:20:19.530304+0300 | INFO | Updating parameters on client #0
2025-02-25T01:20:38.338578+0300 | DEBUG | Test set: Accuracy: 7845/10000 (78%)
2025-02-25T01:20:38.339578+0300 | DEBUG | Test set: Loss: 1.6759073734283447
2025-02-25T01:20:38.427552+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1000
           1       0.89      0.92      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.64      0.58      0.61      1200
           4       0.77      0.80      0.78      1000
           5       0.50      0.57      0.53       800
           6       0.83      0.86      0.84      1000
           7       0.87      0.81      0.84      1000
           8       0.87      0.90      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T01:20:38.430425+0300 | DEBUG | Confusion Matrix:
[[814  18  46  16  22   9   4   6  47  18]
 [ 12 924   1   3   0   1   3   0  18  38]
 [ 50   3 721  45  61  53  48  11   5   3]
 [ 20   7  56 696  48 261  55  32  12  13]
 [ 15   1  40  46 797  30  38  24   8   1]
 [  6   1  51 199  27 455  13  38   8   2]
 [  7   3  36  45  19  21 857   4   6   2]
 [ 13   1   8  29  56  64   5 815   5   4]
 [ 36  15   6   8   4   5   4   2 903  17]
 [ 26  60   6   7   3   7   3   3  22 863]]
2025-02-25T01:20:38.432689+0300 | DEBUG | Class precision: [0.81481481 0.89448209 0.74253347 0.63619744 0.76856316 0.50220751
 0.83203883 0.87165775 0.87330754 0.89802289]
2025-02-25T01:20:38.434690+0300 | DEBUG | Class recall: [0.814   0.924   0.721   0.58    0.797   0.56875 0.857   0.815   0.903
 0.863  ]
2025-02-25T01:20:38.504921+0300 | INFO | Training epoch #70 on client #0
2025-02-25T01:20:38.508087+0300 | DEBUG | Saving model to flat file storage. Save #70
2025-02-25T01:20:38.824114+0300 | INFO | [70,     0] loss: 0.015
2025-02-25T01:20:49.323059+0300 | INFO | [70,   100] loss: 1.519
2025-02-25T01:21:00.013752+0300 | INFO | [70,   200] loss: 1.525
2025-02-25T01:21:10.547262+0300 | INFO | [70,   300] loss: 1.530
2025-02-25T01:21:21.259277+0300 | INFO | [70,   400] loss: 1.510
2025-02-25T01:21:32.444481+0300 | INFO | [70,   500] loss: 1.515
2025-02-25T01:21:43.185393+0300 | INFO | [70,   600] loss: 1.504
2025-02-25T01:21:55.341774+0300 | INFO | [70,   700] loss: 1.512
2025-02-25T01:22:05.872538+0300 | INFO | [70,   800] loss: 1.523
2025-02-25T01:22:16.860808+0300 | INFO | [70,   900] loss: 1.513
2025-02-25T01:22:27.650235+0300 | INFO | [70,  1000] loss: 1.528
2025-02-25T01:22:38.782244+0300 | INFO | [70,  1100] loss: 1.525
2025-02-25T01:22:49.590616+0300 | INFO | [70,  1200] loss: 1.523
2025-02-25T01:23:00.472815+0300 | INFO | [70,  1300] loss: 1.520
2025-02-25T01:23:12.084295+0300 | INFO | [70,  1400] loss: 1.509
2025-02-25T01:23:22.943256+0300 | INFO | [70,  1500] loss: 1.513
2025-02-25T01:23:33.841395+0300 | INFO | [70,  1600] loss: 1.532
2025-02-25T01:23:44.729832+0300 | INFO | [70,  1700] loss: 1.531
2025-02-25T01:23:55.785147+0300 | INFO | [70,  1800] loss: 1.521
2025-02-25T01:24:05.995427+0300 | INFO | [70,  1900] loss: 1.534
2025-02-25T01:24:16.727313+0300 | INFO | [70,  2000] loss: 1.518
2025-02-25T01:24:27.808790+0300 | INFO | [70,  2100] loss: 1.527
2025-02-25T01:24:39.737131+0300 | INFO | [70,  2200] loss: 1.513
2025-02-25T01:24:51.506566+0300 | INFO | [70,  2300] loss: 1.531
2025-02-25T01:25:02.439152+0300 | INFO | [70,  2400] loss: 1.525
2025-02-25T01:25:13.107743+0300 | INFO | [70,  2500] loss: 1.533
2025-02-25T01:25:23.920541+0300 | INFO | [70,  2600] loss: 1.524
2025-02-25T01:25:34.953145+0300 | INFO | [70,  2700] loss: 1.525
2025-02-25T01:25:46.071249+0300 | INFO | [70,  2800] loss: 1.522
2025-02-25T01:25:56.915208+0300 | INFO | [70,  2900] loss: 1.528
2025-02-25T01:26:07.522778+0300 | INFO | [70,  3000] loss: 1.534
2025-02-25T01:26:18.925042+0300 | INFO | [70,  3100] loss: 1.539
2025-02-25T01:26:29.840794+0300 | INFO | [70,  3200] loss: 1.528
2025-02-25T01:26:40.746620+0300 | INFO | [70,  3300] loss: 1.537
2025-02-25T01:26:51.559123+0300 | INFO | [70,  3400] loss: 1.519
2025-02-25T01:27:02.681936+0300 | INFO | [70,  3500] loss: 1.516
2025-02-25T01:27:16.206851+0300 | INFO | [70,  3600] loss: 1.512
2025-02-25T01:27:27.185855+0300 | INFO | [70,  3700] loss: 1.531
2025-02-25T01:27:38.193073+0300 | INFO | [70,  3800] loss: 1.512
2025-02-25T01:27:48.933844+0300 | INFO | [70,  3900] loss: 1.515
2025-02-25T01:27:59.769410+0300 | INFO | [70,  4000] loss: 1.531
2025-02-25T01:28:10.395134+0300 | INFO | [70,  4100] loss: 1.517
2025-02-25T01:28:21.248619+0300 | INFO | [70,  4200] loss: 1.524
2025-02-25T01:28:32.127026+0300 | INFO | [70,  4300] loss: 1.519
2025-02-25T01:28:43.129532+0300 | INFO | [70,  4400] loss: 1.522
2025-02-25T01:28:53.963055+0300 | INFO | [70,  4500] loss: 1.528
2025-02-25T01:29:09.150436+0300 | INFO | [70,  4600] loss: 1.522
2025-02-25T01:29:20.894225+0300 | INFO | [70,  4700] loss: 1.512
2025-02-25T01:29:33.965337+0300 | INFO | [70,  4800] loss: 1.513
2025-02-25T01:29:44.596178+0300 | INFO | [70,  4900] loss: 1.522
2025-02-25T01:29:57.287765+0300 | DEBUG | Saving model to flat file storage. Save #70
2025-02-25T01:29:57.323316+0300 | INFO | Averaging client parameters
2025-02-25T01:29:57.336814+0300 | INFO | Updating parameters on client #0
2025-02-25T01:30:12.591335+0300 | DEBUG | Test set: Accuracy: 7847/10000 (78%)
2025-02-25T01:30:12.593343+0300 | DEBUG | Test set: Loss: 1.6743742227554321
2025-02-25T01:30:12.706655+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.63      0.58      0.61      1200
           4       0.79      0.79      0.79      1000
           5       0.49      0.58      0.53       800
           6       0.87      0.83      0.85      1000
           7       0.83      0.83      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.78      0.79     10000

2025-02-25T01:30:12.708654+0300 | DEBUG | Confusion Matrix:
[[846  13  29  13  18  13   2  11  39  16]
 [ 14 910   1   3   0   2   7   3  12  48]
 [ 62   1 696  56  61  62  30  19   6   7]
 [ 27   8  51 700  40 279  42  29  11  13]
 [ 16   1  40  52 786  26  26  44   8   1]
 [  9   2  48 202  20 467   7  38   7   0]
 [ 13   2  42  46  26  30 830   4   5   2]
 [ 13   1   6  24  47  71   4 830   0   4]
 [ 40  18   5   7   0   3   6   6 893  22]
 [ 20  39   5   6   2   6   3  12  18 889]]
2025-02-25T01:30:12.710651+0300 | DEBUG | Class precision: [0.79811321 0.91457286 0.75406284 0.63119928 0.786      0.48696559
 0.86729363 0.83333333 0.89389389 0.88722555]
2025-02-25T01:30:12.711653+0300 | DEBUG | Class recall: [0.846      0.91       0.696      0.58333333 0.786      0.58375
 0.83       0.83       0.893      0.889     ]
2025-02-25T01:30:12.763191+0300 | INFO | Training epoch #71 on client #0
2025-02-25T01:30:12.766196+0300 | DEBUG | Saving model to flat file storage. Save #71
2025-02-25T01:30:12.911963+0300 | INFO | [71,     0] loss: 0.016
2025-02-25T01:30:23.694377+0300 | INFO | [71,   100] loss: 1.514
2025-02-25T01:30:34.662084+0300 | INFO | [71,   200] loss: 1.515
2025-02-25T01:30:45.636459+0300 | INFO | [71,   300] loss: 1.506
2025-02-25T01:30:57.281496+0300 | INFO | [71,   400] loss: 1.516
2025-02-25T01:31:08.648348+0300 | INFO | [71,   500] loss: 1.517
2025-02-25T01:31:20.140851+0300 | INFO | [71,   600] loss: 1.527
2025-02-25T01:31:31.846173+0300 | INFO | [71,   700] loss: 1.523
2025-02-25T01:31:43.259859+0300 | INFO | [71,   800] loss: 1.519
2025-02-25T01:31:54.770116+0300 | INFO | [71,   900] loss: 1.514
2025-02-25T01:32:06.172715+0300 | INFO | [71,  1000] loss: 1.523
2025-02-25T01:32:20.647550+0300 | INFO | [71,  1100] loss: 1.508
2025-02-25T01:32:32.025904+0300 | INFO | [71,  1200] loss: 1.522
2025-02-25T01:32:44.062978+0300 | INFO | [71,  1300] loss: 1.521
2025-02-25T01:32:55.491752+0300 | INFO | [71,  1400] loss: 1.516
2025-02-25T01:33:08.285711+0300 | INFO | [71,  1500] loss: 1.519
2025-02-25T01:33:19.709317+0300 | INFO | [71,  1600] loss: 1.519
2025-02-25T01:33:32.101017+0300 | INFO | [71,  1700] loss: 1.522
2025-02-25T01:33:45.316593+0300 | INFO | [71,  1800] loss: 1.518
2025-02-25T01:33:55.883564+0300 | INFO | [71,  1900] loss: 1.524
2025-02-25T01:34:06.707257+0300 | INFO | [71,  2000] loss: 1.508
2025-02-25T01:34:17.710724+0300 | INFO | [71,  2100] loss: 1.512
2025-02-25T01:34:28.701288+0300 | INFO | [71,  2200] loss: 1.511
2025-02-25T01:34:40.245043+0300 | INFO | [71,  2300] loss: 1.526
2025-02-25T01:34:52.414855+0300 | INFO | [71,  2400] loss: 1.522
2025-02-25T01:35:05.782790+0300 | INFO | [71,  2500] loss: 1.522
2025-02-25T01:35:18.070679+0300 | INFO | [71,  2600] loss: 1.524
2025-02-25T01:35:28.635430+0300 | INFO | [71,  2700] loss: 1.510
2025-02-25T01:35:39.513454+0300 | INFO | [71,  2800] loss: 1.535
2025-02-25T01:35:50.410809+0300 | INFO | [71,  2900] loss: 1.522
2025-02-25T01:36:01.617253+0300 | INFO | [71,  3000] loss: 1.519
2025-02-25T01:36:12.347179+0300 | INFO | [71,  3100] loss: 1.518
2025-02-25T01:36:23.028271+0300 | INFO | [71,  3200] loss: 1.522
2025-02-25T01:36:33.635389+0300 | INFO | [71,  3300] loss: 1.519
2025-02-25T01:36:44.604218+0300 | INFO | [71,  3400] loss: 1.523
2025-02-25T01:36:55.387146+0300 | INFO | [71,  3500] loss: 1.509
2025-02-25T01:37:05.866827+0300 | INFO | [71,  3600] loss: 1.513
2025-02-25T01:37:15.889417+0300 | INFO | [71,  3700] loss: 1.507
2025-02-25T01:37:26.317453+0300 | INFO | [71,  3800] loss: 1.525
2025-02-25T01:37:37.189699+0300 | INFO | [71,  3900] loss: 1.533
2025-02-25T01:37:48.400548+0300 | INFO | [71,  4000] loss: 1.526
2025-02-25T01:37:58.927844+0300 | INFO | [71,  4100] loss: 1.518
2025-02-25T01:38:12.936779+0300 | INFO | [71,  4200] loss: 1.522
2025-02-25T01:38:26.658226+0300 | INFO | [71,  4300] loss: 1.529
2025-02-25T01:38:38.584321+0300 | INFO | [71,  4400] loss: 1.526
2025-02-25T01:38:49.063352+0300 | INFO | [71,  4500] loss: 1.513
2025-02-25T01:39:00.749324+0300 | INFO | [71,  4600] loss: 1.515
2025-02-25T01:39:11.535738+0300 | INFO | [71,  4700] loss: 1.537
2025-02-25T01:39:22.374034+0300 | INFO | [71,  4800] loss: 1.525
2025-02-25T01:39:33.357391+0300 | INFO | [71,  4900] loss: 1.523
2025-02-25T01:39:44.220285+0300 | DEBUG | Saving model to flat file storage. Save #71
2025-02-25T01:39:44.244641+0300 | INFO | Averaging client parameters
2025-02-25T01:39:44.253640+0300 | INFO | Updating parameters on client #0
2025-02-25T01:39:59.306078+0300 | DEBUG | Test set: Accuracy: 7799/10000 (78%)
2025-02-25T01:39:59.307534+0300 | DEBUG | Test set: Loss: 1.679948091506958
2025-02-25T01:39:59.410944+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.85      0.80      1000
           1       0.90      0.91      0.91      1000
           2       0.71      0.71      0.71      1000
           3       0.65      0.57      0.61      1200
           4       0.75      0.81      0.78      1000
           5       0.52      0.55      0.54       800
           6       0.81      0.85      0.83      1000
           7       0.87      0.79      0.83      1000
           8       0.90      0.88      0.89      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T01:39:59.412946+0300 | DEBUG | Confusion Matrix:
[[847  18  42  12  15   5   6   7  36  12]
 [ 17 914   5   5   0   1   9   2  13  34]
 [ 60   2 715  36  67  46  50  14   4   6]
 [ 36   7  69 684  48 241  58  28  12  17]
 [ 14   1  40  52 805  24  37  21   5   1]
 [ 11   3  62 193  28 443  18  36   6   0]
 [ 12   0  37  35  38  17 851   3   6   1]
 [ 22   1  20  25  64  66   6 791   1   4]
 [ 62  13   8   5   2   4   4   1 883  18]
 [ 32  54   8   3   3   4   8   8  14 866]]
2025-02-25T01:39:59.415229+0300 | DEBUG | Class precision: [0.76100629 0.90227048 0.71073559 0.65142857 0.75233645 0.52056404
 0.81279847 0.86827662 0.90102041 0.90302398]
2025-02-25T01:39:59.416484+0300 | DEBUG | Class recall: [0.847   0.914   0.715   0.57    0.805   0.55375 0.851   0.791   0.883
 0.866  ]
2025-02-25T01:39:59.467213+0300 | INFO | Training epoch #72 on client #0
2025-02-25T01:39:59.468519+0300 | DEBUG | Saving model to flat file storage. Save #72
2025-02-25T01:39:59.594038+0300 | INFO | [72,     0] loss: 0.015
2025-02-25T01:40:09.768796+0300 | INFO | [72,   100] loss: 1.518
2025-02-25T01:40:20.611375+0300 | INFO | [72,   200] loss: 1.515
2025-02-25T01:40:31.513291+0300 | INFO | [72,   300] loss: 1.522
2025-02-25T01:40:42.369696+0300 | INFO | [72,   400] loss: 1.523
2025-02-25T01:40:53.219195+0300 | INFO | [72,   500] loss: 1.527
2025-02-25T01:41:03.806015+0300 | INFO | [72,   600] loss: 1.519
2025-02-25T01:41:14.746087+0300 | INFO | [72,   700] loss: 1.516
2025-02-25T01:41:25.585031+0300 | INFO | [72,   800] loss: 1.530
2025-02-25T01:41:36.697163+0300 | INFO | [72,   900] loss: 1.528
2025-02-25T01:41:47.210756+0300 | INFO | [72,  1000] loss: 1.519
2025-02-25T01:41:58.041454+0300 | INFO | [72,  1100] loss: 1.520
2025-02-25T01:42:09.534984+0300 | INFO | [72,  1200] loss: 1.519
2025-02-25T01:42:20.543610+0300 | INFO | [72,  1300] loss: 1.510
2025-02-25T01:42:31.399977+0300 | INFO | [72,  1400] loss: 1.515
2025-02-25T01:42:42.822187+0300 | INFO | [72,  1500] loss: 1.519
2025-02-25T01:42:56.239651+0300 | INFO | [72,  1600] loss: 1.529
2025-02-25T01:43:07.479235+0300 | INFO | [72,  1700] loss: 1.517
2025-02-25T01:43:18.330406+0300 | INFO | [72,  1800] loss: 1.514
2025-02-25T01:43:29.268248+0300 | INFO | [72,  1900] loss: 1.520
2025-02-25T01:43:40.178262+0300 | INFO | [72,  2000] loss: 1.522
2025-02-25T01:43:51.033885+0300 | INFO | [72,  2100] loss: 1.505
2025-02-25T01:44:01.710506+0300 | INFO | [72,  2200] loss: 1.513
2025-02-25T01:44:12.641914+0300 | INFO | [72,  2300] loss: 1.514
2025-02-25T01:44:23.527410+0300 | INFO | [72,  2400] loss: 1.510
2025-02-25T01:44:34.445255+0300 | INFO | [72,  2500] loss: 1.511
2025-02-25T01:44:45.224060+0300 | INFO | [72,  2600] loss: 1.514
2025-02-25T01:44:56.082809+0300 | INFO | [72,  2700] loss: 1.525
2025-02-25T01:45:06.914597+0300 | INFO | [72,  2800] loss: 1.506
2025-02-25T01:45:21.431105+0300 | INFO | [72,  2900] loss: 1.523
2025-02-25T01:45:32.484460+0300 | INFO | [72,  3000] loss: 1.519
2025-02-25T01:45:42.667311+0300 | INFO | [72,  3100] loss: 1.517
2025-02-25T01:45:53.319684+0300 | INFO | [72,  3200] loss: 1.516
2025-02-25T01:46:03.888047+0300 | INFO | [72,  3300] loss: 1.515
2025-02-25T01:46:14.187263+0300 | INFO | [72,  3400] loss: 1.525
2025-02-25T01:46:27.735404+0300 | INFO | [72,  3500] loss: 1.526
2025-02-25T01:46:38.444294+0300 | INFO | [72,  3600] loss: 1.526
2025-02-25T01:46:50.315611+0300 | INFO | [72,  3700] loss: 1.511
2025-02-25T01:47:00.815398+0300 | INFO | [72,  3800] loss: 1.529
2025-02-25T01:47:14.337760+0300 | INFO | [72,  3900] loss: 1.524
2025-02-25T01:47:26.124259+0300 | INFO | [72,  4000] loss: 1.524
2025-02-25T01:47:36.821811+0300 | INFO | [72,  4100] loss: 1.520
2025-02-25T01:47:47.531321+0300 | INFO | [72,  4200] loss: 1.525
2025-02-25T01:47:58.508457+0300 | INFO | [72,  4300] loss: 1.519
2025-02-25T01:48:09.461585+0300 | INFO | [72,  4400] loss: 1.523
2025-02-25T01:48:20.370891+0300 | INFO | [72,  4500] loss: 1.516
2025-02-25T01:48:31.726919+0300 | INFO | [72,  4600] loss: 1.516
2025-02-25T01:48:43.075580+0300 | INFO | [72,  4700] loss: 1.515
2025-02-25T01:48:54.230466+0300 | INFO | [72,  4800] loss: 1.511
2025-02-25T01:49:05.002483+0300 | INFO | [72,  4900] loss: 1.519
2025-02-25T01:49:15.966846+0300 | DEBUG | Saving model to flat file storage. Save #72
2025-02-25T01:49:16.001329+0300 | INFO | Averaging client parameters
2025-02-25T01:49:16.011618+0300 | INFO | Updating parameters on client #0
2025-02-25T01:49:31.398019+0300 | DEBUG | Test set: Accuracy: 7802/10000 (78%)
2025-02-25T01:49:31.401023+0300 | DEBUG | Test set: Loss: 1.6797325611114502
2025-02-25T01:49:31.531985+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.80      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.74      0.71      0.73      1000
           3       0.64      0.55      0.59      1200
           4       0.75      0.81      0.77      1000
           5       0.47      0.60      0.53       800
           6       0.85      0.82      0.83      1000
           7       0.87      0.80      0.83      1000
           8       0.87      0.91      0.89      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T01:49:31.534987+0300 | DEBUG | Confusion Matrix:
[[803  14  42  16  29  11   4   7  58  16]
 [  7 919   0   3   2   1   5   1  16  46]
 [ 53   2 714  38  71  55  41  12   7   7]
 [ 20   6  54 662  51 318  40  23  12  14]
 [  9   2  42  43 807  30  33  28   5   1]
 [  8   3  48 181  26 484  12  31   7   0]
 [  9   3  41  47  32  36 823   2   5   2]
 [ 11   2  14  27  60  79   5 796   4   2]
 [ 25  13   7  11   2   5   3   4 912  18]
 [ 18  41   4   8   3   5   6  10  23 882]]
2025-02-25T01:49:31.535979+0300 | DEBUG | Class precision: [0.83385254 0.91442786 0.73913043 0.63899614 0.74515235 0.47265625
 0.84670782 0.87089716 0.86939943 0.89271255]
2025-02-25T01:49:31.537984+0300 | DEBUG | Class recall: [0.803      0.919      0.714      0.55166667 0.807      0.605
 0.823      0.796      0.912      0.882     ]
2025-02-25T01:49:31.584507+0300 | INFO | Training epoch #73 on client #0
2025-02-25T01:49:31.585505+0300 | DEBUG | Saving model to flat file storage. Save #73
2025-02-25T01:49:31.732080+0300 | INFO | [73,     0] loss: 0.015
2025-02-25T01:49:42.312123+0300 | INFO | [73,   100] loss: 1.519
2025-02-25T01:49:53.150111+0300 | INFO | [73,   200] loss: 1.517
2025-02-25T01:50:04.163238+0300 | INFO | [73,   300] loss: 1.525
2025-02-25T01:50:14.825535+0300 | INFO | [73,   400] loss: 1.521
2025-02-25T01:50:26.716582+0300 | INFO | [73,   500] loss: 1.520
2025-02-25T01:50:37.735686+0300 | INFO | [73,   600] loss: 1.519
2025-02-25T01:50:48.127865+0300 | INFO | [73,   700] loss: 1.522
2025-02-25T01:50:58.853240+0300 | INFO | [73,   800] loss: 1.514
2025-02-25T01:51:09.570003+0300 | INFO | [73,   900] loss: 1.529
2025-02-25T01:51:20.242985+0300 | INFO | [73,  1000] loss: 1.517
2025-02-25T01:51:32.029208+0300 | INFO | [73,  1100] loss: 1.511
2025-02-25T01:51:42.923936+0300 | INFO | [73,  1200] loss: 1.504
2025-02-25T01:51:53.207599+0300 | INFO | [73,  1300] loss: 1.524
2025-02-25T01:52:03.765986+0300 | INFO | [73,  1400] loss: 1.516
2025-02-25T01:52:14.754803+0300 | INFO | [73,  1500] loss: 1.527
2025-02-25T01:52:28.057307+0300 | INFO | [73,  1600] loss: 1.515
2025-02-25T01:52:39.014716+0300 | INFO | [73,  1700] loss: 1.518
2025-02-25T01:52:50.587838+0300 | INFO | [73,  1800] loss: 1.522
2025-02-25T01:53:01.493037+0300 | INFO | [73,  1900] loss: 1.518
2025-02-25T01:53:12.545385+0300 | INFO | [73,  2000] loss: 1.505
2025-02-25T01:53:23.514071+0300 | INFO | [73,  2100] loss: 1.520
2025-02-25T01:53:37.361884+0300 | INFO | [73,  2200] loss: 1.508
2025-02-25T01:53:51.098966+0300 | INFO | [73,  2300] loss: 1.520
2025-02-25T01:54:04.046964+0300 | INFO | [73,  2400] loss: 1.527
2025-02-25T01:54:15.419484+0300 | INFO | [73,  2500] loss: 1.523
2025-02-25T01:54:25.634981+0300 | INFO | [73,  2600] loss: 1.528
2025-02-25T01:54:36.780256+0300 | INFO | [73,  2700] loss: 1.514
2025-02-25T01:54:48.158597+0300 | INFO | [73,  2800] loss: 1.516
2025-02-25T01:54:59.102644+0300 | INFO | [73,  2900] loss: 1.529
2025-02-25T01:55:10.186771+0300 | INFO | [73,  3000] loss: 1.509
2025-02-25T01:55:21.132972+0300 | INFO | [73,  3100] loss: 1.519
2025-02-25T01:55:32.024261+0300 | INFO | [73,  3200] loss: 1.517
2025-02-25T01:55:45.138548+0300 | INFO | [73,  3300] loss: 1.512
2025-02-25T01:55:56.012182+0300 | INFO | [73,  3400] loss: 1.520
2025-02-25T01:56:06.956142+0300 | INFO | [73,  3500] loss: 1.514
2025-02-25T01:56:17.777636+0300 | INFO | [73,  3600] loss: 1.531
2025-02-25T01:56:32.414960+0300 | INFO | [73,  3700] loss: 1.515
2025-02-25T01:56:45.486327+0300 | INFO | [73,  3800] loss: 1.515
2025-02-25T01:56:56.194520+0300 | INFO | [73,  3900] loss: 1.510
2025-02-25T01:57:06.936169+0300 | INFO | [73,  4000] loss: 1.509
2025-02-25T01:57:17.987486+0300 | INFO | [73,  4100] loss: 1.516
2025-02-25T01:57:28.587308+0300 | INFO | [73,  4200] loss: 1.535
2025-02-25T01:57:39.478404+0300 | INFO | [73,  4300] loss: 1.519
2025-02-25T01:57:50.908128+0300 | INFO | [73,  4400] loss: 1.522
2025-02-25T01:58:04.283075+0300 | INFO | [73,  4500] loss: 1.516
2025-02-25T01:58:14.806384+0300 | INFO | [73,  4600] loss: 1.519
2025-02-25T01:58:25.585806+0300 | INFO | [73,  4700] loss: 1.523
2025-02-25T01:58:36.531116+0300 | INFO | [73,  4800] loss: 1.515
2025-02-25T01:58:47.361938+0300 | INFO | [73,  4900] loss: 1.532
2025-02-25T01:58:58.130227+0300 | DEBUG | Saving model to flat file storage. Save #73
2025-02-25T01:58:58.160229+0300 | INFO | Averaging client parameters
2025-02-25T01:58:58.172278+0300 | INFO | Updating parameters on client #0
2025-02-25T01:59:13.179258+0300 | DEBUG | Test set: Accuracy: 7822/10000 (78%)
2025-02-25T01:59:13.180257+0300 | DEBUG | Test set: Loss: 1.6774355173110962
2025-02-25T01:59:13.289757+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.82      0.81      1000
           1       0.93      0.90      0.92      1000
           2       0.74      0.69      0.71      1000
           3       0.65      0.56      0.60      1200
           4       0.74      0.83      0.79      1000
           5       0.49      0.57      0.53       800
           6       0.81      0.86      0.83      1000
           7       0.86      0.81      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T01:59:13.291757+0300 | DEBUG | Confusion Matrix:
[[823  14  45  13  19   8  10  10  37  21]
 [ 14 902   3   2   0   2   7   1  20  49]
 [ 57   1 689  37  71  59  59  18   4   5]
 [ 27   3  53 666  59 285  59  29   6  13]
 [ 16   2  33  34 834  23  35  19   4   0]
 [  8   1  42 191  39 460  13  39   6   1]
 [ 14   1  34  42  27  19 857   3   2   1]
 [ 17   0  12  22  65  71   3 809   1   0]
 [ 43   9  12  13   4   5   6   1 891  16]
 [ 18  37   9   6   4   4   4   8  19 891]]
2025-02-25T01:59:13.293759+0300 | DEBUG | Class precision: [0.79363549 0.92989691 0.73927039 0.64912281 0.74331551 0.49145299
 0.81386515 0.86339381 0.9        0.89368104]
2025-02-25T01:59:13.295754+0300 | DEBUG | Class recall: [0.823 0.902 0.689 0.555 0.834 0.575 0.857 0.809 0.891 0.891]
2025-02-25T01:59:13.354538+0300 | INFO | Training epoch #74 on client #0
2025-02-25T01:59:13.356538+0300 | DEBUG | Saving model to flat file storage. Save #74
2025-02-25T01:59:13.524018+0300 | INFO | [74,     0] loss: 0.015
2025-02-25T01:59:24.319565+0300 | INFO | [74,   100] loss: 1.512
2025-02-25T01:59:35.084579+0300 | INFO | [74,   200] loss: 1.523
2025-02-25T01:59:45.464738+0300 | INFO | [74,   300] loss: 1.507
2025-02-25T01:59:56.556247+0300 | INFO | [74,   400] loss: 1.512
2025-02-25T02:00:07.318007+0300 | INFO | [74,   500] loss: 1.508
2025-02-25T02:00:18.138126+0300 | INFO | [74,   600] loss: 1.524
2025-02-25T02:00:29.132214+0300 | INFO | [74,   700] loss: 1.513
2025-02-25T02:00:42.668569+0300 | INFO | [74,   800] loss: 1.523
2025-02-25T02:00:52.855096+0300 | INFO | [74,   900] loss: 1.519
2025-02-25T02:01:05.915616+0300 | INFO | [74,  1000] loss: 1.515
2025-02-25T02:01:16.628815+0300 | INFO | [74,  1100] loss: 1.518
2025-02-25T02:01:27.517819+0300 | INFO | [74,  1200] loss: 1.516
2025-02-25T02:01:38.410471+0300 | INFO | [74,  1300] loss: 1.506
2025-02-25T02:01:49.562626+0300 | INFO | [74,  1400] loss: 1.530
2025-02-25T02:02:00.451749+0300 | INFO | [74,  1500] loss: 1.507
2025-02-25T02:02:10.686002+0300 | INFO | [74,  1600] loss: 1.518
2025-02-25T02:02:21.753470+0300 | INFO | [74,  1700] loss: 1.516
2025-02-25T02:02:35.108841+0300 | INFO | [74,  1800] loss: 1.515
2025-02-25T02:02:45.843634+0300 | INFO | [74,  1900] loss: 1.518
2025-02-25T02:02:56.678230+0300 | INFO | [74,  2000] loss: 1.513
2025-02-25T02:03:07.429955+0300 | INFO | [74,  2100] loss: 1.512
2025-02-25T02:03:18.209075+0300 | INFO | [74,  2200] loss: 1.525
2025-02-25T02:03:28.938551+0300 | INFO | [74,  2300] loss: 1.514
2025-02-25T02:03:39.941218+0300 | INFO | [74,  2400] loss: 1.536
2025-02-25T02:03:50.710457+0300 | INFO | [74,  2500] loss: 1.516
2025-02-25T02:04:01.629051+0300 | INFO | [74,  2600] loss: 1.514
2025-02-25T02:04:12.903718+0300 | INFO | [74,  2700] loss: 1.518
2025-02-25T02:04:23.903579+0300 | INFO | [74,  2800] loss: 1.514
2025-02-25T02:04:34.785549+0300 | INFO | [74,  2900] loss: 1.512
2025-02-25T02:04:45.663658+0300 | INFO | [74,  3000] loss: 1.514
2025-02-25T02:04:56.888158+0300 | INFO | [74,  3100] loss: 1.514
2025-02-25T02:05:08.355948+0300 | INFO | [74,  3200] loss: 1.517
2025-02-25T02:05:22.184705+0300 | INFO | [74,  3300] loss: 1.527
2025-02-25T02:05:32.961991+0300 | INFO | [74,  3400] loss: 1.524
2025-02-25T02:05:46.571602+0300 | INFO | [74,  3500] loss: 1.516
2025-02-25T02:05:57.140412+0300 | INFO | [74,  3600] loss: 1.515
2025-02-25T02:06:07.622302+0300 | INFO | [74,  3700] loss: 1.524
2025-02-25T02:06:18.665607+0300 | INFO | [74,  3800] loss: 1.524
2025-02-25T02:06:29.543336+0300 | INFO | [74,  3900] loss: 1.508
2025-02-25T02:06:40.508566+0300 | INFO | [74,  4000] loss: 1.517
2025-02-25T02:06:51.416880+0300 | INFO | [74,  4100] loss: 1.505
2025-02-25T02:07:02.119194+0300 | INFO | [74,  4200] loss: 1.520
2025-02-25T02:07:12.839886+0300 | INFO | [74,  4300] loss: 1.532
2025-02-25T02:07:23.977055+0300 | INFO | [74,  4400] loss: 1.513
2025-02-25T02:07:34.977693+0300 | INFO | [74,  4500] loss: 1.523
2025-02-25T02:07:46.153949+0300 | INFO | [74,  4600] loss: 1.514
2025-02-25T02:07:57.199570+0300 | INFO | [74,  4700] loss: 1.501
2025-02-25T02:08:08.504306+0300 | INFO | [74,  4800] loss: 1.507
2025-02-25T02:08:19.179316+0300 | INFO | [74,  4900] loss: 1.534
2025-02-25T02:08:32.624367+0300 | DEBUG | Saving model to flat file storage. Save #74
2025-02-25T02:08:32.655760+0300 | INFO | Averaging client parameters
2025-02-25T02:08:32.671761+0300 | INFO | Updating parameters on client #0
2025-02-25T02:08:47.695029+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-25T02:08:47.698029+0300 | DEBUG | Test set: Loss: 1.672713041305542
2025-02-25T02:08:47.796360+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.91      0.91      0.91      1000
           2       0.73      0.72      0.72      1000
           3       0.67      0.57      0.62      1200
           4       0.76      0.80      0.78      1000
           5       0.54      0.56      0.55       800
           6       0.81      0.86      0.83      1000
           7       0.87      0.82      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.88      0.90      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T02:08:47.798361+0300 | DEBUG | Confusion Matrix:
[[836  14  43   8  21   4   5   8  40  21]
 [ 15 909   1   1   1   1   6   0  14  52]
 [ 54   1 717  35  58  41  66  17   5   6]
 [ 28   8  61 688  54 245  62  22  11  21]
 [ 19   2  43  41 803  18  36  31   6   1]
 [ 13   4  46 189  33 451  18  36   9   1]
 [ 11   1  41  33  23  19 862   3   6   1]
 [ 19   1  14  30  54  53   8 817   0   4]
 [ 47  16   9   4   5   4   3   1 892  19]
 [ 21  44   4   5   5   2   3   5  12 899]]
2025-02-25T02:08:47.800088+0300 | DEBUG | Class precision: [0.78645343 0.909      0.73237998 0.66537718 0.75969726 0.53818616
 0.80636109 0.86914894 0.89648241 0.87707317]
2025-02-25T02:08:47.801247+0300 | DEBUG | Class recall: [0.836      0.909      0.717      0.57333333 0.803      0.56375
 0.862      0.817      0.892      0.899     ]
2025-02-25T02:08:47.850109+0300 | INFO | Training epoch #75 on client #0
2025-02-25T02:08:47.850109+0300 | DEBUG | Saving model to flat file storage. Save #75
2025-02-25T02:08:47.975300+0300 | INFO | [75,     0] loss: 0.015
2025-02-25T02:09:01.347075+0300 | INFO | [75,   100] loss: 1.519
2025-02-25T02:09:12.153192+0300 | INFO | [75,   200] loss: 1.514
2025-02-25T02:09:23.071961+0300 | INFO | [75,   300] loss: 1.517
2025-02-25T02:09:34.279324+0300 | INFO | [75,   400] loss: 1.507
2025-02-25T02:09:44.955384+0300 | INFO | [75,   500] loss: 1.517
2025-02-25T02:09:55.796430+0300 | INFO | [75,   600] loss: 1.513
2025-02-25T02:10:06.145175+0300 | INFO | [75,   700] loss: 1.516
2025-02-25T02:10:17.012662+0300 | INFO | [75,   800] loss: 1.530
2025-02-25T02:10:28.525752+0300 | INFO | [75,   900] loss: 1.510
2025-02-25T02:10:39.575237+0300 | INFO | [75,  1000] loss: 1.516
2025-02-25T02:10:49.973175+0300 | INFO | [75,  1100] loss: 1.516
2025-02-25T02:11:00.654385+0300 | INFO | [75,  1200] loss: 1.515
2025-02-25T02:11:11.604132+0300 | INFO | [75,  1300] loss: 1.521
2025-02-25T02:11:22.421126+0300 | INFO | [75,  1400] loss: 1.510
2025-02-25T02:11:33.054979+0300 | INFO | [75,  1500] loss: 1.514
2025-02-25T02:11:43.894119+0300 | INFO | [75,  1600] loss: 1.508
2025-02-25T02:11:54.596607+0300 | INFO | [75,  1700] loss: 1.515
2025-02-25T02:12:05.353797+0300 | INFO | [75,  1800] loss: 1.513
2025-02-25T02:12:15.754352+0300 | INFO | [75,  1900] loss: 1.524
2025-02-25T02:12:26.491357+0300 | INFO | [75,  2000] loss: 1.511
2025-02-25T02:12:38.030992+0300 | INFO | [75,  2100] loss: 1.521
2025-02-25T02:12:49.714256+0300 | INFO | [75,  2200] loss: 1.507
2025-02-25T02:13:00.901711+0300 | INFO | [75,  2300] loss: 1.529
2025-02-25T02:13:11.590883+0300 | INFO | [75,  2400] loss: 1.512
2025-02-25T02:13:22.506652+0300 | INFO | [75,  2500] loss: 1.514
2025-02-25T02:13:36.734137+0300 | INFO | [75,  2600] loss: 1.522
2025-02-25T02:13:47.809902+0300 | INFO | [75,  2700] loss: 1.516
2025-02-25T02:13:58.719007+0300 | INFO | [75,  2800] loss: 1.505
2025-02-25T02:14:13.565790+0300 | INFO | [75,  2900] loss: 1.533
2025-02-25T02:14:24.307315+0300 | INFO | [75,  3000] loss: 1.514
2025-02-25T02:14:37.187102+0300 | INFO | [75,  3100] loss: 1.509
2025-02-25T02:14:47.829759+0300 | INFO | [75,  3200] loss: 1.505
2025-02-25T02:15:00.855413+0300 | INFO | [75,  3300] loss: 1.499
2025-02-25T02:15:11.095901+0300 | INFO | [75,  3400] loss: 1.526
2025-02-25T02:15:23.344310+0300 | INFO | [75,  3500] loss: 1.513
2025-02-25T02:15:34.222665+0300 | INFO | [75,  3600] loss: 1.530
2025-02-25T02:15:44.980132+0300 | INFO | [75,  3700] loss: 1.516
2025-02-25T02:15:55.589903+0300 | INFO | [75,  3800] loss: 1.520
2025-02-25T02:16:05.758089+0300 | INFO | [75,  3900] loss: 1.510
2025-02-25T02:16:16.186066+0300 | INFO | [75,  4000] loss: 1.523
2025-02-25T02:16:26.855748+0300 | INFO | [75,  4100] loss: 1.508
2025-02-25T02:16:37.716277+0300 | INFO | [75,  4200] loss: 1.519
2025-02-25T02:16:48.873569+0300 | INFO | [75,  4300] loss: 1.518
2025-02-25T02:16:59.073474+0300 | INFO | [75,  4400] loss: 1.513
2025-02-25T02:17:09.369477+0300 | INFO | [75,  4500] loss: 1.514
2025-02-25T02:17:22.205969+0300 | INFO | [75,  4600] loss: 1.518
2025-02-25T02:17:33.919327+0300 | INFO | [75,  4700] loss: 1.505
2025-02-25T02:17:44.614971+0300 | INFO | [75,  4800] loss: 1.522
2025-02-25T02:17:55.319815+0300 | INFO | [75,  4900] loss: 1.523
2025-02-25T02:18:06.129165+0300 | DEBUG | Saving model to flat file storage. Save #75
2025-02-25T02:18:06.154185+0300 | INFO | Averaging client parameters
2025-02-25T02:18:06.170481+0300 | INFO | Updating parameters on client #0
2025-02-25T02:18:23.753466+0300 | DEBUG | Test set: Accuracy: 7823/10000 (78%)
2025-02-25T02:18:23.754468+0300 | DEBUG | Test set: Loss: 1.6778322458267212
2025-02-25T02:18:23.857195+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.82      0.81      1000
           1       0.91      0.91      0.91      1000
           2       0.78      0.67      0.72      1000
           3       0.63      0.59      0.61      1200
           4       0.75      0.81      0.78      1000
           5       0.49      0.58      0.53       800
           6       0.85      0.83      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.86      0.91      0.88      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T02:18:23.859197+0300 | DEBUG | Confusion Matrix:
[[819  16  39  15  26   8   4   7  50  16]
 [ 11 914   1   2   0   4   5   0  24  39]
 [ 54   3 674  50  68  71  50  16   6   8]
 [ 26   6  40 712  52 274  40  21  14  15]
 [ 15   2  33  46 811  31  27  24   8   3]
 [  8   3  32 206  28 468  13  34   8   0]
 [  8   2  27  48  41  28 834   3   6   3]
 [ 19   1   5  33  57  72   4 801   6   2]
 [ 41  12   5   6   2   5   4   0 907  18]
 [ 22  50   4   8   2   2   5   3  21 883]]
2025-02-25T02:18:23.861200+0300 | DEBUG | Class precision: [0.80058651 0.90584737 0.78372093 0.63232682 0.74609016 0.48598131
 0.84584178 0.88118812 0.86380952 0.89463019]
2025-02-25T02:18:23.862196+0300 | DEBUG | Class recall: [0.819      0.914      0.674      0.59333333 0.811      0.585
 0.834      0.801      0.907      0.883     ]
2025-02-25T02:18:23.911728+0300 | INFO | Training epoch #76 on client #0
2025-02-25T02:18:23.911728+0300 | DEBUG | Saving model to flat file storage. Save #76
2025-02-25T02:18:24.042727+0300 | INFO | [76,     0] loss: 0.015
2025-02-25T02:18:34.873987+0300 | INFO | [76,   100] loss: 1.508
2025-02-25T02:18:45.810293+0300 | INFO | [76,   200] loss: 1.510
2025-02-25T02:18:56.939268+0300 | INFO | [76,   300] loss: 1.499
2025-02-25T02:19:10.226905+0300 | INFO | [76,   400] loss: 1.515
2025-02-25T02:19:23.857707+0300 | INFO | [76,   500] loss: 1.513
2025-02-25T02:19:34.727392+0300 | INFO | [76,   600] loss: 1.506
2025-02-25T02:19:45.799854+0300 | INFO | [76,   700] loss: 1.508
2025-02-25T02:19:57.283477+0300 | INFO | [76,   800] loss: 1.502
2025-02-25T02:20:07.676303+0300 | INFO | [76,   900] loss: 1.509
2025-02-25T02:20:18.473149+0300 | INFO | [76,  1000] loss: 1.503
2025-02-25T02:20:29.472441+0300 | INFO | [76,  1100] loss: 1.516
2025-02-25T02:20:40.151946+0300 | INFO | [76,  1200] loss: 1.511
2025-02-25T02:20:49.496460+0300 | INFO | [76,  1300] loss: 1.514
2025-02-25T02:21:00.958637+0300 | INFO | [76,  1400] loss: 1.517
2025-02-25T02:21:11.390699+0300 | INFO | [76,  1500] loss: 1.517
2025-02-25T02:21:23.230665+0300 | INFO | [76,  1600] loss: 1.520
2025-02-25T02:21:34.319232+0300 | INFO | [76,  1700] loss: 1.515
2025-02-25T02:21:45.009249+0300 | INFO | [76,  1800] loss: 1.521
2025-02-25T02:21:55.719965+0300 | INFO | [76,  1900] loss: 1.512
2025-02-25T02:22:06.321667+0300 | INFO | [76,  2000] loss: 1.538
2025-02-25T02:22:17.043349+0300 | INFO | [76,  2100] loss: 1.526
2025-02-25T02:22:27.826211+0300 | INFO | [76,  2200] loss: 1.516
2025-02-25T02:22:39.071043+0300 | INFO | [76,  2300] loss: 1.515
2025-02-25T02:22:49.813778+0300 | INFO | [76,  2400] loss: 1.519
2025-02-25T02:23:01.101004+0300 | INFO | [76,  2500] loss: 1.516
2025-02-25T02:23:15.011131+0300 | INFO | [76,  2600] loss: 1.513
2025-02-25T02:23:26.539933+0300 | INFO | [76,  2700] loss: 1.515
2025-02-25T02:23:37.244298+0300 | INFO | [76,  2800] loss: 1.534
2025-02-25T02:23:47.893645+0300 | INFO | [76,  2900] loss: 1.512
2025-02-25T02:23:59.726905+0300 | INFO | [76,  3000] loss: 1.512
2025-02-25T02:24:12.457313+0300 | INFO | [76,  3100] loss: 1.524
2025-02-25T02:24:23.158156+0300 | INFO | [76,  3200] loss: 1.521
2025-02-25T02:24:33.789878+0300 | INFO | [76,  3300] loss: 1.516
2025-02-25T02:24:44.659024+0300 | INFO | [76,  3400] loss: 1.517
2025-02-25T02:24:55.503504+0300 | INFO | [76,  3500] loss: 1.526
2025-02-25T02:25:07.011111+0300 | INFO | [76,  3600] loss: 1.508
2025-02-25T02:25:19.085466+0300 | INFO | [76,  3700] loss: 1.515
2025-02-25T02:25:29.931289+0300 | INFO | [76,  3800] loss: 1.515
2025-02-25T02:25:40.972482+0300 | INFO | [76,  3900] loss: 1.515
2025-02-25T02:25:51.690009+0300 | INFO | [76,  4000] loss: 1.509
2025-02-25T02:26:04.380611+0300 | INFO | [76,  4100] loss: 1.519
2025-02-25T02:26:15.754074+0300 | INFO | [76,  4200] loss: 1.512
2025-02-25T02:26:26.703653+0300 | INFO | [76,  4300] loss: 1.505
2025-02-25T02:26:37.749444+0300 | INFO | [76,  4400] loss: 1.514
2025-02-25T02:26:48.648161+0300 | INFO | [76,  4500] loss: 1.516
2025-02-25T02:27:02.355681+0300 | INFO | [76,  4600] loss: 1.531
2025-02-25T02:27:12.891700+0300 | INFO | [76,  4700] loss: 1.520
2025-02-25T02:27:23.771709+0300 | INFO | [76,  4800] loss: 1.508
2025-02-25T02:27:35.307722+0300 | INFO | [76,  4900] loss: 1.527
2025-02-25T02:27:46.075142+0300 | DEBUG | Saving model to flat file storage. Save #76
2025-02-25T02:27:46.104278+0300 | INFO | Averaging client parameters
2025-02-25T02:27:46.117281+0300 | INFO | Updating parameters on client #0
2025-02-25T02:28:01.117881+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-25T02:28:01.118877+0300 | DEBUG | Test set: Loss: 1.6731011867523193
2025-02-25T02:28:01.222228+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.88      0.94      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.63      0.61      0.62      1200
           4       0.81      0.80      0.80      1000
           5       0.52      0.56      0.54       800
           6       0.82      0.85      0.83      1000
           7       0.88      0.80      0.84      1000
           8       0.92      0.88      0.90      1000
           9       0.88      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T02:28:01.224229+0300 | DEBUG | Confusion Matrix:
[[845  24  44   8  11   6   6   6  29  21]
 [ 10 937   2   1   0   1   4   0   8  37]
 [ 54   4 698  48  49  64  62  11   3   7]
 [ 30  10  54 728  36 234  53  28   6  21]
 [ 20   2  37  61 795  19  36  23   6   1]
 [ 13   6  39 223  22 445  15  28   6   3]
 [ 12   4  33  51  16  20 852   6   3   3]
 [ 25   3  12  29  51  65   6 804   2   3]
 [ 54  19   8   6   2   5   4   3 878  21]
 [ 17  52   4   6   1   2   6   6  13 893]]
2025-02-25T02:28:01.228223+0300 | DEBUG | Class precision: [0.78240741 0.88312912 0.74973147 0.62704565 0.80874873 0.51684088
 0.81609195 0.87868852 0.92033543 0.88415842]
2025-02-25T02:28:01.230230+0300 | DEBUG | Class recall: [0.845      0.937      0.698      0.60666667 0.795      0.55625
 0.852      0.804      0.878      0.893     ]
2025-02-25T02:28:01.286188+0300 | INFO | Training epoch #77 on client #0
2025-02-25T02:28:01.287188+0300 | DEBUG | Saving model to flat file storage. Save #77
2025-02-25T02:28:01.425199+0300 | INFO | [77,     0] loss: 0.016
2025-02-25T02:28:11.727453+0300 | INFO | [77,   100] loss: 1.514
2025-02-25T02:28:22.598826+0300 | INFO | [77,   200] loss: 1.520
2025-02-25T02:28:33.316270+0300 | INFO | [77,   300] loss: 1.500
2025-02-25T02:28:44.109403+0300 | INFO | [77,   400] loss: 1.530
2025-02-25T02:28:54.907663+0300 | INFO | [77,   500] loss: 1.519
2025-02-25T02:29:05.145506+0300 | INFO | [77,   600] loss: 1.525
2025-02-25T02:29:16.365995+0300 | INFO | [77,   700] loss: 1.517
2025-02-25T02:29:27.042731+0300 | INFO | [77,   800] loss: 1.521
2025-02-25T02:29:37.895854+0300 | INFO | [77,   900] loss: 1.513
2025-02-25T02:29:48.677059+0300 | INFO | [77,  1000] loss: 1.504
2025-02-25T02:29:59.581457+0300 | INFO | [77,  1100] loss: 1.517
2025-02-25T02:30:13.404823+0300 | INFO | [77,  1200] loss: 1.512
2025-02-25T02:30:23.831995+0300 | INFO | [77,  1300] loss: 1.516
2025-02-25T02:30:34.842636+0300 | INFO | [77,  1400] loss: 1.509
2025-02-25T02:30:47.807120+0300 | INFO | [77,  1500] loss: 1.514
2025-02-25T02:30:58.542791+0300 | INFO | [77,  1600] loss: 1.517
2025-02-25T02:31:09.326275+0300 | INFO | [77,  1700] loss: 1.516
2025-02-25T02:31:19.735699+0300 | INFO | [77,  1800] loss: 1.508
2025-02-25T02:31:30.573157+0300 | INFO | [77,  1900] loss: 1.513
2025-02-25T02:31:41.645656+0300 | INFO | [77,  2000] loss: 1.502
2025-02-25T02:31:54.904463+0300 | INFO | [77,  2100] loss: 1.517
2025-02-25T02:32:05.525710+0300 | INFO | [77,  2200] loss: 1.510
2025-02-25T02:32:18.676313+0300 | INFO | [77,  2300] loss: 1.515
2025-02-25T02:32:31.145649+0300 | INFO | [77,  2400] loss: 1.512
2025-02-25T02:32:42.063204+0300 | INFO | [77,  2500] loss: 1.514
2025-02-25T02:32:52.669281+0300 | INFO | [77,  2600] loss: 1.514
2025-02-25T02:33:03.546031+0300 | INFO | [77,  2700] loss: 1.518
2025-02-25T02:33:14.497106+0300 | INFO | [77,  2800] loss: 1.512
2025-02-25T02:33:24.916026+0300 | INFO | [77,  2900] loss: 1.510
2025-02-25T02:33:35.939665+0300 | INFO | [77,  3000] loss: 1.526
2025-02-25T02:33:49.510534+0300 | INFO | [77,  3100] loss: 1.503
2025-02-25T02:34:00.693206+0300 | INFO | [77,  3200] loss: 1.519
2025-02-25T02:34:11.688829+0300 | INFO | [77,  3300] loss: 1.504
2025-02-25T02:34:23.422823+0300 | INFO | [77,  3400] loss: 1.508
2025-02-25T02:34:34.853366+0300 | INFO | [77,  3500] loss: 1.505
2025-02-25T02:34:46.617650+0300 | INFO | [77,  3600] loss: 1.517
2025-02-25T02:34:58.037719+0300 | INFO | [77,  3700] loss: 1.522
2025-02-25T02:35:09.014418+0300 | INFO | [77,  3800] loss: 1.512
2025-02-25T02:35:20.094431+0300 | INFO | [77,  3900] loss: 1.523
2025-02-25T02:35:31.453181+0300 | INFO | [77,  4000] loss: 1.509
2025-02-25T02:35:43.603862+0300 | INFO | [77,  4100] loss: 1.505
2025-02-25T02:35:54.742377+0300 | INFO | [77,  4200] loss: 1.512
2025-02-25T02:36:06.147105+0300 | INFO | [77,  4300] loss: 1.524
2025-02-25T02:36:17.439118+0300 | INFO | [77,  4400] loss: 1.515
2025-02-25T02:36:29.093794+0300 | INFO | [77,  4500] loss: 1.522
2025-02-25T02:36:40.623473+0300 | INFO | [77,  4600] loss: 1.524
2025-02-25T02:36:52.052782+0300 | INFO | [77,  4700] loss: 1.516
2025-02-25T02:37:02.830257+0300 | INFO | [77,  4800] loss: 1.508
2025-02-25T02:37:13.435502+0300 | INFO | [77,  4900] loss: 1.510
2025-02-25T02:37:23.731485+0300 | DEBUG | Saving model to flat file storage. Save #77
2025-02-25T02:37:23.753033+0300 | INFO | Averaging client parameters
2025-02-25T02:37:23.761037+0300 | INFO | Updating parameters on client #0
2025-02-25T02:37:38.961677+0300 | DEBUG | Test set: Accuracy: 7879/10000 (79%)
2025-02-25T02:37:38.963674+0300 | DEBUG | Test set: Loss: 1.6728096008300781
2025-02-25T02:37:39.067527+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.90      0.94      0.92      1000
           2       0.71      0.73      0.72      1000
           3       0.68      0.55      0.61      1200
           4       0.74      0.84      0.79      1000
           5       0.52      0.57      0.55       800
           6       0.83      0.84      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T02:37:39.069527+0300 | DEBUG | Confusion Matrix:
[[836  18  48   8  24   8   2   5  33  18]
 [  9 940   2   1   0   0   4   0  12  32]
 [ 51   2 734  33  64  49  47  10   3   7]
 [ 27   7  66 659  68 265  51  32  10  15]
 [ 12   2  47  32 842  14  27  20   3   1]
 [ 11   2  53 171  39 460  13  43   6   2]
 [ 11   1  43  35  38  22 840   5   4   1]
 [ 27   2  18  19  52  54   8 818   0   2]
 [ 44  16   9   8   3   5   6   4 892  13]
 [ 23  60  10   6   5   3  10   7  18 858]]
2025-02-25T02:37:39.070526+0300 | DEBUG | Class precision: [0.79543292 0.8952381  0.71262136 0.67798354 0.74185022 0.52272727
 0.83333333 0.86652542 0.90927625 0.90410959]
2025-02-25T02:37:39.072526+0300 | DEBUG | Class recall: [0.836      0.94       0.734      0.54916667 0.842      0.575
 0.84       0.818      0.892      0.858     ]
2025-02-25T02:37:39.130676+0300 | INFO | Training epoch #78 on client #0
2025-02-25T02:37:39.132622+0300 | DEBUG | Saving model to flat file storage. Save #78
2025-02-25T02:37:39.267041+0300 | INFO | [78,     0] loss: 0.017
2025-02-25T02:37:49.892119+0300 | INFO | [78,   100] loss: 1.496
2025-02-25T02:38:00.497266+0300 | INFO | [78,   200] loss: 1.523
2025-02-25T02:38:13.976415+0300 | INFO | [78,   300] loss: 1.517
2025-02-25T02:38:24.535734+0300 | INFO | [78,   400] loss: 1.525
2025-02-25T02:38:37.467131+0300 | INFO | [78,   500] loss: 1.511
2025-02-25T02:38:47.779580+0300 | INFO | [78,   600] loss: 1.521
2025-02-25T02:38:59.043777+0300 | INFO | [78,   700] loss: 1.517
2025-02-25T02:39:08.900531+0300 | INFO | [78,   800] loss: 1.507
2025-02-25T02:39:19.522744+0300 | INFO | [78,   900] loss: 1.514
2025-02-25T02:39:30.240399+0300 | INFO | [78,  1000] loss: 1.507
2025-02-25T02:39:41.448400+0300 | INFO | [78,  1100] loss: 1.506
2025-02-25T02:39:52.233157+0300 | INFO | [78,  1200] loss: 1.509
2025-02-25T02:40:03.412618+0300 | INFO | [78,  1300] loss: 1.515
2025-02-25T02:40:13.992515+0300 | INFO | [78,  1400] loss: 1.509
2025-02-25T02:40:24.531226+0300 | INFO | [78,  1500] loss: 1.515
2025-02-25T02:40:35.480082+0300 | INFO | [78,  1600] loss: 1.504
2025-02-25T02:40:46.567426+0300 | INFO | [78,  1700] loss: 1.503
2025-02-25T02:40:59.800681+0300 | INFO | [78,  1800] loss: 1.527
2025-02-25T02:41:11.769759+0300 | INFO | [78,  1900] loss: 1.513
2025-02-25T02:41:25.113400+0300 | INFO | [78,  2000] loss: 1.501
2025-02-25T02:41:35.684358+0300 | INFO | [78,  2100] loss: 1.517
2025-02-25T02:41:46.664961+0300 | INFO | [78,  2200] loss: 1.501
2025-02-25T02:41:58.040628+0300 | INFO | [78,  2300] loss: 1.506
2025-02-25T02:42:08.806690+0300 | INFO | [78,  2400] loss: 1.517
2025-02-25T02:42:19.798840+0300 | INFO | [78,  2500] loss: 1.514
2025-02-25T02:42:30.653410+0300 | INFO | [78,  2600] loss: 1.504
2025-02-25T02:42:41.025517+0300 | INFO | [78,  2700] loss: 1.523
2025-02-25T02:42:51.950313+0300 | INFO | [78,  2800] loss: 1.502
2025-02-25T02:43:02.676102+0300 | INFO | [78,  2900] loss: 1.520
2025-02-25T02:43:15.178226+0300 | INFO | [78,  3000] loss: 1.514
2025-02-25T02:43:26.702855+0300 | INFO | [78,  3100] loss: 1.515
2025-02-25T02:43:37.598166+0300 | INFO | [78,  3200] loss: 1.518
2025-02-25T02:43:48.227550+0300 | INFO | [78,  3300] loss: 1.508
2025-02-25T02:43:59.151099+0300 | INFO | [78,  3400] loss: 1.506
2025-02-25T02:44:09.777799+0300 | INFO | [78,  3500] loss: 1.503
2025-02-25T02:44:20.560345+0300 | INFO | [78,  3600] loss: 1.519
2025-02-25T02:44:31.525697+0300 | INFO | [78,  3700] loss: 1.509
2025-02-25T02:44:42.437339+0300 | INFO | [78,  3800] loss: 1.513
2025-02-25T02:44:53.245528+0300 | INFO | [78,  3900] loss: 1.505
2025-02-25T02:45:04.798353+0300 | INFO | [78,  4000] loss: 1.513
2025-02-25T02:45:15.894185+0300 | INFO | [78,  4100] loss: 1.516
2025-02-25T02:45:26.641593+0300 | INFO | [78,  4200] loss: 1.519
2025-02-25T02:45:37.378284+0300 | INFO | [78,  4300] loss: 1.520
2025-02-25T02:45:48.664209+0300 | INFO | [78,  4400] loss: 1.522
2025-02-25T02:45:59.088121+0300 | INFO | [78,  4500] loss: 1.512
2025-02-25T02:46:09.227524+0300 | INFO | [78,  4600] loss: 1.522
2025-02-25T02:46:19.936552+0300 | INFO | [78,  4700] loss: 1.513
2025-02-25T02:46:30.541289+0300 | INFO | [78,  4800] loss: 1.513
2025-02-25T02:46:41.393134+0300 | INFO | [78,  4900] loss: 1.530
2025-02-25T02:46:52.676108+0300 | DEBUG | Saving model to flat file storage. Save #78
2025-02-25T02:46:52.703554+0300 | INFO | Averaging client parameters
2025-02-25T02:46:52.714950+0300 | INFO | Updating parameters on client #0
2025-02-25T02:47:07.827420+0300 | DEBUG | Test set: Accuracy: 7854/10000 (79%)
2025-02-25T02:47:07.829422+0300 | DEBUG | Test set: Loss: 1.6747615337371826
2025-02-25T02:47:07.933754+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.91      0.93      0.92      1000
           2       0.77      0.65      0.71      1000
           3       0.64      0.57      0.61      1200
           4       0.74      0.83      0.78      1000
           5       0.51      0.61      0.55       800
           6       0.81      0.86      0.83      1000
           7       0.88      0.80      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.91      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T02:47:07.935755+0300 | DEBUG | Confusion Matrix:
[[843  19  36  14  18  10   4   8  34  14]
 [ 10 925   1   2   0   1   7   1  17  36]
 [ 62   3 654  50  80  67  61  13   5   5]
 [ 22   8  44 690  70 270  54  24   7  11]
 [ 14   1  28  43 834  22  34  20   3   1]
 [ 10   1  33 184  37 486  16  27   6   0]
 [ 14   2  29  43  26  20 857   2   5   2]
 [ 20   2  11  30  57  64  12 801   1   2]
 [ 52  18   6   7   2   6   5   2 886  16]
 [ 23  38   3  11   4   7   7   9  20 878]]
2025-02-25T02:47:07.936759+0300 | DEBUG | Class precision: [0.78785047 0.90953786 0.7739645  0.6424581  0.7393617  0.50996852
 0.81078524 0.8831312  0.9004065  0.90984456]
2025-02-25T02:47:07.938798+0300 | DEBUG | Class recall: [0.843  0.925  0.654  0.575  0.834  0.6075 0.857  0.801  0.886  0.878 ]
2025-02-25T02:47:07.992368+0300 | INFO | Training epoch #79 on client #0
2025-02-25T02:47:07.995369+0300 | DEBUG | Saving model to flat file storage. Save #79
2025-02-25T02:47:08.153741+0300 | INFO | [79,     0] loss: 0.015
2025-02-25T02:47:18.803628+0300 | INFO | [79,   100] loss: 1.502
2025-02-25T02:47:29.613506+0300 | INFO | [79,   200] loss: 1.512
2025-02-25T02:47:43.176319+0300 | INFO | [79,   300] loss: 1.513
2025-02-25T02:47:54.018887+0300 | INFO | [79,   400] loss: 1.504
2025-02-25T02:48:04.805390+0300 | INFO | [79,   500] loss: 1.517
2025-02-25T02:48:15.399762+0300 | INFO | [79,   600] loss: 1.514
2025-02-25T02:48:26.299160+0300 | INFO | [79,   700] loss: 1.511
2025-02-25T02:48:37.153855+0300 | INFO | [79,   800] loss: 1.509
2025-02-25T02:48:47.864145+0300 | INFO | [79,   900] loss: 1.502
2025-02-25T02:48:58.677246+0300 | INFO | [79,  1000] loss: 1.500
2025-02-25T02:49:09.505776+0300 | INFO | [79,  1100] loss: 1.513
2025-02-25T02:49:20.217293+0300 | INFO | [79,  1200] loss: 1.524
2025-02-25T02:49:31.884651+0300 | INFO | [79,  1300] loss: 1.517
2025-02-25T02:49:42.959445+0300 | INFO | [79,  1400] loss: 1.513
2025-02-25T02:49:57.916459+0300 | INFO | [79,  1500] loss: 1.530
2025-02-25T02:50:08.617338+0300 | INFO | [79,  1600] loss: 1.506
2025-02-25T02:50:19.475987+0300 | INFO | [79,  1700] loss: 1.506
2025-02-25T02:50:30.282341+0300 | INFO | [79,  1800] loss: 1.509
2025-02-25T02:50:42.618468+0300 | INFO | [79,  1900] loss: 1.502
2025-02-25T02:50:56.059339+0300 | INFO | [79,  2000] loss: 1.517
2025-02-25T02:51:08.012487+0300 | INFO | [79,  2100] loss: 1.517
2025-02-25T02:51:18.748094+0300 | INFO | [79,  2200] loss: 1.518
2025-02-25T02:51:29.443139+0300 | INFO | [79,  2300] loss: 1.512
2025-02-25T02:51:40.296324+0300 | INFO | [79,  2400] loss: 1.512
2025-02-25T02:51:51.117733+0300 | INFO | [79,  2500] loss: 1.499
2025-02-25T02:52:01.873988+0300 | INFO | [79,  2600] loss: 1.525
2025-02-25T02:52:12.471407+0300 | INFO | [79,  2700] loss: 1.510
2025-02-25T02:52:23.208450+0300 | INFO | [79,  2800] loss: 1.516
2025-02-25T02:52:34.103476+0300 | INFO | [79,  2900] loss: 1.518
2025-02-25T02:52:45.190341+0300 | INFO | [79,  3000] loss: 1.529
2025-02-25T02:52:55.977331+0300 | INFO | [79,  3100] loss: 1.523
2025-02-25T02:53:07.028083+0300 | INFO | [79,  3200] loss: 1.507
2025-02-25T02:53:17.827034+0300 | INFO | [79,  3300] loss: 1.514
2025-02-25T02:53:28.507877+0300 | INFO | [79,  3400] loss: 1.506
2025-02-25T02:53:39.356449+0300 | INFO | [79,  3500] loss: 1.513
2025-02-25T02:53:50.436011+0300 | INFO | [79,  3600] loss: 1.519
2025-02-25T02:54:01.512194+0300 | INFO | [79,  3700] loss: 1.517
2025-02-25T02:54:12.391056+0300 | INFO | [79,  3800] loss: 1.513
2025-02-25T02:54:23.839137+0300 | INFO | [79,  3900] loss: 1.509
2025-02-25T02:54:34.822579+0300 | INFO | [79,  4000] loss: 1.528
2025-02-25T02:54:45.680614+0300 | INFO | [79,  4100] loss: 1.510
2025-02-25T02:54:56.660568+0300 | INFO | [79,  4200] loss: 1.505
2025-02-25T02:55:07.326370+0300 | INFO | [79,  4300] loss: 1.511
2025-02-25T02:55:17.978661+0300 | INFO | [79,  4400] loss: 1.512
2025-02-25T02:55:28.588540+0300 | INFO | [79,  4500] loss: 1.512
2025-02-25T02:55:39.601763+0300 | INFO | [79,  4600] loss: 1.516
2025-02-25T02:55:50.665950+0300 | INFO | [79,  4700] loss: 1.520
2025-02-25T02:56:00.925973+0300 | INFO | [79,  4800] loss: 1.509
2025-02-25T02:56:11.814341+0300 | INFO | [79,  4900] loss: 1.518
2025-02-25T02:56:22.283069+0300 | DEBUG | Saving model to flat file storage. Save #79
2025-02-25T02:56:22.299130+0300 | INFO | Averaging client parameters
2025-02-25T02:56:22.304252+0300 | INFO | Updating parameters on client #0
2025-02-25T02:56:36.974690+0300 | DEBUG | Test set: Accuracy: 7833/10000 (78%)
2025-02-25T02:56:36.976690+0300 | DEBUG | Test set: Loss: 1.6770203113555908
2025-02-25T02:56:37.082795+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.81      1000
           1       0.90      0.93      0.91      1000
           2       0.73      0.71      0.72      1000
           3       0.61      0.61      0.61      1200
           4       0.77      0.81      0.79      1000
           5       0.51      0.55      0.53       800
           6       0.84      0.84      0.84      1000
           7       0.90      0.79      0.84      1000
           8       0.87      0.91      0.89      1000
           9       0.93      0.84      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T02:56:37.086808+0300 | DEBUG | Confusion Matrix:
[[832  11  52  25  12   8   7   7  37   9]
 [ 11 928   1   4   0   1   5   1  22  27]
 [ 56   4 712  50  59  55  46   8   4   6]
 [ 24   5  61 735  55 230  50  17  14   9]
 [ 13   2  40  59 808  22  27  23   5   1]
 [ 10   2  39 233  32 440  10  24  10   0]
 [  9   1  38  45  28  26 845   3   4   1]
 [ 20   3  16  43  51  65   9 788   3   2]
 [ 40  11   9   8   1   8   4   2 905  12]
 [ 29  65   5  11   2   5   3   7  33 840]]
2025-02-25T02:56:37.089821+0300 | DEBUG | Class precision: [0.79693487 0.89922481 0.73175745 0.6059357  0.77099237 0.51162791
 0.83996024 0.89545455 0.87270974 0.9261301 ]
2025-02-25T02:56:37.091808+0300 | DEBUG | Class recall: [0.832  0.928  0.712  0.6125 0.808  0.55   0.845  0.788  0.905  0.84  ]
2025-02-25T02:56:37.147341+0300 | INFO | Training epoch #80 on client #0
2025-02-25T02:56:37.149346+0300 | DEBUG | Saving model to flat file storage. Save #80
2025-02-25T02:56:37.297302+0300 | INFO | [80,     0] loss: 0.015
2025-02-25T02:56:49.294178+0300 | INFO | [80,   100] loss: 1.523
2025-02-25T02:57:00.120485+0300 | INFO | [80,   200] loss: 1.507
2025-02-25T02:57:10.563883+0300 | INFO | [80,   300] loss: 1.506
2025-02-25T02:57:21.625015+0300 | INFO | [80,   400] loss: 1.513
2025-02-25T02:57:33.155890+0300 | INFO | [80,   500] loss: 1.527
2025-02-25T02:57:43.740700+0300 | INFO | [80,   600] loss: 1.506
2025-02-25T02:57:54.583958+0300 | INFO | [80,   700] loss: 1.522
2025-02-25T02:58:05.244752+0300 | INFO | [80,   800] loss: 1.513
2025-02-25T02:58:16.724603+0300 | INFO | [80,   900] loss: 1.496
2025-02-25T02:58:27.666113+0300 | INFO | [80,  1000] loss: 1.521
2025-02-25T02:58:42.888873+0300 | INFO | [80,  1100] loss: 1.509
2025-02-25T02:58:53.563382+0300 | INFO | [80,  1200] loss: 1.517
2025-02-25T02:59:04.172443+0300 | INFO | [80,  1300] loss: 1.509
2025-02-25T02:59:14.939512+0300 | INFO | [80,  1400] loss: 1.523
2025-02-25T02:59:26.079127+0300 | INFO | [80,  1500] loss: 1.525
2025-02-25T02:59:36.960991+0300 | INFO | [80,  1600] loss: 1.507
2025-02-25T02:59:47.758712+0300 | INFO | [80,  1700] loss: 1.503
2025-02-25T02:59:58.782473+0300 | INFO | [80,  1800] loss: 1.521
2025-02-25T03:00:09.446586+0300 | INFO | [80,  1900] loss: 1.519
2025-02-25T03:00:20.329011+0300 | INFO | [80,  2000] loss: 1.518
2025-02-25T03:00:31.364842+0300 | INFO | [80,  2100] loss: 1.507
2025-02-25T03:00:42.370939+0300 | INFO | [80,  2200] loss: 1.510
2025-02-25T03:00:52.964702+0300 | INFO | [80,  2300] loss: 1.510
2025-02-25T03:01:03.719439+0300 | INFO | [80,  2400] loss: 1.499
2025-02-25T03:01:17.368563+0300 | INFO | [80,  2500] loss: 1.526
2025-02-25T03:01:28.446599+0300 | INFO | [80,  2600] loss: 1.509
2025-02-25T03:01:39.717533+0300 | INFO | [80,  2700] loss: 1.503
2025-02-25T03:01:52.155623+0300 | INFO | [80,  2800] loss: 1.515
2025-02-25T03:02:02.968534+0300 | INFO | [80,  2900] loss: 1.514
2025-02-25T03:02:13.610963+0300 | INFO | [80,  3000] loss: 1.505
2025-02-25T03:02:24.496793+0300 | INFO | [80,  3100] loss: 1.512
2025-02-25T03:02:35.399728+0300 | INFO | [80,  3200] loss: 1.509
2025-02-25T03:02:46.109071+0300 | INFO | [80,  3300] loss: 1.517
2025-02-25T03:02:56.799074+0300 | INFO | [80,  3400] loss: 1.505
2025-02-25T03:03:07.308692+0300 | INFO | [80,  3500] loss: 1.516
2025-02-25T03:03:18.030609+0300 | INFO | [80,  3600] loss: 1.513
2025-02-25T03:03:28.802883+0300 | INFO | [80,  3700] loss: 1.509
2025-02-25T03:03:39.702052+0300 | INFO | [80,  3800] loss: 1.507
2025-02-25T03:03:50.810726+0300 | INFO | [80,  3900] loss: 1.496
2025-02-25T03:04:01.697233+0300 | INFO | [80,  4000] loss: 1.517
2025-02-25T03:04:12.347275+0300 | INFO | [80,  4100] loss: 1.510
2025-02-25T03:04:23.079670+0300 | INFO | [80,  4200] loss: 1.510
2025-02-25T03:04:34.051276+0300 | INFO | [80,  4300] loss: 1.513
2025-02-25T03:04:44.879511+0300 | INFO | [80,  4400] loss: 1.509
2025-02-25T03:04:55.729657+0300 | INFO | [80,  4500] loss: 1.517
2025-02-25T03:05:06.686838+0300 | INFO | [80,  4600] loss: 1.516
2025-02-25T03:05:17.662940+0300 | INFO | [80,  4700] loss: 1.511
2025-02-25T03:05:29.286567+0300 | INFO | [80,  4800] loss: 1.514
2025-02-25T03:05:40.220445+0300 | INFO | [80,  4900] loss: 1.514
2025-02-25T03:05:51.304751+0300 | DEBUG | Saving model to flat file storage. Save #80
2025-02-25T03:05:51.327542+0300 | INFO | Averaging client parameters
2025-02-25T03:05:51.333548+0300 | INFO | Updating parameters on client #0
2025-02-25T03:06:05.827689+0300 | DEBUG | Test set: Accuracy: 7864/10000 (79%)
2025-02-25T03:06:05.829694+0300 | DEBUG | Test set: Loss: 1.674294114112854
2025-02-25T03:06:05.930642+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.76      0.67      0.71      1000
           3       0.66      0.57      0.61      1200
           4       0.77      0.82      0.79      1000
           5       0.51      0.61      0.56       800
           6       0.80      0.86      0.83      1000
           7       0.87      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T03:06:05.932637+0300 | DEBUG | Confusion Matrix:
[[839  14  43  14  14   6   5   9  34  22]
 [  6 931   1   4   1   0   4   2  15  36]
 [ 60   4 672  40  68  65  67  16   4   4]
 [ 28   9  53 684  54 260  65  23  13  11]
 [ 12   1  31  40 823  27  37  23   5   1]
 [ 10   2  33 187  22 486  16  33   8   3]
 [ 12   2  26  35  27  23 864   1   8   2]
 [ 19   1   6  26  55  69   6 812   1   5]
 [ 49  18  10   6   3   6   4   2 886  16]
 [ 18  59   5   6   4   5   6   8  22 867]]
2025-02-25T03:06:05.934637+0300 | DEBUG | Class precision: [0.79677113 0.89433237 0.76363636 0.65642994 0.76844071 0.51319958
 0.80446927 0.87405813 0.88955823 0.89658738]
2025-02-25T03:06:05.936636+0300 | DEBUG | Class recall: [0.839  0.931  0.672  0.57   0.823  0.6075 0.864  0.812  0.886  0.867 ]
2025-02-25T03:06:05.993615+0300 | INFO | Training epoch #81 on client #0
2025-02-25T03:06:05.994610+0300 | DEBUG | Saving model to flat file storage. Save #81
2025-02-25T03:06:06.130141+0300 | INFO | [81,     0] loss: 0.015
2025-02-25T03:06:16.356537+0300 | INFO | [81,   100] loss: 1.516
2025-02-25T03:06:29.818122+0300 | INFO | [81,   200] loss: 1.511
2025-02-25T03:06:41.818172+0300 | INFO | [81,   300] loss: 1.517
2025-02-25T03:06:53.387015+0300 | INFO | [81,   400] loss: 1.510
2025-02-25T03:07:03.907494+0300 | INFO | [81,   500] loss: 1.516
2025-02-25T03:07:14.371303+0300 | INFO | [81,   600] loss: 1.512
2025-02-25T03:07:29.351457+0300 | INFO | [81,   700] loss: 1.499
2025-02-25T03:07:40.020076+0300 | INFO | [81,   800] loss: 1.517
2025-02-25T03:07:50.770804+0300 | INFO | [81,   900] loss: 1.508
2025-02-25T03:08:01.427031+0300 | INFO | [81,  1000] loss: 1.509
2025-02-25T03:08:12.963775+0300 | INFO | [81,  1100] loss: 1.521
2025-02-25T03:08:23.623226+0300 | INFO | [81,  1200] loss: 1.508
2025-02-25T03:08:34.363507+0300 | INFO | [81,  1300] loss: 1.510
2025-02-25T03:08:45.296576+0300 | INFO | [81,  1400] loss: 1.538
2025-02-25T03:08:56.218582+0300 | INFO | [81,  1500] loss: 1.514
2025-02-25T03:09:06.942370+0300 | INFO | [81,  1600] loss: 1.513
2025-02-25T03:09:18.134873+0300 | INFO | [81,  1700] loss: 1.519
2025-02-25T03:09:29.151345+0300 | INFO | [81,  1800] loss: 1.512
2025-02-25T03:09:40.039014+0300 | INFO | [81,  1900] loss: 1.511
2025-02-25T03:09:50.870552+0300 | INFO | [81,  2000] loss: 1.510
2025-02-25T03:10:04.166203+0300 | INFO | [81,  2100] loss: 1.505
2025-02-25T03:10:14.614865+0300 | INFO | [81,  2200] loss: 1.503
2025-02-25T03:10:25.354822+0300 | INFO | [81,  2300] loss: 1.517
2025-02-25T03:10:36.463407+0300 | INFO | [81,  2400] loss: 1.499
2025-02-25T03:10:47.305923+0300 | INFO | [81,  2500] loss: 1.511
2025-02-25T03:10:58.030653+0300 | INFO | [81,  2600] loss: 1.530
2025-02-25T03:11:08.544257+0300 | INFO | [81,  2700] loss: 1.508
2025-02-25T03:11:19.463649+0300 | INFO | [81,  2800] loss: 1.510
2025-02-25T03:11:30.262227+0300 | INFO | [81,  2900] loss: 1.503
2025-02-25T03:11:41.355714+0300 | INFO | [81,  3000] loss: 1.524
2025-02-25T03:11:52.058530+0300 | INFO | [81,  3100] loss: 1.501
2025-02-25T03:12:02.774917+0300 | INFO | [81,  3200] loss: 1.511
2025-02-25T03:12:13.274183+0300 | INFO | [81,  3300] loss: 1.504
2025-02-25T03:12:26.166067+0300 | INFO | [81,  3400] loss: 1.511
2025-02-25T03:12:37.602466+0300 | INFO | [81,  3500] loss: 1.505
2025-02-25T03:12:48.428288+0300 | INFO | [81,  3600] loss: 1.519
2025-02-25T03:12:59.366004+0300 | INFO | [81,  3700] loss: 1.515
2025-02-25T03:13:11.066480+0300 | INFO | [81,  3800] loss: 1.518
2025-02-25T03:13:21.945696+0300 | INFO | [81,  3900] loss: 1.511
2025-02-25T03:13:32.998194+0300 | INFO | [81,  4000] loss: 1.508
2025-02-25T03:13:43.759833+0300 | INFO | [81,  4100] loss: 1.512
2025-02-25T03:13:54.642146+0300 | INFO | [81,  4200] loss: 1.505
2025-02-25T03:14:05.373466+0300 | INFO | [81,  4300] loss: 1.515
2025-02-25T03:14:15.868123+0300 | INFO | [81,  4400] loss: 1.508
2025-02-25T03:14:26.715632+0300 | INFO | [81,  4500] loss: 1.514
2025-02-25T03:14:40.288356+0300 | INFO | [81,  4600] loss: 1.516
2025-02-25T03:14:51.348148+0300 | INFO | [81,  4700] loss: 1.520
2025-02-25T03:15:02.113882+0300 | INFO | [81,  4800] loss: 1.502
2025-02-25T03:15:12.631695+0300 | INFO | [81,  4900] loss: 1.518
2025-02-25T03:15:23.561606+0300 | DEBUG | Saving model to flat file storage. Save #81
2025-02-25T03:15:23.588252+0300 | INFO | Averaging client parameters
2025-02-25T03:15:23.599070+0300 | INFO | Updating parameters on client #0
2025-02-25T03:15:38.948712+0300 | DEBUG | Test set: Accuracy: 7802/10000 (78%)
2025-02-25T03:15:38.950711+0300 | DEBUG | Test set: Loss: 1.679211139678955
2025-02-25T03:15:39.056969+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.83      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.60      0.63      0.61      1200
           4       0.79      0.78      0.79      1000
           5       0.49      0.55      0.52       800
           6       0.86      0.83      0.84      1000
           7       0.89      0.78      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T03:15:39.060980+0300 | DEBUG | Confusion Matrix:
[[828   7  47  21  15   7   2   7  43  23]
 [ 11 906   2   2   1   0   5   1  20  52]
 [ 59   2 700  55  59  64  39  11   5   6]
 [ 27   6  46 761  41 241  37  18   9  14]
 [ 17   2  31  70 784  32  33  24   6   1]
 [ 10   2  39 242  24 437   9  30   5   2]
 [ 12   1  39  59  21  30 829   1   7   1]
 [ 23   1  14  50  46  73   5 781   1   6]
 [ 47  10   8   6   3   7   5   2 893  19]
 [ 23  44   6   9   2   4   4   6  19 883]]
2025-02-25T03:15:39.062983+0300 | DEBUG | Class precision: [0.7833491  0.9235474  0.75107296 0.59686275 0.78714859 0.48826816
 0.85640496 0.88649262 0.8859127  0.87686197]
2025-02-25T03:15:39.065983+0300 | DEBUG | Class recall: [0.828      0.906      0.7        0.63416667 0.784      0.54625
 0.829      0.781      0.893      0.883     ]
2025-02-25T03:15:39.117128+0300 | INFO | Training epoch #82 on client #0
2025-02-25T03:15:39.119132+0300 | DEBUG | Saving model to flat file storage. Save #82
2025-02-25T03:15:39.254949+0300 | INFO | [82,     0] loss: 0.015
2025-02-25T03:15:50.003842+0300 | INFO | [82,   100] loss: 1.506
2025-02-25T03:16:03.558078+0300 | INFO | [82,   200] loss: 1.502
2025-02-25T03:16:15.314934+0300 | INFO | [82,   300] loss: 1.510
2025-02-25T03:16:26.670262+0300 | INFO | [82,   400] loss: 1.514
2025-02-25T03:16:37.839261+0300 | INFO | [82,   500] loss: 1.521
2025-02-25T03:16:49.988095+0300 | INFO | [82,   600] loss: 1.521
2025-02-25T03:17:00.654494+0300 | INFO | [82,   700] loss: 1.507
2025-02-25T03:17:11.292575+0300 | INFO | [82,   800] loss: 1.507
2025-02-25T03:17:21.727446+0300 | INFO | [82,   900] loss: 1.503
2025-02-25T03:17:32.662956+0300 | INFO | [82,  1000] loss: 1.514
2025-02-25T03:17:43.433082+0300 | INFO | [82,  1100] loss: 1.516
2025-02-25T03:17:57.043929+0300 | INFO | [82,  1200] loss: 1.513
2025-02-25T03:18:08.149294+0300 | INFO | [82,  1300] loss: 1.504
2025-02-25T03:18:18.704859+0300 | INFO | [82,  1400] loss: 1.509
2025-02-25T03:18:29.553140+0300 | INFO | [82,  1500] loss: 1.526
2025-02-25T03:18:40.385399+0300 | INFO | [82,  1600] loss: 1.515
2025-02-25T03:18:51.180631+0300 | INFO | [82,  1700] loss: 1.507
2025-02-25T03:19:01.970872+0300 | INFO | [82,  1800] loss: 1.511
2025-02-25T03:19:12.773896+0300 | INFO | [82,  1900] loss: 1.515
2025-02-25T03:19:24.274947+0300 | INFO | [82,  2000] loss: 1.506
2025-02-25T03:19:34.887996+0300 | INFO | [82,  2100] loss: 1.507
2025-02-25T03:19:45.926854+0300 | INFO | [82,  2200] loss: 1.513
2025-02-25T03:19:56.864670+0300 | INFO | [82,  2300] loss: 1.512
2025-02-25T03:20:07.678915+0300 | INFO | [82,  2400] loss: 1.493
2025-02-25T03:20:18.706793+0300 | INFO | [82,  2500] loss: 1.501
2025-02-25T03:20:29.467477+0300 | INFO | [82,  2600] loss: 1.500
2025-02-25T03:20:40.147369+0300 | INFO | [82,  2700] loss: 1.516
2025-02-25T03:20:50.919351+0300 | INFO | [82,  2800] loss: 1.520
2025-02-25T03:21:01.608995+0300 | INFO | [82,  2900] loss: 1.502
2025-02-25T03:21:12.132730+0300 | INFO | [82,  3000] loss: 1.521
2025-02-25T03:21:22.904281+0300 | INFO | [82,  3100] loss: 1.510
2025-02-25T03:21:34.059060+0300 | INFO | [82,  3200] loss: 1.519
2025-02-25T03:21:44.661341+0300 | INFO | [82,  3300] loss: 1.510
2025-02-25T03:21:55.472016+0300 | INFO | [82,  3400] loss: 1.511
2025-02-25T03:22:06.604603+0300 | INFO | [82,  3500] loss: 1.513
2025-02-25T03:22:17.493859+0300 | INFO | [82,  3600] loss: 1.506
2025-02-25T03:22:28.909454+0300 | INFO | [82,  3700] loss: 1.519
2025-02-25T03:22:39.848032+0300 | INFO | [82,  3800] loss: 1.511
2025-02-25T03:22:50.802504+0300 | INFO | [82,  3900] loss: 1.508
2025-02-25T03:23:01.594050+0300 | INFO | [82,  4000] loss: 1.512
2025-02-25T03:23:12.735769+0300 | INFO | [82,  4100] loss: 1.512
2025-02-25T03:23:23.765457+0300 | INFO | [82,  4200] loss: 1.512
2025-02-25T03:23:34.480297+0300 | INFO | [82,  4300] loss: 1.514
2025-02-25T03:23:45.164138+0300 | INFO | [82,  4400] loss: 1.507
2025-02-25T03:23:58.333509+0300 | INFO | [82,  4500] loss: 1.515
2025-02-25T03:24:13.880975+0300 | INFO | [82,  4600] loss: 1.512
2025-02-25T03:24:24.696055+0300 | INFO | [82,  4700] loss: 1.511
2025-02-25T03:24:35.462039+0300 | INFO | [82,  4800] loss: 1.514
2025-02-25T03:24:47.588010+0300 | INFO | [82,  4900] loss: 1.504
2025-02-25T03:25:01.151903+0300 | DEBUG | Saving model to flat file storage. Save #82
2025-02-25T03:25:01.173905+0300 | INFO | Averaging client parameters
2025-02-25T03:25:01.182410+0300 | INFO | Updating parameters on client #0
2025-02-25T03:25:16.244156+0300 | DEBUG | Test set: Accuracy: 7821/10000 (78%)
2025-02-25T03:25:16.245151+0300 | DEBUG | Test set: Loss: 1.6778806447982788
2025-02-25T03:25:16.332160+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.83      0.81      1000
           1       0.91      0.92      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.65      0.56      0.60      1200
           4       0.76      0.83      0.79      1000
           5       0.51      0.58      0.54       800
           6       0.85      0.84      0.85      1000
           7       0.87      0.78      0.82      1000
           8       0.85      0.91      0.88      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T03:25:16.333674+0300 | DEBUG | Confusion Matrix:
[[832   7  48   8   9   5   5   7  57  22]
 [ 10 922   1   2   1   0   2   2  24  36]
 [ 61   2 699  41  67  56  43  17   7   7]
 [ 39  11  60 675  57 266  44  22  15  11]
 [ 18   1  36  43 828  22  27  20   4   1]
 [ 13   3  36 191  29 467  13  38   7   3]
 [ 17   2  32  33  31  27 841   3  14   0]
 [ 21   2  13  38  62  67   6 781   6   4]
 [ 32  13   8   8   2   4   3   3 907  20]
 [ 23  55   5   7   5   6   3   6  21 869]]
2025-02-25T03:25:16.335690+0300 | DEBUG | Class precision: [0.7804878  0.90569745 0.74520256 0.64531549 0.75893676 0.5076087
 0.852077   0.86874305 0.85404896 0.89311408]
2025-02-25T03:25:16.336687+0300 | DEBUG | Class recall: [0.832   0.922   0.699   0.5625  0.828   0.58375 0.841   0.781   0.907
 0.869  ]
2025-02-25T03:25:16.399688+0300 | INFO | Training epoch #83 on client #0
2025-02-25T03:25:16.400687+0300 | DEBUG | Saving model to flat file storage. Save #83
2025-02-25T03:25:16.601846+0300 | INFO | [83,     0] loss: 0.015
2025-02-25T03:25:27.000974+0300 | INFO | [83,   100] loss: 1.503
2025-02-25T03:25:40.414682+0300 | INFO | [83,   200] loss: 1.504
2025-02-25T03:25:51.661240+0300 | INFO | [83,   300] loss: 1.499
2025-02-25T03:26:02.188943+0300 | INFO | [83,   400] loss: 1.516
2025-02-25T03:26:12.802471+0300 | INFO | [83,   500] loss: 1.519
2025-02-25T03:26:23.746912+0300 | INFO | [83,   600] loss: 1.509
2025-02-25T03:26:34.704618+0300 | INFO | [83,   700] loss: 1.507
2025-02-25T03:26:45.325326+0300 | INFO | [83,   800] loss: 1.516
2025-02-25T03:26:56.201493+0300 | INFO | [83,   900] loss: 1.511
2025-02-25T03:27:06.585350+0300 | INFO | [83,  1000] loss: 1.519
2025-02-25T03:27:17.376778+0300 | INFO | [83,  1100] loss: 1.512
2025-02-25T03:27:27.797871+0300 | INFO | [83,  1200] loss: 1.506
2025-02-25T03:27:38.755425+0300 | INFO | [83,  1300] loss: 1.507
2025-02-25T03:27:49.620870+0300 | INFO | [83,  1400] loss: 1.507
2025-02-25T03:28:00.450865+0300 | INFO | [83,  1500] loss: 1.505
2025-02-25T03:28:10.959596+0300 | INFO | [83,  1600] loss: 1.513
2025-02-25T03:28:21.798976+0300 | INFO | [83,  1700] loss: 1.515
2025-02-25T03:28:32.547056+0300 | INFO | [83,  1800] loss: 1.498
2025-02-25T03:28:43.462139+0300 | INFO | [83,  1900] loss: 1.523
2025-02-25T03:28:54.870363+0300 | INFO | [83,  2000] loss: 1.503
2025-02-25T03:29:05.645272+0300 | INFO | [83,  2100] loss: 1.515
2025-02-25T03:29:16.651637+0300 | INFO | [83,  2200] loss: 1.502
2025-02-25T03:29:27.417856+0300 | INFO | [83,  2300] loss: 1.497
2025-02-25T03:29:38.191167+0300 | INFO | [83,  2400] loss: 1.516
2025-02-25T03:29:49.194449+0300 | INFO | [83,  2500] loss: 1.510
2025-02-25T03:29:59.907507+0300 | INFO | [83,  2600] loss: 1.510
2025-02-25T03:30:11.607012+0300 | INFO | [83,  2700] loss: 1.500
2025-02-25T03:30:22.513657+0300 | INFO | [83,  2800] loss: 1.510
2025-02-25T03:30:33.481504+0300 | INFO | [83,  2900] loss: 1.504
2025-02-25T03:30:43.976065+0300 | INFO | [83,  3000] loss: 1.516
2025-02-25T03:30:54.937217+0300 | INFO | [83,  3100] loss: 1.518
2025-02-25T03:31:05.425379+0300 | INFO | [83,  3200] loss: 1.511
2025-02-25T03:31:16.151937+0300 | INFO | [83,  3300] loss: 1.505
2025-02-25T03:31:27.778505+0300 | INFO | [83,  3400] loss: 1.516
2025-02-25T03:31:38.516021+0300 | INFO | [83,  3500] loss: 1.515
2025-02-25T03:31:50.156198+0300 | INFO | [83,  3600] loss: 1.518
2025-02-25T03:32:01.099402+0300 | INFO | [83,  3700] loss: 1.509
2025-02-25T03:32:11.906132+0300 | INFO | [83,  3800] loss: 1.505
2025-02-25T03:32:22.854516+0300 | INFO | [83,  3900] loss: 1.515
2025-02-25T03:32:36.690616+0300 | INFO | [83,  4000] loss: 1.518
2025-02-25T03:32:47.646190+0300 | INFO | [83,  4100] loss: 1.519
2025-02-25T03:32:58.592382+0300 | INFO | [83,  4200] loss: 1.506
2025-02-25T03:33:09.078249+0300 | INFO | [83,  4300] loss: 1.516
2025-02-25T03:33:20.022319+0300 | INFO | [83,  4400] loss: 1.506
2025-02-25T03:33:34.193219+0300 | INFO | [83,  4500] loss: 1.509
2025-02-25T03:33:45.396450+0300 | INFO | [83,  4600] loss: 1.526
2025-02-25T03:33:56.268486+0300 | INFO | [83,  4700] loss: 1.507
2025-02-25T03:34:07.923001+0300 | INFO | [83,  4800] loss: 1.512
2025-02-25T03:34:20.968693+0300 | INFO | [83,  4900] loss: 1.511
2025-02-25T03:34:31.739120+0300 | DEBUG | Saving model to flat file storage. Save #83
2025-02-25T03:34:31.768756+0300 | INFO | Averaging client parameters
2025-02-25T03:34:31.782814+0300 | INFO | Updating parameters on client #0
2025-02-25T03:34:46.721376+0300 | DEBUG | Test set: Accuracy: 7808/10000 (78%)
2025-02-25T03:34:46.723696+0300 | DEBUG | Test set: Loss: 1.6793265342712402
2025-02-25T03:34:46.830448+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.86      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.77      0.66      0.71      1000
           3       0.62      0.60      0.61      1200
           4       0.76      0.81      0.79      1000
           5       0.50      0.59      0.54       800
           6       0.87      0.81      0.84      1000
           7       0.86      0.79      0.82      1000
           8       0.87      0.91      0.89      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T03:34:46.833447+0300 | DEBUG | Confusion Matrix:
[[858  12  36  18  13   8   1   6  33  15]
 [ 14 906   1   2   0   3   6   4  25  39]
 [ 73   2 663  47  73  70  41  19   7   5]
 [ 26   5  42 725  47 266  37  25  14  13]
 [ 19   1  33  53 807  30  17  30   7   3]
 [ 13   1  33 204  24 473   8  34  10   0]
 [ 19   1  32  60  36  25 814   3   9   1]
 [ 22   2  10  40  52  69   6 789   4   6]
 [ 46  11   3   9   2   3   4   2 906  14]
 [ 30  45   5   9   2   6   2   6  28 867]]
2025-02-25T03:34:46.836451+0300 | DEBUG | Class precision: [0.76607143 0.9188641  0.77272727 0.62125107 0.76420455 0.49632739
 0.86965812 0.85947712 0.86864813 0.90031153]
2025-02-25T03:34:46.838456+0300 | DEBUG | Class recall: [0.858      0.906      0.663      0.60416667 0.807      0.59125
 0.814      0.789      0.906      0.867     ]
2025-02-25T03:34:46.900136+0300 | INFO | Training epoch #84 on client #0
2025-02-25T03:34:46.903130+0300 | DEBUG | Saving model to flat file storage. Save #84
2025-02-25T03:34:47.060959+0300 | INFO | [84,     0] loss: 0.015
2025-02-25T03:34:58.092746+0300 | INFO | [84,   100] loss: 1.509
2025-02-25T03:35:09.519943+0300 | INFO | [84,   200] loss: 1.503
2025-02-25T03:35:20.069617+0300 | INFO | [84,   300] loss: 1.508
2025-02-25T03:35:30.932565+0300 | INFO | [84,   400] loss: 1.509
2025-02-25T03:35:41.884037+0300 | INFO | [84,   500] loss: 1.501
2025-02-25T03:35:52.326994+0300 | INFO | [84,   600] loss: 1.501
2025-02-25T03:36:03.067877+0300 | INFO | [84,   700] loss: 1.505
2025-02-25T03:36:14.033423+0300 | INFO | [84,   800] loss: 1.507
2025-02-25T03:36:26.201806+0300 | INFO | [84,   900] loss: 1.509
2025-02-25T03:36:37.021971+0300 | INFO | [84,  1000] loss: 1.505
2025-02-25T03:36:48.039717+0300 | INFO | [84,  1100] loss: 1.514
2025-02-25T03:36:59.073997+0300 | INFO | [84,  1200] loss: 1.515
2025-02-25T03:37:10.625805+0300 | INFO | [84,  1300] loss: 1.511
2025-02-25T03:37:21.915853+0300 | INFO | [84,  1400] loss: 1.506
2025-02-25T03:37:32.694760+0300 | INFO | [84,  1500] loss: 1.519
2025-02-25T03:37:43.259373+0300 | INFO | [84,  1600] loss: 1.504
2025-02-25T03:37:53.878995+0300 | INFO | [84,  1700] loss: 1.514
2025-02-25T03:38:05.275571+0300 | INFO | [84,  1800] loss: 1.506
2025-02-25T03:38:17.600722+0300 | INFO | [84,  1900] loss: 1.510
2025-02-25T03:38:28.731455+0300 | INFO | [84,  2000] loss: 1.504
2025-02-25T03:38:39.576282+0300 | INFO | [84,  2100] loss: 1.505
2025-02-25T03:38:50.565127+0300 | INFO | [84,  2200] loss: 1.509
2025-02-25T03:39:02.007971+0300 | INFO | [84,  2300] loss: 1.509
2025-02-25T03:39:13.735670+0300 | INFO | [84,  2400] loss: 1.503
2025-02-25T03:39:26.689459+0300 | INFO | [84,  2500] loss: 1.512
2025-02-25T03:39:38.364381+0300 | INFO | [84,  2600] loss: 1.496
2025-02-25T03:39:49.190074+0300 | INFO | [84,  2700] loss: 1.518
2025-02-25T03:39:59.946678+0300 | INFO | [84,  2800] loss: 1.507
2025-02-25T03:40:10.192588+0300 | INFO | [84,  2900] loss: 1.504
2025-02-25T03:40:20.640365+0300 | INFO | [84,  3000] loss: 1.513
2025-02-25T03:40:30.671685+0300 | INFO | [84,  3100] loss: 1.497
2025-02-25T03:40:42.966137+0300 | INFO | [84,  3200] loss: 1.518
2025-02-25T03:40:53.002299+0300 | INFO | [84,  3300] loss: 1.501
2025-02-25T03:41:02.878073+0300 | INFO | [84,  3400] loss: 1.524
2025-02-25T03:41:13.750040+0300 | INFO | [84,  3500] loss: 1.514
2025-02-25T03:41:24.758057+0300 | INFO | [84,  3600] loss: 1.522
2025-02-25T03:41:34.879513+0300 | INFO | [84,  3700] loss: 1.500
2025-02-25T03:41:46.785757+0300 | INFO | [84,  3800] loss: 1.509
2025-02-25T03:41:57.758603+0300 | INFO | [84,  3900] loss: 1.510
2025-02-25T03:42:09.225859+0300 | INFO | [84,  4000] loss: 1.510
2025-02-25T03:42:23.230973+0300 | INFO | [84,  4100] loss: 1.510
2025-02-25T03:42:34.084663+0300 | INFO | [84,  4200] loss: 1.518
2025-02-25T03:42:44.549743+0300 | INFO | [84,  4300] loss: 1.505
2025-02-25T03:42:55.617304+0300 | INFO | [84,  4400] loss: 1.505
2025-02-25T03:43:06.710359+0300 | INFO | [84,  4500] loss: 1.514
2025-02-25T03:43:17.395440+0300 | INFO | [84,  4600] loss: 1.513
2025-02-25T03:43:28.471303+0300 | INFO | [84,  4700] loss: 1.518
2025-02-25T03:43:39.380698+0300 | INFO | [84,  4800] loss: 1.519
2025-02-25T03:43:50.919512+0300 | INFO | [84,  4900] loss: 1.502
2025-02-25T03:44:01.937250+0300 | DEBUG | Saving model to flat file storage. Save #84
2025-02-25T03:44:01.964781+0300 | INFO | Averaging client parameters
2025-02-25T03:44:01.975775+0300 | INFO | Updating parameters on client #0
2025-02-25T03:44:17.114043+0300 | DEBUG | Test set: Accuracy: 7886/10000 (79%)
2025-02-25T03:44:17.115043+0300 | DEBUG | Test set: Loss: 1.6720331907272339
2025-02-25T03:44:17.194135+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.66      0.58      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.60      0.56       800
           6       0.81      0.86      0.84      1000
           7       0.86      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T03:44:17.197135+0300 | DEBUG | Confusion Matrix:
[[829  12  42  12  23   6   4  10  39  23]
 [  9 907   2   2   1   1   7   3  14  54]
 [ 58   4 708  32  54  60  59  15   4   6]
 [ 21   9  56 699  48 255  58  25  13  16]
 [ 12   2  37  44 809  24  33  31   5   3]
 [ 11   3  36 183  30 478  17  32   8   2]
 [ 11   1  33  39  22  23 858   5   6   2]
 [ 13   2  14  34  51  63   6 809   2   6]
 [ 40  12   7   7   4   8   7   2 887  26]
 [ 17  39   4   7   4   4   4   5  14 902]]
2025-02-25T03:44:17.199142+0300 | DEBUG | Class precision: [0.81194907 0.91523713 0.75399361 0.66005666 0.77342256 0.51843818
 0.81481481 0.86339381 0.89415323 0.86730769]
2025-02-25T03:44:17.203140+0300 | DEBUG | Class recall: [0.829  0.907  0.708  0.5825 0.809  0.5975 0.858  0.809  0.887  0.902 ]
2025-02-25T03:44:17.259590+0300 | INFO | Training epoch #85 on client #0
2025-02-25T03:44:17.261797+0300 | DEBUG | Saving model to flat file storage. Save #85
2025-02-25T03:44:17.418441+0300 | INFO | [85,     0] loss: 0.016
2025-02-25T03:44:31.624352+0300 | INFO | [85,   100] loss: 1.503
2025-02-25T03:44:42.999284+0300 | INFO | [85,   200] loss: 1.511
2025-02-25T03:44:53.964760+0300 | INFO | [85,   300] loss: 1.497
2025-02-25T03:45:04.625067+0300 | INFO | [85,   400] loss: 1.513
2025-02-25T03:45:15.274891+0300 | INFO | [85,   500] loss: 1.487
2025-02-25T03:45:26.044681+0300 | INFO | [85,   600] loss: 1.512
2025-02-25T03:45:36.821061+0300 | INFO | [85,   700] loss: 1.512
2025-02-25T03:45:47.992505+0300 | INFO | [85,   800] loss: 1.511
2025-02-25T03:46:00.188435+0300 | INFO | [85,   900] loss: 1.506
2025-02-25T03:46:10.496211+0300 | INFO | [85,  1000] loss: 1.502
2025-02-25T03:46:21.354147+0300 | INFO | [85,  1100] loss: 1.506
2025-02-25T03:46:31.897755+0300 | INFO | [85,  1200] loss: 1.508
2025-02-25T03:46:42.603233+0300 | INFO | [85,  1300] loss: 1.519
2025-02-25T03:46:53.770159+0300 | INFO | [85,  1400] loss: 1.512
2025-02-25T03:47:05.492939+0300 | INFO | [85,  1500] loss: 1.500
2025-02-25T03:47:16.268168+0300 | INFO | [85,  1600] loss: 1.498
2025-02-25T03:47:27.845354+0300 | INFO | [85,  1700] loss: 1.507
2025-02-25T03:47:39.131734+0300 | INFO | [85,  1800] loss: 1.514
2025-02-25T03:47:49.970843+0300 | INFO | [85,  1900] loss: 1.502
2025-02-25T03:48:00.757614+0300 | INFO | [85,  2000] loss: 1.504
2025-02-25T03:48:11.675659+0300 | INFO | [85,  2100] loss: 1.526
2025-02-25T03:48:21.986762+0300 | INFO | [85,  2200] loss: 1.517
2025-02-25T03:48:32.902850+0300 | INFO | [85,  2300] loss: 1.520
2025-02-25T03:48:43.743919+0300 | INFO | [85,  2400] loss: 1.519
2025-02-25T03:48:54.474752+0300 | INFO | [85,  2500] loss: 1.509
2025-02-25T03:49:05.242980+0300 | INFO | [85,  2600] loss: 1.511
2025-02-25T03:49:16.142725+0300 | INFO | [85,  2700] loss: 1.519
2025-02-25T03:49:27.104805+0300 | INFO | [85,  2800] loss: 1.520
2025-02-25T03:49:38.044762+0300 | INFO | [85,  2900] loss: 1.500
2025-02-25T03:49:49.174369+0300 | INFO | [85,  3000] loss: 1.504
2025-02-25T03:50:02.839122+0300 | INFO | [85,  3100] loss: 1.504
2025-02-25T03:50:15.562445+0300 | INFO | [85,  3200] loss: 1.510
2025-02-25T03:50:27.892804+0300 | INFO | [85,  3300] loss: 1.503
2025-02-25T03:50:39.939503+0300 | INFO | [85,  3400] loss: 1.513
2025-02-25T03:50:50.405518+0300 | INFO | [85,  3500] loss: 1.510
2025-02-25T03:51:01.288247+0300 | INFO | [85,  3600] loss: 1.509
2025-02-25T03:51:12.673944+0300 | INFO | [85,  3700] loss: 1.505
2025-02-25T03:51:26.591495+0300 | INFO | [85,  3800] loss: 1.498
2025-02-25T03:51:37.281779+0300 | INFO | [85,  3900] loss: 1.513
2025-02-25T03:51:48.078675+0300 | INFO | [85,  4000] loss: 1.513
2025-02-25T03:51:59.306581+0300 | INFO | [85,  4100] loss: 1.508
2025-02-25T03:52:09.618549+0300 | INFO | [85,  4200] loss: 1.517
2025-02-25T03:52:20.325631+0300 | INFO | [85,  4300] loss: 1.503
2025-02-25T03:52:31.442227+0300 | INFO | [85,  4400] loss: 1.515
2025-02-25T03:52:42.425854+0300 | INFO | [85,  4500] loss: 1.514
2025-02-25T03:52:53.214931+0300 | INFO | [85,  4600] loss: 1.505
2025-02-25T03:53:07.397107+0300 | INFO | [85,  4700] loss: 1.499
2025-02-25T03:53:17.992358+0300 | INFO | [85,  4800] loss: 1.516
2025-02-25T03:53:29.154957+0300 | INFO | [85,  4900] loss: 1.510
2025-02-25T03:53:39.732834+0300 | DEBUG | Saving model to flat file storage. Save #85
2025-02-25T03:53:39.753795+0300 | INFO | Averaging client parameters
2025-02-25T03:53:39.764842+0300 | INFO | Updating parameters on client #0
2025-02-25T03:53:55.249710+0300 | DEBUG | Test set: Accuracy: 7811/10000 (78%)
2025-02-25T03:53:55.250709+0300 | DEBUG | Test set: Loss: 1.6794252395629883
2025-02-25T03:53:55.346140+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.90      0.91      0.91      1000
           2       0.80      0.63      0.71      1000
           3       0.64      0.59      0.61      1200
           4       0.75      0.81      0.77      1000
           5       0.54      0.53      0.54       800
           6       0.78      0.88      0.83      1000
           7       0.82      0.84      0.83      1000
           8       0.88      0.89      0.88      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T03:53:55.348665+0300 | DEBUG | Confusion Matrix:
[[831  15  29  18  17   5   5  11  49  20]
 [  7 911   1   1   1   1  10   3  18  47]
 [ 65   6 633  51  81  50  77  23   9   5]
 [ 21   9  40 704  67 223  73  35  13  15]
 [ 16   2  26  39 807  15  47  43   4   1]
 [ 11   4  34 213  31 422  19  56   9   1]
 [ 14   0  18  37  20  17 883   7   4   0]
 [ 19   2   9  29  53  38   7 839   1   3]
 [ 43  14   3   7   4   3   7   4 894  21]
 [ 22  45   2   9   2   3   3   7  20 887]]
2025-02-25T03:53:55.350666+0300 | DEBUG | Class precision: [0.79218303 0.90376984 0.79622642 0.63537906 0.74515235 0.54311454
 0.78072502 0.81614786 0.87561214 0.887     ]
2025-02-25T03:53:55.352071+0300 | DEBUG | Class recall: [0.831      0.911      0.633      0.58666667 0.807      0.5275
 0.883      0.839      0.894      0.887     ]
2025-02-25T03:53:55.405282+0300 | INFO | Training epoch #86 on client #0
2025-02-25T03:53:55.408282+0300 | DEBUG | Saving model to flat file storage. Save #86
2025-02-25T03:53:55.549030+0300 | INFO | [86,     0] loss: 0.015
2025-02-25T03:54:06.191627+0300 | INFO | [86,   100] loss: 1.517
2025-02-25T03:54:19.453018+0300 | INFO | [86,   200] loss: 1.501
2025-02-25T03:54:30.759164+0300 | INFO | [86,   300] loss: 1.509
2025-02-25T03:54:41.752855+0300 | INFO | [86,   400] loss: 1.509
2025-02-25T03:54:55.574233+0300 | INFO | [86,   500] loss: 1.509
2025-02-25T03:55:07.005918+0300 | INFO | [86,   600] loss: 1.507
2025-02-25T03:55:19.346744+0300 | INFO | [86,   700] loss: 1.505
2025-02-25T03:55:30.149113+0300 | INFO | [86,   800] loss: 1.503
2025-02-25T03:55:41.284384+0300 | INFO | [86,   900] loss: 1.512
2025-02-25T03:55:52.149657+0300 | INFO | [86,  1000] loss: 1.512
2025-02-25T03:56:02.821155+0300 | INFO | [86,  1100] loss: 1.507
2025-02-25T03:56:13.382636+0300 | INFO | [86,  1200] loss: 1.510
2025-02-25T03:56:24.231635+0300 | INFO | [86,  1300] loss: 1.505
2025-02-25T03:56:36.046168+0300 | INFO | [86,  1400] loss: 1.500
2025-02-25T03:56:47.432885+0300 | INFO | [86,  1500] loss: 1.503
2025-02-25T03:56:58.267514+0300 | INFO | [86,  1600] loss: 1.508
2025-02-25T03:57:09.328775+0300 | INFO | [86,  1700] loss: 1.505
2025-02-25T03:57:20.301921+0300 | INFO | [86,  1800] loss: 1.504
2025-02-25T03:57:31.235155+0300 | INFO | [86,  1900] loss: 1.506
2025-02-25T03:57:43.765711+0300 | INFO | [86,  2000] loss: 1.507
2025-02-25T03:57:55.592483+0300 | INFO | [86,  2100] loss: 1.515
2025-02-25T03:58:07.887698+0300 | INFO | [86,  2200] loss: 1.508
2025-02-25T03:58:18.748235+0300 | INFO | [86,  2300] loss: 1.509
2025-02-25T03:58:29.630604+0300 | INFO | [86,  2400] loss: 1.509
2025-02-25T03:58:40.701549+0300 | INFO | [86,  2500] loss: 1.509
2025-02-25T03:58:53.304398+0300 | INFO | [86,  2600] loss: 1.499
2025-02-25T03:59:03.696555+0300 | INFO | [86,  2700] loss: 1.506
2025-02-25T03:59:14.166412+0300 | INFO | [86,  2800] loss: 1.512
2025-02-25T03:59:25.372555+0300 | INFO | [86,  2900] loss: 1.509
2025-02-25T03:59:36.065173+0300 | INFO | [86,  3000] loss: 1.505
2025-02-25T03:59:46.757320+0300 | INFO | [86,  3100] loss: 1.507
2025-02-25T03:59:57.707244+0300 | INFO | [86,  3200] loss: 1.499
2025-02-25T04:00:11.859825+0300 | INFO | [86,  3300] loss: 1.508
2025-02-25T04:00:22.573182+0300 | INFO | [86,  3400] loss: 1.517
2025-02-25T04:00:33.770558+0300 | INFO | [86,  3500] loss: 1.512
2025-02-25T04:00:48.480843+0300 | INFO | [86,  3600] loss: 1.506
2025-02-25T04:00:59.586121+0300 | INFO | [86,  3700] loss: 1.515
2025-02-25T04:01:10.066221+0300 | INFO | [86,  3800] loss: 1.515
2025-02-25T04:01:20.977634+0300 | INFO | [86,  3900] loss: 1.512
2025-02-25T04:01:31.946569+0300 | INFO | [86,  4000] loss: 1.499
2025-02-25T04:01:42.670164+0300 | INFO | [86,  4100] loss: 1.513
2025-02-25T04:01:53.483789+0300 | INFO | [86,  4200] loss: 1.505
2025-02-25T04:02:04.517296+0300 | INFO | [86,  4300] loss: 1.513
2025-02-25T04:02:14.969696+0300 | INFO | [86,  4400] loss: 1.516
2025-02-25T04:02:25.903005+0300 | INFO | [86,  4500] loss: 1.517
2025-02-25T04:02:38.186976+0300 | INFO | [86,  4600] loss: 1.500
2025-02-25T04:02:51.649799+0300 | INFO | [86,  4700] loss: 1.512
2025-02-25T04:03:02.561970+0300 | INFO | [86,  4800] loss: 1.501
2025-02-25T04:03:13.019635+0300 | INFO | [86,  4900] loss: 1.515
2025-02-25T04:03:24.580952+0300 | DEBUG | Saving model to flat file storage. Save #86
2025-02-25T04:03:24.609441+0300 | INFO | Averaging client parameters
2025-02-25T04:03:24.617009+0300 | INFO | Updating parameters on client #0
2025-02-25T04:03:39.509367+0300 | DEBUG | Test set: Accuracy: 7814/10000 (78%)
2025-02-25T04:03:39.512358+0300 | DEBUG | Test set: Loss: 1.6784734725952148
2025-02-25T04:03:39.611377+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.92      0.92      0.92      1000
           2       0.77      0.68      0.72      1000
           3       0.65      0.56      0.60      1200
           4       0.77      0.80      0.78      1000
           5       0.48      0.61      0.54       800
           6       0.83      0.86      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.87      0.89      0.88      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T04:03:39.613373+0300 | DEBUG | Confusion Matrix:
[[843  15  31  13  20  11   4   6  40  17]
 [ 10 915   1   3   1   0   6   1  19  44]
 [ 60   3 679  48  65  63  59   9   7   7]
 [ 30   9  55 666  47 297  44  21  14  17]
 [ 17   0  34  49 795  34  40  24   4   3]
 [ 11   2  38 174  26 487  13  35  12   2]
 [ 12   0  21  39  24  28 861   5   9   1]
 [ 24   2  11  24  54  76   7 795   1   6]
 [ 53  10   8   6   4   4   4   2 890  19]
 [ 21  44   3   5   1   7   3   5  28 883]]
2025-02-25T04:03:39.616377+0300 | DEBUG | Class precision: [0.77983349 0.915      0.7707151  0.64849075 0.76663452 0.4836147
 0.82708934 0.88039867 0.86914062 0.88388388]
2025-02-25T04:03:39.616377+0300 | DEBUG | Class recall: [0.843   0.915   0.679   0.555   0.795   0.60875 0.861   0.795   0.89
 0.883  ]
2025-02-25T04:03:39.668736+0300 | INFO | Training epoch #87 on client #0
2025-02-25T04:03:39.671738+0300 | DEBUG | Saving model to flat file storage. Save #87
2025-02-25T04:03:39.817818+0300 | INFO | [87,     0] loss: 0.015
2025-02-25T04:03:50.502760+0300 | INFO | [87,   100] loss: 1.506
2025-02-25T04:04:03.605112+0300 | INFO | [87,   200] loss: 1.505
2025-02-25T04:04:14.735787+0300 | INFO | [87,   300] loss: 1.509
2025-02-25T04:04:25.790477+0300 | INFO | [87,   400] loss: 1.500
2025-02-25T04:04:36.391539+0300 | INFO | [87,   500] loss: 1.502
2025-02-25T04:04:47.524761+0300 | INFO | [87,   600] loss: 1.513
2025-02-25T04:05:00.467307+0300 | INFO | [87,   700] loss: 1.507
2025-02-25T04:05:10.874538+0300 | INFO | [87,   800] loss: 1.512
2025-02-25T04:05:21.587546+0300 | INFO | [87,   900] loss: 1.502
2025-02-25T04:05:32.782332+0300 | INFO | [87,  1000] loss: 1.509
2025-02-25T04:05:43.610702+0300 | INFO | [87,  1100] loss: 1.514
2025-02-25T04:05:54.690118+0300 | INFO | [87,  1200] loss: 1.510
2025-02-25T04:06:05.243128+0300 | INFO | [87,  1300] loss: 1.516
2025-02-25T04:06:15.853586+0300 | INFO | [87,  1400] loss: 1.505
2025-02-25T04:06:26.805519+0300 | INFO | [87,  1500] loss: 1.499
2025-02-25T04:06:38.221571+0300 | INFO | [87,  1600] loss: 1.500
2025-02-25T04:06:49.039637+0300 | INFO | [87,  1700] loss: 1.496
2025-02-25T04:06:59.976378+0300 | INFO | [87,  1800] loss: 1.506
2025-02-25T04:07:10.857022+0300 | INFO | [87,  1900] loss: 1.508
2025-02-25T04:07:21.364594+0300 | INFO | [87,  2000] loss: 1.504
2025-02-25T04:07:32.184192+0300 | INFO | [87,  2100] loss: 1.501
2025-02-25T04:07:43.352213+0300 | INFO | [87,  2200] loss: 1.508
2025-02-25T04:07:54.243087+0300 | INFO | [87,  2300] loss: 1.515
2025-02-25T04:08:05.846770+0300 | INFO | [87,  2400] loss: 1.502
2025-02-25T04:08:16.885232+0300 | INFO | [87,  2500] loss: 1.511
2025-02-25T04:08:27.833514+0300 | INFO | [87,  2600] loss: 1.512
2025-02-25T04:08:38.570681+0300 | INFO | [87,  2700] loss: 1.506
2025-02-25T04:08:49.225676+0300 | INFO | [87,  2800] loss: 1.502
2025-02-25T04:09:02.974295+0300 | INFO | [87,  2900] loss: 1.516
2025-02-25T04:09:13.490199+0300 | INFO | [87,  3000] loss: 1.503
2025-02-25T04:09:24.383895+0300 | INFO | [87,  3100] loss: 1.514
2025-02-25T04:09:40.390664+0300 | INFO | [87,  3200] loss: 1.513
2025-02-25T04:09:50.926164+0300 | INFO | [87,  3300] loss: 1.514
2025-02-25T04:10:01.711026+0300 | INFO | [87,  3400] loss: 1.499
2025-02-25T04:10:12.246295+0300 | INFO | [87,  3500] loss: 1.514
2025-02-25T04:10:24.083874+0300 | INFO | [87,  3600] loss: 1.499
2025-02-25T04:10:34.818997+0300 | INFO | [87,  3700] loss: 1.519
2025-02-25T04:10:45.838923+0300 | INFO | [87,  3800] loss: 1.502
2025-02-25T04:10:58.689420+0300 | INFO | [87,  3900] loss: 1.508
2025-02-25T04:11:09.419304+0300 | INFO | [87,  4000] loss: 1.514
2025-02-25T04:11:19.822318+0300 | INFO | [87,  4100] loss: 1.530
2025-02-25T04:11:30.679883+0300 | INFO | [87,  4200] loss: 1.499
2025-02-25T04:11:41.577919+0300 | INFO | [87,  4300] loss: 1.511
2025-02-25T04:11:52.552007+0300 | INFO | [87,  4400] loss: 1.513
2025-02-25T04:12:05.731525+0300 | INFO | [87,  4500] loss: 1.516
2025-02-25T04:12:16.510980+0300 | INFO | [87,  4600] loss: 1.508
2025-02-25T04:12:27.446352+0300 | INFO | [87,  4700] loss: 1.517
2025-02-25T04:12:38.603210+0300 | INFO | [87,  4800] loss: 1.513
2025-02-25T04:12:49.950329+0300 | INFO | [87,  4900] loss: 1.493
2025-02-25T04:13:01.873822+0300 | DEBUG | Saving model to flat file storage. Save #87
2025-02-25T04:13:01.896825+0300 | INFO | Averaging client parameters
2025-02-25T04:13:01.905824+0300 | INFO | Updating parameters on client #0
2025-02-25T04:13:17.678240+0300 | DEBUG | Test set: Accuracy: 7820/10000 (78%)
2025-02-25T04:13:17.680243+0300 | DEBUG | Test set: Loss: 1.67792809009552
2025-02-25T04:13:17.788810+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.63      0.60      0.61      1200
           4       0.78      0.80      0.79      1000
           5       0.53      0.57      0.55       800
           6       0.78      0.88      0.83      1000
           7       0.89      0.78      0.83      1000
           8       0.87      0.89      0.88      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T04:13:17.790805+0300 | DEBUG | Confusion Matrix:
[[827  10  48  22  19  10   7   6  35  16]
 [ 13 907   2   6   1   1   8   3  26  33]
 [ 55   2 698  45  52  52  71  12   8   5]
 [ 24   5  52 719  47 232  72  19  15  15]
 [ 12   0  40  50 796  20  53  22   3   4]
 [  8   0  46 204  29 458  20  26   7   2]
 [ 13   0  26  41  13  13 884   2   8   0]
 [ 24   0  17  41  61  62  10 778   4   3]
 [ 45  13  10  11   5   5   7   2 885  17]
 [ 23  54   4   9   2   4   6   7  23 868]]
2025-02-25T04:13:17.793811+0300 | DEBUG | Class precision: [0.79214559 0.91523713 0.74019088 0.62630662 0.77658537 0.5344224
 0.77680141 0.88711517 0.87278107 0.90134995]
2025-02-25T04:13:17.794814+0300 | DEBUG | Class recall: [0.827      0.907      0.698      0.59916667 0.796      0.5725
 0.884      0.778      0.885      0.868     ]
2025-02-25T04:13:17.841878+0300 | INFO | Training epoch #88 on client #0
2025-02-25T04:13:17.842880+0300 | DEBUG | Saving model to flat file storage. Save #88
2025-02-25T04:13:17.991525+0300 | INFO | [88,     0] loss: 0.015
2025-02-25T04:13:28.852612+0300 | INFO | [88,   100] loss: 1.507
2025-02-25T04:13:40.042870+0300 | INFO | [88,   200] loss: 1.494
2025-02-25T04:13:51.065235+0300 | INFO | [88,   300] loss: 1.501
2025-02-25T04:14:02.078585+0300 | INFO | [88,   400] loss: 1.519
2025-02-25T04:14:12.445298+0300 | INFO | [88,   500] loss: 1.502
2025-02-25T04:14:23.694530+0300 | INFO | [88,   600] loss: 1.514
2025-02-25T04:14:34.733962+0300 | INFO | [88,   700] loss: 1.503
2025-02-25T04:14:47.839478+0300 | INFO | [88,   800] loss: 1.500
2025-02-25T04:14:58.655951+0300 | INFO | [88,   900] loss: 1.492
2025-02-25T04:15:09.208343+0300 | INFO | [88,  1000] loss: 1.500
2025-02-25T04:15:20.009456+0300 | INFO | [88,  1100] loss: 1.513
2025-02-25T04:15:30.712238+0300 | INFO | [88,  1200] loss: 1.505
2025-02-25T04:15:41.845101+0300 | INFO | [88,  1300] loss: 1.514
2025-02-25T04:15:52.691878+0300 | INFO | [88,  1400] loss: 1.511
2025-02-25T04:16:04.065955+0300 | INFO | [88,  1500] loss: 1.512
2025-02-25T04:16:14.522818+0300 | INFO | [88,  1600] loss: 1.501
2025-02-25T04:16:27.879231+0300 | INFO | [88,  1700] loss: 1.513
2025-02-25T04:16:38.970342+0300 | INFO | [88,  1800] loss: 1.513
2025-02-25T04:16:51.783470+0300 | INFO | [88,  1900] loss: 1.509
2025-02-25T04:17:03.707268+0300 | INFO | [88,  2000] loss: 1.503
2025-02-25T04:17:14.506441+0300 | INFO | [88,  2100] loss: 1.490
2025-02-25T04:17:25.663653+0300 | INFO | [88,  2200] loss: 1.507
2025-02-25T04:17:36.662692+0300 | INFO | [88,  2300] loss: 1.507
2025-02-25T04:17:47.081235+0300 | INFO | [88,  2400] loss: 1.516
2025-02-25T04:17:57.986310+0300 | INFO | [88,  2500] loss: 1.512
2025-02-25T04:18:09.016744+0300 | INFO | [88,  2600] loss: 1.502
2025-02-25T04:18:20.095002+0300 | INFO | [88,  2700] loss: 1.513
2025-02-25T04:18:31.009605+0300 | INFO | [88,  2800] loss: 1.513
2025-02-25T04:18:43.485360+0300 | INFO | [88,  2900] loss: 1.502
2025-02-25T04:18:56.782828+0300 | INFO | [88,  3000] loss: 1.497
2025-02-25T04:19:08.350386+0300 | INFO | [88,  3100] loss: 1.507
2025-02-25T04:19:18.949159+0300 | INFO | [88,  3200] loss: 1.506
2025-02-25T04:19:29.775462+0300 | INFO | [88,  3300] loss: 1.510
2025-02-25T04:19:40.917311+0300 | INFO | [88,  3400] loss: 1.506
2025-02-25T04:19:51.647157+0300 | INFO | [88,  3500] loss: 1.515
2025-02-25T04:20:02.424128+0300 | INFO | [88,  3600] loss: 1.513
2025-02-25T04:20:13.908662+0300 | INFO | [88,  3700] loss: 1.514
2025-02-25T04:20:24.850086+0300 | INFO | [88,  3800] loss: 1.506
2025-02-25T04:20:35.578503+0300 | INFO | [88,  3900] loss: 1.508
2025-02-25T04:20:46.241318+0300 | INFO | [88,  4000] loss: 1.505
2025-02-25T04:20:57.215913+0300 | INFO | [88,  4100] loss: 1.518
2025-02-25T04:21:07.583021+0300 | INFO | [88,  4200] loss: 1.511
2025-02-25T04:21:18.456782+0300 | INFO | [88,  4300] loss: 1.519
2025-02-25T04:21:29.359014+0300 | INFO | [88,  4400] loss: 1.503
2025-02-25T04:21:40.021222+0300 | INFO | [88,  4500] loss: 1.513
2025-02-25T04:21:51.034334+0300 | INFO | [88,  4600] loss: 1.503
2025-02-25T04:22:02.044891+0300 | INFO | [88,  4700] loss: 1.510
2025-02-25T04:22:15.896116+0300 | INFO | [88,  4800] loss: 1.498
2025-02-25T04:22:26.845752+0300 | INFO | [88,  4900] loss: 1.509
2025-02-25T04:22:37.897509+0300 | DEBUG | Saving model to flat file storage. Save #88
2025-02-25T04:22:37.929026+0300 | INFO | Averaging client parameters
2025-02-25T04:22:37.946213+0300 | INFO | Updating parameters on client #0
2025-02-25T04:22:53.044892+0300 | DEBUG | Test set: Accuracy: 7803/10000 (78%)
2025-02-25T04:22:53.045922+0300 | DEBUG | Test set: Loss: 1.679289698600769
2025-02-25T04:22:53.150426+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.92      0.91      0.92      1000
           2       0.75      0.69      0.72      1000
           3       0.61      0.61      0.61      1200
           4       0.79      0.78      0.79      1000
           5       0.45      0.59      0.51       800
           6       0.88      0.81      0.85      1000
           7       0.86      0.81      0.83      1000
           8       0.90      0.89      0.89      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T04:22:53.153425+0300 | DEBUG | Confusion Matrix:
[[826  11  49  24  15  14   1   9  33  18]
 [  9 911   2   4   1   5   4   4  20  40]
 [ 49   2 695  58  66  74  38  12   2   4]
 [ 24   5  47 735  37 286  29  16  11  10]
 [ 13   1  36  62 778  49  21  37   2   1]
 [  8   0  37 218  20 472   5  34   6   0]
 [ 10   1  37  55  27  43 813   8   6   0]
 [ 19   0  14  32  31  89   2 808   1   4]
 [ 45  12   7  13   3   6   3   4 886  21]
 [ 22  45   5  10   2   7   3  10  17 879]]
2025-02-25T04:22:53.155425+0300 | DEBUG | Class precision: [0.80585366 0.92206478 0.74811625 0.60693642 0.79387755 0.45167464
 0.88465724 0.85774947 0.9004065  0.89969294]
2025-02-25T04:22:53.156427+0300 | DEBUG | Class recall: [0.826  0.911  0.695  0.6125 0.778  0.59   0.813  0.808  0.886  0.879 ]
2025-02-25T04:22:53.220213+0300 | INFO | Training epoch #89 on client #0
2025-02-25T04:22:53.221220+0300 | DEBUG | Saving model to flat file storage. Save #89
2025-02-25T04:22:53.361101+0300 | INFO | [89,     0] loss: 0.016
2025-02-25T04:23:04.062179+0300 | INFO | [89,   100] loss: 1.510
2025-02-25T04:23:17.460218+0300 | INFO | [89,   200] loss: 1.510
2025-02-25T04:23:28.694791+0300 | INFO | [89,   300] loss: 1.508
2025-02-25T04:23:42.500976+0300 | INFO | [89,   400] loss: 1.498
2025-02-25T04:23:53.087667+0300 | INFO | [89,   500] loss: 1.505
2025-02-25T04:24:06.442334+0300 | INFO | [89,   600] loss: 1.503
2025-02-25T04:24:17.116097+0300 | INFO | [89,   700] loss: 1.498
2025-02-25T04:24:28.236468+0300 | INFO | [89,   800] loss: 1.495
2025-02-25T04:24:39.307381+0300 | INFO | [89,   900] loss: 1.504
2025-02-25T04:24:49.981663+0300 | INFO | [89,  1000] loss: 1.499
2025-02-25T04:25:03.686372+0300 | INFO | [89,  1100] loss: 1.506
2025-02-25T04:25:14.028627+0300 | INFO | [89,  1200] loss: 1.508
2025-02-25T04:25:24.928002+0300 | INFO | [89,  1300] loss: 1.508
2025-02-25T04:25:36.420142+0300 | INFO | [89,  1400] loss: 1.503
2025-02-25T04:25:47.216920+0300 | INFO | [89,  1500] loss: 1.517
2025-02-25T04:25:58.011930+0300 | INFO | [89,  1600] loss: 1.512
2025-02-25T04:26:08.287299+0300 | INFO | [89,  1700] loss: 1.505
2025-02-25T04:26:18.985391+0300 | INFO | [89,  1800] loss: 1.500
2025-02-25T04:26:29.720609+0300 | INFO | [89,  1900] loss: 1.501
2025-02-25T04:26:40.458441+0300 | INFO | [89,  2000] loss: 1.495
2025-02-25T04:26:51.417686+0300 | INFO | [89,  2100] loss: 1.512
2025-02-25T04:27:02.811227+0300 | INFO | [89,  2200] loss: 1.514
2025-02-25T04:27:13.217066+0300 | INFO | [89,  2300] loss: 1.508
2025-02-25T04:27:24.285225+0300 | INFO | [89,  2400] loss: 1.498
2025-02-25T04:27:35.142516+0300 | INFO | [89,  2500] loss: 1.502
2025-02-25T04:27:47.930010+0300 | INFO | [89,  2600] loss: 1.507
2025-02-25T04:28:02.527471+0300 | INFO | [89,  2700] loss: 1.509
2025-02-25T04:28:13.166362+0300 | INFO | [89,  2800] loss: 1.499
2025-02-25T04:28:24.326975+0300 | INFO | [89,  2900] loss: 1.511
2025-02-25T04:28:34.971614+0300 | INFO | [89,  3000] loss: 1.506
2025-02-25T04:28:48.341378+0300 | INFO | [89,  3100] loss: 1.510
2025-02-25T04:29:01.658001+0300 | INFO | [89,  3200] loss: 1.502
2025-02-25T04:29:12.286733+0300 | INFO | [89,  3300] loss: 1.506
2025-02-25T04:29:23.117891+0300 | INFO | [89,  3400] loss: 1.504
2025-02-25T04:29:34.089433+0300 | INFO | [89,  3500] loss: 1.506
2025-02-25T04:29:44.788071+0300 | INFO | [89,  3600] loss: 1.502
2025-02-25T04:29:55.641535+0300 | INFO | [89,  3700] loss: 1.511
2025-02-25T04:30:06.666861+0300 | INFO | [89,  3800] loss: 1.504
2025-02-25T04:30:17.639387+0300 | INFO | [89,  3900] loss: 1.504
2025-02-25T04:30:28.552537+0300 | INFO | [89,  4000] loss: 1.505
2025-02-25T04:30:39.412456+0300 | INFO | [89,  4100] loss: 1.503
2025-02-25T04:30:50.202794+0300 | INFO | [89,  4200] loss: 1.525
2025-02-25T04:31:01.074978+0300 | INFO | [89,  4300] loss: 1.505
2025-02-25T04:31:11.831299+0300 | INFO | [89,  4400] loss: 1.501
2025-02-25T04:31:25.216922+0300 | INFO | [89,  4500] loss: 1.516
2025-02-25T04:31:35.973824+0300 | INFO | [89,  4600] loss: 1.515
2025-02-25T04:31:47.315334+0300 | INFO | [89,  4700] loss: 1.513
2025-02-25T04:31:58.251594+0300 | INFO | [89,  4800] loss: 1.509
2025-02-25T04:32:08.253802+0300 | INFO | [89,  4900] loss: 1.503
2025-02-25T04:32:18.849213+0300 | DEBUG | Saving model to flat file storage. Save #89
2025-02-25T04:32:18.880232+0300 | INFO | Averaging client parameters
2025-02-25T04:32:18.887766+0300 | INFO | Updating parameters on client #0
2025-02-25T04:32:34.013750+0300 | DEBUG | Test set: Accuracy: 7844/10000 (78%)
2025-02-25T04:32:34.015752+0300 | DEBUG | Test set: Loss: 1.6753743886947632
2025-02-25T04:32:34.128717+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.81      1000
           1       0.89      0.94      0.91      1000
           2       0.77      0.67      0.72      1000
           3       0.64      0.59      0.61      1200
           4       0.80      0.79      0.80      1000
           5       0.51      0.55      0.53       800
           6       0.81      0.87      0.84      1000
           7       0.83      0.83      0.83      1000
           8       0.89      0.88      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T04:32:34.130717+0300 | DEBUG | Confusion Matrix:
[[831  15  48  15  10  11   3   7  34  26]
 [  7 937   0   2   1   0   4   1  12  36]
 [ 57   7 673  41  56  57  71  21   8   9]
 [ 28  10  48 709  41 247  57  30  14  16]
 [ 23   2  28  46 788  26  39  41   4   3]
 [  8   2  35 210  22 443  18  49  10   3]
 [  8   2  24  40  21  25 869   5   5   1]
 [ 18   3   9  32  40  53   8 830   2   5]
 [ 45  22   5   9   2   4   5   5 882  21]
 [ 20  57   3   6   1   3   3   9  16 882]]
2025-02-25T04:32:34.133717+0300 | DEBUG | Class precision: [0.79521531 0.88647114 0.77090493 0.63873874 0.80244399 0.50978136
 0.80687094 0.83166333 0.89361702 0.88023952]
2025-02-25T04:32:34.134713+0300 | DEBUG | Class recall: [0.831      0.937      0.673      0.59083333 0.788      0.55375
 0.869      0.83       0.882      0.882     ]
2025-02-25T04:32:34.186224+0300 | INFO | Training epoch #90 on client #0
2025-02-25T04:32:34.187223+0300 | DEBUG | Saving model to flat file storage. Save #90
2025-02-25T04:32:34.335317+0300 | INFO | [90,     0] loss: 0.015
2025-02-25T04:32:45.069148+0300 | INFO | [90,   100] loss: 1.509
2025-02-25T04:32:55.916234+0300 | INFO | [90,   200] loss: 1.506
2025-02-25T04:33:06.586571+0300 | INFO | [90,   300] loss: 1.491
2025-02-25T04:33:17.643544+0300 | INFO | [90,   400] loss: 1.511
2025-02-25T04:33:28.402015+0300 | INFO | [90,   500] loss: 1.503
2025-02-25T04:33:39.354686+0300 | INFO | [90,   600] loss: 1.504
2025-02-25T04:33:50.249563+0300 | INFO | [90,   700] loss: 1.500
2025-02-25T04:34:01.064059+0300 | INFO | [90,   800] loss: 1.516
2025-02-25T04:34:11.699327+0300 | INFO | [90,   900] loss: 1.517
2025-02-25T04:34:22.690186+0300 | INFO | [90,  1000] loss: 1.503
2025-02-25T04:34:33.567715+0300 | INFO | [90,  1100] loss: 1.499
2025-02-25T04:34:44.427461+0300 | INFO | [90,  1200] loss: 1.502
2025-02-25T04:34:56.152466+0300 | INFO | [90,  1300] loss: 1.497
2025-02-25T04:35:06.853148+0300 | INFO | [90,  1400] loss: 1.498
2025-02-25T04:35:18.008958+0300 | INFO | [90,  1500] loss: 1.512
2025-02-25T04:35:28.986585+0300 | INFO | [90,  1600] loss: 1.520
2025-02-25T04:35:39.878999+0300 | INFO | [90,  1700] loss: 1.507
2025-02-25T04:35:50.729631+0300 | INFO | [90,  1800] loss: 1.495
2025-02-25T04:36:01.501409+0300 | INFO | [90,  1900] loss: 1.509
2025-02-25T04:36:12.146533+0300 | INFO | [90,  2000] loss: 1.504
2025-02-25T04:36:22.928806+0300 | INFO | [90,  2100] loss: 1.506
2025-02-25T04:36:35.572398+0300 | INFO | [90,  2200] loss: 1.502
2025-02-25T04:36:48.433654+0300 | INFO | [90,  2300] loss: 1.509
2025-02-25T04:37:01.349455+0300 | INFO | [90,  2400] loss: 1.507
2025-02-25T04:37:12.274685+0300 | INFO | [90,  2500] loss: 1.509
2025-02-25T04:37:23.507753+0300 | INFO | [90,  2600] loss: 1.502
2025-02-25T04:37:35.493182+0300 | INFO | [90,  2700] loss: 1.509
2025-02-25T04:37:46.407645+0300 | INFO | [90,  2800] loss: 1.503
2025-02-25T04:37:57.077401+0300 | INFO | [90,  2900] loss: 1.504
2025-02-25T04:38:08.757533+0300 | INFO | [90,  3000] loss: 1.505
2025-02-25T04:38:19.665924+0300 | INFO | [90,  3100] loss: 1.518
2025-02-25T04:38:30.664162+0300 | INFO | [90,  3200] loss: 1.499
2025-02-25T04:38:41.378045+0300 | INFO | [90,  3300] loss: 1.510
2025-02-25T04:38:52.243470+0300 | INFO | [90,  3400] loss: 1.503
2025-02-25T04:39:03.110200+0300 | INFO | [90,  3500] loss: 1.500
2025-02-25T04:39:13.924257+0300 | INFO | [90,  3600] loss: 1.513
2025-02-25T04:39:24.970473+0300 | INFO | [90,  3700] loss: 1.520
2025-02-25T04:39:35.682085+0300 | INFO | [90,  3800] loss: 1.514
2025-02-25T04:39:46.481703+0300 | INFO | [90,  3900] loss: 1.504
2025-02-25T04:39:57.542198+0300 | INFO | [90,  4000] loss: 1.508
2025-02-25T04:40:08.135535+0300 | INFO | [90,  4100] loss: 1.507
2025-02-25T04:40:19.279775+0300 | INFO | [90,  4200] loss: 1.501
2025-02-25T04:40:31.015789+0300 | INFO | [90,  4300] loss: 1.512
2025-02-25T04:40:42.512785+0300 | INFO | [90,  4400] loss: 1.489
2025-02-25T04:40:54.175578+0300 | INFO | [90,  4500] loss: 1.517
2025-02-25T04:41:05.280119+0300 | INFO | [90,  4600] loss: 1.498
2025-02-25T04:41:17.797006+0300 | INFO | [90,  4700] loss: 1.512
2025-02-25T04:41:29.319088+0300 | INFO | [90,  4800] loss: 1.507
2025-02-25T04:41:40.824308+0300 | INFO | [90,  4900] loss: 1.498
2025-02-25T04:41:52.302824+0300 | DEBUG | Saving model to flat file storage. Save #90
2025-02-25T04:41:52.322818+0300 | INFO | Averaging client parameters
2025-02-25T04:41:52.330822+0300 | INFO | Updating parameters on client #0
2025-02-25T04:42:08.014236+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-25T04:42:08.015238+0300 | DEBUG | Test set: Loss: 1.6728286743164062
2025-02-25T04:42:08.133634+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.73      0.71      0.72      1000
           3       0.66      0.57      0.61      1200
           4       0.80      0.78      0.79      1000
           5       0.53      0.58      0.55       800
           6       0.81      0.88      0.84      1000
           7       0.86      0.82      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T04:42:08.138586+0300 | DEBUG | Confusion Matrix:
[[847  11  50  10  10  11   3   5  32  21]
 [  9 913   1   3   1   0   7   2  14  50]
 [ 48   3 713  38  55  50  60  17   6  10]
 [ 31  10  66 684  48 244  60  25  13  19]
 [ 20   0  38  46 784  27  45  34   4   2]
 [ 12   2  41 181  29 465  17  41   8   4]
 [ 12   1  32  34  13  22 877   3   5   1]
 [ 22   2  18  27  40  53   9 818   3   8]
 [ 45  20   8   5   2   3   4   3 881  29]
 [ 25  35   4   7   2   3   3   5  15 901]]
2025-02-25T04:42:08.139587+0300 | DEBUG | Class precision: [0.79084967 0.91574724 0.73429454 0.66086957 0.79674797 0.52961276
 0.80829493 0.85834208 0.8980632  0.86220096]
2025-02-25T04:42:08.140981+0300 | DEBUG | Class recall: [0.847   0.913   0.713   0.57    0.784   0.58125 0.877   0.818   0.881
 0.901  ]
2025-02-25T04:42:08.195106+0300 | INFO | Training epoch #91 on client #0
2025-02-25T04:42:08.197619+0300 | DEBUG | Saving model to flat file storage. Save #91
2025-02-25T04:42:08.329567+0300 | INFO | [91,     0] loss: 0.015
2025-02-25T04:42:22.645685+0300 | INFO | [91,   100] loss: 1.510
2025-02-25T04:42:34.027351+0300 | INFO | [91,   200] loss: 1.507
2025-02-25T04:42:45.405686+0300 | INFO | [91,   300] loss: 1.505
2025-02-25T04:42:56.927765+0300 | INFO | [91,   400] loss: 1.501
2025-02-25T04:43:08.674740+0300 | INFO | [91,   500] loss: 1.503
2025-02-25T04:43:19.579578+0300 | INFO | [91,   600] loss: 1.513
2025-02-25T04:43:30.459464+0300 | INFO | [91,   700] loss: 1.509
2025-02-25T04:43:41.567485+0300 | INFO | [91,   800] loss: 1.504
2025-02-25T04:43:52.329508+0300 | INFO | [91,   900] loss: 1.509
2025-02-25T04:44:04.616793+0300 | INFO | [91,  1000] loss: 1.511
2025-02-25T04:44:15.315011+0300 | INFO | [91,  1100] loss: 1.502
2025-02-25T04:44:29.812454+0300 | INFO | [91,  1200] loss: 1.518
2025-02-25T04:44:43.529406+0300 | INFO | [91,  1300] loss: 1.505
2025-02-25T04:44:56.947598+0300 | INFO | [91,  1400] loss: 1.500
2025-02-25T04:45:10.392341+0300 | INFO | [91,  1500] loss: 1.506
2025-02-25T04:45:21.220041+0300 | INFO | [91,  1600] loss: 1.507
2025-02-25T04:45:32.318410+0300 | INFO | [91,  1700] loss: 1.498
2025-02-25T04:45:43.004176+0300 | INFO | [91,  1800] loss: 1.511
2025-02-25T04:45:53.887582+0300 | INFO | [91,  1900] loss: 1.495
2025-02-25T04:46:08.922986+0300 | INFO | [91,  2000] loss: 1.503
2025-02-25T04:46:19.333036+0300 | INFO | [91,  2100] loss: 1.504
2025-02-25T04:46:29.832368+0300 | INFO | [91,  2200] loss: 1.512
2025-02-25T04:46:40.541250+0300 | INFO | [91,  2300] loss: 1.505
2025-02-25T04:46:51.782918+0300 | INFO | [91,  2400] loss: 1.500
2025-02-25T04:47:02.378321+0300 | INFO | [91,  2500] loss: 1.508
2025-02-25T04:47:12.824107+0300 | INFO | [91,  2600] loss: 1.508
2025-02-25T04:47:24.764264+0300 | INFO | [91,  2700] loss: 1.503
2025-02-25T04:47:35.656087+0300 | INFO | [91,  2800] loss: 1.497
2025-02-25T04:47:46.883444+0300 | INFO | [91,  2900] loss: 1.508
2025-02-25T04:47:57.913215+0300 | INFO | [91,  3000] loss: 1.505
2025-02-25T04:48:09.502548+0300 | INFO | [91,  3100] loss: 1.509
2025-02-25T04:48:20.207406+0300 | INFO | [91,  3200] loss: 1.497
2025-02-25T04:48:31.413253+0300 | INFO | [91,  3300] loss: 1.510
2025-02-25T04:48:42.139284+0300 | INFO | [91,  3400] loss: 1.511
2025-02-25T04:48:52.518497+0300 | INFO | [91,  3500] loss: 1.499
2025-02-25T04:49:03.559624+0300 | INFO | [91,  3600] loss: 1.505
2025-02-25T04:49:15.598162+0300 | INFO | [91,  3700] loss: 1.511
2025-02-25T04:49:26.500818+0300 | INFO | [91,  3800] loss: 1.510
2025-02-25T04:49:37.196397+0300 | INFO | [91,  3900] loss: 1.504
2025-02-25T04:49:48.161076+0300 | INFO | [91,  4000] loss: 1.514
2025-02-25T04:49:59.511557+0300 | INFO | [91,  4100] loss: 1.512
2025-02-25T04:50:09.999938+0300 | INFO | [91,  4200] loss: 1.499
2025-02-25T04:50:20.986838+0300 | INFO | [91,  4300] loss: 1.497
2025-02-25T04:50:31.889547+0300 | INFO | [91,  4400] loss: 1.509
2025-02-25T04:50:42.529000+0300 | INFO | [91,  4500] loss: 1.513
2025-02-25T04:50:54.097594+0300 | INFO | [91,  4600] loss: 1.505
2025-02-25T04:51:04.698971+0300 | INFO | [91,  4700] loss: 1.498
2025-02-25T04:51:15.083551+0300 | INFO | [91,  4800] loss: 1.498
2025-02-25T04:51:26.051253+0300 | INFO | [91,  4900] loss: 1.508
2025-02-25T04:51:36.743101+0300 | DEBUG | Saving model to flat file storage. Save #91
2025-02-25T04:51:36.771802+0300 | INFO | Averaging client parameters
2025-02-25T04:51:36.784799+0300 | INFO | Updating parameters on client #0
2025-02-25T04:51:51.889278+0300 | DEBUG | Test set: Accuracy: 7819/10000 (78%)
2025-02-25T04:51:51.891282+0300 | DEBUG | Test set: Loss: 1.6765906810760498
2025-02-25T04:51:52.001788+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.67      0.50      0.57      1200
           4       0.74      0.82      0.78      1000
           5       0.50      0.62      0.56       800
           6       0.81      0.87      0.84      1000
           7       0.84      0.82      0.83      1000
           8       0.89      0.88      0.88      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T04:51:52.003789+0300 | DEBUG | Confusion Matrix:
[[829  12  57  11  12  11   4  10  33  21]
 [  7 910   2   4   1   1   9   6  24  36]
 [ 49   3 711  30  81  44  55  16   6   5]
 [ 26   7  59 601  68 315  68  32  10  14]
 [ 14   2  33  27 824  27  34  34   4   1]
 [ 12   1  36 151  36 494  15  48   6   1]
 [ 10   2  25  32  23  27 874   4   3   0]
 [ 20   0  14  23  58  50  11 819   3   2]
 [ 53  14  12   7   3   5   4   3 879  20]
 [ 29  40   4   8   2   5   4   8  22 878]]
2025-02-25T04:51:52.005784+0300 | DEBUG | Class precision: [0.79027645 0.91826438 0.74606506 0.67225951 0.74368231 0.50459653
 0.81076067 0.83571429 0.88787879 0.89775051]
2025-02-25T04:51:52.007212+0300 | DEBUG | Class recall: [0.829      0.91       0.711      0.50083333 0.824      0.6175
 0.874      0.819      0.879      0.878     ]
2025-02-25T04:51:52.067225+0300 | INFO | Training epoch #92 on client #0
2025-02-25T04:51:52.068230+0300 | DEBUG | Saving model to flat file storage. Save #92
2025-02-25T04:51:52.214096+0300 | INFO | [92,     0] loss: 0.015
2025-02-25T04:52:03.275874+0300 | INFO | [92,   100] loss: 1.508
2025-02-25T04:52:16.527006+0300 | INFO | [92,   200] loss: 1.517
2025-02-25T04:52:28.092434+0300 | INFO | [92,   300] loss: 1.507
2025-02-25T04:52:40.902405+0300 | INFO | [92,   400] loss: 1.512
2025-02-25T04:52:51.890353+0300 | INFO | [92,   500] loss: 1.517
2025-02-25T04:53:04.380485+0300 | INFO | [92,   600] loss: 1.508
2025-02-25T04:53:15.333690+0300 | INFO | [92,   700] loss: 1.503
2025-02-25T04:53:26.322061+0300 | INFO | [92,   800] loss: 1.508
2025-02-25T04:53:37.744150+0300 | INFO | [92,   900] loss: 1.504
2025-02-25T04:53:48.580365+0300 | INFO | [92,  1000] loss: 1.500
2025-02-25T04:53:59.961369+0300 | INFO | [92,  1100] loss: 1.508
2025-02-25T04:54:10.233859+0300 | INFO | [92,  1200] loss: 1.512
2025-02-25T04:54:21.304139+0300 | INFO | [92,  1300] loss: 1.505
2025-02-25T04:54:32.757935+0300 | INFO | [92,  1400] loss: 1.506
2025-02-25T04:54:46.262229+0300 | INFO | [92,  1500] loss: 1.513
2025-02-25T04:54:57.189526+0300 | INFO | [92,  1600] loss: 1.510
2025-02-25T04:55:11.825003+0300 | INFO | [92,  1700] loss: 1.503
2025-02-25T04:55:22.440492+0300 | INFO | [92,  1800] loss: 1.497
2025-02-25T04:55:35.816992+0300 | INFO | [92,  1900] loss: 1.499
2025-02-25T04:55:46.783321+0300 | INFO | [92,  2000] loss: 1.506
2025-02-25T04:55:57.763270+0300 | INFO | [92,  2100] loss: 1.504
2025-02-25T04:56:07.995167+0300 | INFO | [92,  2200] loss: 1.517
2025-02-25T04:56:18.654615+0300 | INFO | [92,  2300] loss: 1.501
2025-02-25T04:56:31.341703+0300 | INFO | [92,  2400] loss: 1.492
2025-02-25T04:56:42.888332+0300 | INFO | [92,  2500] loss: 1.510
2025-02-25T04:56:54.910183+0300 | INFO | [92,  2600] loss: 1.511
2025-02-25T04:57:05.335532+0300 | INFO | [92,  2700] loss: 1.503
2025-02-25T04:57:16.794295+0300 | INFO | [92,  2800] loss: 1.506
2025-02-25T04:57:27.687915+0300 | INFO | [92,  2900] loss: 1.505
2025-02-25T04:57:38.625702+0300 | INFO | [92,  3000] loss: 1.501
2025-02-25T04:57:49.633739+0300 | INFO | [92,  3100] loss: 1.496
2025-02-25T04:58:00.558343+0300 | INFO | [92,  3200] loss: 1.501
2025-02-25T04:58:11.458228+0300 | INFO | [92,  3300] loss: 1.502
2025-02-25T04:58:24.227045+0300 | INFO | [92,  3400] loss: 1.502
2025-02-25T04:58:35.233982+0300 | INFO | [92,  3500] loss: 1.505
2025-02-25T04:58:46.280926+0300 | INFO | [92,  3600] loss: 1.505
2025-02-25T04:58:57.021059+0300 | INFO | [92,  3700] loss: 1.517
2025-02-25T04:59:07.875133+0300 | INFO | [92,  3800] loss: 1.515
2025-02-25T04:59:18.407038+0300 | INFO | [92,  3900] loss: 1.503
2025-02-25T04:59:29.236870+0300 | INFO | [92,  4000] loss: 1.505
2025-02-25T04:59:40.213301+0300 | INFO | [92,  4100] loss: 1.511
2025-02-25T04:59:50.950073+0300 | INFO | [92,  4200] loss: 1.504
2025-02-25T05:00:01.721249+0300 | INFO | [92,  4300] loss: 1.502
2025-02-25T05:00:12.542447+0300 | INFO | [92,  4400] loss: 1.498
2025-02-25T05:00:23.967679+0300 | INFO | [92,  4500] loss: 1.502
2025-02-25T05:00:34.989729+0300 | INFO | [92,  4600] loss: 1.502
2025-02-25T05:00:46.016753+0300 | INFO | [92,  4700] loss: 1.514
2025-02-25T05:00:56.657676+0300 | INFO | [92,  4800] loss: 1.514
2025-02-25T05:01:07.313258+0300 | INFO | [92,  4900] loss: 1.511
2025-02-25T05:01:18.155335+0300 | DEBUG | Saving model to flat file storage. Save #92
2025-02-25T05:01:18.180140+0300 | INFO | Averaging client parameters
2025-02-25T05:01:18.187136+0300 | INFO | Updating parameters on client #0
2025-02-25T05:01:33.425589+0300 | DEBUG | Test set: Accuracy: 7869/10000 (79%)
2025-02-25T05:01:33.427592+0300 | DEBUG | Test set: Loss: 1.6738088130950928
2025-02-25T05:01:33.525121+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.91      0.90      0.90      1000
           2       0.73      0.74      0.73      1000
           3       0.63      0.61      0.62      1200
           4       0.75      0.83      0.79      1000
           5       0.53      0.55      0.54       800
           6       0.86      0.84      0.85      1000
           7       0.90      0.77      0.83      1000
           8       0.88      0.89      0.89      1000
           9       0.86      0.91      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T05:01:33.528124+0300 | DEBUG | Confusion Matrix:
[[827  13  57   7  17  11   1   7  38  22]
 [ 11 898   1   4   2   0   6   0  21  57]
 [ 47   4 736  48  59  46  36   9   8   7]
 [ 20   8  66 734  60 215  46  19  12  20]
 [ 11   2  38  38 834  25  27  18   5   2]
 [ 11   2  43 226  32 437   9  28   8   4]
 [  8   4  35  53  29  23 836   4   5   3]
 [ 21   2  17  35  72  60  11 771   3   8]
 [ 41  17  12   8   4   4   3   2 890  19]
 [ 25  36   2   6   2   3   2   2  16 906]]
2025-02-25T05:01:33.528124+0300 | DEBUG | Class precision: [0.80919765 0.91075051 0.73088381 0.63330457 0.75067507 0.53033981
 0.85568066 0.89651163 0.88469185 0.86450382]
2025-02-25T05:01:33.530146+0300 | DEBUG | Class recall: [0.827      0.898      0.736      0.61166667 0.834      0.54625
 0.836      0.771      0.89       0.906     ]
2025-02-25T05:01:33.585609+0300 | INFO | Training epoch #93 on client #0
2025-02-25T05:01:33.587614+0300 | DEBUG | Saving model to flat file storage. Save #93
2025-02-25T05:01:33.723239+0300 | INFO | [93,     0] loss: 0.015
2025-02-25T05:01:44.224091+0300 | INFO | [93,   100] loss: 1.515
2025-02-25T05:01:55.106851+0300 | INFO | [93,   200] loss: 1.505
2025-02-25T05:02:05.943907+0300 | INFO | [93,   300] loss: 1.503
2025-02-25T05:02:16.565471+0300 | INFO | [93,   400] loss: 1.507
2025-02-25T05:02:27.518390+0300 | INFO | [93,   500] loss: 1.500
2025-02-25T05:02:38.463747+0300 | INFO | [93,   600] loss: 1.511
2025-02-25T05:02:49.141798+0300 | INFO | [93,   700] loss: 1.512
2025-02-25T05:02:59.915472+0300 | INFO | [93,   800] loss: 1.494
2025-02-25T05:03:13.808002+0300 | INFO | [93,   900] loss: 1.501
2025-02-25T05:03:24.839285+0300 | INFO | [93,  1000] loss: 1.505
2025-02-25T05:03:36.183322+0300 | INFO | [93,  1100] loss: 1.504
2025-02-25T05:03:47.096811+0300 | INFO | [93,  1200] loss: 1.496
2025-02-25T05:04:01.418786+0300 | INFO | [93,  1300] loss: 1.514
2025-02-25T05:04:13.314582+0300 | INFO | [93,  1400] loss: 1.499
2025-02-25T05:04:24.293431+0300 | INFO | [93,  1500] loss: 1.502
2025-02-25T05:04:35.324617+0300 | INFO | [93,  1600] loss: 1.515
2025-02-25T05:04:46.425828+0300 | INFO | [93,  1700] loss: 1.495
2025-02-25T05:04:57.179641+0300 | INFO | [93,  1800] loss: 1.499
2025-02-25T05:05:07.973625+0300 | INFO | [93,  1900] loss: 1.511
2025-02-25T05:05:19.020207+0300 | INFO | [93,  2000] loss: 1.508
2025-02-25T05:05:30.033308+0300 | INFO | [93,  2100] loss: 1.520
2025-02-25T05:05:40.796145+0300 | INFO | [93,  2200] loss: 1.504
2025-02-25T05:05:52.034571+0300 | INFO | [93,  2300] loss: 1.502
2025-02-25T05:06:02.791571+0300 | INFO | [93,  2400] loss: 1.509
2025-02-25T05:06:13.034634+0300 | INFO | [93,  2500] loss: 1.501
2025-02-25T05:06:25.129993+0300 | INFO | [93,  2600] loss: 1.497
2025-02-25T05:06:36.869405+0300 | INFO | [93,  2700] loss: 1.492
2025-02-25T05:06:47.515823+0300 | INFO | [93,  2800] loss: 1.511
2025-02-25T05:06:58.385951+0300 | INFO | [93,  2900] loss: 1.500
2025-02-25T05:07:09.344461+0300 | INFO | [93,  3000] loss: 1.504
2025-02-25T05:07:20.056580+0300 | INFO | [93,  3100] loss: 1.519
2025-02-25T05:07:31.112820+0300 | INFO | [93,  3200] loss: 1.514
2025-02-25T05:07:42.199340+0300 | INFO | [93,  3300] loss: 1.499
2025-02-25T05:07:56.088437+0300 | INFO | [93,  3400] loss: 1.503
2025-02-25T05:08:07.526167+0300 | INFO | [93,  3500] loss: 1.505
2025-02-25T05:08:18.236973+0300 | INFO | [93,  3600] loss: 1.505
2025-02-25T05:08:29.205570+0300 | INFO | [93,  3700] loss: 1.502
2025-02-25T05:08:40.039222+0300 | INFO | [93,  3800] loss: 1.498
2025-02-25T05:08:53.648678+0300 | INFO | [93,  3900] loss: 1.504
2025-02-25T05:09:04.373971+0300 | INFO | [93,  4000] loss: 1.502
2025-02-25T05:09:15.409076+0300 | INFO | [93,  4100] loss: 1.505
2025-02-25T05:09:25.939433+0300 | INFO | [93,  4200] loss: 1.504
2025-02-25T05:09:36.850852+0300 | INFO | [93,  4300] loss: 1.504
2025-02-25T05:09:48.477553+0300 | INFO | [93,  4400] loss: 1.504
2025-02-25T05:09:59.257804+0300 | INFO | [93,  4500] loss: 1.498
2025-02-25T05:10:12.734303+0300 | INFO | [93,  4600] loss: 1.511
2025-02-25T05:10:23.830590+0300 | INFO | [93,  4700] loss: 1.502
2025-02-25T05:10:34.799180+0300 | INFO | [93,  4800] loss: 1.500
2025-02-25T05:10:47.300418+0300 | INFO | [93,  4900] loss: 1.508
2025-02-25T05:10:58.390910+0300 | DEBUG | Saving model to flat file storage. Save #93
2025-02-25T05:10:58.422652+0300 | INFO | Averaging client parameters
2025-02-25T05:10:58.440665+0300 | INFO | Updating parameters on client #0
2025-02-25T05:11:13.570396+0300 | DEBUG | Test set: Accuracy: 7856/10000 (79%)
2025-02-25T05:11:13.571400+0300 | DEBUG | Test set: Loss: 1.6746015548706055
2025-02-25T05:11:13.674163+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.91      0.91      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.66      0.56      0.60      1200
           4       0.78      0.80      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.82      0.85      0.84      1000
           7       0.86      0.81      0.84      1000
           8       0.88      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T05:11:13.675156+0300 | DEBUG | Confusion Matrix:
[[826  12  46  14  14  12   2   6  44  24]
 [ 10 910   1   2   1   0   7   2  23  44]
 [ 58   3 702  43  56  51  59  16   6   6]
 [ 25   9  55 673  50 279  56  24  13  16]
 [ 17   2  37  40 795  40  29  35   4   1]
 [  8   2  34 171  28 504  14  30   9   0]
 [ 10   1  35  43  27  21 855   3   4   1]
 [ 21   1  15  26  46  61   8 813   2   7]
 [ 44  18   7   3   3   4   5   4 894  18]
 [ 24  46   3  10   2   2   5   8  16 884]]
2025-02-25T05:11:13.677158+0300 | DEBUG | Class precision: [0.79194631 0.9063745  0.75080214 0.65658537 0.7778865  0.5174538
 0.82211538 0.8639745  0.88078818 0.88311688]
2025-02-25T05:11:13.677158+0300 | DEBUG | Class recall: [0.826      0.91       0.702      0.56083333 0.795      0.63
 0.855      0.813      0.894      0.884     ]
2025-02-25T05:11:13.732948+0300 | INFO | Training epoch #94 on client #0
2025-02-25T05:11:13.734219+0300 | DEBUG | Saving model to flat file storage. Save #94
2025-02-25T05:11:13.879224+0300 | INFO | [94,     0] loss: 0.015
2025-02-25T05:11:24.553541+0300 | INFO | [94,   100] loss: 1.503
2025-02-25T05:11:35.203135+0300 | INFO | [94,   200] loss: 1.499
2025-02-25T05:11:46.270731+0300 | INFO | [94,   300] loss: 1.493
2025-02-25T05:11:57.343816+0300 | INFO | [94,   400] loss: 1.506
2025-02-25T05:12:08.270019+0300 | INFO | [94,   500] loss: 1.493
2025-02-25T05:12:19.141119+0300 | INFO | [94,   600] loss: 1.498
2025-02-25T05:12:30.238227+0300 | INFO | [94,   700] loss: 1.502
2025-02-25T05:12:41.150063+0300 | INFO | [94,   800] loss: 1.510
2025-02-25T05:12:55.063923+0300 | INFO | [94,   900] loss: 1.504
2025-02-25T05:13:09.651065+0300 | INFO | [94,  1000] loss: 1.511
2025-02-25T05:13:20.809390+0300 | INFO | [94,  1100] loss: 1.510
2025-02-25T05:13:32.318498+0300 | INFO | [94,  1200] loss: 1.514
2025-02-25T05:13:43.375981+0300 | INFO | [94,  1300] loss: 1.496
2025-02-25T05:13:54.502398+0300 | INFO | [94,  1400] loss: 1.507
2025-02-25T05:14:05.054649+0300 | INFO | [94,  1500] loss: 1.507
2025-02-25T05:14:15.641810+0300 | INFO | [94,  1600] loss: 1.501
2025-02-25T05:14:26.414727+0300 | INFO | [94,  1700] loss: 1.505
2025-02-25T05:14:37.415468+0300 | INFO | [94,  1800] loss: 1.499
2025-02-25T05:14:47.998788+0300 | INFO | [94,  1900] loss: 1.505
2025-02-25T05:14:58.862505+0300 | INFO | [94,  2000] loss: 1.503
2025-02-25T05:15:09.872296+0300 | INFO | [94,  2100] loss: 1.512
2025-02-25T05:15:20.688098+0300 | INFO | [94,  2200] loss: 1.508
2025-02-25T05:15:31.580232+0300 | INFO | [94,  2300] loss: 1.495
2025-02-25T05:15:43.330385+0300 | INFO | [94,  2400] loss: 1.509
2025-02-25T05:15:54.280668+0300 | INFO | [94,  2500] loss: 1.505
2025-02-25T05:16:05.388411+0300 | INFO | [94,  2600] loss: 1.509
2025-02-25T05:16:17.177110+0300 | INFO | [94,  2700] loss: 1.502
2025-02-25T05:16:27.975234+0300 | INFO | [94,  2800] loss: 1.505
2025-02-25T05:16:38.844059+0300 | INFO | [94,  2900] loss: 1.500
2025-02-25T05:16:49.617916+0300 | INFO | [94,  3000] loss: 1.507
2025-02-25T05:17:00.413505+0300 | INFO | [94,  3100] loss: 1.505
2025-02-25T05:17:11.342342+0300 | INFO | [94,  3200] loss: 1.504
2025-02-25T05:17:22.187018+0300 | INFO | [94,  3300] loss: 1.502
2025-02-25T05:17:33.156705+0300 | INFO | [94,  3400] loss: 1.512
2025-02-25T05:17:43.821896+0300 | INFO | [94,  3500] loss: 1.510
2025-02-25T05:17:54.781355+0300 | INFO | [94,  3600] loss: 1.503
2025-02-25T05:18:06.964786+0300 | INFO | [94,  3700] loss: 1.507
2025-02-25T05:18:18.289737+0300 | INFO | [94,  3800] loss: 1.515
2025-02-25T05:18:29.079374+0300 | INFO | [94,  3900] loss: 1.515
2025-02-25T05:18:40.092175+0300 | INFO | [94,  4000] loss: 1.511
2025-02-25T05:18:50.806164+0300 | INFO | [94,  4100] loss: 1.501
2025-02-25T05:19:01.647783+0300 | INFO | [94,  4200] loss: 1.510
2025-02-25T05:19:13.009562+0300 | INFO | [94,  4300] loss: 1.513
2025-02-25T05:19:24.063494+0300 | INFO | [94,  4400] loss: 1.497
2025-02-25T05:19:38.043400+0300 | INFO | [94,  4500] loss: 1.508
2025-02-25T05:19:51.214184+0300 | INFO | [94,  4600] loss: 1.505
2025-02-25T05:20:01.949989+0300 | INFO | [94,  4700] loss: 1.509
2025-02-25T05:20:12.971458+0300 | INFO | [94,  4800] loss: 1.514
2025-02-25T05:20:23.857490+0300 | INFO | [94,  4900] loss: 1.510
2025-02-25T05:20:34.281338+0300 | DEBUG | Saving model to flat file storage. Save #94
2025-02-25T05:20:34.311240+0300 | INFO | Averaging client parameters
2025-02-25T05:20:34.319241+0300 | INFO | Updating parameters on client #0
2025-02-25T05:20:49.171254+0300 | DEBUG | Test set: Accuracy: 7822/10000 (78%)
2025-02-25T05:20:49.172466+0300 | DEBUG | Test set: Loss: 1.6773427724838257
2025-02-25T05:20:49.263216+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.82      0.81      1000
           1       0.92      0.90      0.91      1000
           2       0.71      0.71      0.71      1000
           3       0.67      0.55      0.60      1200
           4       0.77      0.80      0.79      1000
           5       0.52      0.59      0.55       800
           6       0.78      0.89      0.83      1000
           7       0.86      0.81      0.84      1000
           8       0.89      0.88      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T05:20:49.266215+0300 | DEBUG | Confusion Matrix:
[[818   7  61  12  18  10   5   6  41  22]
 [ 15 900   3   1   1   0  10   3  12  55]
 [ 50   4 707  32  53  52  71  18   6   7]
 [ 29   7  67 655  59 267  71  21  11  13]
 [ 11   2  50  32 802  24  45  30   3   1]
 [ 10   2  42 182  29 470  19  38   7   1]
 [ 12   0  31  30  20  16 885   2   4   0]
 [ 19   1  17  24  50  54  13 814   2   6]
 [ 45  20   7   8   5   3   7   2 881  22]
 [ 23  35   4   8   2   3   7   8  20 890]]
2025-02-25T05:20:49.267213+0300 | DEBUG | Class precision: [0.79263566 0.9202454  0.7148635  0.66565041 0.77189605 0.52280311
 0.78111209 0.8641189  0.89260385 0.87512291]
2025-02-25T05:20:49.269211+0300 | DEBUG | Class recall: [0.818      0.9        0.707      0.54583333 0.802      0.5875
 0.885      0.814      0.881      0.89      ]
2025-02-25T05:20:49.316594+0300 | INFO | Training epoch #95 on client #0
2025-02-25T05:20:49.319597+0300 | DEBUG | Saving model to flat file storage. Save #95
2025-02-25T05:20:49.459103+0300 | INFO | [95,     0] loss: 0.015
2025-02-25T05:21:00.060831+0300 | INFO | [95,   100] loss: 1.498
2025-02-25T05:21:10.426138+0300 | INFO | [95,   200] loss: 1.510
2025-02-25T05:21:21.288192+0300 | INFO | [95,   300] loss: 1.504
2025-02-25T05:21:32.178260+0300 | INFO | [95,   400] loss: 1.503
2025-02-25T05:21:43.602739+0300 | INFO | [95,   500] loss: 1.492
2025-02-25T05:21:57.881749+0300 | INFO | [95,   600] loss: 1.501
2025-02-25T05:22:11.469420+0300 | INFO | [95,   700] loss: 1.513
2025-02-25T05:22:22.395238+0300 | INFO | [95,   800] loss: 1.516
2025-02-25T05:22:36.800583+0300 | INFO | [95,   900] loss: 1.503
2025-02-25T05:22:47.800604+0300 | INFO | [95,  1000] loss: 1.496
2025-02-25T05:22:58.722598+0300 | INFO | [95,  1100] loss: 1.503
2025-02-25T05:23:09.841982+0300 | INFO | [95,  1200] loss: 1.507
2025-02-25T05:23:20.618644+0300 | INFO | [95,  1300] loss: 1.509
2025-02-25T05:23:31.579555+0300 | INFO | [95,  1400] loss: 1.506
2025-02-25T05:23:42.601248+0300 | INFO | [95,  1500] loss: 1.504
2025-02-25T05:23:53.459385+0300 | INFO | [95,  1600] loss: 1.503
2025-02-25T05:24:04.189663+0300 | INFO | [95,  1700] loss: 1.487
2025-02-25T05:24:14.985737+0300 | INFO | [95,  1800] loss: 1.503
2025-02-25T05:24:25.805672+0300 | INFO | [95,  1900] loss: 1.500
2025-02-25T05:24:36.669235+0300 | INFO | [95,  2000] loss: 1.497
2025-02-25T05:24:48.705984+0300 | INFO | [95,  2100] loss: 1.503
2025-02-25T05:24:59.625641+0300 | INFO | [95,  2200] loss: 1.510
2025-02-25T05:25:10.201364+0300 | INFO | [95,  2300] loss: 1.512
2025-02-25T05:25:21.065789+0300 | INFO | [95,  2400] loss: 1.517
2025-02-25T05:25:32.377793+0300 | INFO | [95,  2500] loss: 1.502
2025-02-25T05:25:43.905734+0300 | INFO | [95,  2600] loss: 1.501
2025-02-25T05:25:54.949505+0300 | INFO | [95,  2700] loss: 1.499
2025-02-25T05:26:05.298579+0300 | INFO | [95,  2800] loss: 1.501
2025-02-25T05:26:15.916045+0300 | INFO | [95,  2900] loss: 1.509
2025-02-25T05:26:28.745668+0300 | INFO | [95,  3000] loss: 1.512
2025-02-25T05:26:39.756569+0300 | INFO | [95,  3100] loss: 1.510
2025-02-25T05:26:53.084541+0300 | INFO | [95,  3200] loss: 1.510
2025-02-25T05:27:03.582498+0300 | INFO | [95,  3300] loss: 1.513
2025-02-25T05:27:15.527288+0300 | INFO | [95,  3400] loss: 1.508
2025-02-25T05:27:26.401089+0300 | INFO | [95,  3500] loss: 1.512
2025-02-25T05:27:37.149675+0300 | INFO | [95,  3600] loss: 1.498
2025-02-25T05:27:47.934893+0300 | INFO | [95,  3700] loss: 1.503
2025-02-25T05:27:59.062170+0300 | INFO | [95,  3800] loss: 1.508
2025-02-25T05:28:09.896361+0300 | INFO | [95,  3900] loss: 1.507
2025-02-25T05:28:20.327464+0300 | INFO | [95,  4000] loss: 1.500
2025-02-25T05:28:31.356218+0300 | INFO | [95,  4100] loss: 1.502
2025-02-25T05:28:42.691096+0300 | INFO | [95,  4200] loss: 1.501
2025-02-25T05:28:55.608280+0300 | INFO | [95,  4300] loss: 1.512
2025-02-25T05:29:05.892671+0300 | INFO | [95,  4400] loss: 1.509
2025-02-25T05:29:16.855898+0300 | INFO | [95,  4500] loss: 1.504
2025-02-25T05:29:27.675764+0300 | INFO | [95,  4600] loss: 1.498
2025-02-25T05:29:38.498040+0300 | INFO | [95,  4700] loss: 1.510
2025-02-25T05:29:51.572137+0300 | INFO | [95,  4800] loss: 1.502
2025-02-25T05:30:02.422534+0300 | INFO | [95,  4900] loss: 1.496
2025-02-25T05:30:13.162156+0300 | DEBUG | Saving model to flat file storage. Save #95
2025-02-25T05:30:13.190419+0300 | INFO | Averaging client parameters
2025-02-25T05:30:13.202381+0300 | INFO | Updating parameters on client #0
2025-02-25T05:30:28.228933+0300 | DEBUG | Test set: Accuracy: 7814/10000 (78%)
2025-02-25T05:30:28.229935+0300 | DEBUG | Test set: Loss: 1.677880883216858
2025-02-25T05:30:28.335516+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.86      0.80      1000
           1       0.90      0.92      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.63      0.59      0.61      1200
           4       0.76      0.81      0.78      1000
           5       0.50      0.56      0.53       800
           6       0.83      0.85      0.84      1000
           7       0.90      0.79      0.84      1000
           8       0.88      0.89      0.88      1000
           9       0.91      0.86      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-25T05:30:28.337477+0300 | DEBUG | Confusion Matrix:
[[856  10  36   9  14   9   3   5  40  18]
 [ 18 917   2   4   1   0   8   1  23  26]
 [ 68   2 682  39  64  66  59   8   5   7]
 [ 33   9  55 706  54 255  41  20  14  13]
 [ 18   3  30  50 810  27  34  23   3   2]
 [ 13   1  40 221  31 451  10  28   5   0]
 [ 14   0  29  45  24  24 853   2   8   1]
 [ 24   2  11  38  61  59   8 790   2   5]
 [ 59  17   9   4   3   5   2   1 885  15]
 [ 24  63   4   7   3   4   4   4  23 864]]
2025-02-25T05:30:28.340522+0300 | DEBUG | Class precision: [0.7595386  0.89550781 0.75946548 0.6286732  0.76056338 0.50111111
 0.83463796 0.89569161 0.87797619 0.90851735]
2025-02-25T05:30:28.343559+0300 | DEBUG | Class recall: [0.856      0.917      0.682      0.58833333 0.81       0.56375
 0.853      0.79       0.885      0.864     ]
2025-02-25T05:30:28.392085+0300 | INFO | Training epoch #96 on client #0
2025-02-25T05:30:28.394085+0300 | DEBUG | Saving model to flat file storage. Save #96
2025-02-25T05:30:28.540334+0300 | INFO | [96,     0] loss: 0.015
2025-02-25T05:30:39.102775+0300 | INFO | [96,   100] loss: 1.491
2025-02-25T05:30:51.006488+0300 | INFO | [96,   200] loss: 1.503
2025-02-25T05:31:05.169044+0300 | INFO | [96,   300] loss: 1.497
2025-02-25T05:31:15.950319+0300 | INFO | [96,   400] loss: 1.500
2025-02-25T05:31:26.986280+0300 | INFO | [96,   500] loss: 1.508
2025-02-25T05:31:40.778988+0300 | INFO | [96,   600] loss: 1.496
2025-02-25T05:31:52.330862+0300 | INFO | [96,   700] loss: 1.502
2025-02-25T05:32:06.174912+0300 | INFO | [96,   800] loss: 1.499
2025-02-25T05:32:17.089498+0300 | INFO | [96,   900] loss: 1.509
2025-02-25T05:32:28.093769+0300 | INFO | [96,  1000] loss: 1.504
2025-02-25T05:32:38.837404+0300 | INFO | [96,  1100] loss: 1.502
2025-02-25T05:32:49.624598+0300 | INFO | [96,  1200] loss: 1.508
2025-02-25T05:33:00.770607+0300 | INFO | [96,  1300] loss: 1.499
2025-02-25T05:33:14.325751+0300 | INFO | [96,  1400] loss: 1.514
2025-02-25T05:33:25.162301+0300 | INFO | [96,  1500] loss: 1.503
2025-02-25T05:33:36.184723+0300 | INFO | [96,  1600] loss: 1.509
2025-02-25T05:33:46.867870+0300 | INFO | [96,  1700] loss: 1.495
2025-02-25T05:33:57.795990+0300 | INFO | [96,  1800] loss: 1.508
2025-02-25T05:34:08.635844+0300 | INFO | [96,  1900] loss: 1.517
2025-02-25T05:34:19.728585+0300 | INFO | [96,  2000] loss: 1.504
2025-02-25T05:34:31.268787+0300 | INFO | [96,  2100] loss: 1.509
2025-02-25T05:34:42.242690+0300 | INFO | [96,  2200] loss: 1.499
2025-02-25T05:34:53.167428+0300 | INFO | [96,  2300] loss: 1.510
2025-02-25T05:35:04.093736+0300 | INFO | [96,  2400] loss: 1.507
2025-02-25T05:35:15.594543+0300 | INFO | [96,  2500] loss: 1.506
2025-02-25T05:35:26.467635+0300 | INFO | [96,  2600] loss: 1.512
2025-02-25T05:35:37.356447+0300 | INFO | [96,  2700] loss: 1.505
2025-02-25T05:35:48.119145+0300 | INFO | [96,  2800] loss: 1.491
2025-02-25T05:35:59.193613+0300 | INFO | [96,  2900] loss: 1.502
2025-02-25T05:36:11.155757+0300 | INFO | [96,  3000] loss: 1.512
2025-02-25T05:36:22.035667+0300 | INFO | [96,  3100] loss: 1.507
2025-02-25T05:36:33.166194+0300 | INFO | [96,  3200] loss: 1.497
2025-02-25T05:36:44.062872+0300 | INFO | [96,  3300] loss: 1.519
2025-02-25T05:36:56.421670+0300 | INFO | [96,  3400] loss: 1.499
2025-02-25T05:37:09.731844+0300 | INFO | [96,  3500] loss: 1.509
2025-02-25T05:37:20.690379+0300 | INFO | [96,  3600] loss: 1.500
2025-02-25T05:37:31.588304+0300 | INFO | [96,  3700] loss: 1.500
2025-02-25T05:37:42.424195+0300 | INFO | [96,  3800] loss: 1.507
2025-02-25T05:37:53.168293+0300 | INFO | [96,  3900] loss: 1.496
2025-02-25T05:38:04.136875+0300 | INFO | [96,  4000] loss: 1.504
2025-02-25T05:38:16.063738+0300 | INFO | [96,  4100] loss: 1.507
2025-02-25T05:38:26.828415+0300 | INFO | [96,  4200] loss: 1.497
2025-02-25T05:38:37.764192+0300 | INFO | [96,  4300] loss: 1.505
2025-02-25T05:38:49.251668+0300 | INFO | [96,  4400] loss: 1.498
2025-02-25T05:39:01.801291+0300 | INFO | [96,  4500] loss: 1.507
2025-02-25T05:39:12.846057+0300 | INFO | [96,  4600] loss: 1.502
2025-02-25T05:39:23.869637+0300 | INFO | [96,  4700] loss: 1.509
2025-02-25T05:39:35.027041+0300 | INFO | [96,  4800] loss: 1.500
2025-02-25T05:39:45.922692+0300 | INFO | [96,  4900] loss: 1.511
2025-02-25T05:39:59.599738+0300 | DEBUG | Saving model to flat file storage. Save #96
2025-02-25T05:39:59.623260+0300 | INFO | Averaging client parameters
2025-02-25T05:39:59.636267+0300 | INFO | Updating parameters on client #0
2025-02-25T05:40:15.831635+0300 | DEBUG | Test set: Accuracy: 7868/10000 (79%)
2025-02-25T05:40:15.834630+0300 | DEBUG | Test set: Loss: 1.6733587980270386
2025-02-25T05:40:15.928259+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.86      0.81      1000
           1       0.92      0.89      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.68      0.55      0.61      1200
           4       0.82      0.79      0.80      1000
           5       0.50      0.62      0.55       800
           6       0.80      0.87      0.83      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.90      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T05:40:15.929345+0300 | DEBUG | Confusion Matrix:
[[858   8  37   9   7   8   4   7  37  25]
 [ 17 894   2   3   0   1   8   2  21  52]
 [ 70   3 686  32  46  65  66  20   7   5]
 [ 39   7  55 660  33 293  64  21  11  17]
 [ 15   2  37  41 788  38  40  33   4   2]
 [ 13   1  35 157  29 494  17  44   7   3]
 [ 12   2  26  36  16  26 869   8   5   0]
 [ 26   1  15  24  39  51   8 829   2   5]
 [ 42  13   4   3   4   4   3   3 903  21]
 [ 25  42   2   9   1   3   7   8  16 887]]
2025-02-25T05:40:15.932869+0300 | DEBUG | Class precision: [0.76812892 0.91880781 0.76307008 0.67761807 0.81827622 0.50254323
 0.80018416 0.85025641 0.89141165 0.87217306]
2025-02-25T05:40:15.934876+0300 | DEBUG | Class recall: [0.858  0.894  0.686  0.55   0.788  0.6175 0.869  0.829  0.903  0.887 ]
2025-02-25T05:40:15.988224+0300 | INFO | Training epoch #97 on client #0
2025-02-25T05:40:15.989220+0300 | DEBUG | Saving model to flat file storage. Save #97
2025-02-25T05:40:16.127201+0300 | INFO | [97,     0] loss: 0.016
2025-02-25T05:40:26.828683+0300 | INFO | [97,   100] loss: 1.502
2025-02-25T05:40:37.804791+0300 | INFO | [97,   200] loss: 1.496
2025-02-25T05:40:48.820527+0300 | INFO | [97,   300] loss: 1.495
2025-02-25T05:40:59.769067+0300 | INFO | [97,   400] loss: 1.502
2025-02-25T05:41:10.231991+0300 | INFO | [97,   500] loss: 1.498
2025-02-25T05:41:21.188306+0300 | INFO | [97,   600] loss: 1.503
2025-02-25T05:41:32.535900+0300 | INFO | [97,   700] loss: 1.507
2025-02-25T05:41:44.518139+0300 | INFO | [97,   800] loss: 1.502
2025-02-25T05:41:56.209201+0300 | INFO | [97,   900] loss: 1.501
2025-02-25T05:42:06.119511+0300 | INFO | [97,  1000] loss: 1.503
2025-02-25T05:42:16.896430+0300 | INFO | [97,  1100] loss: 1.496
2025-02-25T05:42:29.914079+0300 | INFO | [97,  1200] loss: 1.500
2025-02-25T05:42:40.826869+0300 | INFO | [97,  1300] loss: 1.507
2025-02-25T05:42:51.634831+0300 | INFO | [97,  1400] loss: 1.501
2025-02-25T05:43:02.477684+0300 | INFO | [97,  1500] loss: 1.499
2025-02-25T05:43:13.056349+0300 | INFO | [97,  1600] loss: 1.496
2025-02-25T05:43:24.170467+0300 | INFO | [97,  1700] loss: 1.500
2025-02-25T05:43:35.434225+0300 | INFO | [97,  1800] loss: 1.499
2025-02-25T05:43:46.885740+0300 | INFO | [97,  1900] loss: 1.511
2025-02-25T05:43:58.581962+0300 | INFO | [97,  2000] loss: 1.513
2025-02-25T05:44:12.955383+0300 | INFO | [97,  2100] loss: 1.507
2025-02-25T05:44:24.437623+0300 | INFO | [97,  2200] loss: 1.513
2025-02-25T05:44:35.775222+0300 | INFO | [97,  2300] loss: 1.508
2025-02-25T05:44:50.945010+0300 | INFO | [97,  2400] loss: 1.499
2025-02-25T05:45:02.558633+0300 | INFO | [97,  2500] loss: 1.497
2025-02-25T05:45:14.116822+0300 | INFO | [97,  2600] loss: 1.500
2025-02-25T05:45:25.649096+0300 | INFO | [97,  2700] loss: 1.516
2025-02-25T05:45:37.197103+0300 | INFO | [97,  2800] loss: 1.503
2025-02-25T05:45:50.881054+0300 | INFO | [97,  2900] loss: 1.512
2025-02-25T05:46:03.729842+0300 | INFO | [97,  3000] loss: 1.500
2025-02-25T05:46:16.062046+0300 | INFO | [97,  3100] loss: 1.507
2025-02-25T05:46:27.421794+0300 | INFO | [97,  3200] loss: 1.501
2025-02-25T05:46:39.131185+0300 | INFO | [97,  3300] loss: 1.499
2025-02-25T05:46:50.072712+0300 | INFO | [97,  3400] loss: 1.515
2025-02-25T05:47:00.964807+0300 | INFO | [97,  3500] loss: 1.509
2025-02-25T05:47:12.013380+0300 | INFO | [97,  3600] loss: 1.508
2025-02-25T05:47:23.045973+0300 | INFO | [97,  3700] loss: 1.506
2025-02-25T05:47:35.348001+0300 | INFO | [97,  3800] loss: 1.509
2025-02-25T05:47:46.439214+0300 | INFO | [97,  3900] loss: 1.500
2025-02-25T05:47:57.602138+0300 | INFO | [97,  4000] loss: 1.507
2025-02-25T05:48:09.094993+0300 | INFO | [97,  4100] loss: 1.502
2025-02-25T05:48:19.968532+0300 | INFO | [97,  4200] loss: 1.504
2025-02-25T05:48:31.033558+0300 | INFO | [97,  4300] loss: 1.508
2025-02-25T05:48:41.820877+0300 | INFO | [97,  4400] loss: 1.503
2025-02-25T05:48:52.549457+0300 | INFO | [97,  4500] loss: 1.512
2025-02-25T05:49:03.515409+0300 | INFO | [97,  4600] loss: 1.498
2025-02-25T05:49:17.244492+0300 | INFO | [97,  4700] loss: 1.505
2025-02-25T05:49:31.277752+0300 | INFO | [97,  4800] loss: 1.500
2025-02-25T05:49:42.123578+0300 | INFO | [97,  4900] loss: 1.504
2025-02-25T05:49:53.352578+0300 | DEBUG | Saving model to flat file storage. Save #97
2025-02-25T05:49:53.369579+0300 | INFO | Averaging client parameters
2025-02-25T05:49:53.381576+0300 | INFO | Updating parameters on client #0
2025-02-25T05:50:09.695292+0300 | DEBUG | Test set: Accuracy: 7822/10000 (78%)
2025-02-25T05:50:09.696391+0300 | DEBUG | Test set: Loss: 1.6770530939102173
2025-02-25T05:50:09.811340+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.82      0.81      1000
           1       0.90      0.92      0.91      1000
           2       0.78      0.68      0.72      1000
           3       0.64      0.58      0.61      1200
           4       0.76      0.80      0.78      1000
           5       0.49      0.60      0.54       800
           6       0.82      0.86      0.84      1000
           7       0.87      0.80      0.83      1000
           8       0.88      0.90      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T05:50:09.813339+0300 | DEBUG | Confusion Matrix:
[[819  10  49   9  18   9   5   6  46  29]
 [ 11 917   1   3   0   0   8   3  22  35]
 [ 55   4 677  45  67  74  55  12   5   6]
 [ 29   9  45 694  49 275  52  18  13  16]
 [ 12   1  35  47 803  36  34  27   4   1]
 [ 10   1  25 199  31 482  15  30   6   1]
 [  8   3  21  45  22  25 860   8   5   3]
 [ 17   1  10  30  54  78   7 797   3   3]
 [ 37  18   6   4   7   6   4   2 900  16]
 [ 23  54   3   7   1   5   5   9  20 873]]
2025-02-25T05:50:09.814338+0300 | DEBUG | Class precision: [0.80215475 0.90078585 0.77637615 0.64081256 0.76330798 0.48686869
 0.82296651 0.87390351 0.87890625 0.88809766]
2025-02-25T05:50:09.816392+0300 | DEBUG | Class recall: [0.819      0.917      0.677      0.57833333 0.803      0.6025
 0.86       0.797      0.9        0.873     ]
2025-02-25T05:50:09.875842+0300 | INFO | Training epoch #98 on client #0
2025-02-25T05:50:09.876843+0300 | DEBUG | Saving model to flat file storage. Save #98
2025-02-25T05:50:10.025384+0300 | INFO | [98,     0] loss: 0.015
2025-02-25T05:50:20.908788+0300 | INFO | [98,   100] loss: 1.501
2025-02-25T05:50:31.669424+0300 | INFO | [98,   200] loss: 1.507
2025-02-25T05:50:42.542546+0300 | INFO | [98,   300] loss: 1.512
2025-02-25T05:50:55.977531+0300 | INFO | [98,   400] loss: 1.506
2025-02-25T05:51:06.574635+0300 | INFO | [98,   500] loss: 1.494
2025-02-25T05:51:17.790388+0300 | INFO | [98,   600] loss: 1.500
2025-02-25T05:51:28.857714+0300 | INFO | [98,   700] loss: 1.497
2025-02-25T05:51:39.882928+0300 | INFO | [98,   800] loss: 1.508
2025-02-25T05:51:50.739955+0300 | INFO | [98,   900] loss: 1.514
2025-02-25T05:52:01.538306+0300 | INFO | [98,  1000] loss: 1.499
2025-02-25T05:52:12.435322+0300 | INFO | [98,  1100] loss: 1.511
2025-02-25T05:52:23.166615+0300 | INFO | [98,  1200] loss: 1.508
2025-02-25T05:52:33.960476+0300 | INFO | [98,  1300] loss: 1.505
2025-02-25T05:52:45.043873+0300 | INFO | [98,  1400] loss: 1.500
2025-02-25T05:52:55.845983+0300 | INFO | [98,  1500] loss: 1.509
2025-02-25T05:53:07.073408+0300 | INFO | [98,  1600] loss: 1.503
2025-02-25T05:53:18.063396+0300 | INFO | [98,  1700] loss: 1.498
2025-02-25T05:53:29.061794+0300 | INFO | [98,  1800] loss: 1.507
2025-02-25T05:53:40.671211+0300 | INFO | [98,  1900] loss: 1.515
2025-02-25T05:53:52.673702+0300 | INFO | [98,  2000] loss: 1.505
2025-02-25T05:54:05.620347+0300 | INFO | [98,  2100] loss: 1.497
2025-02-25T05:54:16.486359+0300 | INFO | [98,  2200] loss: 1.502
2025-02-25T05:54:30.916602+0300 | INFO | [98,  2300] loss: 1.502
2025-02-25T05:54:41.695114+0300 | INFO | [98,  2400] loss: 1.497
2025-02-25T05:54:52.674292+0300 | INFO | [98,  2500] loss: 1.504
2025-02-25T05:55:05.963138+0300 | INFO | [98,  2600] loss: 1.494
2025-02-25T05:55:17.158839+0300 | INFO | [98,  2700] loss: 1.508
2025-02-25T05:55:28.230622+0300 | INFO | [98,  2800] loss: 1.495
2025-02-25T05:55:40.300746+0300 | INFO | [98,  2900] loss: 1.507
2025-02-25T05:55:53.693670+0300 | INFO | [98,  3000] loss: 1.495
2025-02-25T05:56:04.903097+0300 | INFO | [98,  3100] loss: 1.501
2025-02-25T05:56:16.719020+0300 | INFO | [98,  3200] loss: 1.503
2025-02-25T05:56:28.801625+0300 | INFO | [98,  3300] loss: 1.511
2025-02-25T05:56:39.639747+0300 | INFO | [98,  3400] loss: 1.491
2025-02-25T05:56:50.317856+0300 | INFO | [98,  3500] loss: 1.497
2025-02-25T05:57:01.100624+0300 | INFO | [98,  3600] loss: 1.509
2025-02-25T05:57:11.997420+0300 | INFO | [98,  3700] loss: 1.519
2025-02-25T05:57:22.847114+0300 | INFO | [98,  3800] loss: 1.506
2025-02-25T05:57:36.026059+0300 | INFO | [98,  3900] loss: 1.507
2025-02-25T05:57:47.598031+0300 | INFO | [98,  4000] loss: 1.511
2025-02-25T05:57:58.621890+0300 | INFO | [98,  4100] loss: 1.508
2025-02-25T05:58:09.258509+0300 | INFO | [98,  4200] loss: 1.517
2025-02-25T05:58:20.201174+0300 | INFO | [98,  4300] loss: 1.500
2025-02-25T05:58:31.042500+0300 | INFO | [98,  4400] loss: 1.502
2025-02-25T05:58:44.747024+0300 | INFO | [98,  4500] loss: 1.509
2025-02-25T05:58:59.387046+0300 | INFO | [98,  4600] loss: 1.496
2025-02-25T05:59:10.569247+0300 | INFO | [98,  4700] loss: 1.509
2025-02-25T05:59:21.373066+0300 | INFO | [98,  4800] loss: 1.494
2025-02-25T05:59:31.797495+0300 | INFO | [98,  4900] loss: 1.503
2025-02-25T05:59:42.780714+0300 | DEBUG | Saving model to flat file storage. Save #98
2025-02-25T05:59:42.801035+0300 | INFO | Averaging client parameters
2025-02-25T05:59:42.806946+0300 | INFO | Updating parameters on client #0
2025-02-25T05:59:57.635933+0300 | DEBUG | Test set: Accuracy: 7832/10000 (78%)
2025-02-25T05:59:57.637935+0300 | DEBUG | Test set: Loss: 1.6763056516647339
2025-02-25T05:59:57.760178+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.84      0.80      1000
           1       0.91      0.91      0.91      1000
           2       0.79      0.64      0.71      1000
           3       0.70      0.52      0.60      1200
           4       0.76      0.81      0.78      1000
           5       0.49      0.67      0.57       800
           6       0.82      0.86      0.84      1000
           7       0.83      0.84      0.84      1000
           8       0.90      0.87      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T05:59:57.763177+0300 | DEBUG | Confusion Matrix:
[[843  10  44  12  15  10   5  12  30  19]
 [ 13 909   1   5   1   2   6   4  12  47]
 [ 61   1 643  32  74  79  74  24   7   5]
 [ 34   7  41 626  59 322  47  35  16  13]
 [ 13   2  25  38 811  31  41  35   3   1]
 [ 13   2  28 127  36 534  13  42   4   1]
 [ 12   3  17  31  24  34 864   5   5   5]
 [ 20   2   7  15  46  58   4 844   1   3]
 [ 60  21   5   5   5   6   3   3 873  19]
 [ 29  40   4   8   3   4   3   9  15 885]]
2025-02-25T05:59:57.766173+0300 | DEBUG | Class precision: [0.76775956 0.91173521 0.78895706 0.69632925 0.75512104 0.49444444
 0.81509434 0.83316881 0.90372671 0.88677355]
2025-02-25T05:59:57.767171+0300 | DEBUG | Class recall: [0.843      0.909      0.643      0.52166667 0.811      0.6675
 0.864      0.844      0.873      0.885     ]
2025-02-25T05:59:57.827699+0300 | INFO | Training epoch #99 on client #0
2025-02-25T05:59:57.830694+0300 | DEBUG | Saving model to flat file storage. Save #99
2025-02-25T05:59:57.971975+0300 | INFO | [99,     0] loss: 0.015
2025-02-25T06:00:09.508136+0300 | INFO | [99,   100] loss: 1.503
2025-02-25T06:00:22.133018+0300 | INFO | [99,   200] loss: 1.499
2025-02-25T06:00:33.012558+0300 | INFO | [99,   300] loss: 1.504
2025-02-25T06:00:43.446710+0300 | INFO | [99,   400] loss: 1.499
2025-02-25T06:00:55.893820+0300 | INFO | [99,   500] loss: 1.500
2025-02-25T06:01:09.120603+0300 | INFO | [99,   600] loss: 1.496
2025-02-25T06:01:20.318675+0300 | INFO | [99,   700] loss: 1.501
2025-02-25T06:01:31.197133+0300 | INFO | [99,   800] loss: 1.502
2025-02-25T06:01:41.763159+0300 | INFO | [99,   900] loss: 1.494
2025-02-25T06:01:52.749059+0300 | INFO | [99,  1000] loss: 1.502
2025-02-25T06:02:03.731810+0300 | INFO | [99,  1100] loss: 1.489
2025-02-25T06:02:14.555484+0300 | INFO | [99,  1200] loss: 1.505
2025-02-25T06:02:25.531231+0300 | INFO | [99,  1300] loss: 1.502
2025-02-25T06:02:36.163340+0300 | INFO | [99,  1400] loss: 1.496
2025-02-25T06:02:46.753326+0300 | INFO | [99,  1500] loss: 1.503
2025-02-25T06:02:57.399471+0300 | INFO | [99,  1600] loss: 1.503
2025-02-25T06:03:08.963406+0300 | INFO | [99,  1700] loss: 1.503
2025-02-25T06:03:19.913200+0300 | INFO | [99,  1800] loss: 1.494
2025-02-25T06:03:33.228830+0300 | INFO | [99,  1900] loss: 1.503
2025-02-25T06:03:44.985001+0300 | INFO | [99,  2000] loss: 1.517
2025-02-25T06:03:57.996864+0300 | INFO | [99,  2100] loss: 1.510
2025-02-25T06:04:09.527368+0300 | INFO | [99,  2200] loss: 1.513
2025-02-25T06:04:21.436223+0300 | INFO | [99,  2300] loss: 1.497
2025-02-25T06:04:32.819138+0300 | INFO | [99,  2400] loss: 1.500
2025-02-25T06:04:44.227735+0300 | INFO | [99,  2500] loss: 1.492
2025-02-25T06:04:55.436304+0300 | INFO | [99,  2600] loss: 1.515
2025-02-25T06:05:09.368963+0300 | INFO | [99,  2700] loss: 1.506
2025-02-25T06:05:21.582080+0300 | INFO | [99,  2800] loss: 1.510
2025-02-25T06:05:32.642647+0300 | INFO | [99,  2900] loss: 1.506
2025-02-25T06:05:43.753957+0300 | INFO | [99,  3000] loss: 1.506
2025-02-25T06:05:54.645154+0300 | INFO | [99,  3100] loss: 1.503
2025-02-25T06:06:06.565804+0300 | INFO | [99,  3200] loss: 1.504
2025-02-25T06:06:17.560585+0300 | INFO | [99,  3300] loss: 1.504
2025-02-25T06:06:28.493382+0300 | INFO | [99,  3400] loss: 1.507
2025-02-25T06:06:39.481472+0300 | INFO | [99,  3500] loss: 1.503
2025-02-25T06:06:50.217466+0300 | INFO | [99,  3600] loss: 1.503
2025-02-25T06:07:00.817514+0300 | INFO | [99,  3700] loss: 1.492
2025-02-25T06:07:11.778543+0300 | INFO | [99,  3800] loss: 1.503
2025-02-25T06:07:22.971233+0300 | INFO | [99,  3900] loss: 1.519
2025-02-25T06:07:36.257762+0300 | INFO | [99,  4000] loss: 1.502
2025-02-25T06:07:47.181183+0300 | INFO | [99,  4100] loss: 1.498
2025-02-25T06:08:00.488862+0300 | INFO | [99,  4200] loss: 1.510
2025-02-25T06:08:12.587516+0300 | INFO | [99,  4300] loss: 1.508
2025-02-25T06:08:27.860723+0300 | INFO | [99,  4400] loss: 1.499
2025-02-25T06:08:38.264617+0300 | INFO | [99,  4500] loss: 1.513
2025-02-25T06:08:51.962289+0300 | INFO | [99,  4600] loss: 1.517
2025-02-25T06:09:02.831093+0300 | INFO | [99,  4700] loss: 1.505
2025-02-25T06:09:13.855406+0300 | INFO | [99,  4800] loss: 1.508
2025-02-25T06:09:25.732353+0300 | INFO | [99,  4900] loss: 1.497
2025-02-25T06:09:37.474936+0300 | DEBUG | Saving model to flat file storage. Save #99
2025-02-25T06:09:37.495266+0300 | INFO | Averaging client parameters
2025-02-25T06:09:37.506267+0300 | INFO | Updating parameters on client #0
2025-02-25T06:09:53.053099+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-25T06:09:53.057100+0300 | DEBUG | Test set: Loss: 1.6733875274658203
2025-02-25T06:09:53.154117+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.66      0.57      0.61      1200
           4       0.75      0.83      0.79      1000
           5       0.54      0.57      0.56       800
           6       0.81      0.87      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.86      0.91      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T06:09:53.155124+0300 | DEBUG | Confusion Matrix:
[[837   8  49  16  14  10   6   5  32  23]
 [ 13 908   1   2   0   0   8   1  17  50]
 [ 53   3 698  37  67  48  62  16   6  10]
 [ 30  12  63 685  65 232  60  25   9  19]
 [ 10   2  39  33 831  25  28  22   6   4]
 [  8   3  41 183  39 456  25  35   5   5]
 [  8   2  30  41  20  18 869   3   5   4]
 [ 22   2  14  31  66  43   9 801   2  10]
 [ 46  20   8   8   7   3   4   2 880  22]
 [ 22  31   2   6   3   2   2   3  19 910]]
2025-02-25T06:09:53.157114+0300 | DEBUG | Class precision: [0.79790276 0.91624622 0.73862434 0.65738964 0.74730216 0.54480287
 0.80987884 0.87732749 0.89704383 0.86092715]
2025-02-25T06:09:53.158630+0300 | DEBUG | Class recall: [0.837      0.908      0.698      0.57083333 0.831      0.57
 0.869      0.801      0.88       0.91      ]
2025-02-25T06:09:53.213644+0300 | INFO | Training epoch #100 on client #0
2025-02-25T06:09:53.215648+0300 | DEBUG | Saving model to flat file storage. Save #100
2025-02-25T06:09:53.358019+0300 | INFO | [100,     0] loss: 0.016
2025-02-25T06:10:04.188407+0300 | INFO | [100,   100] loss: 1.513
2025-02-25T06:10:15.119700+0300 | INFO | [100,   200] loss: 1.505
2025-02-25T06:10:26.351343+0300 | INFO | [100,   300] loss: 1.503
2025-02-25T06:10:38.383994+0300 | INFO | [100,   400] loss: 1.510
2025-02-25T06:10:49.198314+0300 | INFO | [100,   500] loss: 1.505
2025-02-25T06:11:00.972369+0300 | INFO | [100,   600] loss: 1.511
2025-02-25T06:11:11.892953+0300 | INFO | [100,   700] loss: 1.509
2025-02-25T06:11:22.628236+0300 | INFO | [100,   800] loss: 1.506
2025-02-25T06:11:33.420907+0300 | INFO | [100,   900] loss: 1.500
2025-02-25T06:11:44.964258+0300 | INFO | [100,  1000] loss: 1.499
2025-02-25T06:11:58.547519+0300 | INFO | [100,  1100] loss: 1.496
2025-02-25T06:12:10.020473+0300 | INFO | [100,  1200] loss: 1.492
2025-02-25T06:12:21.037243+0300 | INFO | [100,  1300] loss: 1.502
2025-02-25T06:12:32.089633+0300 | INFO | [100,  1400] loss: 1.508
2025-02-25T06:12:45.712733+0300 | INFO | [100,  1500] loss: 1.501
2025-02-25T06:12:57.005970+0300 | INFO | [100,  1600] loss: 1.492
2025-02-25T06:13:10.481850+0300 | INFO | [100,  1700] loss: 1.504
2025-02-25T06:13:21.604025+0300 | INFO | [100,  1800] loss: 1.515
2025-02-25T06:13:32.757096+0300 | INFO | [100,  1900] loss: 1.503
2025-02-25T06:13:43.859062+0300 | INFO | [100,  2000] loss: 1.486
2025-02-25T06:13:55.285100+0300 | INFO | [100,  2100] loss: 1.513
2025-02-25T06:14:05.645058+0300 | INFO | [100,  2200] loss: 1.506
2025-02-25T06:14:16.654206+0300 | INFO | [100,  2300] loss: 1.508
2025-02-25T06:14:27.510136+0300 | INFO | [100,  2400] loss: 1.512
2025-02-25T06:14:38.561715+0300 | INFO | [100,  2500] loss: 1.510
2025-02-25T06:14:49.237894+0300 | INFO | [100,  2600] loss: 1.495
2025-02-25T06:15:00.159934+0300 | INFO | [100,  2700] loss: 1.497
2025-02-25T06:15:10.561300+0300 | INFO | [100,  2800] loss: 1.498
2025-02-25T06:15:21.423631+0300 | INFO | [100,  2900] loss: 1.506
2025-02-25T06:15:32.322302+0300 | INFO | [100,  3000] loss: 1.504
2025-02-25T06:15:43.215169+0300 | INFO | [100,  3100] loss: 1.501
2025-02-25T06:15:54.194348+0300 | INFO | [100,  3200] loss: 1.495
2025-02-25T06:16:04.783054+0300 | INFO | [100,  3300] loss: 1.505
2025-02-25T06:16:15.441234+0300 | INFO | [100,  3400] loss: 1.511
2025-02-25T06:16:26.155709+0300 | INFO | [100,  3500] loss: 1.495
2025-02-25T06:16:36.719858+0300 | INFO | [100,  3600] loss: 1.502
2025-02-25T06:16:47.691637+0300 | INFO | [100,  3700] loss: 1.504
2025-02-25T06:16:58.259303+0300 | INFO | [100,  3800] loss: 1.499
2025-02-25T06:17:09.021374+0300 | INFO | [100,  3900] loss: 1.503
2025-02-25T06:17:20.271713+0300 | INFO | [100,  4000] loss: 1.503
2025-02-25T06:17:33.589724+0300 | INFO | [100,  4100] loss: 1.496
2025-02-25T06:17:46.391418+0300 | INFO | [100,  4200] loss: 1.505
2025-02-25T06:17:57.157132+0300 | INFO | [100,  4300] loss: 1.508
2025-02-25T06:18:07.908817+0300 | INFO | [100,  4400] loss: 1.503
2025-02-25T06:18:18.786872+0300 | INFO | [100,  4500] loss: 1.498
2025-02-25T06:18:29.866533+0300 | INFO | [100,  4600] loss: 1.504
2025-02-25T06:18:40.785700+0300 | INFO | [100,  4700] loss: 1.493
2025-02-25T06:18:51.441886+0300 | INFO | [100,  4800] loss: 1.500
2025-02-25T06:19:02.330251+0300 | INFO | [100,  4900] loss: 1.503
2025-02-25T06:19:13.378394+0300 | DEBUG | Updating LR for optimizer
2025-02-25T06:19:13.379411+0300 | DEBUG | New LR: 2.5e-05
2025-02-25T06:19:13.380850+0300 | DEBUG | Saving model to flat file storage. Save #100
2025-02-25T06:19:13.397861+0300 | INFO | Averaging client parameters
2025-02-25T06:19:13.406864+0300 | INFO | Updating parameters on client #0
2025-02-25T06:19:28.743690+0300 | DEBUG | Test set: Accuracy: 7862/10000 (79%)
2025-02-25T06:19:28.744686+0300 | DEBUG | Test set: Loss: 1.6746107339859009
2025-02-25T06:19:28.842424+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.87      0.93      0.90      1000
           2       0.77      0.67      0.72      1000
           3       0.66      0.56      0.61      1200
           4       0.78      0.81      0.79      1000
           5       0.53      0.60      0.56       800
           6       0.83      0.86      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.86      0.90      0.88      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T06:19:28.844426+0300 | DEBUG | Confusion Matrix:
[[848  15  36   8   8   7   4   5  47  22]
 [  6 925   0   2   0   1   6   0  20  40]
 [ 70   7 672  36  60  66  56  16  12   5]
 [ 36  19  49 678  54 253  56  21  19  15]
 [ 13   2  39  40 805  25  27  40   6   3]
 [ 11   6  35 179  27 480  12  36   8   6]
 [ 14   4  25  36  25  19 863   3   6   5]
 [ 28   5  15  33  46  51   7 804   4   7]
 [ 39  21   5   3   2   4   3   2 901  20]
 [ 21  55   2   6   0   2   2   2  24 886]]
2025-02-25T06:19:28.846425+0300 | DEBUG | Class precision: [0.78084715 0.87346553 0.76537585 0.66405485 0.78383642 0.52863436
 0.83301158 0.86544672 0.86055396 0.87809713]
2025-02-25T06:19:28.847421+0300 | DEBUG | Class recall: [0.848 0.925 0.672 0.565 0.805 0.6   0.863 0.804 0.901 0.886]
2025-02-25T06:19:28.897913+0300 | INFO | Training epoch #101 on client #0
2025-02-25T06:19:28.900913+0300 | DEBUG | Saving model to flat file storage. Save #101
2025-02-25T06:19:29.036253+0300 | INFO | [101,     0] loss: 0.015
2025-02-25T06:19:40.056702+0300 | INFO | [101,   100] loss: 1.498
2025-02-25T06:19:52.373483+0300 | INFO | [101,   200] loss: 1.509
2025-02-25T06:20:03.321711+0300 | INFO | [101,   300] loss: 1.504
2025-02-25T06:20:14.612828+0300 | INFO | [101,   400] loss: 1.493
2025-02-25T06:20:25.519816+0300 | INFO | [101,   500] loss: 1.501
2025-02-25T06:20:36.484296+0300 | INFO | [101,   600] loss: 1.492
2025-02-25T06:20:46.536773+0300 | INFO | [101,   700] loss: 1.502
2025-02-25T06:20:57.234246+0300 | INFO | [101,   800] loss: 1.503
2025-02-25T06:21:07.937786+0300 | INFO | [101,   900] loss: 1.499
2025-02-25T06:21:19.151716+0300 | INFO | [101,  1000] loss: 1.498
2025-02-25T06:21:30.100545+0300 | INFO | [101,  1100] loss: 1.492
2025-02-25T06:21:41.165158+0300 | INFO | [101,  1200] loss: 1.497
2025-02-25T06:21:52.113783+0300 | INFO | [101,  1300] loss: 1.510
2025-02-25T06:22:02.860405+0300 | INFO | [101,  1400] loss: 1.496
2025-02-25T06:22:13.713287+0300 | INFO | [101,  1500] loss: 1.496
2025-02-25T06:22:24.829487+0300 | INFO | [101,  1600] loss: 1.494
2025-02-25T06:22:35.628640+0300 | INFO | [101,  1700] loss: 1.499
2025-02-25T06:22:47.519694+0300 | INFO | [101,  1800] loss: 1.499
2025-02-25T06:22:58.076779+0300 | INFO | [101,  1900] loss: 1.503
2025-02-25T06:23:09.155886+0300 | INFO | [101,  2000] loss: 1.496
2025-02-25T06:23:20.611628+0300 | INFO | [101,  2100] loss: 1.504
2025-02-25T06:23:31.541242+0300 | INFO | [101,  2200] loss: 1.497
2025-02-25T06:23:43.093821+0300 | INFO | [101,  2300] loss: 1.499
2025-02-25T06:23:53.772922+0300 | INFO | [101,  2400] loss: 1.497
2025-02-25T06:24:04.493357+0300 | INFO | [101,  2500] loss: 1.508
2025-02-25T06:24:15.313032+0300 | INFO | [101,  2600] loss: 1.502
2025-02-25T06:24:26.299524+0300 | INFO | [101,  2700] loss: 1.499
2025-02-25T06:24:37.280579+0300 | INFO | [101,  2800] loss: 1.504
2025-02-25T06:24:48.409029+0300 | INFO | [101,  2900] loss: 1.493
2025-02-25T06:24:59.380668+0300 | INFO | [101,  3000] loss: 1.499
2025-02-25T06:25:10.087554+0300 | INFO | [101,  3100] loss: 1.497
2025-02-25T06:25:21.137881+0300 | INFO | [101,  3200] loss: 1.502
2025-02-25T06:25:32.731065+0300 | INFO | [101,  3300] loss: 1.497
2025-02-25T06:25:43.665154+0300 | INFO | [101,  3400] loss: 1.502
2025-02-25T06:25:53.809341+0300 | INFO | [101,  3500] loss: 1.498
2025-02-25T06:26:06.960051+0300 | INFO | [101,  3600] loss: 1.496
2025-02-25T06:26:22.049654+0300 | INFO | [101,  3700] loss: 1.503
2025-02-25T06:26:32.938781+0300 | INFO | [101,  3800] loss: 1.510
2025-02-25T06:26:43.793391+0300 | INFO | [101,  3900] loss: 1.492
2025-02-25T06:26:54.680689+0300 | INFO | [101,  4000] loss: 1.505
2025-02-25T06:27:05.608770+0300 | INFO | [101,  4100] loss: 1.502
2025-02-25T06:27:16.357615+0300 | INFO | [101,  4200] loss: 1.507
2025-02-25T06:27:27.429422+0300 | INFO | [101,  4300] loss: 1.505
2025-02-25T06:27:38.057576+0300 | INFO | [101,  4400] loss: 1.495
2025-02-25T06:27:48.816973+0300 | INFO | [101,  4500] loss: 1.501
2025-02-25T06:27:59.873649+0300 | INFO | [101,  4600] loss: 1.517
2025-02-25T06:28:10.388807+0300 | INFO | [101,  4700] loss: 1.506
2025-02-25T06:28:21.109172+0300 | INFO | [101,  4800] loss: 1.511
2025-02-25T06:28:34.261217+0300 | INFO | [101,  4900] loss: 1.495
2025-02-25T06:28:45.285406+0300 | DEBUG | Saving model to flat file storage. Save #101
2025-02-25T06:28:45.307720+0300 | INFO | Averaging client parameters
2025-02-25T06:28:45.320697+0300 | INFO | Updating parameters on client #0
2025-02-25T06:29:01.256667+0300 | DEBUG | Test set: Accuracy: 7854/10000 (79%)
2025-02-25T06:29:01.257678+0300 | DEBUG | Test set: Loss: 1.6752814054489136
2025-02-25T06:29:01.353199+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.87      0.80      1000
           1       0.89      0.91      0.90      1000
           2       0.74      0.71      0.72      1000
           3       0.66      0.57      0.61      1200
           4       0.77      0.81      0.79      1000
           5       0.54      0.57      0.56       800
           6       0.86      0.83      0.85      1000
           7       0.87      0.82      0.84      1000
           8       0.87      0.89      0.88      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T06:29:01.356195+0300 | DEBUG | Confusion Matrix:
[[866  13  38   6  11   3   2   4  39  18]
 [ 13 913   1   0   1   0   6   1  18  47]
 [ 73   4 710  29  63  52  38  12  11   8]
 [ 44  17  67 679  55 238  45  25  14  16]
 [ 14   2  39  42 808  26  23  36   7   3]
 [ 13   4  41 194  29 458   7  39   9   6]
 [ 16   5  41  41  29  22 829   4   6   7]
 [ 30   2  16  32  46  40   5 818   3   8]
 [ 54  17   6   3   4   4   3   1 889  19]
 [ 34  45   2   5   0   1   2   4  23 884]]
2025-02-25T06:29:01.357194+0300 | DEBUG | Class precision: [0.74848747 0.89334638 0.73881374 0.6585839  0.77246654 0.54265403
 0.86354167 0.86652542 0.87242395 0.87007874]
2025-02-25T06:29:01.359195+0300 | DEBUG | Class recall: [0.866      0.913      0.71       0.56583333 0.808      0.5725
 0.829      0.818      0.889      0.884     ]
2025-02-25T06:29:01.361193+0300 | INFO | Training epoch #102 on client #0
2025-02-25T06:29:01.362200+0300 | DEBUG | Saving model to flat file storage. Save #102
2025-02-25T06:29:01.569256+0300 | INFO | [102,     0] loss: 0.015
2025-02-25T06:29:12.822305+0300 | INFO | [102,   100] loss: 1.494
2025-02-25T06:29:23.895166+0300 | INFO | [102,   200] loss: 1.500
2025-02-25T06:29:35.995912+0300 | INFO | [102,   300] loss: 1.487
2025-02-25T06:29:47.130293+0300 | INFO | [102,   400] loss: 1.496
2025-02-25T06:29:58.109879+0300 | INFO | [102,   500] loss: 1.495
2025-02-25T06:30:08.785994+0300 | INFO | [102,   600] loss: 1.492
2025-02-25T06:30:20.025102+0300 | INFO | [102,   700] loss: 1.505
2025-02-25T06:30:30.727971+0300 | INFO | [102,   800] loss: 1.496
2025-02-25T06:30:44.161606+0300 | INFO | [102,   900] loss: 1.500
2025-02-25T06:30:55.188096+0300 | INFO | [102,  1000] loss: 1.496
2025-02-25T06:31:07.372516+0300 | INFO | [102,  1100] loss: 1.496
2025-02-25T06:31:20.142524+0300 | INFO | [102,  1200] loss: 1.497
2025-02-25T06:31:31.226144+0300 | INFO | [102,  1300] loss: 1.499
2025-02-25T06:31:42.187029+0300 | INFO | [102,  1400] loss: 1.498
2025-02-25T06:31:55.641938+0300 | INFO | [102,  1500] loss: 1.499
2025-02-25T06:32:06.439045+0300 | INFO | [102,  1600] loss: 1.500
2025-02-25T06:32:16.890346+0300 | INFO | [102,  1700] loss: 1.495
2025-02-25T06:32:27.698167+0300 | INFO | [102,  1800] loss: 1.498
2025-02-25T06:32:38.503586+0300 | INFO | [102,  1900] loss: 1.494
2025-02-25T06:32:49.754383+0300 | INFO | [102,  2000] loss: 1.496
2025-02-25T06:33:00.948863+0300 | INFO | [102,  2100] loss: 1.505
2025-02-25T06:33:14.603710+0300 | INFO | [102,  2200] loss: 1.495
2025-02-25T06:33:25.801758+0300 | INFO | [102,  2300] loss: 1.495
2025-02-25T06:33:36.785724+0300 | INFO | [102,  2400] loss: 1.499
2025-02-25T06:33:47.572344+0300 | INFO | [102,  2500] loss: 1.498
2025-02-25T06:33:59.106235+0300 | INFO | [102,  2600] loss: 1.501
2025-02-25T06:34:10.183069+0300 | INFO | [102,  2700] loss: 1.503
2025-02-25T06:34:24.098233+0300 | INFO | [102,  2800] loss: 1.502
2025-02-25T06:34:34.992705+0300 | INFO | [102,  2900] loss: 1.502
2025-02-25T06:34:45.562453+0300 | INFO | [102,  3000] loss: 1.500
2025-02-25T06:34:56.351562+0300 | INFO | [102,  3100] loss: 1.496
2025-02-25T06:35:07.212950+0300 | INFO | [102,  3200] loss: 1.505
2025-02-25T06:35:18.115608+0300 | INFO | [102,  3300] loss: 1.498
2025-02-25T06:35:29.469290+0300 | INFO | [102,  3400] loss: 1.504
2025-02-25T06:35:44.547369+0300 | INFO | [102,  3500] loss: 1.497
2025-02-25T06:35:56.249975+0300 | INFO | [102,  3600] loss: 1.498
2025-02-25T06:36:10.682915+0300 | INFO | [102,  3700] loss: 1.501
2025-02-25T06:36:21.414622+0300 | INFO | [102,  3800] loss: 1.500
2025-02-25T06:36:32.568225+0300 | INFO | [102,  3900] loss: 1.501
2025-02-25T06:36:43.303974+0300 | INFO | [102,  4000] loss: 1.492
2025-02-25T06:36:54.240934+0300 | INFO | [102,  4100] loss: 1.506
2025-02-25T06:37:05.074855+0300 | INFO | [102,  4200] loss: 1.513
2025-02-25T06:37:16.234797+0300 | INFO | [102,  4300] loss: 1.501
2025-02-25T06:37:26.750527+0300 | INFO | [102,  4400] loss: 1.496
2025-02-25T06:37:37.705727+0300 | INFO | [102,  4500] loss: 1.492
2025-02-25T06:37:51.603134+0300 | INFO | [102,  4600] loss: 1.490
2025-02-25T06:38:02.910984+0300 | INFO | [102,  4700] loss: 1.498
2025-02-25T06:38:13.868886+0300 | INFO | [102,  4800] loss: 1.511
2025-02-25T06:38:25.064227+0300 | INFO | [102,  4900] loss: 1.497
2025-02-25T06:38:36.874402+0300 | DEBUG | Saving model to flat file storage. Save #102
2025-02-25T06:38:36.902958+0300 | INFO | Averaging client parameters
2025-02-25T06:38:36.915574+0300 | INFO | Updating parameters on client #0
2025-02-25T06:38:52.428081+0300 | DEBUG | Test set: Accuracy: 7859/10000 (79%)
2025-02-25T06:38:52.429081+0300 | DEBUG | Test set: Loss: 1.6741276979446411
2025-02-25T06:38:52.548309+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.81      1000
           1       0.90      0.91      0.91      1000
           2       0.73      0.70      0.72      1000
           3       0.68      0.53      0.59      1200
           4       0.77      0.82      0.80      1000
           5       0.52      0.64      0.57       800
           6       0.83      0.87      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.87      0.89      0.88      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T06:38:52.549309+0300 | DEBUG | Confusion Matrix:
[[831  14  55   9  12   7   5   5  44  18]
 [  8 914   3   1   1   0   6   1  22  44]
 [ 55   3 705  33  61  60  50  17   9   7]
 [ 30  10  62 634  55 300  55  25  14  15]
 [  8   2  39  34 819  32  30  28   5   3]
 [ 10   1  40 146  29 515  15  33   7   4]
 [  9   2  33  34  25  18 866   6   3   4]
 [ 23   2  18  27  52  60   8 801   2   7]
 [ 39  22   9   6   4   4   4   1 892  19]
 [ 27  42   4   9   1   2   4   6  23 882]]
2025-02-25T06:38:52.553308+0300 | DEBUG | Class precision: [0.79903846 0.90316206 0.72830579 0.6795284  0.7733711  0.51603206
 0.83029722 0.86782232 0.87365328 0.87936191]
2025-02-25T06:38:52.554308+0300 | DEBUG | Class recall: [0.831      0.914      0.705      0.52833333 0.819      0.64375
 0.866      0.801      0.892      0.882     ]
2025-02-25T06:38:52.606435+0300 | INFO | Training epoch #103 on client #0
2025-02-25T06:38:52.607439+0300 | DEBUG | Saving model to flat file storage. Save #103
2025-02-25T06:38:52.754936+0300 | INFO | [103,     0] loss: 0.016
2025-02-25T06:39:03.643834+0300 | INFO | [103,   100] loss: 1.503
2025-02-25T06:39:15.268621+0300 | INFO | [103,   200] loss: 1.494
2025-02-25T06:39:26.098385+0300 | INFO | [103,   300] loss: 1.499
2025-02-25T06:39:37.058284+0300 | INFO | [103,   400] loss: 1.498
2025-02-25T06:39:47.742773+0300 | INFO | [103,   500] loss: 1.503
2025-02-25T06:39:58.815971+0300 | INFO | [103,   600] loss: 1.496
2025-02-25T06:40:09.356933+0300 | INFO | [103,   700] loss: 1.507
2025-02-25T06:40:20.412749+0300 | INFO | [103,   800] loss: 1.499
2025-02-25T06:40:31.501578+0300 | INFO | [103,   900] loss: 1.499
2025-02-25T06:40:44.967024+0300 | INFO | [103,  1000] loss: 1.499
2025-02-25T06:40:55.806412+0300 | INFO | [103,  1100] loss: 1.498
2025-02-25T06:41:07.965737+0300 | INFO | [103,  1200] loss: 1.500
2025-02-25T06:41:20.193725+0300 | INFO | [103,  1300] loss: 1.492
2025-02-25T06:41:31.196034+0300 | INFO | [103,  1400] loss: 1.492
2025-02-25T06:41:42.110608+0300 | INFO | [103,  1500] loss: 1.493
2025-02-25T06:41:52.908104+0300 | INFO | [103,  1600] loss: 1.490
2025-02-25T06:42:03.771257+0300 | INFO | [103,  1700] loss: 1.483
2025-02-25T06:42:14.622864+0300 | INFO | [103,  1800] loss: 1.498
2025-02-25T06:42:26.292437+0300 | INFO | [103,  1900] loss: 1.498
2025-02-25T06:42:38.430266+0300 | INFO | [103,  2000] loss: 1.497
2025-02-25T06:42:52.223649+0300 | INFO | [103,  2100] loss: 1.488
2025-02-25T06:43:03.227135+0300 | INFO | [103,  2200] loss: 1.508
2025-02-25T06:43:13.904444+0300 | INFO | [103,  2300] loss: 1.496
2025-02-25T06:43:25.070034+0300 | INFO | [103,  2400] loss: 1.497
2025-02-25T06:43:35.940659+0300 | INFO | [103,  2500] loss: 1.492
2025-02-25T06:43:46.877962+0300 | INFO | [103,  2600] loss: 1.506
2025-02-25T06:43:57.925691+0300 | INFO | [103,  2700] loss: 1.502
2025-02-25T06:44:07.569896+0300 | INFO | [103,  2800] loss: 1.497
2025-02-25T06:44:17.811598+0300 | INFO | [103,  2900] loss: 1.500
2025-02-25T06:44:28.704158+0300 | INFO | [103,  3000] loss: 1.496
2025-02-25T06:44:39.652753+0300 | INFO | [103,  3100] loss: 1.506
2025-02-25T06:44:54.635787+0300 | INFO | [103,  3200] loss: 1.489
2025-02-25T06:45:05.910498+0300 | INFO | [103,  3300] loss: 1.507
2025-02-25T06:45:17.177437+0300 | INFO | [103,  3400] loss: 1.502
2025-02-25T06:45:28.091838+0300 | INFO | [103,  3500] loss: 1.501
2025-02-25T06:45:39.668696+0300 | INFO | [103,  3600] loss: 1.494
2025-02-25T06:45:50.942545+0300 | INFO | [103,  3700] loss: 1.499
2025-02-25T06:46:01.896925+0300 | INFO | [103,  3800] loss: 1.500
2025-02-25T06:46:12.689055+0300 | INFO | [103,  3900] loss: 1.505
2025-02-25T06:46:23.794999+0300 | INFO | [103,  4000] loss: 1.498
2025-02-25T06:46:34.433770+0300 | INFO | [103,  4100] loss: 1.493
2025-02-25T06:46:45.257883+0300 | INFO | [103,  4200] loss: 1.496
2025-02-25T06:46:56.412238+0300 | INFO | [103,  4300] loss: 1.501
2025-02-25T06:47:11.223012+0300 | INFO | [103,  4400] loss: 1.502
2025-02-25T06:47:23.262715+0300 | INFO | [103,  4500] loss: 1.500
2025-02-25T06:47:35.031061+0300 | INFO | [103,  4600] loss: 1.488
2025-02-25T06:47:46.905401+0300 | INFO | [103,  4700] loss: 1.494
2025-02-25T06:47:58.958196+0300 | INFO | [103,  4800] loss: 1.505
2025-02-25T06:48:10.559922+0300 | INFO | [103,  4900] loss: 1.497
2025-02-25T06:48:22.183916+0300 | DEBUG | Saving model to flat file storage. Save #103
2025-02-25T06:48:22.215590+0300 | INFO | Averaging client parameters
2025-02-25T06:48:22.226076+0300 | INFO | Updating parameters on client #0
2025-02-25T06:48:38.378874+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-25T06:48:38.379894+0300 | DEBUG | Test set: Loss: 1.6733388900756836
2025-02-25T06:48:38.498109+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.91      0.90      0.91      1000
           2       0.77      0.66      0.72      1000
           3       0.64      0.60      0.62      1200
           4       0.75      0.82      0.78      1000
           5       0.53      0.58      0.56       800
           6       0.82      0.87      0.85      1000
           7       0.88      0.82      0.85      1000
           8       0.87      0.90      0.88      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T06:48:38.501116+0300 | DEBUG | Confusion Matrix:
[[827  11  43  16  17   8   6   5  44  23]
 [  9 902   3   4   0   0   5   2  25  50]
 [ 59   2 664  49  75  62  57  15  10   7]
 [ 29   7  41 719  60 243  57  21  10  13]
 [  9   3  33  46 816  25  35  25   4   4]
 [ 11   3  32 199  33 466  15  30   8   3]
 [  8   0  22  45  24  17 873   3   6   2]
 [ 19   1  12  35  52  49   6 818   1   7]
 [ 43  18   4   4   6   3   4   1 895  22]
 [ 28  41   3   8   1   2   6   7  21 883]]
2025-02-25T06:48:38.502119+0300 | DEBUG | Class precision: [0.79366603 0.91295547 0.7747958  0.63911111 0.75276753 0.53257143
 0.82048872 0.8824164  0.87402344 0.87080868]
2025-02-25T06:48:38.504114+0300 | DEBUG | Class recall: [0.827      0.902      0.664      0.59916667 0.816      0.5825
 0.873      0.818      0.895      0.883     ]
2025-02-25T06:48:38.563280+0300 | INFO | Training epoch #104 on client #0
2025-02-25T06:48:38.566565+0300 | DEBUG | Saving model to flat file storage. Save #104
2025-02-25T06:48:38.720575+0300 | INFO | [104,     0] loss: 0.015
2025-02-25T06:48:50.540184+0300 | INFO | [104,   100] loss: 1.492
2025-02-25T06:49:03.339376+0300 | INFO | [104,   200] loss: 1.487
2025-02-25T06:49:14.997667+0300 | INFO | [104,   300] loss: 1.490
2025-02-25T06:49:26.772992+0300 | INFO | [104,   400] loss: 1.495
2025-02-25T06:49:38.618888+0300 | INFO | [104,   500] loss: 1.503
2025-02-25T06:49:50.309709+0300 | INFO | [104,   600] loss: 1.490
2025-02-25T06:50:02.019668+0300 | INFO | [104,   700] loss: 1.491
2025-02-25T06:50:14.919240+0300 | INFO | [104,   800] loss: 1.498
2025-02-25T06:50:25.851791+0300 | INFO | [104,   900] loss: 1.503
2025-02-25T06:50:36.802127+0300 | INFO | [104,  1000] loss: 1.500
2025-02-25T06:50:47.692269+0300 | INFO | [104,  1100] loss: 1.505
2025-02-25T06:50:58.621682+0300 | INFO | [104,  1200] loss: 1.493
2025-02-25T06:51:10.166174+0300 | INFO | [104,  1300] loss: 1.496
2025-02-25T06:51:22.309211+0300 | INFO | [104,  1400] loss: 1.494
2025-02-25T06:51:35.573848+0300 | INFO | [104,  1500] loss: 1.490
2025-02-25T06:51:50.845956+0300 | INFO | [104,  1600] loss: 1.491
2025-02-25T06:52:08.400236+0300 | INFO | [104,  1700] loss: 1.492
2025-02-25T06:52:20.819691+0300 | INFO | [104,  1800] loss: 1.504
2025-02-25T06:52:32.465720+0300 | INFO | [104,  1900] loss: 1.496
2025-02-25T06:52:44.215983+0300 | INFO | [104,  2000] loss: 1.494
2025-02-25T06:52:57.555732+0300 | INFO | [104,  2100] loss: 1.501
2025-02-25T06:53:09.171450+0300 | INFO | [104,  2200] loss: 1.490
2025-02-25T06:53:20.254326+0300 | INFO | [104,  2300] loss: 1.499
2025-02-25T06:53:31.257753+0300 | INFO | [104,  2400] loss: 1.508
2025-02-25T06:53:42.290054+0300 | INFO | [104,  2500] loss: 1.490
2025-02-25T06:53:53.194615+0300 | INFO | [104,  2600] loss: 1.505
2025-02-25T06:54:03.724318+0300 | INFO | [104,  2700] loss: 1.494
2025-02-25T06:54:16.646106+0300 | INFO | [104,  2800] loss: 1.504
2025-02-25T06:54:29.693220+0300 | INFO | [104,  2900] loss: 1.495
2025-02-25T06:54:42.929609+0300 | INFO | [104,  3000] loss: 1.492
2025-02-25T06:54:53.999542+0300 | INFO | [104,  3100] loss: 1.508
2025-02-25T06:55:04.707743+0300 | INFO | [104,  3200] loss: 1.508
2025-02-25T06:55:15.084542+0300 | INFO | [104,  3300] loss: 1.502
2025-02-25T06:55:26.264535+0300 | INFO | [104,  3400] loss: 1.487
2025-02-25T06:55:37.678963+0300 | INFO | [104,  3500] loss: 1.506
2025-02-25T06:55:48.530841+0300 | INFO | [104,  3600] loss: 1.502
2025-02-25T06:55:59.448509+0300 | INFO | [104,  3700] loss: 1.496
2025-02-25T06:56:09.618948+0300 | INFO | [104,  3800] loss: 1.486
2025-02-25T06:56:22.340131+0300 | INFO | [104,  3900] loss: 1.500
2025-02-25T06:56:34.538349+0300 | INFO | [104,  4000] loss: 1.486
2025-02-25T06:56:45.502161+0300 | INFO | [104,  4100] loss: 1.490
2025-02-25T06:56:56.327436+0300 | INFO | [104,  4200] loss: 1.497
2025-02-25T06:57:07.110146+0300 | INFO | [104,  4300] loss: 1.498
2025-02-25T06:57:18.369447+0300 | INFO | [104,  4400] loss: 1.496
2025-02-25T06:57:29.247634+0300 | INFO | [104,  4500] loss: 1.493
2025-02-25T06:57:41.253901+0300 | INFO | [104,  4600] loss: 1.505
2025-02-25T06:57:52.212271+0300 | INFO | [104,  4700] loss: 1.505
2025-02-25T06:58:03.136231+0300 | INFO | [104,  4800] loss: 1.504
2025-02-25T06:58:14.235435+0300 | INFO | [104,  4900] loss: 1.494
2025-02-25T06:58:25.237932+0300 | DEBUG | Saving model to flat file storage. Save #104
2025-02-25T06:58:25.251460+0300 | INFO | Averaging client parameters
2025-02-25T06:58:25.257715+0300 | INFO | Updating parameters on client #0
2025-02-25T06:58:40.176604+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-25T06:58:40.179598+0300 | DEBUG | Test set: Loss: 1.6716872453689575
2025-02-25T06:58:40.282365+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.65      0.58      0.61      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.60      0.56       800
           6       0.83      0.86      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T06:58:40.286365+0300 | DEBUG | Confusion Matrix:
[[838  12  50  12  15   9   4   5  38  17]
 [ 11 917   3   3   0   2   6   2  17  39]
 [ 56   2 688  44  61  58  57  19  10   5]
 [ 27   9  59 691  53 262  44  28  12  15]
 [ 14   1  32  47 812  27  37  26   4   0]
 [  9   2  37 177  32 482  16  35   8   2]
 [  9   1  28  45  23  22 863   4   3   2]
 [ 20   1  14  26  49  53   8 824   2   3]
 [ 46  19   9   3   4   1   4   2 898  14]
 [ 28  54   3  10   2   4   4   6  24 865]]
2025-02-25T06:58:40.289365+0300 | DEBUG | Class precision: [0.79206049 0.90078585 0.74539545 0.65311909 0.77259753 0.52391304
 0.8274209  0.86645636 0.88385827 0.8991684 ]
2025-02-25T06:58:40.291369+0300 | DEBUG | Class recall: [0.838      0.917      0.688      0.57583333 0.812      0.6025
 0.863      0.824      0.898      0.865     ]
2025-02-25T06:58:40.349938+0300 | INFO | Training epoch #105 on client #0
2025-02-25T06:58:40.350898+0300 | DEBUG | Saving model to flat file storage. Save #105
2025-02-25T06:58:40.505239+0300 | INFO | [105,     0] loss: 0.015
2025-02-25T06:58:53.098566+0300 | INFO | [105,   100] loss: 1.501
2025-02-25T06:59:04.135384+0300 | INFO | [105,   200] loss: 1.496
2025-02-25T06:59:15.124230+0300 | INFO | [105,   300] loss: 1.497
2025-02-25T06:59:26.338652+0300 | INFO | [105,   400] loss: 1.503
2025-02-25T06:59:36.881940+0300 | INFO | [105,   500] loss: 1.496
2025-02-25T06:59:47.651830+0300 | INFO | [105,   600] loss: 1.500
2025-02-25T06:59:58.656422+0300 | INFO | [105,   700] loss: 1.500
2025-02-25T07:00:09.449739+0300 | INFO | [105,   800] loss: 1.503
2025-02-25T07:00:20.335295+0300 | INFO | [105,   900] loss: 1.499
2025-02-25T07:00:31.713579+0300 | INFO | [105,  1000] loss: 1.493
2025-02-25T07:00:42.314841+0300 | INFO | [105,  1100] loss: 1.493
2025-02-25T07:00:55.999486+0300 | INFO | [105,  1200] loss: 1.493
2025-02-25T07:01:06.785342+0300 | INFO | [105,  1300] loss: 1.502
2025-02-25T07:01:17.799061+0300 | INFO | [105,  1400] loss: 1.499
2025-02-25T07:01:28.787005+0300 | INFO | [105,  1500] loss: 1.491
2025-02-25T07:01:39.973154+0300 | INFO | [105,  1600] loss: 1.492
2025-02-25T07:01:50.830330+0300 | INFO | [105,  1700] loss: 1.493
2025-02-25T07:02:02.298354+0300 | INFO | [105,  1800] loss: 1.512
2025-02-25T07:02:13.181413+0300 | INFO | [105,  1900] loss: 1.499
2025-02-25T07:02:24.299758+0300 | INFO | [105,  2000] loss: 1.500
2025-02-25T07:02:35.297903+0300 | INFO | [105,  2100] loss: 1.492
2025-02-25T07:02:46.012640+0300 | INFO | [105,  2200] loss: 1.500
2025-02-25T07:02:57.077842+0300 | INFO | [105,  2300] loss: 1.491
2025-02-25T07:03:08.193591+0300 | INFO | [105,  2400] loss: 1.502
2025-02-25T07:03:23.260146+0300 | INFO | [105,  2500] loss: 1.497
2025-02-25T07:03:34.035895+0300 | INFO | [105,  2600] loss: 1.494
2025-02-25T07:03:44.935761+0300 | INFO | [105,  2700] loss: 1.497
2025-02-25T07:03:58.639819+0300 | INFO | [105,  2800] loss: 1.499
2025-02-25T07:04:09.582710+0300 | INFO | [105,  2900] loss: 1.500
2025-02-25T07:04:21.557205+0300 | INFO | [105,  3000] loss: 1.500
2025-02-25T07:04:32.551857+0300 | INFO | [105,  3100] loss: 1.495
2025-02-25T07:04:43.584886+0300 | INFO | [105,  3200] loss: 1.496
2025-02-25T07:04:54.752155+0300 | INFO | [105,  3300] loss: 1.493
2025-02-25T07:05:05.789713+0300 | INFO | [105,  3400] loss: 1.503
2025-02-25T07:05:17.477495+0300 | INFO | [105,  3500] loss: 1.486
2025-02-25T07:05:30.489313+0300 | INFO | [105,  3600] loss: 1.492
2025-02-25T07:05:41.864954+0300 | INFO | [105,  3700] loss: 1.512
2025-02-25T07:05:52.890960+0300 | INFO | [105,  3800] loss: 1.502
2025-02-25T07:06:03.468246+0300 | INFO | [105,  3900] loss: 1.488
2025-02-25T07:06:13.898526+0300 | INFO | [105,  4000] loss: 1.489
2025-02-25T07:06:24.995832+0300 | INFO | [105,  4100] loss: 1.493
2025-02-25T07:06:35.760636+0300 | INFO | [105,  4200] loss: 1.488
2025-02-25T07:06:46.482333+0300 | INFO | [105,  4300] loss: 1.503
2025-02-25T07:06:57.267322+0300 | INFO | [105,  4400] loss: 1.500
2025-02-25T07:07:08.180251+0300 | INFO | [105,  4500] loss: 1.490
2025-02-25T07:07:19.016953+0300 | INFO | [105,  4600] loss: 1.496
2025-02-25T07:07:29.948274+0300 | INFO | [105,  4700] loss: 1.501
2025-02-25T07:07:41.205735+0300 | INFO | [105,  4800] loss: 1.488
2025-02-25T07:07:51.794913+0300 | INFO | [105,  4900] loss: 1.495
2025-02-25T07:08:06.571506+0300 | DEBUG | Saving model to flat file storage. Save #105
2025-02-25T07:08:06.604316+0300 | INFO | Averaging client parameters
2025-02-25T07:08:06.619025+0300 | INFO | Updating parameters on client #0
2025-02-25T07:08:22.350154+0300 | DEBUG | Test set: Accuracy: 7867/10000 (79%)
2025-02-25T07:08:22.351154+0300 | DEBUG | Test set: Loss: 1.6732099056243896
2025-02-25T07:08:22.417250+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.67      0.72      1000
           3       0.66      0.56      0.61      1200
           4       0.74      0.83      0.78      1000
           5       0.52      0.60      0.55       800
           6       0.83      0.85      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T07:08:22.418717+0300 | DEBUG | Confusion Matrix:
[[854  10  39  11  19   7   6   6  31  17]
 [ 13 918   1   3   0   0   7   2  16  40]
 [ 64   2 674  36  75  66  53  18   8   4]
 [ 32  10  46 672  62 279  48  29  10  12]
 [  9   2  31  40 832  29  29  24   4   0]
 [ 10   2  33 176  39 480  11  40   7   2]
 [ 12   1  24  47  32  20 852   6   4   2]
 [ 21   1  13  21  57  46   8 827   2   4]
 [ 43  22   6   5   6   2   4   3 890  19]
 [ 33  52   3   8   3   3   4   6  20 868]]
2025-02-25T07:08:22.419724+0300 | DEBUG | Class precision: [0.7827681  0.9        0.77471264 0.65947007 0.73955556 0.51502146
 0.83365949 0.86056191 0.89717742 0.89669421]
2025-02-25T07:08:22.420723+0300 | DEBUG | Class recall: [0.854 0.918 0.674 0.56  0.832 0.6   0.852 0.827 0.89  0.868]
2025-02-25T07:08:22.470742+0300 | INFO | Training epoch #106 on client #0
2025-02-25T07:08:22.472750+0300 | DEBUG | Saving model to flat file storage. Save #106
2025-02-25T07:08:22.620070+0300 | INFO | [106,     0] loss: 0.016
2025-02-25T07:08:35.245223+0300 | INFO | [106,   100] loss: 1.498
2025-02-25T07:08:46.109644+0300 | INFO | [106,   200] loss: 1.498
2025-02-25T07:08:56.956524+0300 | INFO | [106,   300] loss: 1.487
2025-02-25T07:09:07.657523+0300 | INFO | [106,   400] loss: 1.494
2025-02-25T07:09:18.463837+0300 | INFO | [106,   500] loss: 1.494
2025-02-25T07:09:29.594594+0300 | INFO | [106,   600] loss: 1.491
2025-02-25T07:09:40.468485+0300 | INFO | [106,   700] loss: 1.497
2025-02-25T07:09:51.502782+0300 | INFO | [106,   800] loss: 1.492
2025-02-25T07:10:04.414638+0300 | INFO | [106,   900] loss: 1.499
2025-02-25T07:10:18.022670+0300 | INFO | [106,  1000] loss: 1.491
2025-02-25T07:10:29.101296+0300 | INFO | [106,  1100] loss: 1.508
2025-02-25T07:10:40.177068+0300 | INFO | [106,  1200] loss: 1.495
2025-02-25T07:10:50.934490+0300 | INFO | [106,  1300] loss: 1.501
2025-02-25T07:11:01.596952+0300 | INFO | [106,  1400] loss: 1.492
2025-02-25T07:11:12.413786+0300 | INFO | [106,  1500] loss: 1.496
2025-02-25T07:11:23.452193+0300 | INFO | [106,  1600] loss: 1.487
2025-02-25T07:11:34.818130+0300 | INFO | [106,  1700] loss: 1.486
2025-02-25T07:11:45.598491+0300 | INFO | [106,  1800] loss: 1.487
2025-02-25T07:11:56.295299+0300 | INFO | [106,  1900] loss: 1.493
2025-02-25T07:12:07.297879+0300 | INFO | [106,  2000] loss: 1.497
2025-02-25T07:12:18.441545+0300 | INFO | [106,  2100] loss: 1.493
2025-02-25T07:12:33.272614+0300 | INFO | [106,  2200] loss: 1.495
2025-02-25T07:12:45.223337+0300 | INFO | [106,  2300] loss: 1.494
2025-02-25T07:12:56.092190+0300 | INFO | [106,  2400] loss: 1.499
2025-02-25T07:13:06.719925+0300 | INFO | [106,  2500] loss: 1.493
2025-02-25T07:13:17.688502+0300 | INFO | [106,  2600] loss: 1.493
2025-02-25T07:13:28.648041+0300 | INFO | [106,  2700] loss: 1.498
2025-02-25T07:13:39.595861+0300 | INFO | [106,  2800] loss: 1.492
2025-02-25T07:13:50.586465+0300 | INFO | [106,  2900] loss: 1.502
2025-02-25T07:14:01.260444+0300 | INFO | [106,  3000] loss: 1.499
2025-02-25T07:14:11.772857+0300 | INFO | [106,  3100] loss: 1.500
2025-02-25T07:14:22.661624+0300 | INFO | [106,  3200] loss: 1.501
2025-02-25T07:14:33.534531+0300 | INFO | [106,  3300] loss: 1.500
2025-02-25T07:14:44.601630+0300 | INFO | [106,  3400] loss: 1.501
2025-02-25T07:14:55.629249+0300 | INFO | [106,  3500] loss: 1.491
2025-02-25T07:15:06.482248+0300 | INFO | [106,  3600] loss: 1.506
2025-02-25T07:15:17.320444+0300 | INFO | [106,  3700] loss: 1.501
2025-02-25T07:15:28.340486+0300 | INFO | [106,  3800] loss: 1.495
2025-02-25T07:15:39.363217+0300 | INFO | [106,  3900] loss: 1.494
2025-02-25T07:15:51.383262+0300 | INFO | [106,  4000] loss: 1.509
2025-02-25T07:16:03.311720+0300 | INFO | [106,  4100] loss: 1.496
2025-02-25T07:16:13.952745+0300 | INFO | [106,  4200] loss: 1.511
2025-02-25T07:16:24.611095+0300 | INFO | [106,  4300] loss: 1.493
2025-02-25T07:16:35.284908+0300 | INFO | [106,  4400] loss: 1.497
2025-02-25T07:16:46.231005+0300 | INFO | [106,  4500] loss: 1.501
2025-02-25T07:16:56.770381+0300 | INFO | [106,  4600] loss: 1.502
2025-02-25T07:17:08.944918+0300 | INFO | [106,  4700] loss: 1.492
2025-02-25T07:17:20.124037+0300 | INFO | [106,  4800] loss: 1.492
2025-02-25T07:17:31.038076+0300 | INFO | [106,  4900] loss: 1.496
2025-02-25T07:17:44.574657+0300 | DEBUG | Saving model to flat file storage. Save #106
2025-02-25T07:17:44.603305+0300 | INFO | Averaging client parameters
2025-02-25T07:17:44.611301+0300 | INFO | Updating parameters on client #0
2025-02-25T07:18:00.111515+0300 | DEBUG | Test set: Accuracy: 7887/10000 (79%)
2025-02-25T07:18:00.114515+0300 | DEBUG | Test set: Loss: 1.6716691255569458
2025-02-25T07:18:00.215696+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.67      0.55      0.60      1200
           4       0.78      0.81      0.80      1000
           5       0.53      0.63      0.57       800
           6       0.83      0.86      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.87      0.89      0.88      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T07:18:00.219694+0300 | DEBUG | Confusion Matrix:
[[841  13  43  10  10   8   4   6  43  22]
 [ 10 930   2   1   0   0   3   0  12  42]
 [ 58   2 688  33  64  60  54  17  14  10]
 [ 35  13  58 657  50 275  53  24  16  19]
 [ 12   3  36  47 812  30  30  24   4   2]
 [ 10   4  39 150  32 504  17  32   9   3]
 [  8   2  21  43  26  21 864   5   6   4]
 [ 20   2  20  28  42  55   7 810   6  10]
 [ 39  22   7   4   3   2   4   3 894  22]
 [ 25  50   2   7   1   3   2   5  18 887]]
2025-02-25T07:18:00.222695+0300 | DEBUG | Class precision: [0.79489603 0.89337176 0.7510917  0.67040816 0.78076923 0.52609603
 0.83236994 0.87473002 0.87475538 0.86875612]
2025-02-25T07:18:00.225694+0300 | DEBUG | Class recall: [0.841  0.93   0.688  0.5475 0.812  0.63   0.864  0.81   0.894  0.887 ]
2025-02-25T07:18:00.273213+0300 | INFO | Training epoch #107 on client #0
2025-02-25T07:18:00.275218+0300 | DEBUG | Saving model to flat file storage. Save #107
2025-02-25T07:18:00.400768+0300 | INFO | [107,     0] loss: 0.016
2025-02-25T07:18:12.293826+0300 | INFO | [107,   100] loss: 1.491
2025-02-25T07:18:24.956865+0300 | INFO | [107,   200] loss: 1.492
2025-02-25T07:18:37.378455+0300 | INFO | [107,   300] loss: 1.498
2025-02-25T07:18:49.179662+0300 | INFO | [107,   400] loss: 1.487
2025-02-25T07:19:00.050227+0300 | INFO | [107,   500] loss: 1.499
2025-02-25T07:19:10.854635+0300 | INFO | [107,   600] loss: 1.498
2025-02-25T07:19:21.766343+0300 | INFO | [107,   700] loss: 1.492
2025-02-25T07:19:32.629276+0300 | INFO | [107,   800] loss: 1.495
2025-02-25T07:19:43.896988+0300 | INFO | [107,   900] loss: 1.503
2025-02-25T07:19:54.900215+0300 | INFO | [107,  1000] loss: 1.496
2025-02-25T07:20:05.574175+0300 | INFO | [107,  1100] loss: 1.484
2025-02-25T07:20:16.717329+0300 | INFO | [107,  1200] loss: 1.497
2025-02-25T07:20:27.722119+0300 | INFO | [107,  1300] loss: 1.489
2025-02-25T07:20:38.635875+0300 | INFO | [107,  1400] loss: 1.490
2025-02-25T07:20:49.519367+0300 | INFO | [107,  1500] loss: 1.497
2025-02-25T07:21:00.436341+0300 | INFO | [107,  1600] loss: 1.495
2025-02-25T07:21:11.616208+0300 | INFO | [107,  1700] loss: 1.504
2025-02-25T07:21:24.567686+0300 | INFO | [107,  1800] loss: 1.500
2025-02-25T07:21:37.407437+0300 | INFO | [107,  1900] loss: 1.495
2025-02-25T07:21:48.225881+0300 | INFO | [107,  2000] loss: 1.496
2025-02-25T07:22:01.568642+0300 | INFO | [107,  2100] loss: 1.494
2025-02-25T07:22:12.402867+0300 | INFO | [107,  2200] loss: 1.494
2025-02-25T07:22:23.668450+0300 | INFO | [107,  2300] loss: 1.489
2025-02-25T07:22:34.594663+0300 | INFO | [107,  2400] loss: 1.495
2025-02-25T07:22:45.662568+0300 | INFO | [107,  2500] loss: 1.501
2025-02-25T07:22:58.803743+0300 | INFO | [107,  2600] loss: 1.493
2025-02-25T07:23:10.969113+0300 | INFO | [107,  2700] loss: 1.487
2025-02-25T07:23:21.769108+0300 | INFO | [107,  2800] loss: 1.509
2025-02-25T07:23:32.514543+0300 | INFO | [107,  2900] loss: 1.498
2025-02-25T07:23:46.014499+0300 | INFO | [107,  3000] loss: 1.496
2025-02-25T07:23:57.027688+0300 | INFO | [107,  3100] loss: 1.490
2025-02-25T07:24:07.662358+0300 | INFO | [107,  3200] loss: 1.502
2025-02-25T07:24:18.355747+0300 | INFO | [107,  3300] loss: 1.490
2025-02-25T07:24:30.183960+0300 | INFO | [107,  3400] loss: 1.497
2025-02-25T07:24:40.992602+0300 | INFO | [107,  3500] loss: 1.494
2025-02-25T07:24:51.948738+0300 | INFO | [107,  3600] loss: 1.496
2025-02-25T07:25:02.990759+0300 | INFO | [107,  3700] loss: 1.499
2025-02-25T07:25:13.944985+0300 | INFO | [107,  3800] loss: 1.496
2025-02-25T07:25:24.773236+0300 | INFO | [107,  3900] loss: 1.491
2025-02-25T07:25:35.978718+0300 | INFO | [107,  4000] loss: 1.496
2025-02-25T07:25:49.620204+0300 | INFO | [107,  4100] loss: 1.489
2025-02-25T07:26:00.286185+0300 | INFO | [107,  4200] loss: 1.492
2025-02-25T07:26:10.360689+0300 | INFO | [107,  4300] loss: 1.496
2025-02-25T07:26:21.444537+0300 | INFO | [107,  4400] loss: 1.502
2025-02-25T07:26:32.477178+0300 | INFO | [107,  4500] loss: 1.511
2025-02-25T07:26:43.233344+0300 | INFO | [107,  4600] loss: 1.492
2025-02-25T07:26:54.267485+0300 | INFO | [107,  4700] loss: 1.499
2025-02-25T07:27:05.013177+0300 | INFO | [107,  4800] loss: 1.496
2025-02-25T07:27:15.891037+0300 | INFO | [107,  4900] loss: 1.500
2025-02-25T07:27:27.117937+0300 | DEBUG | Saving model to flat file storage. Save #107
2025-02-25T07:27:27.136939+0300 | INFO | Averaging client parameters
2025-02-25T07:27:27.148940+0300 | INFO | Updating parameters on client #0
2025-02-25T07:27:42.367590+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-25T07:27:42.371102+0300 | DEBUG | Test set: Loss: 1.6736470460891724
2025-02-25T07:27:42.458756+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.89      0.92      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.65      0.57      0.61      1200
           4       0.78      0.81      0.79      1000
           5       0.54      0.59      0.56       800
           6       0.81      0.86      0.84      1000
           7       0.85      0.82      0.84      1000
           8       0.89      0.90      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T07:27:42.461744+0300 | DEBUG | Confusion Matrix:
[[832  14  51   9   9   8   9   7  41  20]
 [ 13 923   3   3   0   1   7   0  14  36]
 [ 61   1 688  38  63  52  58  24   8   7]
 [ 34  10  60 682  49 247  55  33  13  17]
 [ 14   3  31  50 808  30  30  27   4   3]
 [ 10   3  40 173  29 476  18  40   8   3]
 [ 10   1  27  43  28  19 859   6   5   2]
 [ 23   1  13  30  47  48   8 820   3   7]
 [ 35  21   5   7   6   3   5   1 900  17]
 [ 24  55   2   9   2   2   6   6  19 875]]
2025-02-25T07:27:42.462771+0300 | DEBUG | Class precision: [0.78787879 0.89437984 0.74782609 0.6532567  0.77617675 0.53724605
 0.81421801 0.85062241 0.88669951 0.88652482]
2025-02-25T07:27:42.465788+0300 | DEBUG | Class recall: [0.832      0.923      0.688      0.56833333 0.808      0.595
 0.859      0.82       0.9        0.875     ]
2025-02-25T07:27:42.517143+0300 | INFO | Training epoch #108 on client #0
2025-02-25T07:27:42.519617+0300 | DEBUG | Saving model to flat file storage. Save #108
2025-02-25T07:27:42.656954+0300 | INFO | [108,     0] loss: 0.015
2025-02-25T07:27:53.044160+0300 | INFO | [108,   100] loss: 1.503
2025-02-25T07:28:03.937662+0300 | INFO | [108,   200] loss: 1.493
2025-02-25T07:28:15.364097+0300 | INFO | [108,   300] loss: 1.502
2025-02-25T07:28:27.812767+0300 | INFO | [108,   400] loss: 1.497
2025-02-25T07:28:39.703559+0300 | INFO | [108,   500] loss: 1.494
2025-02-25T07:28:50.667482+0300 | INFO | [108,   600] loss: 1.488
2025-02-25T07:29:01.355690+0300 | INFO | [108,   700] loss: 1.485
2025-02-25T07:29:12.958991+0300 | INFO | [108,   800] loss: 1.492
2025-02-25T07:29:23.956963+0300 | INFO | [108,   900] loss: 1.495
2025-02-25T07:29:37.616634+0300 | INFO | [108,  1000] loss: 1.495
2025-02-25T07:29:50.441269+0300 | INFO | [108,  1100] loss: 1.493
2025-02-25T07:30:01.669273+0300 | INFO | [108,  1200] loss: 1.488
2025-02-25T07:30:12.196833+0300 | INFO | [108,  1300] loss: 1.501
2025-02-25T07:30:23.226529+0300 | INFO | [108,  1400] loss: 1.495
2025-02-25T07:30:34.073438+0300 | INFO | [108,  1500] loss: 1.498
2025-02-25T07:30:48.704524+0300 | INFO | [108,  1600] loss: 1.497
2025-02-25T07:31:02.502596+0300 | INFO | [108,  1700] loss: 1.500
2025-02-25T07:31:12.854053+0300 | INFO | [108,  1800] loss: 1.490
2025-02-25T07:31:23.728854+0300 | INFO | [108,  1900] loss: 1.487
2025-02-25T07:31:34.606816+0300 | INFO | [108,  2000] loss: 1.500
2025-02-25T07:31:45.503859+0300 | INFO | [108,  2100] loss: 1.491
2025-02-25T07:31:56.319035+0300 | INFO | [108,  2200] loss: 1.488
2025-02-25T07:32:07.043200+0300 | INFO | [108,  2300] loss: 1.504
2025-02-25T07:32:17.890922+0300 | INFO | [108,  2400] loss: 1.493
2025-02-25T07:32:28.878427+0300 | INFO | [108,  2500] loss: 1.497
2025-02-25T07:32:39.607459+0300 | INFO | [108,  2600] loss: 1.491
2025-02-25T07:32:50.232706+0300 | INFO | [108,  2700] loss: 1.502
2025-02-25T07:33:01.381533+0300 | INFO | [108,  2800] loss: 1.492
2025-02-25T07:33:14.000101+0300 | INFO | [108,  2900] loss: 1.498
2025-02-25T07:33:25.553847+0300 | INFO | [108,  3000] loss: 1.496
2025-02-25T07:33:36.755837+0300 | INFO | [108,  3100] loss: 1.500
2025-02-25T07:33:47.642714+0300 | INFO | [108,  3200] loss: 1.505
2025-02-25T07:33:59.026047+0300 | INFO | [108,  3300] loss: 1.493
2025-02-25T07:34:10.082307+0300 | INFO | [108,  3400] loss: 1.488
2025-02-25T07:34:21.099953+0300 | INFO | [108,  3500] loss: 1.500
2025-02-25T07:34:36.296437+0300 | INFO | [108,  3600] loss: 1.489
2025-02-25T07:34:47.168370+0300 | INFO | [108,  3700] loss: 1.501
2025-02-25T07:34:58.096229+0300 | INFO | [108,  3800] loss: 1.491
2025-02-25T07:35:10.663936+0300 | INFO | [108,  3900] loss: 1.493
2025-02-25T07:35:21.302385+0300 | INFO | [108,  4000] loss: 1.488
2025-02-25T07:35:32.378482+0300 | INFO | [108,  4100] loss: 1.497
2025-02-25T07:35:43.713330+0300 | INFO | [108,  4200] loss: 1.500
2025-02-25T07:35:55.314832+0300 | INFO | [108,  4300] loss: 1.487
2025-02-25T07:36:07.869009+0300 | INFO | [108,  4400] loss: 1.499
2025-02-25T07:36:18.679851+0300 | INFO | [108,  4500] loss: 1.502
2025-02-25T07:36:29.976791+0300 | INFO | [108,  4600] loss: 1.491
2025-02-25T07:36:40.572477+0300 | INFO | [108,  4700] loss: 1.493
2025-02-25T07:36:51.319731+0300 | INFO | [108,  4800] loss: 1.495
2025-02-25T07:37:02.268291+0300 | INFO | [108,  4900] loss: 1.498
2025-02-25T07:37:16.664824+0300 | DEBUG | Saving model to flat file storage. Save #108
2025-02-25T07:37:16.692864+0300 | INFO | Averaging client parameters
2025-02-25T07:37:16.699875+0300 | INFO | Updating parameters on client #0
2025-02-25T07:37:32.343988+0300 | DEBUG | Test set: Accuracy: 7865/10000 (79%)
2025-02-25T07:37:32.345986+0300 | DEBUG | Test set: Loss: 1.6728129386901855
2025-02-25T07:37:32.456304+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.75      0.68      0.72      1000
           3       0.65      0.57      0.61      1200
           4       0.78      0.82      0.80      1000
           5       0.50      0.61      0.55       800
           6       0.82      0.85      0.83      1000
           7       0.86      0.82      0.84      1000
           8       0.88      0.89      0.89      1000
           9       0.88      0.90      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T07:37:32.459308+0300 | DEBUG | Confusion Matrix:
[[831   8  43  16   9  12   7   6  45  23]
 [ 12 901   4   2   0   2   8   2  18  51]
 [ 58   2 680  41  59  70  57  17  10   6]
 [ 28   8  50 688  49 276  50  27  11  13]
 [  7   2  36  43 816  33  34  25   4   0]
 [  7   1  36 170  29 489  17  42   7   2]
 [  8   1  30  45  23  27 851   7   4   4]
 [ 19   0  13  28  52  51   8 823   1   5]
 [ 37  20   7   8   6   6   4   2 890  20]
 [ 20  37   3  10   2   4   4   4  20 896]]
2025-02-25T07:37:32.461313+0300 | DEBUG | Class precision: [0.80915287 0.91938776 0.75388027 0.65461465 0.78086124 0.50412371
 0.81826923 0.8617801  0.88118812 0.87843137]
2025-02-25T07:37:32.462309+0300 | DEBUG | Class recall: [0.831      0.901      0.68       0.57333333 0.816      0.61125
 0.851      0.823      0.89       0.896     ]
2025-02-25T07:37:32.511081+0300 | INFO | Training epoch #109 on client #0
2025-02-25T07:37:32.512079+0300 | DEBUG | Saving model to flat file storage. Save #109
2025-02-25T07:37:32.661462+0300 | INFO | [109,     0] loss: 0.015
2025-02-25T07:37:43.221702+0300 | INFO | [109,   100] loss: 1.491
2025-02-25T07:37:54.047383+0300 | INFO | [109,   200] loss: 1.503
2025-02-25T07:38:04.853953+0300 | INFO | [109,   300] loss: 1.490
2025-02-25T07:38:16.091587+0300 | INFO | [109,   400] loss: 1.501
2025-02-25T07:38:27.026011+0300 | INFO | [109,   500] loss: 1.490
2025-02-25T07:38:38.208223+0300 | INFO | [109,   600] loss: 1.498
2025-02-25T07:38:49.128881+0300 | INFO | [109,   700] loss: 1.496
2025-02-25T07:39:00.103174+0300 | INFO | [109,   800] loss: 1.490
2025-02-25T07:39:11.580555+0300 | INFO | [109,   900] loss: 1.493
2025-02-25T07:39:22.479087+0300 | INFO | [109,  1000] loss: 1.497
2025-02-25T07:39:33.500962+0300 | INFO | [109,  1100] loss: 1.497
2025-02-25T07:39:44.359474+0300 | INFO | [109,  1200] loss: 1.493
2025-02-25T07:39:56.031406+0300 | INFO | [109,  1300] loss: 1.490
2025-02-25T07:40:10.068877+0300 | INFO | [109,  1400] loss: 1.494
2025-02-25T07:40:27.080620+0300 | INFO | [109,  1500] loss: 1.495
2025-02-25T07:40:37.896521+0300 | INFO | [109,  1600] loss: 1.491
2025-02-25T07:40:48.867362+0300 | INFO | [109,  1700] loss: 1.482
2025-02-25T07:40:59.625231+0300 | INFO | [109,  1800] loss: 1.492
2025-02-25T07:41:10.126284+0300 | INFO | [109,  1900] loss: 1.495
2025-02-25T07:41:21.199464+0300 | INFO | [109,  2000] loss: 1.497
2025-02-25T07:41:32.470476+0300 | INFO | [109,  2100] loss: 1.497
2025-02-25T07:41:47.589022+0300 | INFO | [109,  2200] loss: 1.498
2025-02-25T07:41:58.084323+0300 | INFO | [109,  2300] loss: 1.493
2025-02-25T07:42:09.252103+0300 | INFO | [109,  2400] loss: 1.502
2025-02-25T07:42:20.184577+0300 | INFO | [109,  2500] loss: 1.492
2025-02-25T07:42:31.072092+0300 | INFO | [109,  2600] loss: 1.497
2025-02-25T07:42:42.019788+0300 | INFO | [109,  2700] loss: 1.503
2025-02-25T07:42:52.861881+0300 | INFO | [109,  2800] loss: 1.504
2025-02-25T07:43:03.937115+0300 | INFO | [109,  2900] loss: 1.501
2025-02-25T07:43:14.616748+0300 | INFO | [109,  3000] loss: 1.495
2025-02-25T07:43:25.657193+0300 | INFO | [109,  3100] loss: 1.504
2025-02-25T07:43:37.144340+0300 | INFO | [109,  3200] loss: 1.492
2025-02-25T07:43:47.904153+0300 | INFO | [109,  3300] loss: 1.493
2025-02-25T07:43:59.380190+0300 | INFO | [109,  3400] loss: 1.505
2025-02-25T07:44:11.329228+0300 | INFO | [109,  3500] loss: 1.503
2025-02-25T07:44:21.993599+0300 | INFO | [109,  3600] loss: 1.483
2025-02-25T07:44:33.117850+0300 | INFO | [109,  3700] loss: 1.505
2025-02-25T07:44:43.986885+0300 | INFO | [109,  3800] loss: 1.489
2025-02-25T07:44:57.793202+0300 | INFO | [109,  3900] loss: 1.496
2025-02-25T07:45:08.546776+0300 | INFO | [109,  4000] loss: 1.495
2025-02-25T07:45:19.697543+0300 | INFO | [109,  4100] loss: 1.502
2025-02-25T07:45:30.787407+0300 | INFO | [109,  4200] loss: 1.497
2025-02-25T07:45:41.811868+0300 | INFO | [109,  4300] loss: 1.494
2025-02-25T07:45:52.674017+0300 | INFO | [109,  4400] loss: 1.489
2025-02-25T07:46:02.917401+0300 | INFO | [109,  4500] loss: 1.494
2025-02-25T07:46:13.079253+0300 | INFO | [109,  4600] loss: 1.509
2025-02-25T07:46:23.944499+0300 | INFO | [109,  4700] loss: 1.491
2025-02-25T07:46:34.674576+0300 | INFO | [109,  4800] loss: 1.493
2025-02-25T07:46:46.973276+0300 | INFO | [109,  4900] loss: 1.492
2025-02-25T07:47:00.647537+0300 | DEBUG | Saving model to flat file storage. Save #109
2025-02-25T07:47:00.670181+0300 | INFO | Averaging client parameters
2025-02-25T07:47:00.682184+0300 | INFO | Updating parameters on client #0
2025-02-25T07:47:16.176915+0300 | DEBUG | Test set: Accuracy: 7859/10000 (79%)
2025-02-25T07:47:16.178908+0300 | DEBUG | Test set: Loss: 1.67478609085083
2025-02-25T07:47:16.264786+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.86      0.94      0.90      1000
           2       0.74      0.71      0.72      1000
           3       0.68      0.55      0.61      1200
           4       0.74      0.84      0.79      1000
           5       0.55      0.57      0.56       800
           6       0.81      0.87      0.84      1000
           7       0.88      0.79      0.83      1000
           8       0.87      0.91      0.89      1000
           9       0.91      0.85      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T07:47:16.266779+0300 | DEBUG | Confusion Matrix:
[[846  17  39   7   8   7   6   3  49  18]
 [  8 939   1   2   0   0   7   0  17  26]
 [ 58   3 709  36  62  41  59  15  12   5]
 [ 33  15  65 659  68 241  63  23  18  15]
 [ 13   2  43  34 839  18  26  21   4   0]
 [ 13   2  47 170  40 458  25  34   8   3]
 [ 15   3  28  34  29  12 869   3   4   3]
 [ 27   3  21  26  72  44  13 785   5   4]
 [ 33  24   5   2   6   3   4   2 909  12]
 [ 27  81   3   6   4   2   4   4  23 846]]
2025-02-25T07:47:16.267778+0300 | DEBUG | Class precision: [0.78844362 0.86225895 0.73777315 0.67520492 0.74379433 0.55447942
 0.80762082 0.88202247 0.86653956 0.90772532]
2025-02-25T07:47:16.268779+0300 | DEBUG | Class recall: [0.846      0.939      0.709      0.54916667 0.839      0.5725
 0.869      0.785      0.909      0.846     ]
2025-02-25T07:47:16.317549+0300 | INFO | Training epoch #110 on client #0
2025-02-25T07:47:16.319549+0300 | DEBUG | Saving model to flat file storage. Save #110
2025-02-25T07:47:16.460394+0300 | INFO | [110,     0] loss: 0.015
2025-02-25T07:47:27.297879+0300 | INFO | [110,   100] loss: 1.500
2025-02-25T07:47:38.031861+0300 | INFO | [110,   200] loss: 1.486
2025-02-25T07:47:48.954932+0300 | INFO | [110,   300] loss: 1.502
2025-02-25T07:47:59.985606+0300 | INFO | [110,   400] loss: 1.499
2025-02-25T07:48:10.795733+0300 | INFO | [110,   500] loss: 1.510
2025-02-25T07:48:21.790771+0300 | INFO | [110,   600] loss: 1.490
2025-02-25T07:48:32.817942+0300 | INFO | [110,   700] loss: 1.486
2025-02-25T07:48:43.597251+0300 | INFO | [110,   800] loss: 1.495
2025-02-25T07:48:54.525228+0300 | INFO | [110,   900] loss: 1.496
2025-02-25T07:49:05.311395+0300 | INFO | [110,  1000] loss: 1.488
2025-02-25T07:49:16.803049+0300 | INFO | [110,  1100] loss: 1.503
2025-02-25T07:49:31.405419+0300 | INFO | [110,  1200] loss: 1.507
2025-02-25T07:49:42.252833+0300 | INFO | [110,  1300] loss: 1.493
2025-02-25T07:49:53.246135+0300 | INFO | [110,  1400] loss: 1.492
2025-02-25T07:50:04.652704+0300 | INFO | [110,  1500] loss: 1.508
2025-02-25T07:50:15.292852+0300 | INFO | [110,  1600] loss: 1.477
2025-02-25T07:50:26.675514+0300 | INFO | [110,  1700] loss: 1.501
2025-02-25T07:50:38.295656+0300 | INFO | [110,  1800] loss: 1.492
2025-02-25T07:50:49.651699+0300 | INFO | [110,  1900] loss: 1.499
2025-02-25T07:51:00.808894+0300 | INFO | [110,  2000] loss: 1.491
2025-02-25T07:51:12.044543+0300 | INFO | [110,  2100] loss: 1.496
2025-02-25T07:51:26.504404+0300 | INFO | [110,  2200] loss: 1.492
2025-02-25T07:51:38.004887+0300 | INFO | [110,  2300] loss: 1.493
2025-02-25T07:51:49.401074+0300 | INFO | [110,  2400] loss: 1.484
2025-02-25T07:52:00.799603+0300 | INFO | [110,  2500] loss: 1.502
2025-02-25T07:52:12.079017+0300 | INFO | [110,  2600] loss: 1.495
2025-02-25T07:52:23.595079+0300 | INFO | [110,  2700] loss: 1.498
2025-02-25T07:52:35.038061+0300 | INFO | [110,  2800] loss: 1.500
2025-02-25T07:52:46.807303+0300 | INFO | [110,  2900] loss: 1.488
2025-02-25T07:52:58.958556+0300 | INFO | [110,  3000] loss: 1.497
2025-02-25T07:53:13.111275+0300 | INFO | [110,  3100] loss: 1.492
2025-02-25T07:53:24.785277+0300 | INFO | [110,  3200] loss: 1.505
2025-02-25T07:53:35.947051+0300 | INFO | [110,  3300] loss: 1.497
2025-02-25T07:53:47.982655+0300 | INFO | [110,  3400] loss: 1.497
2025-02-25T07:54:01.682327+0300 | INFO | [110,  3500] loss: 1.496
2025-02-25T07:54:12.060536+0300 | INFO | [110,  3600] loss: 1.488
2025-02-25T07:54:23.221526+0300 | INFO | [110,  3700] loss: 1.493
2025-02-25T07:54:34.245032+0300 | INFO | [110,  3800] loss: 1.487
2025-02-25T07:54:44.936727+0300 | INFO | [110,  3900] loss: 1.500
2025-02-25T07:54:56.101708+0300 | INFO | [110,  4000] loss: 1.498
2025-02-25T07:55:06.755809+0300 | INFO | [110,  4100] loss: 1.498
2025-02-25T07:55:17.470330+0300 | INFO | [110,  4200] loss: 1.488
2025-02-25T07:55:28.612666+0300 | INFO | [110,  4300] loss: 1.495
2025-02-25T07:55:39.890971+0300 | INFO | [110,  4400] loss: 1.490
2025-02-25T07:55:50.855699+0300 | INFO | [110,  4500] loss: 1.499
2025-02-25T07:56:01.723458+0300 | INFO | [110,  4600] loss: 1.495
2025-02-25T07:56:12.050048+0300 | INFO | [110,  4700] loss: 1.487
2025-02-25T07:56:22.668283+0300 | INFO | [110,  4800] loss: 1.490
2025-02-25T07:56:33.384421+0300 | INFO | [110,  4900] loss: 1.509
2025-02-25T07:56:44.061859+0300 | DEBUG | Saving model to flat file storage. Save #110
2025-02-25T07:56:44.086862+0300 | INFO | Averaging client parameters
2025-02-25T07:56:44.100865+0300 | INFO | Updating parameters on client #0
2025-02-25T07:56:59.304523+0300 | DEBUG | Test set: Accuracy: 7862/10000 (79%)
2025-02-25T07:56:59.306521+0300 | DEBUG | Test set: Loss: 1.6740056276321411
2025-02-25T07:56:59.407188+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.74      0.71      0.72      1000
           3       0.66      0.58      0.61      1200
           4       0.72      0.85      0.78      1000
           5       0.55      0.57      0.56       800
           6       0.86      0.82      0.84      1000
           7       0.86      0.82      0.84      1000
           8       0.86      0.90      0.88      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T07:56:59.408404+0300 | DEBUG | Confusion Matrix:
[[828  10  50  11  13   9   4   9  47  19]
 [ 12 900   4   1   0   1   5   2  25  50]
 [ 53   1 707  41  75  46  40  18  11   8]
 [ 26   7  59 691  73 238  46  28  18  14]
 [ 10   1  33  37 851  21  17  21   7   2]
 [  9   2  49 175  44 456  10  43   8   4]
 [ 11   0  30  50  52  19 821   8   6   3]
 [ 18   1  13  30  63  40   7 816   4   8]
 [ 38  18   6   4   5   3   3   2 902  19]
 [ 25  38   4   8   3   1   4   6  21 890]]
2025-02-25T07:56:59.409843+0300 | DEBUG | Class precision: [0.8038835  0.9202454  0.74031414 0.65935115 0.72179813 0.54676259
 0.85788924 0.85624344 0.85986654 0.87512291]
2025-02-25T07:56:59.410863+0300 | DEBUG | Class recall: [0.828      0.9        0.707      0.57583333 0.851      0.57
 0.821      0.816      0.902      0.89      ]
2025-02-25T07:56:59.465961+0300 | INFO | Training epoch #111 on client #0
2025-02-25T07:56:59.469403+0300 | DEBUG | Saving model to flat file storage. Save #111
2025-02-25T07:56:59.616169+0300 | INFO | [111,     0] loss: 0.016
2025-02-25T07:57:12.614909+0300 | INFO | [111,   100] loss: 1.488
2025-02-25T07:57:23.586484+0300 | INFO | [111,   200] loss: 1.495
2025-02-25T07:57:34.569306+0300 | INFO | [111,   300] loss: 1.503
2025-02-25T07:57:45.136863+0300 | INFO | [111,   400] loss: 1.494
2025-02-25T07:57:56.264390+0300 | INFO | [111,   500] loss: 1.483
2025-02-25T07:58:07.046721+0300 | INFO | [111,   600] loss: 1.495
2025-02-25T07:58:17.901119+0300 | INFO | [111,   700] loss: 1.492
2025-02-25T07:58:32.972665+0300 | INFO | [111,   800] loss: 1.487
2025-02-25T07:58:43.672708+0300 | INFO | [111,   900] loss: 1.497
2025-02-25T07:58:54.841441+0300 | INFO | [111,  1000] loss: 1.498
2025-02-25T07:59:05.195266+0300 | INFO | [111,  1100] loss: 1.498
2025-02-25T07:59:15.996716+0300 | INFO | [111,  1200] loss: 1.494
2025-02-25T07:59:27.510286+0300 | INFO | [111,  1300] loss: 1.490
2025-02-25T07:59:40.204600+0300 | INFO | [111,  1400] loss: 1.494
2025-02-25T07:59:51.479898+0300 | INFO | [111,  1500] loss: 1.498
2025-02-25T08:00:02.069121+0300 | INFO | [111,  1600] loss: 1.505
2025-02-25T08:00:16.526950+0300 | INFO | [111,  1700] loss: 1.488
2025-02-25T08:00:27.522178+0300 | INFO | [111,  1800] loss: 1.495
2025-02-25T08:00:40.526991+0300 | INFO | [111,  1900] loss: 1.492
2025-02-25T08:00:51.397055+0300 | INFO | [111,  2000] loss: 1.503
2025-02-25T08:01:02.329534+0300 | INFO | [111,  2100] loss: 1.494
2025-02-25T08:01:13.134229+0300 | INFO | [111,  2200] loss: 1.486
2025-02-25T08:01:25.020947+0300 | INFO | [111,  2300] loss: 1.494
2025-02-25T08:01:36.259440+0300 | INFO | [111,  2400] loss: 1.499
2025-02-25T08:01:47.969204+0300 | INFO | [111,  2500] loss: 1.493
2025-02-25T08:01:58.662864+0300 | INFO | [111,  2600] loss: 1.493
2025-02-25T08:02:09.579766+0300 | INFO | [111,  2700] loss: 1.509
2025-02-25T08:02:21.302214+0300 | INFO | [111,  2800] loss: 1.493
2025-02-25T08:02:34.293040+0300 | INFO | [111,  2900] loss: 1.495
2025-02-25T08:02:45.960356+0300 | INFO | [111,  3000] loss: 1.496
2025-02-25T08:02:59.291375+0300 | INFO | [111,  3100] loss: 1.484
2025-02-25T08:03:10.397025+0300 | INFO | [111,  3200] loss: 1.493
2025-02-25T08:03:21.442758+0300 | INFO | [111,  3300] loss: 1.497
2025-02-25T08:03:31.970532+0300 | INFO | [111,  3400] loss: 1.496
2025-02-25T08:03:42.859200+0300 | INFO | [111,  3500] loss: 1.509
2025-02-25T08:03:53.527713+0300 | INFO | [111,  3600] loss: 1.502
2025-02-25T08:04:04.459105+0300 | INFO | [111,  3700] loss: 1.493
2025-02-25T08:04:15.540545+0300 | INFO | [111,  3800] loss: 1.491
2025-02-25T08:04:26.329425+0300 | INFO | [111,  3900] loss: 1.493
2025-02-25T08:04:39.005369+0300 | INFO | [111,  4000] loss: 1.493
2025-02-25T08:04:50.139114+0300 | INFO | [111,  4100] loss: 1.486
2025-02-25T08:05:01.184845+0300 | INFO | [111,  4200] loss: 1.486
2025-02-25T08:05:12.051725+0300 | INFO | [111,  4300] loss: 1.494
2025-02-25T08:05:25.640268+0300 | INFO | [111,  4400] loss: 1.506
2025-02-25T08:05:37.314887+0300 | INFO | [111,  4500] loss: 1.497
2025-02-25T08:05:50.888180+0300 | INFO | [111,  4600] loss: 1.492
2025-02-25T08:06:01.538636+0300 | INFO | [111,  4700] loss: 1.492
2025-02-25T08:06:12.492977+0300 | INFO | [111,  4800] loss: 1.492
2025-02-25T08:06:23.570403+0300 | INFO | [111,  4900] loss: 1.491
2025-02-25T08:06:34.767853+0300 | DEBUG | Saving model to flat file storage. Save #111
2025-02-25T08:06:34.787864+0300 | INFO | Averaging client parameters
2025-02-25T08:06:34.795381+0300 | INFO | Updating parameters on client #0
2025-02-25T08:06:51.200472+0300 | DEBUG | Test set: Accuracy: 7886/10000 (79%)
2025-02-25T08:06:51.201478+0300 | DEBUG | Test set: Loss: 1.6719236373901367
2025-02-25T08:06:51.305672+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.80      0.65      0.72      1000
           3       0.65      0.60      0.62      1200
           4       0.74      0.84      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.84      0.84      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.87      0.90      0.88      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T08:06:51.307631+0300 | DEBUG | Confusion Matrix:
[[845  15  34  16  16   8   3   6  41  16]
 [ 12 911   2   2   1   1   6   0  20  45]
 [ 63   1 654  54  76  71  48  16  11   6]
 [ 31   7  36 715  59 247  52  21  18  14]
 [  9   2  29  49 836  26  22  19   6   2]
 [ 10   1  25 169  40 496  15  35   7   2]
 [ 14   1  27  47  28  27 840   7   5   4]
 [ 20   1   6  33  60  53  10 804   4   9]
 [ 46  21   2   4   5   5   3   2 896  16]
 [ 23  44   2   7   2   2   2   5  24 889]]
2025-02-25T08:06:51.310637+0300 | DEBUG | Class precision: [0.78751165 0.90737052 0.8004896  0.65237226 0.74443455 0.52991453
 0.83916084 0.87868852 0.86821705 0.88634098]
2025-02-25T08:06:51.311758+0300 | DEBUG | Class recall: [0.845      0.911      0.654      0.59583333 0.836      0.62
 0.84       0.804      0.896      0.889     ]
2025-02-25T08:06:51.362585+0300 | INFO | Training epoch #112 on client #0
2025-02-25T08:06:51.364584+0300 | DEBUG | Saving model to flat file storage. Save #112
2025-02-25T08:06:51.529226+0300 | INFO | [112,     0] loss: 0.016
2025-02-25T08:07:02.084646+0300 | INFO | [112,   100] loss: 1.496
2025-02-25T08:07:12.949971+0300 | INFO | [112,   200] loss: 1.487
2025-02-25T08:07:23.812874+0300 | INFO | [112,   300] loss: 1.498
2025-02-25T08:07:34.704122+0300 | INFO | [112,   400] loss: 1.495
2025-02-25T08:07:45.672800+0300 | INFO | [112,   500] loss: 1.493
2025-02-25T08:07:57.604595+0300 | INFO | [112,   600] loss: 1.479
2025-02-25T08:08:12.574974+0300 | INFO | [112,   700] loss: 1.502
2025-02-25T08:08:23.422142+0300 | INFO | [112,   800] loss: 1.498
2025-02-25T08:08:34.464247+0300 | INFO | [112,   900] loss: 1.492
2025-02-25T08:08:45.448938+0300 | INFO | [112,  1000] loss: 1.491
2025-02-25T08:08:56.247093+0300 | INFO | [112,  1100] loss: 1.490
2025-02-25T08:09:07.236970+0300 | INFO | [112,  1200] loss: 1.498
2025-02-25T08:09:18.329363+0300 | INFO | [112,  1300] loss: 1.498
2025-02-25T08:09:29.692949+0300 | INFO | [112,  1400] loss: 1.498
2025-02-25T08:09:40.172126+0300 | INFO | [112,  1500] loss: 1.496
2025-02-25T08:09:51.286907+0300 | INFO | [112,  1600] loss: 1.492
2025-02-25T08:10:02.108504+0300 | INFO | [112,  1700] loss: 1.487
2025-02-25T08:10:13.030112+0300 | INFO | [112,  1800] loss: 1.497
2025-02-25T08:10:24.315125+0300 | INFO | [112,  1900] loss: 1.480
2025-02-25T08:10:35.286114+0300 | INFO | [112,  2000] loss: 1.492
2025-02-25T08:10:46.220557+0300 | INFO | [112,  2100] loss: 1.511
2025-02-25T08:10:57.194322+0300 | INFO | [112,  2200] loss: 1.489
2025-02-25T08:11:07.332189+0300 | INFO | [112,  2300] loss: 1.488
2025-02-25T08:11:18.293997+0300 | INFO | [112,  2400] loss: 1.497
2025-02-25T08:11:29.330372+0300 | INFO | [112,  2500] loss: 1.510
2025-02-25T08:11:40.056241+0300 | INFO | [112,  2600] loss: 1.508
2025-02-25T08:11:50.837205+0300 | INFO | [112,  2700] loss: 1.501
2025-02-25T08:12:01.470311+0300 | INFO | [112,  2800] loss: 1.489
2025-02-25T08:12:12.455313+0300 | INFO | [112,  2900] loss: 1.510
2025-02-25T08:12:23.436528+0300 | INFO | [112,  3000] loss: 1.488
2025-02-25T08:12:35.383881+0300 | INFO | [112,  3100] loss: 1.489
2025-02-25T08:12:48.599804+0300 | INFO | [112,  3200] loss: 1.496
2025-02-25T08:12:59.701533+0300 | INFO | [112,  3300] loss: 1.494
2025-02-25T08:13:10.111652+0300 | INFO | [112,  3400] loss: 1.499
2025-02-25T08:13:20.949992+0300 | INFO | [112,  3500] loss: 1.487
2025-02-25T08:13:31.773056+0300 | INFO | [112,  3600] loss: 1.494
2025-02-25T08:13:42.643052+0300 | INFO | [112,  3700] loss: 1.504
2025-02-25T08:13:53.763535+0300 | INFO | [112,  3800] loss: 1.501
2025-02-25T08:14:04.625387+0300 | INFO | [112,  3900] loss: 1.482
2025-02-25T08:14:15.532816+0300 | INFO | [112,  4000] loss: 1.494
2025-02-25T08:14:26.466564+0300 | INFO | [112,  4100] loss: 1.493
2025-02-25T08:14:37.488312+0300 | INFO | [112,  4200] loss: 1.497
2025-02-25T08:14:48.455478+0300 | INFO | [112,  4300] loss: 1.500
2025-02-25T08:15:00.660457+0300 | INFO | [112,  4400] loss: 1.484
2025-02-25T08:15:11.679202+0300 | INFO | [112,  4500] loss: 1.496
2025-02-25T08:15:22.519322+0300 | INFO | [112,  4600] loss: 1.502
2025-02-25T08:15:33.327765+0300 | INFO | [112,  4700] loss: 1.492
2025-02-25T08:15:45.042335+0300 | INFO | [112,  4800] loss: 1.492
2025-02-25T08:15:55.849892+0300 | INFO | [112,  4900] loss: 1.504
2025-02-25T08:16:06.370227+0300 | DEBUG | Saving model to flat file storage. Save #112
2025-02-25T08:16:06.393984+0300 | INFO | Averaging client parameters
2025-02-25T08:16:06.400983+0300 | INFO | Updating parameters on client #0
2025-02-25T08:16:23.276567+0300 | DEBUG | Test set: Accuracy: 7853/10000 (79%)
2025-02-25T08:16:23.280594+0300 | DEBUG | Test set: Loss: 1.673723578453064
2025-02-25T08:16:23.387724+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.64      0.59      0.62      1200
           4       0.76      0.83      0.79      1000
           5       0.53      0.60      0.56       800
           6       0.79      0.87      0.83      1000
           7       0.90      0.79      0.84      1000
           8       0.87      0.90      0.89      1000
           9       0.91      0.85      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T08:16:23.392722+0300 | DEBUG | Confusion Matrix:
[[819  16  48  14  15   8   7   7  46  20]
 [ 11 926   2   1   0   0   9   0  18  33]
 [ 53   1 677  51  62  64  63  14  10   5]
 [ 28   5  48 711  60 240  66  17  17   8]
 [  6   1  35  46 828  23  37  17   6   1]
 [  7   1  31 190  38 478  22  24   7   2]
 [  8   2  26  47  22  14 872   4   3   2]
 [ 16   1  12  35  59  65  14 792   3   3]
 [ 36  22   9   5   6   4   3   1 902  12]
 [ 23  71   4  10   2   4   8   5  25 848]]
2025-02-25T08:16:23.396236+0300 | DEBUG | Class precision: [0.81330685 0.88527725 0.75896861 0.64054054 0.75824176 0.53111111
 0.79200727 0.89897843 0.86981678 0.90792291]
2025-02-25T08:16:23.397237+0300 | DEBUG | Class recall: [0.819  0.926  0.677  0.5925 0.828  0.5975 0.872  0.792  0.902  0.848 ]
2025-02-25T08:16:23.454118+0300 | INFO | Training epoch #113 on client #0
2025-02-25T08:16:23.456118+0300 | DEBUG | Saving model to flat file storage. Save #113
2025-02-25T08:16:23.606283+0300 | INFO | [113,     0] loss: 0.016
2025-02-25T08:16:34.247466+0300 | INFO | [113,   100] loss: 1.498
2025-02-25T08:16:48.319918+0300 | INFO | [113,   200] loss: 1.494
2025-02-25T08:16:59.692848+0300 | INFO | [113,   300] loss: 1.492
2025-02-25T08:17:10.147219+0300 | INFO | [113,   400] loss: 1.493
2025-02-25T08:17:21.811508+0300 | INFO | [113,   500] loss: 1.497
2025-02-25T08:17:32.642362+0300 | INFO | [113,   600] loss: 1.493
2025-02-25T08:17:43.580138+0300 | INFO | [113,   700] loss: 1.487
2025-02-25T08:17:54.585643+0300 | INFO | [113,   800] loss: 1.489
2025-02-25T08:18:05.446256+0300 | INFO | [113,   900] loss: 1.504
2025-02-25T08:18:18.482646+0300 | INFO | [113,  1000] loss: 1.500
2025-02-25T08:18:29.465258+0300 | INFO | [113,  1100] loss: 1.495
2025-02-25T08:18:40.807900+0300 | INFO | [113,  1200] loss: 1.494
2025-02-25T08:18:51.617333+0300 | INFO | [113,  1300] loss: 1.486
2025-02-25T08:19:02.900048+0300 | INFO | [113,  1400] loss: 1.494
2025-02-25T08:19:13.837107+0300 | INFO | [113,  1500] loss: 1.500
2025-02-25T08:19:27.153277+0300 | INFO | [113,  1600] loss: 1.488
2025-02-25T08:19:39.717712+0300 | INFO | [113,  1700] loss: 1.504
2025-02-25T08:19:50.323947+0300 | INFO | [113,  1800] loss: 1.488
2025-02-25T08:20:00.866497+0300 | INFO | [113,  1900] loss: 1.504
2025-02-25T08:20:11.251771+0300 | INFO | [113,  2000] loss: 1.496
2025-02-25T08:20:22.299607+0300 | INFO | [113,  2100] loss: 1.494
2025-02-25T08:20:33.499845+0300 | INFO | [113,  2200] loss: 1.497
2025-02-25T08:20:44.037688+0300 | INFO | [113,  2300] loss: 1.497
2025-02-25T08:20:54.965110+0300 | INFO | [113,  2400] loss: 1.502
2025-02-25T08:21:05.620134+0300 | INFO | [113,  2500] loss: 1.490
2025-02-25T08:21:16.338497+0300 | INFO | [113,  2600] loss: 1.487
2025-02-25T08:21:27.235885+0300 | INFO | [113,  2700] loss: 1.487
2025-02-25T08:21:38.234284+0300 | INFO | [113,  2800] loss: 1.494
2025-02-25T08:21:49.240391+0300 | INFO | [113,  2900] loss: 1.494
2025-02-25T08:21:59.967803+0300 | INFO | [113,  3000] loss: 1.488
2025-02-25T08:22:10.965482+0300 | INFO | [113,  3100] loss: 1.489
2025-02-25T08:22:22.000562+0300 | INFO | [113,  3200] loss: 1.489
2025-02-25T08:22:32.910596+0300 | INFO | [113,  3300] loss: 1.486
2025-02-25T08:22:43.850586+0300 | INFO | [113,  3400] loss: 1.492
2025-02-25T08:22:54.773293+0300 | INFO | [113,  3500] loss: 1.493
2025-02-25T08:23:11.014126+0300 | INFO | [113,  3600] loss: 1.506
2025-02-25T08:23:21.671390+0300 | INFO | [113,  3700] loss: 1.491
2025-02-25T08:23:32.685646+0300 | INFO | [113,  3800] loss: 1.494
2025-02-25T08:23:43.813040+0300 | INFO | [113,  3900] loss: 1.496
2025-02-25T08:23:54.711587+0300 | INFO | [113,  4000] loss: 1.499
2025-02-25T08:24:08.384030+0300 | INFO | [113,  4100] loss: 1.502
2025-02-25T08:24:19.016699+0300 | INFO | [113,  4200] loss: 1.498
2025-02-25T08:24:30.133610+0300 | INFO | [113,  4300] loss: 1.485
2025-02-25T08:24:41.283401+0300 | INFO | [113,  4400] loss: 1.512
2025-02-25T08:24:52.818344+0300 | INFO | [113,  4500] loss: 1.492
2025-02-25T08:25:03.894218+0300 | INFO | [113,  4600] loss: 1.496
2025-02-25T08:25:15.081570+0300 | INFO | [113,  4700] loss: 1.490
2025-02-25T08:25:26.571049+0300 | INFO | [113,  4800] loss: 1.501
2025-02-25T08:25:37.581339+0300 | INFO | [113,  4900] loss: 1.494
2025-02-25T08:25:52.823064+0300 | DEBUG | Saving model to flat file storage. Save #113
2025-02-25T08:25:52.840767+0300 | INFO | Averaging client parameters
2025-02-25T08:25:52.848721+0300 | INFO | Updating parameters on client #0
2025-02-25T08:26:07.614002+0300 | DEBUG | Test set: Accuracy: 7866/10000 (79%)
2025-02-25T08:26:07.616000+0300 | DEBUG | Test set: Loss: 1.673658013343811
2025-02-25T08:26:07.713553+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.83      0.80      1000
           1       0.91      0.91      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.66      0.55      0.60      1200
           4       0.77      0.81      0.79      1000
           5       0.55      0.60      0.57       800
           6       0.82      0.85      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.85      0.91      0.88      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T08:26:07.717554+0300 | DEBUG | Confusion Matrix:
[[835   9  40  12   9   6   5   7  55  22]
 [ 16 913   2   2   0   1   4   2  20  40]
 [ 61   1 715  36  66  41  46  17  10   7]
 [ 42   6  57 661  60 259  59  23  20  13]
 [ 11   2  41  40 812  25  35  27   6   1]
 [ 15   1  41 166  34 478  20  36   8   1]
 [ 15   2  33  43  23  15 855   6   6   2]
 [ 23   1  18  32  50  43   8 816   7   2]
 [ 37  18   7   4   3   4   3   1 910  13]
 [ 29  47   3   7   2   5   5   6  25 871]]
2025-02-25T08:26:07.719555+0300 | DEBUG | Class precision: [0.7702952  0.913      0.74712644 0.65902293 0.7667611  0.54503991
 0.82211538 0.86716259 0.85285848 0.89609053]
2025-02-25T08:26:07.720556+0300 | DEBUG | Class recall: [0.835      0.913      0.715      0.55083333 0.812      0.5975
 0.855      0.816      0.91       0.871     ]
2025-02-25T08:26:07.776815+0300 | INFO | Training epoch #114 on client #0
2025-02-25T08:26:07.779816+0300 | DEBUG | Saving model to flat file storage. Save #114
2025-02-25T08:26:07.948245+0300 | INFO | [114,     0] loss: 0.015
2025-02-25T08:26:18.532004+0300 | INFO | [114,   100] loss: 1.494
2025-02-25T08:26:29.527704+0300 | INFO | [114,   200] loss: 1.491
2025-02-25T08:26:40.708889+0300 | INFO | [114,   300] loss: 1.489
2025-02-25T08:26:51.637613+0300 | INFO | [114,   400] loss: 1.512
2025-02-25T08:27:02.122363+0300 | INFO | [114,   500] loss: 1.498
2025-02-25T08:27:13.586311+0300 | INFO | [114,   600] loss: 1.496
2025-02-25T08:27:25.912298+0300 | INFO | [114,   700] loss: 1.493
2025-02-25T08:27:36.713923+0300 | INFO | [114,   800] loss: 1.496
2025-02-25T08:27:47.270122+0300 | INFO | [114,   900] loss: 1.505
2025-02-25T08:27:58.282545+0300 | INFO | [114,  1000] loss: 1.493
2025-02-25T08:28:08.947527+0300 | INFO | [114,  1100] loss: 1.500
2025-02-25T08:28:19.956732+0300 | INFO | [114,  1200] loss: 1.501
2025-02-25T08:28:31.089820+0300 | INFO | [114,  1300] loss: 1.500
2025-02-25T08:28:42.596781+0300 | INFO | [114,  1400] loss: 1.495
2025-02-25T08:28:53.591330+0300 | INFO | [114,  1500] loss: 1.497
2025-02-25T08:29:05.763401+0300 | INFO | [114,  1600] loss: 1.496
2025-02-25T08:29:16.735756+0300 | INFO | [114,  1700] loss: 1.485
2025-02-25T08:29:27.751491+0300 | INFO | [114,  1800] loss: 1.489
2025-02-25T08:29:38.690068+0300 | INFO | [114,  1900] loss: 1.487
2025-02-25T08:29:49.286335+0300 | INFO | [114,  2000] loss: 1.493
2025-02-25T08:30:00.015124+0300 | INFO | [114,  2100] loss: 1.497
2025-02-25T08:30:11.496756+0300 | INFO | [114,  2200] loss: 1.499
2025-02-25T08:30:22.562131+0300 | INFO | [114,  2300] loss: 1.496
2025-02-25T08:30:33.659433+0300 | INFO | [114,  2400] loss: 1.488
2025-02-25T08:30:43.983391+0300 | INFO | [114,  2500] loss: 1.494
2025-02-25T08:30:54.878542+0300 | INFO | [114,  2600] loss: 1.491
2025-02-25T08:31:05.172529+0300 | INFO | [114,  2700] loss: 1.489
2025-02-25T08:31:15.954745+0300 | INFO | [114,  2800] loss: 1.499
2025-02-25T08:31:28.997023+0300 | INFO | [114,  2900] loss: 1.499
2025-02-25T08:31:39.615469+0300 | INFO | [114,  3000] loss: 1.497
2025-02-25T08:31:51.078889+0300 | INFO | [114,  3100] loss: 1.493
2025-02-25T08:32:01.778818+0300 | INFO | [114,  3200] loss: 1.492
2025-02-25T08:32:12.294785+0300 | INFO | [114,  3300] loss: 1.498
2025-02-25T08:32:23.430452+0300 | INFO | [114,  3400] loss: 1.495
2025-02-25T08:32:34.355436+0300 | INFO | [114,  3500] loss: 1.499
2025-02-25T08:32:45.226104+0300 | INFO | [114,  3600] loss: 1.493
2025-02-25T08:32:56.045722+0300 | INFO | [114,  3700] loss: 1.486
2025-02-25T08:33:06.784536+0300 | INFO | [114,  3800] loss: 1.494
2025-02-25T08:33:17.770052+0300 | INFO | [114,  3900] loss: 1.495
2025-02-25T08:33:28.818075+0300 | INFO | [114,  4000] loss: 1.492
2025-02-25T08:33:39.763560+0300 | INFO | [114,  4100] loss: 1.491
2025-02-25T08:33:50.676911+0300 | INFO | [114,  4200] loss: 1.496
2025-02-25T08:34:02.721100+0300 | INFO | [114,  4300] loss: 1.488
2025-02-25T08:34:14.620523+0300 | INFO | [114,  4400] loss: 1.492
2025-02-25T08:34:26.894890+0300 | INFO | [114,  4500] loss: 1.490
2025-02-25T08:34:40.538356+0300 | INFO | [114,  4600] loss: 1.490
2025-02-25T08:34:51.417288+0300 | INFO | [114,  4700] loss: 1.495
2025-02-25T08:35:02.743261+0300 | INFO | [114,  4800] loss: 1.492
2025-02-25T08:35:14.493920+0300 | INFO | [114,  4900] loss: 1.485
2025-02-25T08:35:27.183340+0300 | DEBUG | Saving model to flat file storage. Save #114
2025-02-25T08:35:27.202350+0300 | INFO | Averaging client parameters
2025-02-25T08:35:27.213341+0300 | INFO | Updating parameters on client #0
2025-02-25T08:35:43.273388+0300 | DEBUG | Test set: Accuracy: 7873/10000 (79%)
2025-02-25T08:35:43.274596+0300 | DEBUG | Test set: Loss: 1.6726986169815063
2025-02-25T08:35:43.388380+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.90      0.91      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.66      0.56      0.61      1200
           4       0.76      0.81      0.79      1000
           5       0.51      0.62      0.56       800
           6       0.80      0.87      0.84      1000
           7       0.87      0.82      0.85      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T08:35:43.391383+0300 | DEBUG | Confusion Matrix:
[[826  16  39  17  12  11   7   6  43  23]
 [  9 913   2   4   1   4   7   3  13  44]
 [ 54   1 681  43  66  65  60  17   7   6]
 [ 22   6  48 675  57 285  58  24  14  11]
 [  8   2  37  41 815  35  36  22   3   1]
 [ 11   1  31 167  36 493  22  32   6   1]
 [  8   0  23  44  24  21 869   6   4   1]
 [ 15   1   9  27  55  53  12 823   2   3]
 [ 40  23   8   4   4   4   3   2 893  19]
 [ 15  48   4   6   3   4   7   9  19 885]]
2025-02-25T08:35:43.393896+0300 | DEBUG | Class precision: [0.81944444 0.90306627 0.77210884 0.65661479 0.75955266 0.50564103
 0.80388529 0.87182203 0.88944223 0.89034205]
2025-02-25T08:35:43.395404+0300 | DEBUG | Class recall: [0.826   0.913   0.681   0.5625  0.815   0.61625 0.869   0.823   0.893
 0.885  ]
2025-02-25T08:35:43.450314+0300 | INFO | Training epoch #115 on client #0
2025-02-25T08:35:43.451668+0300 | DEBUG | Saving model to flat file storage. Save #115
2025-02-25T08:35:43.593480+0300 | INFO | [115,     0] loss: 0.015
2025-02-25T08:35:54.444391+0300 | INFO | [115,   100] loss: 1.510
2025-02-25T08:36:04.821428+0300 | INFO | [115,   200] loss: 1.485
2025-02-25T08:36:15.935864+0300 | INFO | [115,   300] loss: 1.494
2025-02-25T08:36:26.873861+0300 | INFO | [115,   400] loss: 1.492
2025-02-25T08:36:37.757639+0300 | INFO | [115,   500] loss: 1.498
2025-02-25T08:36:49.012200+0300 | INFO | [115,   600] loss: 1.493
2025-02-25T08:36:59.619614+0300 | INFO | [115,   700] loss: 1.488
2025-02-25T08:37:10.483086+0300 | INFO | [115,   800] loss: 1.491
2025-02-25T08:37:21.542084+0300 | INFO | [115,   900] loss: 1.496
2025-02-25T08:37:31.368606+0300 | INFO | [115,  1000] loss: 1.498
2025-02-25T08:37:41.184365+0300 | INFO | [115,  1100] loss: 1.498
2025-02-25T08:37:51.022358+0300 | INFO | [115,  1200] loss: 1.503
2025-02-25T08:38:01.202880+0300 | INFO | [115,  1300] loss: 1.488
2025-02-25T08:38:13.068072+0300 | INFO | [115,  1400] loss: 1.502
2025-02-25T08:38:23.326681+0300 | INFO | [115,  1500] loss: 1.486
2025-02-25T08:38:33.834573+0300 | INFO | [115,  1600] loss: 1.500
2025-02-25T08:38:44.060190+0300 | INFO | [115,  1700] loss: 1.494
2025-02-25T08:38:54.054273+0300 | INFO | [115,  1800] loss: 1.491
2025-02-25T08:39:04.320542+0300 | INFO | [115,  1900] loss: 1.502
2025-02-25T08:39:15.003906+0300 | INFO | [115,  2000] loss: 1.503
2025-02-25T08:39:25.369381+0300 | INFO | [115,  2100] loss: 1.492
2025-02-25T08:39:35.845025+0300 | INFO | [115,  2200] loss: 1.484
2025-02-25T08:39:46.275136+0300 | INFO | [115,  2300] loss: 1.483
2025-02-25T08:39:56.471017+0300 | INFO | [115,  2400] loss: 1.491
2025-02-25T08:40:06.873082+0300 | INFO | [115,  2500] loss: 1.489
2025-02-25T08:40:17.104139+0300 | INFO | [115,  2600] loss: 1.501
2025-02-25T08:40:28.608902+0300 | INFO | [115,  2700] loss: 1.498
2025-02-25T08:40:38.636094+0300 | INFO | [115,  2800] loss: 1.494
2025-02-25T08:40:48.752254+0300 | INFO | [115,  2900] loss: 1.493
2025-02-25T08:40:59.187436+0300 | INFO | [115,  3000] loss: 1.495
2025-02-25T08:41:10.519822+0300 | INFO | [115,  3100] loss: 1.500
2025-02-25T08:41:21.351656+0300 | INFO | [115,  3200] loss: 1.488
2025-02-25T08:41:32.374663+0300 | INFO | [115,  3300] loss: 1.486
2025-02-25T08:41:43.181522+0300 | INFO | [115,  3400] loss: 1.499
2025-02-25T08:41:54.184031+0300 | INFO | [115,  3500] loss: 1.484
2025-02-25T08:42:04.632010+0300 | INFO | [115,  3600] loss: 1.484
2025-02-25T08:42:19.603965+0300 | INFO | [115,  3700] loss: 1.499
2025-02-25T08:43:22.984000+0300 | INFO | [115,  3800] loss: 1.500
2025-02-25T08:44:13.497047+0300 | INFO | [115,  3900] loss: 1.496
2025-02-25T08:45:18.195075+0300 | INFO | [115,  4000] loss: 1.495
2025-02-25T08:45:38.696770+0300 | INFO | [115,  4100] loss: 1.503
2025-02-25T08:45:49.296892+0300 | INFO | [115,  4200] loss: 1.495
2025-02-25T08:46:30.517818+0300 | INFO | [115,  4300] loss: 1.493
2025-02-25T08:47:28.556080+0300 | INFO | [115,  4400] loss: 1.490
2025-02-25T08:48:30.373848+0300 | INFO | [115,  4500] loss: 1.496
2025-02-25T08:49:27.421793+0300 | INFO | [115,  4600] loss: 1.498
2025-02-25T08:50:56.331407+0300 | INFO | [115,  4700] loss: 1.489
2025-02-25T08:52:10.517276+0300 | INFO | [115,  4800] loss: 1.487
2025-02-25T08:53:47.273005+0300 | INFO | [115,  4900] loss: 1.488
2025-02-25T08:54:59.962697+0300 | DEBUG | Saving model to flat file storage. Save #115
2025-02-25T08:55:00.036653+0300 | INFO | Averaging client parameters
2025-02-25T08:55:00.067698+0300 | INFO | Updating parameters on client #0
2025-02-25T08:55:49.320020+0300 | DEBUG | Test set: Accuracy: 7904/10000 (79%)
2025-02-25T08:55:49.323574+0300 | DEBUG | Test set: Loss: 1.6703672409057617
2025-02-25T08:55:49.424490+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.90      0.93      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.70      0.53      0.61      1200
           4       0.75      0.83      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.82      0.87      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T08:55:49.427023+0300 | DEBUG | Confusion Matrix:
[[842  14  34   8  11   9   3   7  51  21]
 [ 12 925   3   0   0   0   5   1  13  41]
 [ 66   2 688  35  70  51  54  15  10   9]
 [ 38   7  52 638  58 297  58  23  16  13]
 [ 13   2  33  30 834  33  28  22   3   2]
 [ 17   2  37 136  35 507  23  36   6   1]
 [ 13   1  26  36  29  14 866   5   6   4]
 [ 21   0  12  20  61  49  12 817   2   6]
 [ 36  21   5   3   5   3   3   2 903  19]
 [ 20  55   3   3   2   5   5   7  16 884]]
2025-02-25T08:55:49.429027+0300 | DEBUG | Class precision: [0.78107607 0.898931   0.77043673 0.70187019 0.75475113 0.52376033
 0.81929991 0.87379679 0.88011696 0.884     ]
2025-02-25T08:55:49.431821+0300 | DEBUG | Class recall: [0.842      0.925      0.688      0.53166667 0.834      0.63375
 0.866      0.817      0.903      0.884     ]
2025-02-25T08:55:49.477720+0300 | INFO | Training epoch #116 on client #0
2025-02-25T08:55:49.479963+0300 | DEBUG | Saving model to flat file storage. Save #116
2025-02-25T08:55:49.614676+0300 | INFO | [116,     0] loss: 0.016
2025-02-25T08:55:59.337211+0300 | INFO | [116,   100] loss: 1.488
2025-02-25T08:56:09.568225+0300 | INFO | [116,   200] loss: 1.500
2025-02-25T08:56:20.251994+0300 | INFO | [116,   300] loss: 1.494
2025-02-25T08:56:30.258127+0300 | INFO | [116,   400] loss: 1.504
2025-02-25T08:56:39.116065+0300 | INFO | [116,   500] loss: 1.488
2025-02-25T08:56:48.666119+0300 | INFO | [116,   600] loss: 1.490
2025-02-25T08:56:58.059963+0300 | INFO | [116,   700] loss: 1.499
2025-02-25T08:57:07.485817+0300 | INFO | [116,   800] loss: 1.499
2025-02-25T08:57:16.748977+0300 | INFO | [116,   900] loss: 1.496
2025-02-25T08:57:26.078733+0300 | INFO | [116,  1000] loss: 1.491
2025-02-25T08:57:36.030896+0300 | INFO | [116,  1100] loss: 1.489
2025-02-25T08:57:46.540023+0300 | INFO | [116,  1200] loss: 1.493
2025-02-25T08:57:57.742528+0300 | INFO | [116,  1300] loss: 1.492
2025-02-25T08:58:08.020972+0300 | INFO | [116,  1400] loss: 1.499
2025-02-25T08:58:18.624207+0300 | INFO | [116,  1500] loss: 1.494
2025-02-25T08:58:31.581808+0300 | INFO | [116,  1600] loss: 1.492
2025-02-25T08:58:41.614848+0300 | INFO | [116,  1700] loss: 1.491
2025-02-25T08:58:51.577840+0300 | INFO | [116,  1800] loss: 1.489
2025-02-25T08:59:01.051748+0300 | INFO | [116,  1900] loss: 1.483
2025-02-25T08:59:10.466135+0300 | INFO | [116,  2000] loss: 1.501
2025-02-25T08:59:19.568832+0300 | INFO | [116,  2100] loss: 1.493
2025-02-25T08:59:31.578443+0300 | INFO | [116,  2200] loss: 1.494
2025-02-25T08:59:40.748571+0300 | INFO | [116,  2300] loss: 1.492
2025-02-25T08:59:50.886308+0300 | INFO | [116,  2400] loss: 1.492
2025-02-25T09:00:00.356747+0300 | INFO | [116,  2500] loss: 1.500
2025-02-25T09:00:10.617672+0300 | INFO | [116,  2600] loss: 1.488
2025-02-25T09:00:20.745139+0300 | INFO | [116,  2700] loss: 1.503
2025-02-25T09:00:29.693860+0300 | INFO | [116,  2800] loss: 1.497
2025-02-25T09:00:38.033574+0300 | INFO | [116,  2900] loss: 1.491
2025-02-25T09:00:48.402529+0300 | INFO | [116,  3000] loss: 1.499
2025-02-25T09:00:58.626290+0300 | INFO | [116,  3100] loss: 1.493
2025-02-25T09:01:09.617691+0300 | INFO | [116,  3200] loss: 1.482
2025-02-25T09:01:20.153127+0300 | INFO | [116,  3300] loss: 1.497
2025-02-25T09:01:31.081187+0300 | INFO | [116,  3400] loss: 1.495
2025-02-25T09:01:41.389582+0300 | INFO | [116,  3500] loss: 1.492
2025-02-25T09:01:54.541027+0300 | INFO | [116,  3600] loss: 1.490
2025-02-25T09:02:05.155537+0300 | INFO | [116,  3700] loss: 1.496
2025-02-25T09:02:14.168278+0300 | INFO | [116,  3800] loss: 1.495
2025-02-25T09:02:24.859454+0300 | INFO | [116,  3900] loss: 1.502
2025-02-25T09:02:35.396337+0300 | INFO | [116,  4000] loss: 1.498
2025-02-25T09:02:47.929168+0300 | INFO | [116,  4100] loss: 1.491
2025-02-25T09:02:58.158412+0300 | INFO | [116,  4200] loss: 1.491
2025-02-25T09:03:08.772366+0300 | INFO | [116,  4300] loss: 1.486
2025-02-25T09:03:18.078343+0300 | INFO | [116,  4400] loss: 1.484
2025-02-25T09:03:27.826526+0300 | INFO | [116,  4500] loss: 1.491
2025-02-25T09:03:38.023509+0300 | INFO | [116,  4600] loss: 1.496
2025-02-25T09:03:48.955176+0300 | INFO | [116,  4700] loss: 1.498
2025-02-25T09:03:59.112036+0300 | INFO | [116,  4800] loss: 1.496
2025-02-25T09:04:09.248636+0300 | INFO | [116,  4900] loss: 1.497
2025-02-25T09:04:20.049180+0300 | DEBUG | Saving model to flat file storage. Save #116
2025-02-25T09:04:20.071709+0300 | INFO | Averaging client parameters
2025-02-25T09:04:20.084665+0300 | INFO | Updating parameters on client #0
2025-02-25T09:04:34.984015+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-25T09:04:34.986793+0300 | DEBUG | Test set: Loss: 1.6728222370147705
2025-02-25T09:04:35.082145+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.91      0.93      0.92      1000
           2       0.73      0.70      0.72      1000
           3       0.70      0.52      0.60      1200
           4       0.75      0.84      0.79      1000
           5       0.51      0.66      0.58       800
           6       0.84      0.85      0.85      1000
           7       0.87      0.79      0.83      1000
           8       0.88      0.90      0.89      1000
           9       0.90      0.87      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T09:04:35.083156+0300 | DEBUG | Confusion Matrix:
[[843  13  51   9  11   7   4   5  43  14]
 [ 15 929   2   0   0   0   3   1  20  30]
 [ 61   2 704  36  63  55  48  16   9   6]
 [ 34   6  64 620  60 311  51  25  15  14]
 [ 10   2  42  29 836  37  24  15   3   2]
 [ 12   1  37 125  37 529  14  38   6   1]
 [ 13   1  35  36  22  25 853   4   7   4]
 [ 24   2  15  20  73  58   9 793   2   4]
 [ 43  16   6   4   4   4   4   1 901  17]
 [ 24  54   6   4   2   4   4   9  23 870]]
2025-02-25T09:04:35.083156+0300 | DEBUG | Class precision: [0.78127896 0.90545809 0.73180873 0.70215176 0.75451264 0.51359223
 0.84122288 0.87431092 0.87560739 0.9043659 ]
2025-02-25T09:04:35.084564+0300 | DEBUG | Class recall: [0.843      0.929      0.704      0.51666667 0.836      0.66125
 0.853      0.793      0.901      0.87      ]
2025-02-25T09:04:35.135922+0300 | INFO | Training epoch #117 on client #0
2025-02-25T09:04:35.139298+0300 | DEBUG | Saving model to flat file storage. Save #117
2025-02-25T09:04:35.273542+0300 | INFO | [117,     0] loss: 0.015
2025-02-25T09:04:45.385573+0300 | INFO | [117,   100] loss: 1.500
2025-02-25T09:04:55.659889+0300 | INFO | [117,   200] loss: 1.490
2025-02-25T09:05:05.839286+0300 | INFO | [117,   300] loss: 1.496
2025-02-25T09:05:17.925600+0300 | INFO | [117,   400] loss: 1.500
2025-02-25T09:05:29.231113+0300 | INFO | [117,   500] loss: 1.491
2025-02-25T09:05:42.382814+0300 | INFO | [117,   600] loss: 1.495
2025-02-25T09:05:56.168049+0300 | INFO | [117,   700] loss: 1.494
2025-02-25T09:06:10.585840+0300 | INFO | [117,   800] loss: 1.492
2025-02-25T09:06:25.457002+0300 | INFO | [117,   900] loss: 1.503
2025-02-25T09:06:38.686189+0300 | INFO | [117,  1000] loss: 1.502
2025-02-25T09:06:52.213899+0300 | INFO | [117,  1100] loss: 1.497
2025-02-25T09:07:05.780861+0300 | INFO | [117,  1200] loss: 1.494
2025-02-25T09:07:18.651743+0300 | INFO | [117,  1300] loss: 1.496
2025-02-25T09:07:30.463851+0300 | INFO | [117,  1400] loss: 1.483
2025-02-25T09:07:42.539102+0300 | INFO | [117,  1500] loss: 1.494
2025-02-25T09:07:54.483193+0300 | INFO | [117,  1600] loss: 1.486
2025-02-25T09:08:07.171499+0300 | INFO | [117,  1700] loss: 1.487
2025-02-25T09:08:18.373419+0300 | INFO | [117,  1800] loss: 1.489
2025-02-25T09:08:29.637718+0300 | INFO | [117,  1900] loss: 1.486
2025-02-25T09:08:43.651546+0300 | INFO | [117,  2000] loss: 1.503
2025-02-25T09:08:56.111984+0300 | INFO | [117,  2100] loss: 1.491
2025-02-25T09:09:07.174050+0300 | INFO | [117,  2200] loss: 1.491
2025-02-25T09:09:18.362855+0300 | INFO | [117,  2300] loss: 1.507
2025-02-25T09:09:31.055613+0300 | INFO | [117,  2400] loss: 1.484
2025-02-25T09:09:41.949795+0300 | INFO | [117,  2500] loss: 1.501
2025-02-25T09:09:53.223469+0300 | INFO | [117,  2600] loss: 1.499
2025-02-25T09:10:04.629229+0300 | INFO | [117,  2700] loss: 1.487
2025-02-25T09:10:18.854107+0300 | INFO | [117,  2800] loss: 1.493
2025-02-25T09:10:30.048326+0300 | INFO | [117,  2900] loss: 1.491
2025-02-25T09:10:44.730457+0300 | INFO | [117,  3000] loss: 1.495
2025-02-25T09:10:56.186150+0300 | INFO | [117,  3100] loss: 1.496
2025-02-25T09:11:09.705490+0300 | INFO | [117,  3200] loss: 1.492
2025-02-25T09:11:25.344356+0300 | INFO | [117,  3300] loss: 1.496
2025-02-25T09:11:36.842484+0300 | INFO | [117,  3400] loss: 1.496
2025-02-25T09:11:48.103127+0300 | INFO | [117,  3500] loss: 1.489
2025-02-25T09:11:59.533716+0300 | INFO | [117,  3600] loss: 1.494
2025-02-25T09:12:10.867004+0300 | INFO | [117,  3700] loss: 1.496
2025-02-25T09:12:23.635956+0300 | INFO | [117,  3800] loss: 1.494
2025-02-25T09:12:34.410764+0300 | INFO | [117,  3900] loss: 1.492
2025-02-25T09:12:45.869106+0300 | INFO | [117,  4000] loss: 1.494
2025-02-25T09:12:56.978775+0300 | INFO | [117,  4100] loss: 1.505
2025-02-25T09:13:08.192714+0300 | INFO | [117,  4200] loss: 1.480
2025-02-25T09:13:20.316611+0300 | INFO | [117,  4300] loss: 1.492
2025-02-25T09:13:31.434565+0300 | INFO | [117,  4400] loss: 1.489
2025-02-25T09:13:45.718825+0300 | INFO | [117,  4500] loss: 1.492
2025-02-25T09:13:56.960704+0300 | INFO | [117,  4600] loss: 1.484
2025-02-25T09:14:09.292949+0300 | INFO | [117,  4700] loss: 1.486
2025-02-25T09:14:20.331953+0300 | INFO | [117,  4800] loss: 1.502
2025-02-25T09:14:31.513506+0300 | INFO | [117,  4900] loss: 1.497
2025-02-25T09:14:42.229711+0300 | DEBUG | Saving model to flat file storage. Save #117
2025-02-25T09:14:42.254844+0300 | INFO | Averaging client parameters
2025-02-25T09:14:42.264196+0300 | INFO | Updating parameters on client #0
2025-02-25T09:14:58.646591+0300 | DEBUG | Test set: Accuracy: 7894/10000 (79%)
2025-02-25T09:14:58.649585+0300 | DEBUG | Test set: Loss: 1.670906662940979
2025-02-25T09:14:58.752549+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.66      0.57      0.61      1200
           4       0.79      0.80      0.80      1000
           5       0.51      0.62      0.56       800
           6       0.82      0.87      0.84      1000
           7       0.88      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T09:14:58.754564+0300 | DEBUG | Confusion Matrix:
[[831  14  46   9  12  10   7   6  39  26]
 [ 11 919   3   1   0   0   8   0  17  41]
 [ 53   3 700  49  54  57  56  10   8  10]
 [ 30   8  53 683  47 279  49  23  11  17]
 [ 12   3  38  40 802  38  36  25   4   2]
 [ 11   1  37 165  27 495  17  36   6   5]
 [  7   0  26  44  18  24 867   5   4   5]
 [ 16   2  15  28  46  57  12 813   2   9]
 [ 46  17   6   3   3   4   4   3 893  21]
 [ 18  51   4   6   2   2   6   6  14 891]]
2025-02-25T09:14:58.756576+0300 | DEBUG | Class precision: [0.80289855 0.90275049 0.75431034 0.66439689 0.79327399 0.51242236
 0.81638418 0.87702265 0.89478958 0.86757546]
2025-02-25T09:14:58.758575+0300 | DEBUG | Class recall: [0.831      0.919      0.7        0.56916667 0.802      0.61875
 0.867      0.813      0.893      0.891     ]
2025-02-25T09:14:58.807117+0300 | INFO | Training epoch #118 on client #0
2025-02-25T09:14:58.809643+0300 | DEBUG | Saving model to flat file storage. Save #118
2025-02-25T09:14:58.964581+0300 | INFO | [118,     0] loss: 0.015
2025-02-25T09:15:10.224230+0300 | INFO | [118,   100] loss: 1.498
2025-02-25T09:15:21.698041+0300 | INFO | [118,   200] loss: 1.495
2025-02-25T09:15:32.553060+0300 | INFO | [118,   300] loss: 1.490
2025-02-25T09:15:43.558734+0300 | INFO | [118,   400] loss: 1.493
2025-02-25T09:15:56.665932+0300 | INFO | [118,   500] loss: 1.488
2025-02-25T09:16:09.410276+0300 | INFO | [118,   600] loss: 1.504
2025-02-25T09:16:21.972621+0300 | INFO | [118,   700] loss: 1.497
2025-02-25T09:16:34.651356+0300 | INFO | [118,   800] loss: 1.490
2025-02-25T09:16:46.695018+0300 | INFO | [118,   900] loss: 1.494
2025-02-25T09:16:58.557438+0300 | INFO | [118,  1000] loss: 1.492
2025-02-25T09:17:10.548339+0300 | INFO | [118,  1100] loss: 1.485
2025-02-25T09:17:22.601135+0300 | INFO | [118,  1200] loss: 1.490
2025-02-25T09:17:35.096269+0300 | INFO | [118,  1300] loss: 1.493
2025-02-25T09:17:48.296560+0300 | INFO | [118,  1400] loss: 1.495
2025-02-25T09:18:01.017088+0300 | INFO | [118,  1500] loss: 1.489
2025-02-25T09:18:15.344014+0300 | INFO | [118,  1600] loss: 1.484
2025-02-25T09:18:26.677226+0300 | INFO | [118,  1700] loss: 1.500
2025-02-25T09:18:38.028878+0300 | INFO | [118,  1800] loss: 1.512
2025-02-25T09:18:49.623952+0300 | INFO | [118,  1900] loss: 1.493
2025-02-25T09:19:01.311553+0300 | INFO | [118,  2000] loss: 1.492
2025-02-25T09:19:13.002825+0300 | INFO | [118,  2100] loss: 1.491
2025-02-25T09:19:25.210960+0300 | INFO | [118,  2200] loss: 1.494
2025-02-25T09:19:39.930989+0300 | INFO | [118,  2300] loss: 1.500
2025-02-25T09:19:53.953489+0300 | INFO | [118,  2400] loss: 1.507
2025-02-25T09:20:05.666479+0300 | INFO | [118,  2500] loss: 1.491
2025-02-25T09:20:17.094698+0300 | INFO | [118,  2600] loss: 1.491
2025-02-25T09:20:29.497102+0300 | INFO | [118,  2700] loss: 1.494
2025-02-25T09:20:45.388336+0300 | INFO | [118,  2800] loss: 1.498
2025-02-25T09:20:57.000238+0300 | INFO | [118,  2900] loss: 1.486
2025-02-25T09:21:09.276488+0300 | INFO | [118,  3000] loss: 1.500
2025-02-25T09:21:20.911362+0300 | INFO | [118,  3100] loss: 1.491
2025-02-25T09:21:32.880897+0300 | INFO | [118,  3200] loss: 1.492
2025-02-25T09:21:45.524920+0300 | INFO | [118,  3300] loss: 1.491
2025-02-25T09:21:57.600523+0300 | INFO | [118,  3400] loss: 1.490
2025-02-25T09:22:08.816336+0300 | INFO | [118,  3500] loss: 1.496
2025-02-25T09:22:21.233771+0300 | INFO | [118,  3600] loss: 1.496
2025-02-25T09:22:32.255290+0300 | INFO | [118,  3700] loss: 1.496
2025-02-25T09:22:43.331482+0300 | INFO | [118,  3800] loss: 1.487
2025-02-25T09:22:55.672613+0300 | INFO | [118,  3900] loss: 1.494
2025-02-25T09:23:09.525154+0300 | INFO | [118,  4000] loss: 1.492
2025-02-25T09:23:21.828803+0300 | INFO | [118,  4100] loss: 1.493
2025-02-25T09:23:36.032835+0300 | INFO | [118,  4200] loss: 1.493
2025-02-25T09:23:47.805940+0300 | INFO | [118,  4300] loss: 1.500
2025-02-25T09:23:59.566899+0300 | INFO | [118,  4400] loss: 1.493
2025-02-25T09:24:11.415463+0300 | INFO | [118,  4500] loss: 1.492
2025-02-25T09:24:22.583327+0300 | INFO | [118,  4600] loss: 1.495
2025-02-25T09:24:34.165876+0300 | INFO | [118,  4700] loss: 1.487
2025-02-25T09:24:45.756677+0300 | INFO | [118,  4800] loss: 1.494
2025-02-25T09:24:57.271924+0300 | INFO | [118,  4900] loss: 1.493
2025-02-25T09:25:09.137170+0300 | DEBUG | Saving model to flat file storage. Save #118
2025-02-25T09:25:09.155226+0300 | INFO | Averaging client parameters
2025-02-25T09:25:09.167551+0300 | INFO | Updating parameters on client #0
2025-02-25T09:25:27.452423+0300 | DEBUG | Test set: Accuracy: 7850/10000 (78%)
2025-02-25T09:25:27.453432+0300 | DEBUG | Test set: Loss: 1.6752259731292725
2025-02-25T09:25:27.555842+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.68      0.71      1000
           3       0.66      0.58      0.61      1200
           4       0.74      0.82      0.78      1000
           5       0.53      0.58      0.55       800
           6       0.82      0.85      0.84      1000
           7       0.88      0.79      0.84      1000
           8       0.91      0.88      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T09:25:27.558887+0300 | DEBUG | Confusion Matrix:
[[846  16  35  12  11   8   6   6  34  26]
 [ 11 928   1   1   0   0   7   0  11  41]
 [ 68   3 680  38  72  52  55  16   8   8]
 [ 31   8  60 694  60 249  55  20  11  12]
 [ 12   2  40  48 820  26  26  21   3   2]
 [ 13   1  45 181  36 466  21  32   5   0]
 [ 13   2  29  40  34  18 855   1   3   5]
 [ 24   1  17  32  61  56  11 794   1   3]
 [ 46  26   4   6   6   6   3   2 879  22]
 [ 17  54   3   7   2   4   4   6  15 888]]
2025-02-25T09:25:27.562955+0300 | DEBUG | Class precision: [0.7826087  0.89145053 0.74398249 0.65533522 0.74410163 0.52655367
 0.81975072 0.88418708 0.90618557 0.88182721]
2025-02-25T09:25:27.564138+0300 | DEBUG | Class recall: [0.846      0.928      0.68       0.57833333 0.82       0.5825
 0.855      0.794      0.879      0.888     ]
2025-02-25T09:25:27.618456+0300 | INFO | Training epoch #119 on client #0
2025-02-25T09:25:27.620883+0300 | DEBUG | Saving model to flat file storage. Save #119
2025-02-25T09:25:27.763108+0300 | INFO | [119,     0] loss: 0.016
2025-02-25T09:25:38.739099+0300 | INFO | [119,   100] loss: 1.489
2025-02-25T09:25:55.206864+0300 | INFO | [119,   200] loss: 1.500
2025-02-25T09:26:08.363181+0300 | INFO | [119,   300] loss: 1.499
2025-02-25T09:26:24.080989+0300 | INFO | [119,   400] loss: 1.487
2025-02-25T09:26:36.432166+0300 | INFO | [119,   500] loss: 1.500
2025-02-25T09:26:49.544371+0300 | INFO | [119,   600] loss: 1.489
2025-02-25T09:27:02.060884+0300 | INFO | [119,   700] loss: 1.492
2025-02-25T09:27:14.623970+0300 | INFO | [119,   800] loss: 1.490
2025-02-25T09:27:28.034138+0300 | INFO | [119,   900] loss: 1.490
2025-02-25T09:27:41.200661+0300 | INFO | [119,  1000] loss: 1.487
2025-02-25T09:27:53.668076+0300 | INFO | [119,  1100] loss: 1.501
2025-02-25T09:28:07.005090+0300 | INFO | [119,  1200] loss: 1.494
2025-02-25T09:28:19.377799+0300 | INFO | [119,  1300] loss: 1.489
2025-02-25T09:28:31.765154+0300 | INFO | [119,  1400] loss: 1.498
2025-02-25T09:28:44.437876+0300 | INFO | [119,  1500] loss: 1.485
2025-02-25T09:28:57.238983+0300 | INFO | [119,  1600] loss: 1.494
2025-02-25T09:29:11.716471+0300 | INFO | [119,  1700] loss: 1.496
2025-02-25T09:29:25.461911+0300 | INFO | [119,  1800] loss: 1.493
2025-02-25T09:29:37.818383+0300 | INFO | [119,  1900] loss: 1.496
2025-02-25T09:29:50.187988+0300 | INFO | [119,  2000] loss: 1.497
2025-02-25T09:30:02.865954+0300 | INFO | [119,  2100] loss: 1.494
2025-02-25T09:30:17.425621+0300 | INFO | [119,  2200] loss: 1.491
2025-02-25T09:30:33.097912+0300 | INFO | [119,  2300] loss: 1.498
2025-02-25T09:30:45.390703+0300 | INFO | [119,  2400] loss: 1.503
2025-02-25T09:30:57.721270+0300 | INFO | [119,  2500] loss: 1.492
2025-02-25T09:31:10.345174+0300 | INFO | [119,  2600] loss: 1.493
2025-02-25T09:31:26.055699+0300 | INFO | [119,  2700] loss: 1.484
2025-02-25T09:31:38.272029+0300 | INFO | [119,  2800] loss: 1.485
2025-02-25T09:31:51.368069+0300 | INFO | [119,  2900] loss: 1.495
2025-02-25T09:32:06.549456+0300 | INFO | [119,  3000] loss: 1.486
2025-02-25T09:32:19.495522+0300 | INFO | [119,  3100] loss: 1.497
2025-02-25T09:32:31.810968+0300 | INFO | [119,  3200] loss: 1.505
2025-02-25T09:32:44.117897+0300 | INFO | [119,  3300] loss: 1.494
2025-02-25T09:32:56.683360+0300 | INFO | [119,  3400] loss: 1.490
2025-02-25T09:33:09.079150+0300 | INFO | [119,  3500] loss: 1.504
2025-02-25T09:33:24.150566+0300 | INFO | [119,  3600] loss: 1.491
2025-02-25T09:33:36.276516+0300 | INFO | [119,  3700] loss: 1.494
2025-02-25T09:33:48.695945+0300 | INFO | [119,  3800] loss: 1.500
2025-02-25T09:34:01.372376+0300 | INFO | [119,  3900] loss: 1.494
2025-02-25T09:34:14.280941+0300 | INFO | [119,  4000] loss: 1.494
2025-02-25T09:34:27.053962+0300 | INFO | [119,  4100] loss: 1.486
2025-02-25T09:34:39.268985+0300 | INFO | [119,  4200] loss: 1.501
2025-02-25T09:34:51.834413+0300 | INFO | [119,  4300] loss: 1.491
2025-02-25T09:35:07.364139+0300 | INFO | [119,  4400] loss: 1.484
2025-02-25T09:35:20.225923+0300 | INFO | [119,  4500] loss: 1.496
2025-02-25T09:35:33.375289+0300 | INFO | [119,  4600] loss: 1.495
2025-02-25T09:35:46.519035+0300 | INFO | [119,  4700] loss: 1.494
2025-02-25T09:35:59.136427+0300 | INFO | [119,  4800] loss: 1.486
2025-02-25T09:36:11.646387+0300 | INFO | [119,  4900] loss: 1.497
2025-02-25T09:36:23.635993+0300 | DEBUG | Saving model to flat file storage. Save #119
2025-02-25T09:36:23.667154+0300 | INFO | Averaging client parameters
2025-02-25T09:36:23.676601+0300 | INFO | Updating parameters on client #0
2025-02-25T09:36:40.881313+0300 | DEBUG | Test set: Accuracy: 7895/10000 (79%)
2025-02-25T09:36:40.883491+0300 | DEBUG | Test set: Loss: 1.6714863777160645
2025-02-25T09:36:40.996121+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.91      0.91      0.91      1000
           2       0.73      0.70      0.72      1000
           3       0.69      0.54      0.60      1200
           4       0.78      0.81      0.79      1000
           5       0.53      0.63      0.57       800
           6       0.84      0.85      0.84      1000
           7       0.86      0.83      0.85      1000
           8       0.89      0.90      0.89      1000
           9       0.88      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T09:36:40.998043+0300 | DEBUG | Confusion Matrix:
[[855   8  34  11  10   7   4   7  41  23]
 [ 16 911   3   0   0   0   5   2  16  47]
 [ 65   1 705  36  56  54  47  21   8   7]
 [ 36   8  70 647  55 280  50  26  14  14]
 [ 14   2  46  40 805  33  30  24   4   2]
 [ 14   2  45 139  31 503  15  42   6   3]
 [ 19   3  36  31  28  20 850   3   6   4]
 [ 19   0  19  29  46  47   5 830   2   3]
 [ 43  21   3   5   3   4   3   3 898  17]
 [ 24  44   3   5   1   5   4   6  17 891]]
2025-02-25T09:36:41.002222+0300 | DEBUG | Class precision: [0.77375566 0.911      0.7313278  0.68610817 0.77777778 0.52780693
 0.83909181 0.86099585 0.88735178 0.88130564]
2025-02-25T09:36:41.003233+0300 | DEBUG | Class recall: [0.855      0.911      0.705      0.53916667 0.805      0.62875
 0.85       0.83       0.898      0.891     ]
2025-02-25T09:36:41.056091+0300 | INFO | Training epoch #120 on client #0
2025-02-25T09:36:41.057603+0300 | DEBUG | Saving model to flat file storage. Save #120
2025-02-25T09:36:41.193125+0300 | INFO | [120,     0] loss: 0.015
2025-02-25T09:36:52.755669+0300 | INFO | [120,   100] loss: 1.500
2025-02-25T09:37:04.982336+0300 | INFO | [120,   200] loss: 1.499
2025-02-25T09:37:16.953050+0300 | INFO | [120,   300] loss: 1.492
2025-02-25T09:37:28.465153+0300 | INFO | [120,   400] loss: 1.496
2025-02-25T09:37:38.945317+0300 | INFO | [120,   500] loss: 1.490
2025-02-25T09:37:49.847646+0300 | INFO | [120,   600] loss: 1.504
2025-02-25T09:38:01.321754+0300 | INFO | [120,   700] loss: 1.492
2025-02-25T09:38:13.422228+0300 | INFO | [120,   800] loss: 1.499
2025-02-25T09:38:25.733289+0300 | INFO | [120,   900] loss: 1.490
2025-02-25T09:38:36.828113+0300 | INFO | [120,  1000] loss: 1.490
2025-02-25T09:38:48.083305+0300 | INFO | [120,  1100] loss: 1.489
2025-02-25T09:39:00.109720+0300 | INFO | [120,  1200] loss: 1.491
2025-02-25T09:39:10.935198+0300 | INFO | [120,  1300] loss: 1.489
2025-02-25T09:39:21.948540+0300 | INFO | [120,  1400] loss: 1.486
2025-02-25T09:39:33.849644+0300 | INFO | [120,  1500] loss: 1.504
2025-02-25T09:39:44.801449+0300 | INFO | [120,  1600] loss: 1.493
2025-02-25T09:39:56.470858+0300 | INFO | [120,  1700] loss: 1.494
2025-02-25T09:40:07.664086+0300 | INFO | [120,  1800] loss: 1.487
2025-02-25T09:40:19.919773+0300 | INFO | [120,  1900] loss: 1.499
2025-02-25T09:40:34.770902+0300 | INFO | [120,  2000] loss: 1.499
2025-02-25T09:40:45.813566+0300 | INFO | [120,  2100] loss: 1.493
2025-02-25T09:40:57.167983+0300 | INFO | [120,  2200] loss: 1.481
2025-02-25T09:41:08.696949+0300 | INFO | [120,  2300] loss: 1.498
2025-02-25T09:41:19.407647+0300 | INFO | [120,  2400] loss: 1.489
2025-02-25T09:41:30.483314+0300 | INFO | [120,  2500] loss: 1.502
2025-02-25T09:41:41.395323+0300 | INFO | [120,  2600] loss: 1.489
2025-02-25T09:41:52.020632+0300 | INFO | [120,  2700] loss: 1.502
2025-02-25T09:42:03.439602+0300 | INFO | [120,  2800] loss: 1.498
2025-02-25T09:42:15.410959+0300 | INFO | [120,  2900] loss: 1.484
2025-02-25T09:42:27.500599+0300 | INFO | [120,  3000] loss: 1.492
2025-02-25T09:42:39.029915+0300 | INFO | [120,  3100] loss: 1.492
2025-02-25T09:42:49.909945+0300 | INFO | [120,  3200] loss: 1.494
2025-02-25T09:43:00.859207+0300 | INFO | [120,  3300] loss: 1.494
2025-02-25T09:43:11.534186+0300 | INFO | [120,  3400] loss: 1.496
2025-02-25T09:43:22.961867+0300 | INFO | [120,  3500] loss: 1.490
2025-02-25T09:43:34.114146+0300 | INFO | [120,  3600] loss: 1.495
2025-02-25T09:43:44.930350+0300 | INFO | [120,  3700] loss: 1.493
2025-02-25T09:43:56.086347+0300 | INFO | [120,  3800] loss: 1.489
2025-02-25T09:44:07.340484+0300 | INFO | [120,  3900] loss: 1.500
2025-02-25T09:44:17.773000+0300 | INFO | [120,  4000] loss: 1.490
2025-02-25T09:44:28.775737+0300 | INFO | [120,  4100] loss: 1.497
2025-02-25T09:44:39.571052+0300 | INFO | [120,  4200] loss: 1.490
2025-02-25T09:44:51.534701+0300 | INFO | [120,  4300] loss: 1.489
2025-02-25T09:45:02.453165+0300 | INFO | [120,  4400] loss: 1.491
2025-02-25T09:45:14.207561+0300 | INFO | [120,  4500] loss: 1.499
2025-02-25T09:45:26.067194+0300 | INFO | [120,  4600] loss: 1.499
2025-02-25T09:45:37.037934+0300 | INFO | [120,  4700] loss: 1.495
2025-02-25T09:45:48.369071+0300 | INFO | [120,  4800] loss: 1.488
2025-02-25T09:46:00.141645+0300 | INFO | [120,  4900] loss: 1.502
2025-02-25T09:46:11.270568+0300 | DEBUG | Saving model to flat file storage. Save #120
2025-02-25T09:46:11.301911+0300 | INFO | Averaging client parameters
2025-02-25T09:46:11.319605+0300 | INFO | Updating parameters on client #0
2025-02-25T09:46:33.396188+0300 | DEBUG | Test set: Accuracy: 7889/10000 (79%)
2025-02-25T09:46:33.398567+0300 | DEBUG | Test set: Loss: 1.67179274559021
2025-02-25T09:46:33.588052+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.93      0.90      0.92      1000
           2       0.76      0.69      0.72      1000
           3       0.66      0.56      0.61      1200
           4       0.76      0.82      0.79      1000
           5       0.51      0.63      0.57       800
           6       0.87      0.83      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.90      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T09:46:33.595444+0300 | DEBUG | Confusion Matrix:
[[852   8  34  11  10   8   4   7  47  19]
 [ 17 904   1   2   0   0   4   0  19  53]
 [ 67   2 685  49  61  64  35  18  12   7]
 [ 34   6  56 676  58 280  38  25  12  15]
 [ 12   2  34  47 823  32  22  23   4   1]
 [ 17   3  34 158  32 503  12  35   5   1]
 [ 14   2  31  46  29  29 832   4   7   6]
 [ 21   1  16  29  57  55   5 810   3   3]
 [ 45  13   2   5   5   4   2   2 904  18]
 [ 26  34   3   5   2   3   3   7  17 900]]
2025-02-25T09:46:33.599519+0300 | DEBUG | Class precision: [0.77104072 0.92717949 0.76450893 0.65758755 0.7641597  0.51431493
 0.86938349 0.87003222 0.8776699  0.8797654 ]
2025-02-25T09:46:33.601031+0300 | DEBUG | Class recall: [0.852      0.904      0.685      0.56333333 0.823      0.62875
 0.832      0.81       0.904      0.9       ]
2025-02-25T09:46:33.680982+0300 | INFO | Training epoch #121 on client #0
2025-02-25T09:46:33.683983+0300 | DEBUG | Saving model to flat file storage. Save #121
2025-02-25T09:46:33.955599+0300 | INFO | [121,     0] loss: 0.015
2025-02-25T09:46:52.646923+0300 | INFO | [121,   100] loss: 1.503
2025-02-25T09:47:09.249285+0300 | INFO | [121,   200] loss: 1.487
2025-02-25T09:47:24.162959+0300 | INFO | [121,   300] loss: 1.503
2025-02-25T09:47:40.972451+0300 | INFO | [121,   400] loss: 1.494
2025-02-25T09:47:53.940696+0300 | INFO | [121,   500] loss: 1.490
2025-02-25T09:48:08.119605+0300 | INFO | [121,   600] loss: 1.502
2025-02-25T09:48:22.172133+0300 | INFO | [121,   700] loss: 1.492
2025-02-25T09:48:35.518262+0300 | INFO | [121,   800] loss: 1.490
2025-02-25T09:48:48.066403+0300 | INFO | [121,   900] loss: 1.491
2025-02-25T09:49:01.179960+0300 | INFO | [121,  1000] loss: 1.493
2025-02-25T09:49:14.538099+0300 | INFO | [121,  1100] loss: 1.493
2025-02-25T09:49:32.964591+0300 | INFO | [121,  1200] loss: 1.491
2025-02-25T09:49:48.941774+0300 | INFO | [121,  1300] loss: 1.497
2025-02-25T09:50:03.954193+0300 | INFO | [121,  1400] loss: 1.497
2025-02-25T09:50:26.184216+0300 | INFO | [121,  1500] loss: 1.499
2025-02-25T09:50:38.023214+0300 | INFO | [121,  1600] loss: 1.497
2025-02-25T09:50:51.988186+0300 | INFO | [121,  1700] loss: 1.493
2025-02-25T09:51:06.518541+0300 | INFO | [121,  1800] loss: 1.490
2025-02-25T09:51:20.906910+0300 | INFO | [121,  1900] loss: 1.498
2025-02-25T09:51:34.727312+0300 | INFO | [121,  2000] loss: 1.493
2025-02-25T09:51:49.185851+0300 | INFO | [121,  2100] loss: 1.496
2025-02-25T09:52:04.671809+0300 | INFO | [121,  2200] loss: 1.488
2025-02-25T09:52:18.438038+0300 | INFO | [121,  2300] loss: 1.491
2025-02-25T09:52:32.694741+0300 | INFO | [121,  2400] loss: 1.496
2025-02-25T09:52:51.554023+0300 | INFO | [121,  2500] loss: 1.500
2025-02-25T09:53:06.355320+0300 | INFO | [121,  2600] loss: 1.489
2025-02-25T09:53:20.583686+0300 | INFO | [121,  2700] loss: 1.483
2025-02-25T09:53:34.675774+0300 | INFO | [121,  2800] loss: 1.492
2025-02-25T09:53:49.735537+0300 | INFO | [121,  2900] loss: 1.495
2025-02-25T09:54:03.027651+0300 | INFO | [121,  3000] loss: 1.500
2025-02-25T09:54:17.365832+0300 | INFO | [121,  3100] loss: 1.486
2025-02-25T09:54:31.240673+0300 | INFO | [121,  3200] loss: 1.489
2025-02-25T09:54:45.744040+0300 | INFO | [121,  3300] loss: 1.496
2025-02-25T09:55:00.169835+0300 | INFO | [121,  3400] loss: 1.489
2025-02-25T09:55:15.315293+0300 | INFO | [121,  3500] loss: 1.504
2025-02-25T09:55:30.720517+0300 | INFO | [121,  3600] loss: 1.492
2025-02-25T09:55:49.705518+0300 | INFO | [121,  3700] loss: 1.497
2025-02-25T09:56:09.170633+0300 | INFO | [121,  3800] loss: 1.491
2025-02-25T09:56:26.425314+0300 | INFO | [121,  3900] loss: 1.487
2025-02-25T09:56:41.552130+0300 | INFO | [121,  4000] loss: 1.489
2025-02-25T09:56:56.504177+0300 | INFO | [121,  4100] loss: 1.491
2025-02-25T09:57:11.007196+0300 | INFO | [121,  4200] loss: 1.501
2025-02-25T09:57:25.448158+0300 | INFO | [121,  4300] loss: 1.496
2025-02-25T09:57:39.912222+0300 | INFO | [121,  4400] loss: 1.495
2025-02-25T09:57:57.493859+0300 | INFO | [121,  4500] loss: 1.497
2025-02-25T09:58:11.151086+0300 | INFO | [121,  4600] loss: 1.492
2025-02-25T09:58:27.005600+0300 | INFO | [121,  4700] loss: 1.497
2025-02-25T09:58:43.585505+0300 | INFO | [121,  4800] loss: 1.487
2025-02-25T09:58:58.779044+0300 | INFO | [121,  4900] loss: 1.482
2025-02-25T09:59:13.502630+0300 | DEBUG | Saving model to flat file storage. Save #121
2025-02-25T09:59:13.537138+0300 | INFO | Averaging client parameters
2025-02-25T09:59:13.549292+0300 | INFO | Updating parameters on client #0
2025-02-25T09:59:36.505419+0300 | DEBUG | Test set: Accuracy: 7884/10000 (79%)
2025-02-25T09:59:36.510127+0300 | DEBUG | Test set: Loss: 1.6719768047332764
2025-02-25T09:59:36.678161+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.62      0.62      0.62      1200
           4       0.79      0.80      0.79      1000
           5       0.53      0.55      0.54       800
           6       0.87      0.83      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T09:59:36.681169+0300 | DEBUG | Confusion Matrix:
[[855  13  38  14   7   6   3   6  33  25]
 [ 13 921   4   2   0   0   3   0  15  42]
 [ 62   2 709  57  51  52  37  17   6   7]
 [ 35  11  56 745  50 221  35  22  10  15]
 [ 18   2  44  52 800  25  23  30   4   2]
 [ 15   2  35 220  26 443  14  36   7   2]
 [ 11   3  32  58  29  24 830   5   4   4]
 [ 21   1  15  40  46  53   8 809   0   7]
 [ 46  19   7   6   4   5   2   1 890  20]
 [ 25  52   4   7   2   2   4   6  16 882]]
2025-02-25T09:59:36.684478+0300 | DEBUG | Class precision: [0.77656676 0.89766082 0.75105932 0.6203164  0.78817734 0.53309266
 0.86548488 0.86802575 0.9035533  0.87673956]
2025-02-25T09:59:36.687001+0300 | DEBUG | Class recall: [0.855      0.921      0.709      0.62083333 0.8        0.55375
 0.83       0.809      0.89       0.882     ]
2025-02-25T09:59:36.689017+0300 | INFO | Training epoch #122 on client #0
2025-02-25T09:59:36.690195+0300 | DEBUG | Saving model to flat file storage. Save #122
2025-02-25T09:59:36.912382+0300 | INFO | [122,     0] loss: 0.016
2025-02-25T09:59:52.394609+0300 | INFO | [122,   100] loss: 1.489
2025-02-25T10:00:07.861297+0300 | INFO | [122,   200] loss: 1.493
2025-02-25T10:00:23.366943+0300 | INFO | [122,   300] loss: 1.498
2025-02-25T10:00:39.123868+0300 | INFO | [122,   400] loss: 1.499
2025-02-25T10:00:58.530513+0300 | INFO | [122,   500] loss: 1.493
2025-02-25T10:01:14.037806+0300 | INFO | [122,   600] loss: 1.488
2025-02-25T10:01:29.465679+0300 | INFO | [122,   700] loss: 1.489
2025-02-25T10:01:49.336224+0300 | INFO | [122,   800] loss: 1.492
2025-02-25T10:02:07.275855+0300 | INFO | [122,   900] loss: 1.491
2025-02-25T10:02:26.901280+0300 | INFO | [122,  1000] loss: 1.497
2025-02-25T10:02:46.632251+0300 | INFO | [122,  1100] loss: 1.489
2025-02-25T10:03:01.572593+0300 | INFO | [122,  1200] loss: 1.485
2025-02-25T10:03:15.837294+0300 | INFO | [122,  1300] loss: 1.489
2025-02-25T10:03:29.904642+0300 | INFO | [122,  1400] loss: 1.489
2025-02-25T10:03:44.100369+0300 | INFO | [122,  1500] loss: 1.489
2025-02-25T10:03:59.618248+0300 | INFO | [122,  1600] loss: 1.486
2025-02-25T10:04:13.814170+0300 | INFO | [122,  1700] loss: 1.498
2025-02-25T10:04:28.407814+0300 | INFO | [122,  1800] loss: 1.496
2025-02-25T10:04:42.344209+0300 | INFO | [122,  1900] loss: 1.495
2025-02-25T10:04:56.481794+0300 | INFO | [122,  2000] loss: 1.494
2025-02-25T10:05:11.049328+0300 | INFO | [122,  2100] loss: 1.490
2025-02-25T10:05:25.056800+0300 | INFO | [122,  2200] loss: 1.495
2025-02-25T10:05:38.894622+0300 | INFO | [122,  2300] loss: 1.499
2025-02-25T10:05:55.661127+0300 | INFO | [122,  2400] loss: 1.497
2025-02-25T10:06:08.688082+0300 | INFO | [122,  2500] loss: 1.502
2025-02-25T10:06:20.752241+0300 | INFO | [122,  2600] loss: 1.499
2025-02-25T10:06:33.179627+0300 | INFO | [122,  2700] loss: 1.497
2025-02-25T10:06:46.788057+0300 | INFO | [122,  2800] loss: 1.487
2025-02-25T10:06:59.518022+0300 | INFO | [122,  2900] loss: 1.490
2025-02-25T10:07:12.303814+0300 | INFO | [122,  3000] loss: 1.500
2025-02-25T10:07:24.665342+0300 | INFO | [122,  3100] loss: 1.486
2025-02-25T10:07:37.033780+0300 | INFO | [122,  3200] loss: 1.498
2025-02-25T10:07:49.955352+0300 | INFO | [122,  3300] loss: 1.497
2025-02-25T10:08:05.997994+0300 | INFO | [122,  3400] loss: 1.502
2025-02-25T10:08:20.768134+0300 | INFO | [122,  3500] loss: 1.499
2025-02-25T10:08:34.156627+0300 | INFO | [122,  3600] loss: 1.492
2025-02-25T10:08:46.213855+0300 | INFO | [122,  3700] loss: 1.496
2025-02-25T10:08:58.734778+0300 | INFO | [122,  3800] loss: 1.498
2025-02-25T10:09:11.507972+0300 | INFO | [122,  3900] loss: 1.502
2025-02-25T10:09:26.445585+0300 | INFO | [122,  4000] loss: 1.484
2025-02-25T10:09:38.699893+0300 | INFO | [122,  4100] loss: 1.488
2025-02-25T10:09:50.774962+0300 | INFO | [122,  4200] loss: 1.490
2025-02-25T10:10:01.903928+0300 | INFO | [122,  4300] loss: 1.499
2025-02-25T10:10:12.488969+0300 | INFO | [122,  4400] loss: 1.488
2025-02-25T10:10:24.073120+0300 | INFO | [122,  4500] loss: 1.493
2025-02-25T10:10:35.142986+0300 | INFO | [122,  4600] loss: 1.497
2025-02-25T10:10:46.054804+0300 | INFO | [122,  4700] loss: 1.487
2025-02-25T10:10:57.120183+0300 | INFO | [122,  4800] loss: 1.488
2025-02-25T10:11:08.240802+0300 | INFO | [122,  4900] loss: 1.485
2025-02-25T10:11:18.885611+0300 | DEBUG | Saving model to flat file storage. Save #122
2025-02-25T10:11:18.922039+0300 | INFO | Averaging client parameters
2025-02-25T10:11:18.935790+0300 | INFO | Updating parameters on client #0
2025-02-25T10:11:35.965529+0300 | DEBUG | Test set: Accuracy: 7865/10000 (79%)
2025-02-25T10:11:35.966487+0300 | DEBUG | Test set: Loss: 1.6737544536590576
2025-02-25T10:11:36.079591+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.91      0.92      0.91      1000
           2       0.73      0.70      0.72      1000
           3       0.65      0.59      0.62      1200
           4       0.76      0.81      0.79      1000
           5       0.53      0.59      0.56       800
           6       0.83      0.85      0.84      1000
           7       0.87      0.80      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.92      0.87      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T10:11:36.084889+0300 | DEBUG | Confusion Matrix:
[[852   7  46  12  10   7   4   6  38  18]
 [ 13 923   3   3   1   0   9   0  20  28]
 [ 59   1 703  45  57  57  51  15   7   5]
 [ 37   6  61 703  56 247  48  22  11   9]
 [ 17   2  40  47 809  30  27  24   3   1]
 [ 11   1  43 179  32 475  16  36   6   1]
 [ 12   3  32  44  27  24 847   5   4   2]
 [ 26   1  15  39  59  52   7 799   1   1]
 [ 54  15   9   4   6   5   3   3 888  13]
 [ 28  59   5   7   3   3   6   4  19 866]]
2025-02-25T10:11:36.086941+0300 | DEBUG | Class precision: [0.76825969 0.90667976 0.73458725 0.64912281 0.76320755 0.52777778
 0.83202358 0.87417943 0.89067202 0.91737288]
2025-02-25T10:11:36.087951+0300 | DEBUG | Class recall: [0.852      0.923      0.703      0.58583333 0.809      0.59375
 0.847      0.799      0.888      0.866     ]
2025-02-25T10:11:36.141852+0300 | INFO | Training epoch #123 on client #0
2025-02-25T10:11:36.142856+0300 | DEBUG | Saving model to flat file storage. Save #123
2025-02-25T10:11:36.297960+0300 | INFO | [123,     0] loss: 0.016
2025-02-25T10:11:47.009821+0300 | INFO | [123,   100] loss: 1.487
2025-02-25T10:11:58.186945+0300 | INFO | [123,   200] loss: 1.491
2025-02-25T10:12:09.440266+0300 | INFO | [123,   300] loss: 1.500
2025-02-25T10:12:20.101223+0300 | INFO | [123,   400] loss: 1.497
2025-02-25T10:12:35.848807+0300 | INFO | [123,   500] loss: 1.499
2025-02-25T10:12:47.084332+0300 | INFO | [123,   600] loss: 1.493
2025-02-25T10:12:58.462343+0300 | INFO | [123,   700] loss: 1.497
2025-02-25T10:13:09.263277+0300 | INFO | [123,   800] loss: 1.491
2025-02-25T10:13:20.163200+0300 | INFO | [123,   900] loss: 1.507
2025-02-25T10:13:31.205878+0300 | INFO | [123,  1000] loss: 1.493
2025-02-25T10:13:43.008490+0300 | INFO | [123,  1100] loss: 1.495
2025-02-25T10:13:53.754424+0300 | INFO | [123,  1200] loss: 1.490
2025-02-25T10:14:04.980650+0300 | INFO | [123,  1300] loss: 1.494
2025-02-25T10:14:15.825530+0300 | INFO | [123,  1400] loss: 1.498
2025-02-25T10:14:26.633405+0300 | INFO | [123,  1500] loss: 1.490
2025-02-25T10:14:38.787805+0300 | INFO | [123,  1600] loss: 1.491
2025-02-25T10:14:51.421582+0300 | INFO | [123,  1700] loss: 1.488
2025-02-25T10:15:02.738319+0300 | INFO | [123,  1800] loss: 1.493
2025-02-25T10:15:17.414691+0300 | INFO | [123,  1900] loss: 1.487
2025-02-25T10:15:29.875623+0300 | INFO | [123,  2000] loss: 1.490
2025-02-25T10:15:41.184083+0300 | INFO | [123,  2100] loss: 1.488
2025-02-25T10:15:52.864018+0300 | INFO | [123,  2200] loss: 1.489
2025-02-25T10:16:04.557361+0300 | INFO | [123,  2300] loss: 1.495
2025-02-25T10:16:15.925561+0300 | INFO | [123,  2400] loss: 1.497
2025-02-25T10:16:27.226767+0300 | INFO | [123,  2500] loss: 1.493
2025-02-25T10:16:38.616836+0300 | INFO | [123,  2600] loss: 1.488
2025-02-25T10:16:49.517926+0300 | INFO | [123,  2700] loss: 1.491
2025-02-25T10:17:00.976727+0300 | INFO | [123,  2800] loss: 1.495
2025-02-25T10:17:11.789710+0300 | INFO | [123,  2900] loss: 1.486
2025-02-25T10:17:22.786584+0300 | INFO | [123,  3000] loss: 1.493
2025-02-25T10:17:35.331929+0300 | INFO | [123,  3100] loss: 1.500
2025-02-25T10:17:48.434309+0300 | INFO | [123,  3200] loss: 1.496
2025-02-25T10:18:00.621974+0300 | INFO | [123,  3300] loss: 1.495
2025-02-25T10:18:13.210716+0300 | INFO | [123,  3400] loss: 1.482
2025-02-25T10:18:24.537851+0300 | INFO | [123,  3500] loss: 1.504
2025-02-25T10:18:37.047160+0300 | INFO | [123,  3600] loss: 1.491
2025-02-25T10:18:48.895378+0300 | INFO | [123,  3700] loss: 1.507
2025-02-25T10:19:01.808708+0300 | INFO | [123,  3800] loss: 1.494
2025-02-25T10:19:13.736800+0300 | INFO | [123,  3900] loss: 1.492
2025-02-25T10:19:26.207801+0300 | INFO | [123,  4000] loss: 1.492
2025-02-25T10:19:38.102864+0300 | INFO | [123,  4100] loss: 1.491
2025-02-25T10:19:49.909767+0300 | INFO | [123,  4200] loss: 1.499
2025-02-25T10:20:01.815664+0300 | INFO | [123,  4300] loss: 1.488
2025-02-25T10:20:14.275491+0300 | INFO | [123,  4400] loss: 1.492
2025-02-25T10:20:29.699909+0300 | INFO | [123,  4500] loss: 1.496
2025-02-25T10:20:40.856754+0300 | INFO | [123,  4600] loss: 1.486
2025-02-25T10:20:52.216813+0300 | INFO | [123,  4700] loss: 1.491
2025-02-25T10:21:03.753334+0300 | INFO | [123,  4800] loss: 1.492
2025-02-25T10:21:16.206974+0300 | INFO | [123,  4900] loss: 1.500
2025-02-25T10:21:27.418207+0300 | DEBUG | Saving model to flat file storage. Save #123
2025-02-25T10:21:27.445632+0300 | INFO | Averaging client parameters
2025-02-25T10:21:27.454230+0300 | INFO | Updating parameters on client #0
2025-02-25T10:21:45.723242+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-25T10:21:45.724242+0300 | DEBUG | Test set: Loss: 1.673463225364685
2025-02-25T10:21:45.830228+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.89      0.93      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.65      0.60      0.62      1200
           4       0.76      0.81      0.78      1000
           5       0.54      0.56      0.55       800
           6       0.84      0.84      0.84      1000
           7       0.86      0.81      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T10:21:45.832225+0300 | DEBUG | Confusion Matrix:
[[847  13  43  11  13   6   4   5  39  19]
 [ 11 926   1   0   0   0   7   0  13  42]
 [ 59   2 685  49  67  56  45  23   5   9]
 [ 35  13  57 718  55 227  46  25  10  14]
 [ 13   2  40  44 814  31  25  26   3   2]
 [ 12   2  31 200  35 449  23  39   6   3]
 [ 11   2  34  42  30  20 844   6   5   6]
 [ 22   1  12  33  58  41   9 814   2   8]
 [ 49  21   7   5   5   2   3   2 888  18]
 [ 22  54   4   5   1   1   3   4  17 889]]
2025-02-25T10:21:45.834230+0300 | DEBUG | Class precision: [0.78353377 0.89382239 0.74945295 0.64859982 0.75510204 0.53901561
 0.83647175 0.86228814 0.89878543 0.88019802]
2025-02-25T10:21:45.835742+0300 | DEBUG | Class recall: [0.847      0.926      0.685      0.59833333 0.814      0.56125
 0.844      0.814      0.888      0.889     ]
2025-02-25T10:21:45.911746+0300 | INFO | Training epoch #124 on client #0
2025-02-25T10:21:45.912746+0300 | DEBUG | Saving model to flat file storage. Save #124
2025-02-25T10:21:46.382613+0300 | INFO | [124,     0] loss: 0.015
2025-02-25T10:21:59.930001+0300 | INFO | [124,   100] loss: 1.498
2025-02-25T10:22:11.854548+0300 | INFO | [124,   200] loss: 1.487
2025-02-25T10:22:23.478046+0300 | INFO | [124,   300] loss: 1.493
2025-02-25T10:22:35.879128+0300 | INFO | [124,   400] loss: 1.487
2025-02-25T10:22:49.403264+0300 | INFO | [124,   500] loss: 1.500
2025-02-25T10:23:01.187929+0300 | INFO | [124,   600] loss: 1.501
2025-02-25T10:23:13.560005+0300 | INFO | [124,   700] loss: 1.488
2025-02-25T10:23:26.005656+0300 | INFO | [124,   800] loss: 1.487
2025-02-25T10:23:38.271928+0300 | INFO | [124,   900] loss: 1.495
2025-02-25T10:23:50.884713+0300 | INFO | [124,  1000] loss: 1.498
2025-02-25T10:24:03.440954+0300 | INFO | [124,  1100] loss: 1.498
2025-02-25T10:24:14.761756+0300 | INFO | [124,  1200] loss: 1.491
2025-02-25T10:24:25.786880+0300 | INFO | [124,  1300] loss: 1.494
2025-02-25T10:24:36.888693+0300 | INFO | [124,  1400] loss: 1.496
2025-02-25T10:24:48.132476+0300 | INFO | [124,  1500] loss: 1.493
2025-02-25T10:25:02.860443+0300 | INFO | [124,  1600] loss: 1.497
2025-02-25T10:25:14.799092+0300 | INFO | [124,  1700] loss: 1.495
2025-02-25T10:25:25.968609+0300 | INFO | [124,  1800] loss: 1.494
2025-02-25T10:25:36.790948+0300 | INFO | [124,  1900] loss: 1.496
2025-02-25T10:25:49.509597+0300 | INFO | [124,  2000] loss: 1.494
2025-02-25T10:26:02.098696+0300 | INFO | [124,  2100] loss: 1.488
2025-02-25T10:26:16.253306+0300 | INFO | [124,  2200] loss: 1.486
2025-02-25T10:26:27.468756+0300 | INFO | [124,  2300] loss: 1.491
2025-02-25T10:26:39.824717+0300 | INFO | [124,  2400] loss: 1.485
2025-02-25T10:26:52.229152+0300 | INFO | [124,  2500] loss: 1.509
2025-02-25T10:27:03.885607+0300 | INFO | [124,  2600] loss: 1.495
2025-02-25T10:27:16.701996+0300 | INFO | [124,  2700] loss: 1.499
2025-02-25T10:27:30.884569+0300 | INFO | [124,  2800] loss: 1.486
2025-02-25T10:27:43.209840+0300 | INFO | [124,  2900] loss: 1.481
2025-02-25T10:27:55.638089+0300 | INFO | [124,  3000] loss: 1.492
2025-02-25T10:28:06.788068+0300 | INFO | [124,  3100] loss: 1.494
2025-02-25T10:28:18.743227+0300 | INFO | [124,  3200] loss: 1.489
2025-02-25T10:28:30.113810+0300 | INFO | [124,  3300] loss: 1.495
2025-02-25T10:28:40.540834+0300 | INFO | [124,  3400] loss: 1.496
2025-02-25T10:28:51.082467+0300 | INFO | [124,  3500] loss: 1.493
2025-02-25T10:29:02.265566+0300 | INFO | [124,  3600] loss: 1.493
2025-02-25T10:29:13.607758+0300 | INFO | [124,  3700] loss: 1.487
2025-02-25T10:29:27.194539+0300 | INFO | [124,  3800] loss: 1.494
2025-02-25T10:29:38.193129+0300 | INFO | [124,  3900] loss: 1.494
2025-02-25T10:29:49.041155+0300 | INFO | [124,  4000] loss: 1.491
2025-02-25T10:30:00.430657+0300 | INFO | [124,  4100] loss: 1.494
2025-02-25T10:30:11.625398+0300 | INFO | [124,  4200] loss: 1.490
2025-02-25T10:30:22.491650+0300 | INFO | [124,  4300] loss: 1.493
2025-02-25T10:30:32.964291+0300 | INFO | [124,  4400] loss: 1.494
2025-02-25T10:30:44.101405+0300 | INFO | [124,  4500] loss: 1.490
2025-02-25T10:30:53.995613+0300 | INFO | [124,  4600] loss: 1.499
2025-02-25T10:31:11.700147+0300 | INFO | [124,  4700] loss: 1.490
2025-02-25T10:31:23.895785+0300 | INFO | [124,  4800] loss: 1.487
2025-02-25T10:31:36.030791+0300 | INFO | [124,  4900] loss: 1.487
2025-02-25T10:31:49.913162+0300 | DEBUG | Saving model to flat file storage. Save #124
2025-02-25T10:31:49.940162+0300 | INFO | Averaging client parameters
2025-02-25T10:31:49.948391+0300 | INFO | Updating parameters on client #0
2025-02-25T10:32:07.269246+0300 | DEBUG | Test set: Accuracy: 7858/10000 (79%)
2025-02-25T10:32:07.270247+0300 | DEBUG | Test set: Loss: 1.6743965148925781
2025-02-25T10:32:07.381677+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.90      0.91      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.62      0.61      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.53      0.56      0.54       800
           6       0.84      0.84      0.84      1000
           7       0.87      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T10:32:07.385673+0300 | DEBUG | Confusion Matrix:
[[829  15  43  11  13   8   5   8  46  22]
 [ 10 911   1   0   0   0   6   0  15  57]
 [ 61   3 684  59  60  52  48  17   6  10]
 [ 36  10  48 734  52 235  40  24   9  12]
 [ 13   3  31  55 811  25  32  23   5   2]
 [ 12   1  39 212  31 444  17  38   4   2]
 [ 11   3  32  55  29  18 837   7   4   4]
 [ 16   1  14  35  57  45   7 815   3   7]
 [ 43  17   5   8   5   2   2   2 894  22]
 [ 19  45   5   7   2   1   3   6  13 899]]
2025-02-25T10:32:07.386680+0300 | DEBUG | Class precision: [0.78952381 0.90287413 0.75831486 0.62414966 0.76509434 0.53493976
 0.83951856 0.86702128 0.89489489 0.86692382]
2025-02-25T10:32:07.387676+0300 | DEBUG | Class recall: [0.829      0.911      0.684      0.61166667 0.811      0.555
 0.837      0.815      0.894      0.899     ]
2025-02-25T10:32:07.467614+0300 | INFO | Training epoch #125 on client #0
2025-02-25T10:32:07.472610+0300 | DEBUG | Saving model to flat file storage. Save #125
2025-02-25T10:32:07.719197+0300 | INFO | [125,     0] loss: 0.016
2025-02-25T10:32:22.093237+0300 | INFO | [125,   100] loss: 1.511
2025-02-25T10:32:36.631342+0300 | INFO | [125,   200] loss: 1.489
2025-02-25T10:32:50.785323+0300 | INFO | [125,   300] loss: 1.501
2025-02-25T10:33:07.312649+0300 | INFO | [125,   400] loss: 1.495
2025-02-25T10:33:22.404036+0300 | INFO | [125,   500] loss: 1.492
2025-02-25T10:33:36.654534+0300 | INFO | [125,   600] loss: 1.484
2025-02-25T10:33:48.642043+0300 | INFO | [125,   700] loss: 1.489
2025-02-25T10:34:00.371688+0300 | INFO | [125,   800] loss: 1.489
2025-02-25T10:34:12.168706+0300 | INFO | [125,   900] loss: 1.499
2025-02-25T10:34:24.256786+0300 | INFO | [125,  1000] loss: 1.493
2025-02-25T10:34:36.437251+0300 | INFO | [125,  1100] loss: 1.495
2025-02-25T10:34:47.614547+0300 | INFO | [125,  1200] loss: 1.493
2025-02-25T10:34:59.349295+0300 | INFO | [125,  1300] loss: 1.484
2025-02-25T10:35:11.687433+0300 | INFO | [125,  1400] loss: 1.495
2025-02-25T10:35:24.139553+0300 | INFO | [125,  1500] loss: 1.493
2025-02-25T10:35:35.319475+0300 | INFO | [125,  1600] loss: 1.495
2025-02-25T10:35:46.932446+0300 | INFO | [125,  1700] loss: 1.500
2025-02-25T10:35:59.696521+0300 | INFO | [125,  1800] loss: 1.493
2025-02-25T10:36:11.095413+0300 | INFO | [125,  1900] loss: 1.494
2025-02-25T10:36:23.393977+0300 | INFO | [125,  2000] loss: 1.490
2025-02-25T10:36:35.449432+0300 | INFO | [125,  2100] loss: 1.493
2025-02-25T10:36:47.219634+0300 | INFO | [125,  2200] loss: 1.503
2025-02-25T10:36:59.782027+0300 | INFO | [125,  2300] loss: 1.496
2025-02-25T10:37:09.405564+0300 | INFO | [125,  2400] loss: 1.480
2025-02-25T10:37:23.636516+0300 | INFO | [125,  2500] loss: 1.501
2025-02-25T10:37:35.003446+0300 | INFO | [125,  2600] loss: 1.493
2025-02-25T10:37:45.808638+0300 | INFO | [125,  2700] loss: 1.501
2025-02-25T10:37:58.128531+0300 | INFO | [125,  2800] loss: 1.491
2025-02-25T10:38:09.971337+0300 | INFO | [125,  2900] loss: 1.497
2025-02-25T10:38:21.483932+0300 | INFO | [125,  3000] loss: 1.488
2025-02-25T10:38:34.247623+0300 | INFO | [125,  3100] loss: 1.495
2025-02-25T10:38:46.072930+0300 | INFO | [125,  3200] loss: 1.487
2025-02-25T10:38:58.030303+0300 | INFO | [125,  3300] loss: 1.491
2025-02-25T10:39:10.851457+0300 | INFO | [125,  3400] loss: 1.497
2025-02-25T10:39:23.655691+0300 | INFO | [125,  3500] loss: 1.490
2025-02-25T10:39:35.899668+0300 | INFO | [125,  3600] loss: 1.495
2025-02-25T10:39:48.495275+0300 | INFO | [125,  3700] loss: 1.486
2025-02-25T10:40:00.163747+0300 | INFO | [125,  3800] loss: 1.499
2025-02-25T10:40:12.670524+0300 | INFO | [125,  3900] loss: 1.488
2025-02-25T10:40:24.452371+0300 | INFO | [125,  4000] loss: 1.490
2025-02-25T10:40:36.257927+0300 | INFO | [125,  4100] loss: 1.492
2025-02-25T10:40:49.776651+0300 | INFO | [125,  4200] loss: 1.489
2025-02-25T10:41:04.645500+0300 | INFO | [125,  4300] loss: 1.495
2025-02-25T10:41:16.298818+0300 | INFO | [125,  4400] loss: 1.488
2025-02-25T10:41:28.592131+0300 | INFO | [125,  4500] loss: 1.494
2025-02-25T10:41:39.703604+0300 | INFO | [125,  4600] loss: 1.494
2025-02-25T10:41:51.135335+0300 | INFO | [125,  4700] loss: 1.487
2025-02-25T10:42:03.672730+0300 | INFO | [125,  4800] loss: 1.494
2025-02-25T10:42:16.490488+0300 | INFO | [125,  4900] loss: 1.490
2025-02-25T10:42:28.885439+0300 | DEBUG | Saving model to flat file storage. Save #125
2025-02-25T10:42:28.927497+0300 | INFO | Averaging client parameters
2025-02-25T10:42:28.938492+0300 | INFO | Updating parameters on client #0
2025-02-25T10:42:47.040406+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-25T10:42:47.041407+0300 | DEBUG | Test set: Loss: 1.6739228963851929
2025-02-25T10:42:47.172180+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.91      0.92      0.91      1000
           2       0.77      0.67      0.72      1000
           3       0.64      0.60      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.51      0.59      0.55       800
           6       0.83      0.85      0.84      1000
           7       0.86      0.82      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T10:42:47.175219+0300 | DEBUG | Confusion Matrix:
[[848  15  38  13  12   8   5   6  36  19]
 [ 10 917   3   1   0   1   8   1  15  44]
 [ 63   1 670  49  65  67  54  19   5   7]
 [ 31   6  50 717  49 256  48  24   8  11]
 [ 15   2  28  59 802  34  25  31   3   1]
 [ 14   1  34 191  24 474  21  33   8   0]
 [ 14   1  25  45  27  26 849   7   2   4]
 [ 17   1  13  35  44  59   9 819   0   3]
 [ 44  20   6   7   5   2   3   2 888  23]
 [ 23  48   5   9   3   3   5   7  18 879]]
2025-02-25T10:42:47.178689+0300 | DEBUG | Class precision: [0.78591288 0.90612648 0.76834862 0.63676732 0.77788555 0.50967742
 0.82667965 0.8630137  0.90335707 0.88698285]
2025-02-25T10:42:47.180932+0300 | DEBUG | Class recall: [0.848  0.917  0.67   0.5975 0.802  0.5925 0.849  0.819  0.888  0.879 ]
2025-02-25T10:42:47.185632+0300 | INFO | Training epoch #126 on client #0
2025-02-25T10:42:47.188047+0300 | DEBUG | Saving model to flat file storage. Save #126
2025-02-25T10:42:47.380439+0300 | INFO | [126,     0] loss: 0.015
2025-02-25T10:43:00.582315+0300 | INFO | [126,   100] loss: 1.501
2025-02-25T10:43:15.530029+0300 | INFO | [126,   200] loss: 1.506
2025-02-25T10:43:29.425598+0300 | INFO | [126,   300] loss: 1.494
2025-02-25T10:43:44.589253+0300 | INFO | [126,   400] loss: 1.493
2025-02-25T10:43:55.854336+0300 | INFO | [126,   500] loss: 1.490
2025-02-25T10:44:07.277111+0300 | INFO | [126,   600] loss: 1.494
2025-02-25T10:44:18.819744+0300 | INFO | [126,   700] loss: 1.492
2025-02-25T10:44:30.451653+0300 | INFO | [126,   800] loss: 1.491
2025-02-25T10:44:41.380208+0300 | INFO | [126,   900] loss: 1.498
2025-02-25T10:44:53.229450+0300 | INFO | [126,  1000] loss: 1.487
2025-02-25T10:45:05.631582+0300 | INFO | [126,  1100] loss: 1.491
2025-02-25T10:45:16.579151+0300 | INFO | [126,  1200] loss: 1.492
2025-02-25T10:45:27.379619+0300 | INFO | [126,  1300] loss: 1.481
2025-02-25T10:45:38.807894+0300 | INFO | [126,  1400] loss: 1.507
2025-02-25T10:45:50.122299+0300 | INFO | [126,  1500] loss: 1.488
2025-02-25T10:46:01.166733+0300 | INFO | [126,  1600] loss: 1.488
2025-02-25T10:46:12.558106+0300 | INFO | [126,  1700] loss: 1.486
2025-02-25T10:46:23.753398+0300 | INFO | [126,  1800] loss: 1.497
2025-02-25T10:46:35.979904+0300 | INFO | [126,  1900] loss: 1.481
2025-02-25T10:46:48.051933+0300 | INFO | [126,  2000] loss: 1.485
2025-02-25T10:47:00.129099+0300 | INFO | [126,  2100] loss: 1.499
2025-02-25T10:47:12.745302+0300 | INFO | [126,  2200] loss: 1.495
2025-02-25T10:47:26.263432+0300 | INFO | [126,  2300] loss: 1.496
2025-02-25T10:47:38.129997+0300 | INFO | [126,  2400] loss: 1.500
2025-02-25T10:47:49.445255+0300 | INFO | [126,  2500] loss: 1.497
2025-02-25T10:48:01.770474+0300 | INFO | [126,  2600] loss: 1.499
2025-02-25T10:48:13.825496+0300 | INFO | [126,  2700] loss: 1.487
2025-02-25T10:48:26.136573+0300 | INFO | [126,  2800] loss: 1.488
2025-02-25T10:48:37.156181+0300 | INFO | [126,  2900] loss: 1.498
2025-02-25T10:48:48.068999+0300 | INFO | [126,  3000] loss: 1.501
2025-02-25T10:49:00.088648+0300 | INFO | [126,  3100] loss: 1.494
2025-02-25T10:49:12.123103+0300 | INFO | [126,  3200] loss: 1.486
2025-02-25T10:49:25.931125+0300 | INFO | [126,  3300] loss: 1.489
2025-02-25T10:49:39.779975+0300 | INFO | [126,  3400] loss: 1.488
2025-02-25T10:49:51.306838+0300 | INFO | [126,  3500] loss: 1.493
2025-02-25T10:50:02.288994+0300 | INFO | [126,  3600] loss: 1.488
2025-02-25T10:50:13.172153+0300 | INFO | [126,  3700] loss: 1.492
2025-02-25T10:50:29.309767+0300 | INFO | [126,  3800] loss: 1.493
2025-02-25T10:50:41.648217+0300 | INFO | [126,  3900] loss: 1.491
2025-02-25T10:50:52.863022+0300 | INFO | [126,  4000] loss: 1.491
2025-02-25T10:51:04.760995+0300 | INFO | [126,  4100] loss: 1.489
2025-02-25T10:51:16.191073+0300 | INFO | [126,  4200] loss: 1.492
2025-02-25T10:51:28.551590+0300 | INFO | [126,  4300] loss: 1.494
2025-02-25T10:51:40.074456+0300 | INFO | [126,  4400] loss: 1.496
2025-02-25T10:51:52.245090+0300 | INFO | [126,  4500] loss: 1.491
2025-02-25T10:52:03.329849+0300 | INFO | [126,  4600] loss: 1.498
2025-02-25T10:52:16.661996+0300 | INFO | [126,  4700] loss: 1.501
2025-02-25T10:53:21.146785+0300 | INFO | [126,  4800] loss: 1.502
2025-02-25T10:55:15.697849+0300 | INFO | [126,  4900] loss: 1.484
2025-02-25T10:57:34.713562+0300 | DEBUG | Saving model to flat file storage. Save #126
2025-02-25T10:57:34.794125+0300 | INFO | Averaging client parameters
2025-02-25T10:57:35.101843+0300 | INFO | Updating parameters on client #0
2025-02-25T10:59:36.413515+0300 | DEBUG | Test set: Accuracy: 7862/10000 (79%)
2025-02-25T10:59:36.456685+0300 | DEBUG | Test set: Loss: 1.6739498376846313
2025-02-25T10:59:38.713428+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.82      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.64      0.59      0.62      1200
           4       0.72      0.83      0.78      1000
           5       0.55      0.55      0.55       800
           6       0.80      0.87      0.84      1000
           7       0.89      0.78      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.91      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T10:59:38.726991+0300 | DEBUG | Confusion Matrix:
[[825  14  45  18  14   5   7   6  44  22]
 [  9 906   3   2   1   0   7   0  19  53]
 [ 57   1 693  47  70  47  62  10   5   8]
 [ 29   5  59 714  70 227  59  20   7  10]
 [ 11   1  33  43 835  24  30  19   3   1]
 [ 11   1  39 196  44 442  29  29   7   2]
 [ 11   0  28  37  29  12 869   6   5   3]
 [ 17   1  12  46  83  44  11 779   1   6]
 [ 43  17   8   5   5   4   4   1 894  19]
 [ 16  37   6   7   2   3   3   3  18 905]]
2025-02-25T10:59:38.727980+0300 | DEBUG | Class precision: [0.80174927 0.92166836 0.74838013 0.64035874 0.72419775 0.5470297
 0.80388529 0.89232532 0.89132602 0.87949466]
2025-02-25T10:59:38.823453+0300 | DEBUG | Class recall: [0.825  0.906  0.693  0.595  0.835  0.5525 0.869  0.779  0.894  0.905 ]
2025-02-25T10:59:38.825049+0300 | INFO | Training epoch #127 on client #0
2025-02-25T10:59:38.849258+0300 | DEBUG | Saving model to flat file storage. Save #127
2025-02-25T10:59:41.635687+0300 | INFO | [127,     0] loss: 0.015
2025-02-25T11:02:37.236772+0300 | INFO | [127,   100] loss: 1.496
2025-02-25T11:05:50.086331+0300 | INFO | [127,   200] loss: 1.493
2025-02-25T11:07:15.329017+0300 | INFO | [127,   300] loss: 1.495
2025-02-25T11:08:34.881204+0300 | INFO | [127,   400] loss: 1.495
2025-02-25T11:09:45.952309+0300 | INFO | [127,   500] loss: 1.492
2025-02-25T11:10:58.487298+0300 | INFO | [127,   600] loss: 1.492
2025-02-25T11:12:12.575461+0300 | INFO | [127,   700] loss: 1.482
2025-02-25T11:13:22.957463+0300 | INFO | [127,   800] loss: 1.503
2025-02-25T11:14:38.566848+0300 | INFO | [127,   900] loss: 1.491
2025-02-25T11:15:51.924690+0300 | INFO | [127,  1000] loss: 1.505
2025-02-25T11:17:06.045915+0300 | INFO | [127,  1100] loss: 1.499
2025-02-25T11:18:19.212133+0300 | INFO | [127,  1200] loss: 1.504
2025-02-25T11:19:30.720008+0300 | INFO | [127,  1300] loss: 1.492
2025-02-25T11:20:37.961017+0300 | INFO | [127,  1400] loss: 1.493
2025-02-25T11:21:42.904128+0300 | INFO | [127,  1500] loss: 1.496
2025-02-25T11:22:47.532148+0300 | INFO | [127,  1600] loss: 1.491
2025-02-25T11:23:55.937725+0300 | INFO | [127,  1700] loss: 1.483
2025-02-25T11:24:59.296199+0300 | INFO | [127,  1800] loss: 1.500
2025-02-25T11:26:04.325631+0300 | INFO | [127,  1900] loss: 1.500
2025-02-25T11:27:09.555565+0300 | INFO | [127,  2000] loss: 1.486
2025-02-25T11:28:14.286773+0300 | INFO | [127,  2100] loss: 1.493
2025-02-25T11:29:19.946590+0300 | INFO | [127,  2200] loss: 1.489
2025-02-25T11:30:26.286413+0300 | INFO | [127,  2300] loss: 1.490
2025-02-25T11:31:29.433674+0300 | INFO | [127,  2400] loss: 1.492
2025-02-25T11:32:35.668410+0300 | INFO | [127,  2500] loss: 1.485
2025-02-25T11:33:39.772625+0300 | INFO | [127,  2600] loss: 1.494
2025-02-25T11:34:53.440960+0300 | INFO | [127,  2700] loss: 1.486
2025-02-25T11:35:58.783201+0300 | INFO | [127,  2800] loss: 1.490
2025-02-25T11:37:01.827308+0300 | INFO | [127,  2900] loss: 1.494
2025-02-25T11:38:10.768628+0300 | INFO | [127,  3000] loss: 1.499
2025-02-25T11:39:20.413671+0300 | INFO | [127,  3100] loss: 1.484
2025-02-25T11:40:26.447207+0300 | INFO | [127,  3200] loss: 1.495
2025-02-25T11:42:00.004486+0300 | INFO | [127,  3300] loss: 1.494
2025-02-25T11:43:07.697560+0300 | INFO | [127,  3400] loss: 1.495
2025-02-25T11:44:16.269103+0300 | INFO | [127,  3500] loss: 1.484
2025-02-25T11:45:21.502461+0300 | INFO | [127,  3600] loss: 1.491
2025-02-25T11:46:27.806607+0300 | INFO | [127,  3700] loss: 1.499
2025-02-25T11:47:33.966935+0300 | INFO | [127,  3800] loss: 1.491
2025-02-25T11:48:41.475290+0300 | INFO | [127,  3900] loss: 1.486
2025-02-25T11:49:50.638859+0300 | INFO | [127,  4000] loss: 1.502
2025-02-25T11:50:59.833785+0300 | INFO | [127,  4100] loss: 1.497
2025-02-25T11:52:06.609757+0300 | INFO | [127,  4200] loss: 1.489
2025-02-25T11:53:17.260827+0300 | INFO | [127,  4300] loss: 1.492
2025-02-25T11:54:26.217809+0300 | INFO | [127,  4400] loss: 1.492
2025-02-25T11:55:34.011297+0300 | INFO | [127,  4500] loss: 1.492
2025-02-25T11:56:37.963053+0300 | INFO | [127,  4600] loss: 1.479
2025-02-25T11:57:44.967308+0300 | INFO | [127,  4700] loss: 1.497
2025-02-25T11:58:27.656252+0300 | INFO | [127,  4800] loss: 1.494
2025-02-25T11:58:42.978451+0300 | INFO | [127,  4900] loss: 1.497
2025-02-25T11:58:54.656974+0300 | DEBUG | Saving model to flat file storage. Save #127
2025-02-25T11:58:54.689303+0300 | INFO | Averaging client parameters
2025-02-25T11:58:54.698826+0300 | INFO | Updating parameters on client #0
2025-02-25T11:59:10.046154+0300 | DEBUG | Test set: Accuracy: 7886/10000 (79%)
2025-02-25T11:59:10.049151+0300 | DEBUG | Test set: Loss: 1.671514630317688
2025-02-25T11:59:10.109952+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.86      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.75      0.69      0.72      1000
           3       0.64      0.59      0.62      1200
           4       0.79      0.80      0.79      1000
           5       0.52      0.59      0.55       800
           6       0.83      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T11:59:10.110956+0300 | DEBUG | Confusion Matrix:
[[857  11  37  12  10   9   3   5  36  20]
 [ 12 913   3   5   0   0   7   1  16  43]
 [ 69   0 686  44  56  60  55  18   5   7]
 [ 36   5  60 711  49 246  48  26  10   9]
 [ 17   2  35  51 800  33  30  28   3   1]
 [ 15   1  37 188  26 474  14  37   7   1]
 [ 14   0  29  43  21  24 857   4   4   4]
 [ 19   0  12  39  50  53   6 818   2   1]
 [ 51  13   8   4   4   6   5   1 891  17]
 [ 29  46   4   9   2   4   3   9  15 879]]
2025-02-25T11:59:10.111952+0300 | DEBUG | Class precision: [0.76586238 0.92129162 0.75301866 0.64285714 0.78585462 0.52145215
 0.83365759 0.86378036 0.90091001 0.89511202]
2025-02-25T11:59:10.113952+0300 | DEBUG | Class recall: [0.857  0.913  0.686  0.5925 0.8    0.5925 0.857  0.818  0.891  0.879 ]
2025-02-25T11:59:10.144990+0300 | INFO | Training epoch #128 on client #0
2025-02-25T11:59:10.145993+0300 | DEBUG | Saving model to flat file storage. Save #128
2025-02-25T11:59:10.376160+0300 | INFO | [128,     0] loss: 0.015
2025-02-25T11:59:20.928137+0300 | INFO | [128,   100] loss: 1.492
2025-02-25T11:59:31.604084+0300 | INFO | [128,   200] loss: 1.499
2025-02-25T11:59:42.220840+0300 | INFO | [128,   300] loss: 1.496
2025-02-25T11:59:52.954317+0300 | INFO | [128,   400] loss: 1.488
2025-02-25T12:00:05.198639+0300 | INFO | [128,   500] loss: 1.490
2025-02-25T12:00:19.353641+0300 | INFO | [128,   600] loss: 1.495
2025-02-25T12:00:32.611391+0300 | INFO | [128,   700] loss: 1.487
2025-02-25T12:00:44.664419+0300 | INFO | [128,   800] loss: 1.489
2025-02-25T12:00:57.399794+0300 | INFO | [128,   900] loss: 1.492
2025-02-25T12:01:11.456250+0300 | INFO | [128,  1000] loss: 1.488
2025-02-25T12:01:24.617866+0300 | INFO | [128,  1100] loss: 1.481
2025-02-25T12:01:37.798604+0300 | INFO | [128,  1200] loss: 1.495
2025-02-25T12:01:50.777008+0300 | INFO | [128,  1300] loss: 1.495
2025-02-25T12:02:06.883509+0300 | INFO | [128,  1400] loss: 1.489
2025-02-25T12:02:19.568327+0300 | INFO | [128,  1500] loss: 1.488
2025-02-25T12:02:32.658612+0300 | INFO | [128,  1600] loss: 1.498
2025-02-25T12:02:45.186809+0300 | INFO | [128,  1700] loss: 1.490
2025-02-25T12:02:58.434218+0300 | INFO | [128,  1800] loss: 1.496
2025-02-25T12:03:11.133038+0300 | INFO | [128,  1900] loss: 1.492
2025-02-25T12:03:26.540513+0300 | INFO | [128,  2000] loss: 1.486
2025-02-25T12:03:40.005519+0300 | INFO | [128,  2100] loss: 1.497
2025-02-25T12:03:54.260184+0300 | INFO | [128,  2200] loss: 1.493
2025-02-25T12:04:09.263856+0300 | INFO | [128,  2300] loss: 1.491
2025-02-25T12:04:26.032132+0300 | INFO | [128,  2400] loss: 1.493
2025-02-25T12:04:40.554385+0300 | INFO | [128,  2500] loss: 1.486
2025-02-25T12:04:57.358719+0300 | INFO | [128,  2600] loss: 1.486
2025-02-25T12:05:12.426248+0300 | INFO | [128,  2700] loss: 1.487
2025-02-25T12:05:29.060748+0300 | INFO | [128,  2800] loss: 1.486
2025-02-25T12:05:41.884188+0300 | INFO | [128,  2900] loss: 1.491
2025-02-25T12:05:55.921562+0300 | INFO | [128,  3000] loss: 1.498
2025-02-25T12:06:07.366362+0300 | INFO | [128,  3100] loss: 1.492
2025-02-25T12:06:17.803538+0300 | INFO | [128,  3200] loss: 1.484
2025-02-25T12:06:28.686530+0300 | INFO | [128,  3300] loss: 1.487
2025-02-25T12:06:42.055413+0300 | INFO | [128,  3400] loss: 1.492
2025-02-25T12:06:52.838866+0300 | INFO | [128,  3500] loss: 1.508
2025-02-25T12:07:05.486598+0300 | INFO | [128,  3600] loss: 1.494
2025-02-25T12:07:16.672796+0300 | INFO | [128,  3700] loss: 1.506
2025-02-25T12:07:27.774667+0300 | INFO | [128,  3800] loss: 1.493
2025-02-25T12:07:41.276190+0300 | INFO | [128,  3900] loss: 1.490
2025-02-25T12:07:51.847122+0300 | INFO | [128,  4000] loss: 1.497
2025-02-25T12:08:03.030536+0300 | INFO | [128,  4100] loss: 1.495
2025-02-25T12:08:14.531638+0300 | INFO | [128,  4200] loss: 1.490
2025-02-25T12:08:25.874557+0300 | INFO | [128,  4300] loss: 1.492
2025-02-25T12:08:36.680161+0300 | INFO | [128,  4400] loss: 1.503
2025-02-25T12:08:47.551945+0300 | INFO | [128,  4500] loss: 1.497
2025-02-25T12:09:00.850657+0300 | INFO | [128,  4600] loss: 1.503
2025-02-25T12:09:11.799207+0300 | INFO | [128,  4700] loss: 1.500
2025-02-25T12:09:21.458616+0300 | INFO | [128,  4800] loss: 1.496
2025-02-25T12:09:35.060440+0300 | INFO | [128,  4900] loss: 1.495
2025-02-25T12:09:46.910590+0300 | DEBUG | Saving model to flat file storage. Save #128
2025-02-25T12:09:46.929472+0300 | INFO | Averaging client parameters
2025-02-25T12:09:46.940389+0300 | INFO | Updating parameters on client #0
2025-02-25T12:10:04.421653+0300 | DEBUG | Test set: Accuracy: 7876/10000 (79%)
2025-02-25T12:10:04.424331+0300 | DEBUG | Test set: Loss: 1.6724615097045898
2025-02-25T12:10:04.550859+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.91      0.91      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.68      0.56      0.62      1200
           4       0.76      0.83      0.79      1000
           5       0.51      0.63      0.56       800
           6       0.84      0.85      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T12:10:04.554302+0300 | DEBUG | Confusion Matrix:
[[838  14  49   9  10  10   5   8  40  17]
 [ 14 914   2   2   0   1   5   1  18  43]
 [ 59   1 702  39  65  57  51  16   5   5]
 [ 33   5  58 677  56 282  48  25  10   6]
 [ 15   2  37  39 827  33  26  17   3   1]
 [ 12   1  37 155  33 502  16  37   6   1]
 [ 11   2  35  41  27  21 853   5   4   1]
 [ 20   1  12  26  65  62   8 802   1   3]
 [ 49  15  12   4   5   5   4   1 885  20]
 [ 26  53   7   9   2   5   3   4  15 876]]
2025-02-25T12:10:04.555766+0300 | DEBUG | Class precision: [0.77808728 0.90674603 0.73817035 0.67632368 0.7587156  0.51329243
 0.83709519 0.87554585 0.89665653 0.90030832]
2025-02-25T12:10:04.556950+0300 | DEBUG | Class recall: [0.838      0.914      0.702      0.56416667 0.827      0.6275
 0.853      0.802      0.885      0.876     ]
2025-02-25T12:10:04.621769+0300 | INFO | Training epoch #129 on client #0
2025-02-25T12:10:04.624768+0300 | DEBUG | Saving model to flat file storage. Save #129
2025-02-25T12:10:04.794515+0300 | INFO | [129,     0] loss: 0.016
2025-02-25T12:10:16.807578+0300 | INFO | [129,   100] loss: 1.488
2025-02-25T12:10:29.784590+0300 | INFO | [129,   200] loss: 1.493
2025-02-25T12:10:43.150422+0300 | INFO | [129,   300] loss: 1.492
2025-02-25T12:10:57.279160+0300 | INFO | [129,   400] loss: 1.489
2025-02-25T12:11:12.614469+0300 | INFO | [129,   500] loss: 1.480
2025-02-25T12:11:26.991436+0300 | INFO | [129,   600] loss: 1.495
2025-02-25T12:11:40.702949+0300 | INFO | [129,   700] loss: 1.488
2025-02-25T12:11:55.517580+0300 | INFO | [129,   800] loss: 1.496
2025-02-25T12:12:09.369936+0300 | INFO | [129,   900] loss: 1.491
2025-02-25T12:12:23.758652+0300 | INFO | [129,  1000] loss: 1.489
2025-02-25T12:12:37.705600+0300 | INFO | [129,  1100] loss: 1.494
2025-02-25T12:12:53.087768+0300 | INFO | [129,  1200] loss: 1.497
2025-02-25T12:13:08.194890+0300 | INFO | [129,  1300] loss: 1.496
2025-02-25T12:13:22.835404+0300 | INFO | [129,  1400] loss: 1.497
2025-02-25T12:13:34.856340+0300 | INFO | [129,  1500] loss: 1.497
2025-02-25T12:13:46.990302+0300 | INFO | [129,  1600] loss: 1.498
2025-02-25T12:13:59.645650+0300 | INFO | [129,  1700] loss: 1.492
2025-02-25T12:14:12.247787+0300 | INFO | [129,  1800] loss: 1.489
2025-02-25T12:14:24.481801+0300 | INFO | [129,  1900] loss: 1.493
2025-02-25T12:14:38.408750+0300 | INFO | [129,  2000] loss: 1.491
2025-02-25T12:14:52.319882+0300 | INFO | [129,  2100] loss: 1.487
2025-02-25T12:15:05.457638+0300 | INFO | [129,  2200] loss: 1.494
2025-02-25T12:15:17.584811+0300 | INFO | [129,  2300] loss: 1.486
2025-02-25T12:15:35.309899+0300 | INFO | [129,  2400] loss: 1.481
2025-02-25T12:15:49.371507+0300 | INFO | [129,  2500] loss: 1.492
2025-02-25T12:16:05.084879+0300 | INFO | [129,  2600] loss: 1.488
2025-02-25T12:16:19.341164+0300 | INFO | [129,  2700] loss: 1.490
2025-02-25T12:16:34.463986+0300 | INFO | [129,  2800] loss: 1.487
2025-02-25T12:16:48.722948+0300 | INFO | [129,  2900] loss: 1.494
2025-02-25T12:17:02.450096+0300 | INFO | [129,  3000] loss: 1.492
2025-02-25T12:17:14.803535+0300 | INFO | [129,  3100] loss: 1.495
2025-02-25T12:17:27.554350+0300 | INFO | [129,  3200] loss: 1.481
2025-02-25T12:17:39.656713+0300 | INFO | [129,  3300] loss: 1.491
2025-02-25T12:17:51.434668+0300 | INFO | [129,  3400] loss: 1.496
2025-02-25T12:18:03.934050+0300 | INFO | [129,  3500] loss: 1.494
2025-02-25T12:18:16.196129+0300 | INFO | [129,  3600] loss: 1.502
2025-02-25T12:18:28.319920+0300 | INFO | [129,  3700] loss: 1.499
2025-02-25T12:18:39.425713+0300 | INFO | [129,  3800] loss: 1.496
2025-02-25T12:18:53.219623+0300 | INFO | [129,  3900] loss: 1.483
2025-02-25T12:19:06.646853+0300 | INFO | [129,  4000] loss: 1.495
2025-02-25T12:19:19.659460+0300 | INFO | [129,  4100] loss: 1.503
2025-02-25T12:19:32.712375+0300 | INFO | [129,  4200] loss: 1.492
2025-02-25T12:19:42.654712+0300 | INFO | [129,  4300] loss: 1.494
2025-02-25T12:19:53.400030+0300 | INFO | [129,  4400] loss: 1.503
2025-02-25T12:20:07.267648+0300 | INFO | [129,  4500] loss: 1.491
2025-02-25T12:20:18.880051+0300 | INFO | [129,  4600] loss: 1.495
2025-02-25T12:20:33.873687+0300 | INFO | [129,  4700] loss: 1.495
2025-02-25T12:20:49.145166+0300 | INFO | [129,  4800] loss: 1.492
2025-02-25T12:21:02.905640+0300 | INFO | [129,  4900] loss: 1.499
2025-02-25T12:21:15.428518+0300 | DEBUG | Saving model to flat file storage. Save #129
2025-02-25T12:21:15.447492+0300 | INFO | Averaging client parameters
2025-02-25T12:21:15.459008+0300 | INFO | Updating parameters on client #0
2025-02-25T12:21:31.923803+0300 | DEBUG | Test set: Accuracy: 7848/10000 (78%)
2025-02-25T12:21:31.927023+0300 | DEBUG | Test set: Loss: 1.6755269765853882
2025-02-25T12:21:32.049895+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.92      0.91      0.92      1000
           2       0.78      0.68      0.72      1000
           3       0.65      0.58      0.61      1200
           4       0.74      0.82      0.78      1000
           5       0.51      0.55      0.53       800
           6       0.81      0.86      0.83      1000
           7       0.85      0.81      0.83      1000
           8       0.88      0.90      0.89      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T12:21:32.052896+0300 | DEBUG | Confusion Matrix:
[[851   8  30  11  12  11   4   8  49  16]
 [ 14 911   1   4   1   1   5   2  18  43]
 [ 65   1 675  41  66  59  59  20   8   6]
 [ 29   5  50 700  67 244  57  26  14   8]
 [ 15   1  27  37 820  31  31  31   5   2]
 [ 12   1  36 204  36 442  23  39   6   1]
 [ 12   1  28  36  34  21 856   3   7   2]
 [ 24   1   9  37  61  48   8 807   1   4]
 [ 39  14   6   5   4   6   4   2 902  18]
 [ 26  46   5   8   1   2   4   6  18 884]]
2025-02-25T12:21:32.054186+0300 | DEBUG | Class precision: [0.78288868 0.92113246 0.77854671 0.64635272 0.74410163 0.51098266
 0.81446242 0.85487288 0.87743191 0.89837398]
2025-02-25T12:21:32.057201+0300 | DEBUG | Class recall: [0.851      0.911      0.675      0.58333333 0.82       0.5525
 0.856      0.807      0.902      0.884     ]
2025-02-25T12:21:32.116963+0300 | INFO | Training epoch #130 on client #0
2025-02-25T12:21:32.120445+0300 | DEBUG | Saving model to flat file storage. Save #130
2025-02-25T12:21:32.266319+0300 | INFO | [130,     0] loss: 0.015
2025-02-25T12:21:46.449108+0300 | INFO | [130,   100] loss: 1.495
2025-02-25T12:22:01.653597+0300 | INFO | [130,   200] loss: 1.499
2025-02-25T12:22:15.377166+0300 | INFO | [130,   300] loss: 1.502
2025-02-25T12:22:29.425055+0300 | INFO | [130,   400] loss: 1.490
2025-02-25T12:22:44.228755+0300 | INFO | [130,   500] loss: 1.497
2025-02-25T12:23:00.137210+0300 | INFO | [130,   600] loss: 1.484
2025-02-25T12:23:17.114511+0300 | INFO | [130,   700] loss: 1.498
2025-02-25T12:23:34.482796+0300 | INFO | [130,   800] loss: 1.485
2025-02-25T12:23:48.952284+0300 | INFO | [130,   900] loss: 1.492
2025-02-25T12:24:05.179421+0300 | INFO | [130,  1000] loss: 1.491
2025-02-25T12:24:20.398032+0300 | INFO | [130,  1100] loss: 1.499
2025-02-25T12:24:33.490865+0300 | INFO | [130,  1200] loss: 1.495
2025-02-25T12:24:44.476503+0300 | INFO | [130,  1300] loss: 1.491
2025-02-25T12:24:54.374778+0300 | INFO | [130,  1400] loss: 1.491
2025-02-25T12:25:04.707775+0300 | INFO | [130,  1500] loss: 1.490
2025-02-25T12:25:17.223534+0300 | INFO | [130,  1600] loss: 1.488
2025-02-25T12:25:31.076383+0300 | INFO | [130,  1700] loss: 1.495
2025-02-25T12:25:43.961211+0300 | INFO | [130,  1800] loss: 1.497
2025-02-25T12:26:02.776859+0300 | INFO | [130,  1900] loss: 1.488
2025-02-25T12:26:18.624077+0300 | INFO | [130,  2000] loss: 1.489
2025-02-25T12:26:33.647205+0300 | INFO | [130,  2100] loss: 1.487
2025-02-25T12:26:47.124615+0300 | INFO | [130,  2200] loss: 1.481
2025-02-25T12:27:01.267712+0300 | INFO | [130,  2300] loss: 1.490
2025-02-25T12:27:15.940789+0300 | INFO | [130,  2400] loss: 1.490
2025-02-25T12:27:30.410842+0300 | INFO | [130,  2500] loss: 1.488
2025-02-25T12:27:44.132207+0300 | INFO | [130,  2600] loss: 1.488
2025-02-25T12:27:58.566858+0300 | INFO | [130,  2700] loss: 1.489
2025-02-25T12:28:12.866379+0300 | INFO | [130,  2800] loss: 1.497
2025-02-25T12:28:27.151376+0300 | INFO | [130,  2900] loss: 1.481
2025-02-25T12:28:41.617081+0300 | INFO | [130,  3000] loss: 1.500
2025-02-25T12:28:56.063706+0300 | INFO | [130,  3100] loss: 1.493
2025-02-25T12:29:10.066997+0300 | INFO | [130,  3200] loss: 1.503
2025-02-25T12:29:23.669521+0300 | INFO | [130,  3300] loss: 1.497
2025-02-25T12:29:36.451161+0300 | INFO | [130,  3400] loss: 1.488
2025-02-25T12:29:50.645073+0300 | INFO | [130,  3500] loss: 1.502
2025-02-25T12:30:03.480371+0300 | INFO | [130,  3600] loss: 1.498
2025-02-25T12:30:17.561910+0300 | INFO | [130,  3700] loss: 1.495
2025-02-25T12:30:30.770202+0300 | INFO | [130,  3800] loss: 1.504
2025-02-25T12:30:43.475436+0300 | INFO | [130,  3900] loss: 1.493
2025-02-25T12:30:55.431145+0300 | INFO | [130,  4000] loss: 1.490
2025-02-25T12:31:09.135836+0300 | INFO | [130,  4100] loss: 1.493
2025-02-25T12:31:23.680573+0300 | INFO | [130,  4200] loss: 1.494
2025-02-25T12:31:37.041817+0300 | INFO | [130,  4300] loss: 1.480
2025-02-25T12:31:49.166846+0300 | INFO | [130,  4400] loss: 1.495
2025-02-25T12:32:07.048056+0300 | INFO | [130,  4500] loss: 1.489
2025-02-25T12:32:22.031227+0300 | INFO | [130,  4600] loss: 1.487
2025-02-25T12:32:36.692105+0300 | INFO | [130,  4700] loss: 1.489
2025-02-25T12:32:50.784558+0300 | INFO | [130,  4800] loss: 1.508
2025-02-25T12:33:05.408582+0300 | INFO | [130,  4900] loss: 1.493
2025-02-25T12:33:19.639780+0300 | DEBUG | Saving model to flat file storage. Save #130
2025-02-25T12:33:19.677746+0300 | INFO | Averaging client parameters
2025-02-25T12:33:19.689070+0300 | INFO | Updating parameters on client #0
2025-02-25T12:33:40.939958+0300 | DEBUG | Test set: Accuracy: 7857/10000 (79%)
2025-02-25T12:33:40.945562+0300 | DEBUG | Test set: Loss: 1.6737087965011597
2025-02-25T12:33:41.087100+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.77      0.68      0.72      1000
           3       0.63      0.59      0.61      1200
           4       0.76      0.81      0.79      1000
           5       0.50      0.60      0.55       800
           6       0.83      0.85      0.84      1000
           7       0.87      0.81      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.90      0.87      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T12:33:41.087100+0300 | DEBUG | Confusion Matrix:
[[846  11  36  16  16  12   5   8  33  17]
 [ 10 916   1   2   2   1   6   2  20  40]
 [ 61   1 680  51  63  65  53  16   5   5]
 [ 30   4  51 708  56 262  48  23  10   8]
 [ 10   1  33  49 811  32  30  29   3   2]
 [  9   1  30 197  30 477  18  31   5   2]
 [ 13   0  27  45  33  24 849   5   3   1]
 [ 17   1   9  38  47  63   8 812   2   3]
 [ 50  15   7   5   4   8   4   3 886  18]
 [ 29  52   5  10   1   3   5   7  16 872]]
2025-02-25T12:33:41.093682+0300 | DEBUG | Class precision: [0.78697674 0.91417166 0.77360637 0.63157895 0.76293509 0.50369588
 0.82748538 0.86752137 0.90132248 0.90082645]
2025-02-25T12:33:41.095092+0300 | DEBUG | Class recall: [0.846   0.916   0.68    0.59    0.811   0.59625 0.849   0.812   0.886
 0.872  ]
2025-02-25T12:33:41.143384+0300 | INFO | Training epoch #131 on client #0
2025-02-25T12:33:41.151368+0300 | DEBUG | Saving model to flat file storage. Save #131
2025-02-25T12:33:41.351735+0300 | INFO | [131,     0] loss: 0.015
2025-02-25T12:33:56.356273+0300 | INFO | [131,   100] loss: 1.488
2025-02-25T12:34:10.747377+0300 | INFO | [131,   200] loss: 1.488
2025-02-25T12:34:25.448511+0300 | INFO | [131,   300] loss: 1.496
2025-02-25T12:34:40.634825+0300 | INFO | [131,   400] loss: 1.489
2025-02-25T12:34:55.316476+0300 | INFO | [131,   500] loss: 1.489
2025-02-25T12:35:10.076412+0300 | INFO | [131,   600] loss: 1.503
2025-02-25T12:35:26.220263+0300 | INFO | [131,   700] loss: 1.482
2025-02-25T12:35:40.783187+0300 | INFO | [131,   800] loss: 1.496
2025-02-25T12:35:55.550907+0300 | INFO | [131,   900] loss: 1.492
2025-02-25T12:36:10.283500+0300 | INFO | [131,  1000] loss: 1.496
2025-02-25T12:36:24.935270+0300 | INFO | [131,  1100] loss: 1.493
2025-02-25T12:36:39.527521+0300 | INFO | [131,  1200] loss: 1.495
2025-02-25T12:36:53.993375+0300 | INFO | [131,  1300] loss: 1.498
2025-02-25T12:37:14.431552+0300 | INFO | [131,  1400] loss: 1.492
2025-02-25T12:37:32.369188+0300 | INFO | [131,  1500] loss: 1.493
2025-02-25T12:37:47.159888+0300 | INFO | [131,  1600] loss: 1.497
2025-02-25T12:38:01.718818+0300 | INFO | [131,  1700] loss: 1.490
2025-02-25T12:38:18.059595+0300 | INFO | [131,  1800] loss: 1.485
2025-02-25T12:38:32.934222+0300 | INFO | [131,  1900] loss: 1.500
2025-02-25T12:38:47.919983+0300 | INFO | [131,  2000] loss: 1.488
2025-02-25T12:39:03.184631+0300 | INFO | [131,  2100] loss: 1.493
2025-02-25T12:39:18.171171+0300 | INFO | [131,  2200] loss: 1.493
2025-02-25T12:39:35.326402+0300 | INFO | [131,  2300] loss: 1.496
2025-02-25T12:39:51.072719+0300 | INFO | [131,  2400] loss: 1.481
2025-02-25T12:40:07.343309+0300 | INFO | [131,  2500] loss: 1.496
2025-02-25T12:40:22.412232+0300 | INFO | [131,  2600] loss: 1.494
2025-02-25T12:40:37.147543+0300 | INFO | [131,  2700] loss: 1.491
2025-02-25T12:40:52.277373+0300 | INFO | [131,  2800] loss: 1.487
2025-02-25T12:41:06.821467+0300 | INFO | [131,  2900] loss: 1.487
2025-02-25T12:41:22.278218+0300 | INFO | [131,  3000] loss: 1.492
2025-02-25T12:41:37.235750+0300 | INFO | [131,  3100] loss: 1.489
2025-02-25T12:41:52.422995+0300 | INFO | [131,  3200] loss: 1.484
2025-02-25T12:42:07.708586+0300 | INFO | [131,  3300] loss: 1.493
2025-02-25T12:42:23.580208+0300 | INFO | [131,  3400] loss: 1.484
2025-02-25T12:42:36.879680+0300 | INFO | [131,  3500] loss: 1.488
2025-02-25T12:42:50.243971+0300 | INFO | [131,  3600] loss: 1.492
2025-02-25T12:43:02.597334+0300 | INFO | [131,  3700] loss: 1.497
2025-02-25T12:43:15.993815+0300 | INFO | [131,  3800] loss: 1.492
2025-02-25T12:43:28.680905+0300 | INFO | [131,  3900] loss: 1.490
2025-02-25T12:43:42.329787+0300 | INFO | [131,  4000] loss: 1.492
2025-02-25T12:43:54.908350+0300 | INFO | [131,  4100] loss: 1.490
2025-02-25T12:44:03.137327+0300 | INFO | [131,  4200] loss: 1.494
2025-02-25T12:44:11.169806+0300 | INFO | [131,  4300] loss: 1.496
2025-02-25T12:44:18.366453+0300 | INFO | [131,  4400] loss: 1.511
2025-02-25T12:44:24.981066+0300 | INFO | [131,  4500] loss: 1.496
2025-02-25T12:44:31.042756+0300 | INFO | [131,  4600] loss: 1.500
2025-02-25T12:44:37.923545+0300 | INFO | [131,  4700] loss: 1.493
2025-02-25T12:44:43.981774+0300 | INFO | [131,  4800] loss: 1.487
2025-02-25T12:44:51.453002+0300 | INFO | [131,  4900] loss: 1.495
2025-02-25T12:44:59.276054+0300 | DEBUG | Saving model to flat file storage. Save #131
2025-02-25T12:44:59.284242+0300 | INFO | Averaging client parameters
2025-02-25T12:44:59.289207+0300 | INFO | Updating parameters on client #0
2025-02-25T12:45:11.013096+0300 | DEBUG | Test set: Accuracy: 7890/10000 (79%)
2025-02-25T12:45:11.013096+0300 | DEBUG | Test set: Loss: 1.6717724800109863
2025-02-25T12:45:11.059583+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.65      0.58      0.61      1200
           4       0.76      0.81      0.79      1000
           5       0.52      0.59      0.56       800
           6       0.84      0.85      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.90      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T12:45:11.062045+0300 | DEBUG | Confusion Matrix:
[[829  10  37  16  13  11   5   9  52  18]
 [ 12 910   2   5   1   0   5   1  21  43]
 [ 51   1 694  47  65  56  51  23   6   6]
 [ 25   6  55 691  55 270  51  29   8  10]
 [ 11   1  40  44 812  30  23  33   4   2]
 [ 10   1  35 178  31 476  16  47   6   0]
 [  9   1  32  40  30  20 855   5   4   4]
 [ 15   1  12  28  51  43   7 838   2   3]
 [ 41  16   6   8   5   5   3   3 895  18]
 [ 22  43   6   6   2   4   3   6  18 890]]
2025-02-25T12:45:11.063064+0300 | DEBUG | Class precision: [0.80878049 0.91919192 0.75516866 0.65004704 0.76244131 0.52021858
 0.8390579  0.84305835 0.88090551 0.89537223]
2025-02-25T12:45:11.064064+0300 | DEBUG | Class recall: [0.829      0.91       0.694      0.57583333 0.812      0.595
 0.855      0.838      0.895      0.89      ]
2025-02-25T12:45:11.114018+0300 | INFO | Training epoch #132 on client #0
2025-02-25T12:45:11.115021+0300 | DEBUG | Saving model to flat file storage. Save #132
2025-02-25T12:45:11.187155+0300 | INFO | [132,     0] loss: 0.015
2025-02-25T12:45:20.438828+0300 | INFO | [132,   100] loss: 1.491
2025-02-25T12:45:32.487409+0300 | INFO | [132,   200] loss: 1.486
2025-02-25T12:45:41.785611+0300 | INFO | [132,   300] loss: 1.483
2025-02-25T12:45:55.795899+0300 | INFO | [132,   400] loss: 1.485
2025-02-25T12:46:07.905951+0300 | INFO | [132,   500] loss: 1.488
2025-02-25T12:46:17.781410+0300 | INFO | [132,   600] loss: 1.497
2025-02-25T12:46:26.671068+0300 | INFO | [132,   700] loss: 1.495
2025-02-25T12:46:35.502197+0300 | INFO | [132,   800] loss: 1.499
2025-02-25T12:46:43.764442+0300 | INFO | [132,   900] loss: 1.496
2025-02-25T12:46:51.743378+0300 | INFO | [132,  1000] loss: 1.500
2025-02-25T12:47:06.277669+0300 | INFO | [132,  1100] loss: 1.490
2025-02-25T12:47:14.620027+0300 | INFO | [132,  1200] loss: 1.502
2025-02-25T12:47:24.080003+0300 | INFO | [132,  1300] loss: 1.493
2025-02-25T12:47:32.442256+0300 | INFO | [132,  1400] loss: 1.488
2025-02-25T12:47:40.020222+0300 | INFO | [132,  1500] loss: 1.493
2025-02-25T12:47:47.783394+0300 | INFO | [132,  1600] loss: 1.492
2025-02-25T12:47:55.357293+0300 | INFO | [132,  1700] loss: 1.491
2025-02-25T12:48:02.919703+0300 | INFO | [132,  1800] loss: 1.500
2025-02-25T12:48:11.407027+0300 | INFO | [132,  1900] loss: 1.498
2025-02-25T12:48:20.216672+0300 | INFO | [132,  2000] loss: 1.486
2025-02-25T12:48:28.191679+0300 | INFO | [132,  2100] loss: 1.488
2025-02-25T12:48:35.747855+0300 | INFO | [132,  2200] loss: 1.490
2025-02-25T12:48:44.326074+0300 | INFO | [132,  2300] loss: 1.490
2025-02-25T12:48:52.425273+0300 | INFO | [132,  2400] loss: 1.492
2025-02-25T12:49:00.573996+0300 | INFO | [132,  2500] loss: 1.487
2025-02-25T12:49:08.654905+0300 | INFO | [132,  2600] loss: 1.478
2025-02-25T12:49:15.994406+0300 | INFO | [132,  2700] loss: 1.491
2025-02-25T12:49:23.531336+0300 | INFO | [132,  2800] loss: 1.493
2025-02-25T12:49:31.401704+0300 | INFO | [132,  2900] loss: 1.491
2025-02-25T12:49:38.786150+0300 | INFO | [132,  3000] loss: 1.496
2025-02-25T12:49:46.365151+0300 | INFO | [132,  3100] loss: 1.487
2025-02-25T12:49:53.757851+0300 | INFO | [132,  3200] loss: 1.496
2025-02-25T12:50:01.810710+0300 | INFO | [132,  3300] loss: 1.488
2025-02-25T12:50:12.322014+0300 | INFO | [132,  3400] loss: 1.486
2025-02-25T12:50:20.176582+0300 | INFO | [132,  3500] loss: 1.499
2025-02-25T12:50:27.809668+0300 | INFO | [132,  3600] loss: 1.488
2025-02-25T12:50:35.312151+0300 | INFO | [132,  3700] loss: 1.484
2025-02-25T12:50:42.776386+0300 | INFO | [132,  3800] loss: 1.496
2025-02-25T12:50:51.523681+0300 | INFO | [132,  3900] loss: 1.502
2025-02-25T12:51:01.442169+0300 | INFO | [132,  4000] loss: 1.502
2025-02-25T12:51:09.461443+0300 | INFO | [132,  4100] loss: 1.491
2025-02-25T12:51:17.307684+0300 | INFO | [132,  4200] loss: 1.487
2025-02-25T12:51:24.892076+0300 | INFO | [132,  4300] loss: 1.495
2025-02-25T12:51:32.648830+0300 | INFO | [132,  4400] loss: 1.506
2025-02-25T12:51:39.899295+0300 | INFO | [132,  4500] loss: 1.494
2025-02-25T12:51:47.461564+0300 | INFO | [132,  4600] loss: 1.494
2025-02-25T12:51:55.057898+0300 | INFO | [132,  4700] loss: 1.479
2025-02-25T12:52:02.753938+0300 | INFO | [132,  4800] loss: 1.493
2025-02-25T12:52:10.497324+0300 | INFO | [132,  4900] loss: 1.511
2025-02-25T12:52:19.637232+0300 | DEBUG | Saving model to flat file storage. Save #132
2025-02-25T12:52:19.648845+0300 | INFO | Averaging client parameters
2025-02-25T12:52:19.654180+0300 | INFO | Updating parameters on client #0
2025-02-25T12:52:32.068561+0300 | DEBUG | Test set: Accuracy: 7849/10000 (78%)
2025-02-25T12:52:32.068561+0300 | DEBUG | Test set: Loss: 1.6750577688217163
2025-02-25T12:52:32.116570+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.93      0.90      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.62      0.61      0.62      1200
           4       0.76      0.83      0.79      1000
           5       0.51      0.56      0.53       800
           6       0.85      0.84      0.84      1000
           7       0.86      0.82      0.84      1000
           8       0.86      0.90      0.88      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.78      0.79     10000

2025-02-25T12:52:32.116570+0300 | DEBUG | Confusion Matrix:
[[830   9  40  18  14  11   5   7  49  17]
 [ 12 896   5   4   1   1   5   3  27  46]
 [ 53   1 681  58  68  58  49  19   8   5]
 [ 25   3  47 735  57 243  45  26  12   7]
 [  9   2  32  46 828  25  21  30   5   2]
 [  9   0  37 221  32 444  13  37   6   1]
 [ 12   1  27  52  33  22 841   5   6   1]
 [ 16   1  13  37  52  54   6 816   3   2]
 [ 40  11   8  10   5   5   4   3 899  15]
 [ 24  39   8   8   1   4   4   8  25 879]]
2025-02-25T12:52:32.117970+0300 | DEBUG | Class precision: [0.80582524 0.93042575 0.75835189 0.61816653 0.75893676 0.51211073
 0.8469285  0.85534591 0.86442308 0.90153846]
2025-02-25T12:52:32.119122+0300 | DEBUG | Class recall: [0.83   0.896  0.681  0.6125 0.828  0.555  0.841  0.816  0.899  0.879 ]
2025-02-25T12:52:32.165734+0300 | INFO | Training epoch #133 on client #0
2025-02-25T12:52:32.167232+0300 | DEBUG | Saving model to flat file storage. Save #133
2025-02-25T12:52:32.242640+0300 | INFO | [133,     0] loss: 0.015
2025-02-25T12:52:39.742905+0300 | INFO | [133,   100] loss: 1.495
2025-02-25T12:52:47.137902+0300 | INFO | [133,   200] loss: 1.492
2025-02-25T12:52:55.292776+0300 | INFO | [133,   300] loss: 1.496
2025-02-25T12:53:02.948335+0300 | INFO | [133,   400] loss: 1.480
2025-02-25T12:53:12.355291+0300 | INFO | [133,   500] loss: 1.491
2025-02-25T12:53:19.255009+0300 | INFO | [133,   600] loss: 1.496
2025-02-25T12:53:27.703390+0300 | INFO | [133,   700] loss: 1.490
2025-02-25T12:53:35.295392+0300 | INFO | [133,   800] loss: 1.488
2025-02-25T12:53:43.235904+0300 | INFO | [133,   900] loss: 1.485
2025-02-25T12:53:50.291398+0300 | INFO | [133,  1000] loss: 1.484
2025-02-25T12:53:58.203856+0300 | INFO | [133,  1100] loss: 1.492
2025-02-25T12:54:06.143705+0300 | INFO | [133,  1200] loss: 1.482
2025-02-25T12:54:15.275544+0300 | INFO | [133,  1300] loss: 1.495
2025-02-25T12:54:25.633693+0300 | INFO | [133,  1400] loss: 1.498
2025-02-25T12:54:34.052758+0300 | INFO | [133,  1500] loss: 1.501
2025-02-25T12:54:43.737582+0300 | INFO | [133,  1600] loss: 1.491
2025-02-25T12:54:52.855750+0300 | INFO | [133,  1700] loss: 1.496
2025-02-25T12:55:01.715847+0300 | INFO | [133,  1800] loss: 1.493
2025-02-25T12:55:11.674481+0300 | INFO | [133,  1900] loss: 1.485
2025-02-25T12:55:20.430354+0300 | INFO | [133,  2000] loss: 1.488
2025-02-25T12:55:27.851886+0300 | INFO | [133,  2100] loss: 1.481
2025-02-25T12:55:35.450032+0300 | INFO | [133,  2200] loss: 1.488
2025-02-25T12:55:42.755868+0300 | INFO | [133,  2300] loss: 1.487
2025-02-25T12:55:51.192475+0300 | INFO | [133,  2400] loss: 1.490
2025-02-25T12:55:58.426600+0300 | INFO | [133,  2500] loss: 1.493
2025-02-25T12:56:07.505861+0300 | INFO | [133,  2600] loss: 1.496
2025-02-25T12:56:15.451139+0300 | INFO | [133,  2700] loss: 1.500
2025-02-25T12:56:23.980131+0300 | INFO | [133,  2800] loss: 1.499
2025-02-25T12:56:30.977041+0300 | INFO | [133,  2900] loss: 1.485
2025-02-25T12:56:38.784247+0300 | INFO | [133,  3000] loss: 1.488
2025-02-25T12:56:46.172169+0300 | INFO | [133,  3100] loss: 1.486
2025-02-25T12:56:56.735854+0300 | INFO | [133,  3200] loss: 1.497
2025-02-25T12:57:04.527612+0300 | INFO | [133,  3300] loss: 1.497
2025-02-25T12:57:12.747201+0300 | INFO | [133,  3400] loss: 1.487
2025-02-25T12:57:20.082847+0300 | INFO | [133,  3500] loss: 1.491
2025-02-25T12:57:27.903857+0300 | INFO | [133,  3600] loss: 1.495
2025-02-25T12:57:35.110761+0300 | INFO | [133,  3700] loss: 1.486
2025-02-25T12:57:42.982214+0300 | INFO | [133,  3800] loss: 1.496
2025-02-25T12:57:49.968541+0300 | INFO | [133,  3900] loss: 1.500
2025-02-25T12:57:57.983355+0300 | INFO | [133,  4000] loss: 1.488
2025-02-25T12:58:05.715480+0300 | INFO | [133,  4100] loss: 1.497
2025-02-25T12:58:13.669787+0300 | INFO | [133,  4200] loss: 1.487
2025-02-25T12:58:20.766126+0300 | INFO | [133,  4300] loss: 1.501
2025-02-25T12:58:29.357524+0300 | INFO | [133,  4400] loss: 1.495
2025-02-25T12:58:36.904770+0300 | INFO | [133,  4500] loss: 1.494
2025-02-25T12:58:44.951894+0300 | INFO | [133,  4600] loss: 1.502
2025-02-25T12:58:52.838294+0300 | INFO | [133,  4700] loss: 1.496
2025-02-25T12:59:01.331061+0300 | INFO | [133,  4800] loss: 1.495
2025-02-25T12:59:11.977748+0300 | INFO | [133,  4900] loss: 1.495
2025-02-25T12:59:21.684843+0300 | DEBUG | Saving model to flat file storage. Save #133
2025-02-25T12:59:21.693103+0300 | INFO | Averaging client parameters
2025-02-25T12:59:21.697958+0300 | INFO | Updating parameters on client #0
2025-02-25T12:59:35.564485+0300 | DEBUG | Test set: Accuracy: 7829/10000 (78%)
2025-02-25T12:59:35.565504+0300 | DEBUG | Test set: Loss: 1.6767826080322266
2025-02-25T12:59:35.648978+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.85      0.80      1000
           1       0.91      0.92      0.91      1000
           2       0.74      0.69      0.72      1000
           3       0.64      0.58      0.61      1200
           4       0.77      0.80      0.78      1000
           5       0.50      0.59      0.54       800
           6       0.84      0.84      0.84      1000
           7       0.89      0.79      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T12:59:35.651303+0300 | DEBUG | Confusion Matrix:
[[852  11  33  12  11  12   6   5  37  21]
 [ 11 922   3   5   0   0   3   1  17  38]
 [ 67   2 689  43  62  62  52  10   7   6]
 [ 36   7  57 695  52 259  47  22  14  11]
 [ 17   2  45  48 798  31  29  24   4   2]
 [ 15   2  39 203  25 470  14  25   6   1]
 [ 13   2  34  43  26  27 844   4   6   1]
 [ 26   1  17  29  59  63   8 791   4   2]
 [ 49  19   4   3   6   4   4   1 893  17]
 [ 34  49   5   6   2   5   2   5  17 875]]
2025-02-25T12:59:35.652301+0300 | DEBUG | Class precision: [0.76071429 0.906588   0.74406048 0.63937443 0.76657061 0.50375134
 0.83647175 0.89076577 0.88855721 0.89835729]
2025-02-25T12:59:35.653304+0300 | DEBUG | Class recall: [0.852      0.922      0.689      0.57916667 0.798      0.5875
 0.844      0.791      0.893      0.875     ]
2025-02-25T12:59:35.654304+0300 | INFO | Training epoch #134 on client #0
2025-02-25T12:59:35.655618+0300 | DEBUG | Saving model to flat file storage. Save #134
2025-02-25T12:59:35.748991+0300 | INFO | [134,     0] loss: 0.016
2025-02-25T12:59:44.614233+0300 | INFO | [134,   100] loss: 1.491
2025-02-25T12:59:52.791374+0300 | INFO | [134,   200] loss: 1.494
2025-02-25T13:00:00.117342+0300 | INFO | [134,   300] loss: 1.488
2025-02-25T13:00:08.865129+0300 | INFO | [134,   400] loss: 1.503
2025-02-25T13:00:17.364628+0300 | INFO | [134,   500] loss: 1.489
2025-02-25T13:00:27.990167+0300 | INFO | [134,   600] loss: 1.499
2025-02-25T13:00:36.876934+0300 | INFO | [134,   700] loss: 1.495
2025-02-25T13:00:45.574548+0300 | INFO | [134,   800] loss: 1.495
2025-02-25T13:00:53.944445+0300 | INFO | [134,   900] loss: 1.484
2025-02-25T13:01:04.484340+0300 | INFO | [134,  1000] loss: 1.494
2025-02-25T13:01:12.651590+0300 | INFO | [134,  1100] loss: 1.490
2025-02-25T13:01:19.940855+0300 | INFO | [134,  1200] loss: 1.491
2025-02-25T13:01:29.327049+0300 | INFO | [134,  1300] loss: 1.488
2025-02-25T13:01:36.753516+0300 | INFO | [134,  1400] loss: 1.495
2025-02-25T13:01:44.698525+0300 | INFO | [134,  1500] loss: 1.495
2025-02-25T13:01:51.919216+0300 | INFO | [134,  1600] loss: 1.507
2025-02-25T13:01:59.554970+0300 | INFO | [134,  1700] loss: 1.491
2025-02-25T13:02:07.050224+0300 | INFO | [134,  1800] loss: 1.494
2025-02-25T13:02:18.154629+0300 | INFO | [134,  1900] loss: 1.490
2025-02-25T13:02:27.661433+0300 | INFO | [134,  2000] loss: 1.496
2025-02-25T13:02:37.029486+0300 | INFO | [134,  2100] loss: 1.498
2025-02-25T13:02:46.011939+0300 | INFO | [134,  2200] loss: 1.488
2025-02-25T13:02:53.692717+0300 | INFO | [134,  2300] loss: 1.490
2025-02-25T13:03:06.658194+0300 | INFO | [134,  2400] loss: 1.494
2025-02-25T13:03:17.529140+0300 | INFO | [134,  2500] loss: 1.488
2025-02-25T13:03:27.009406+0300 | INFO | [134,  2600] loss: 1.496
2025-02-25T13:03:37.228313+0300 | INFO | [134,  2700] loss: 1.484
2025-02-25T13:03:46.173706+0300 | INFO | [134,  2800] loss: 1.495
2025-02-25T13:03:54.013512+0300 | INFO | [134,  2900] loss: 1.499
2025-02-25T13:04:01.394684+0300 | INFO | [134,  3000] loss: 1.488
2025-02-25T13:04:08.809572+0300 | INFO | [134,  3100] loss: 1.487
2025-02-25T13:04:17.697434+0300 | INFO | [134,  3200] loss: 1.497
2025-02-25T13:04:25.873550+0300 | INFO | [134,  3300] loss: 1.496
2025-02-25T13:04:33.397636+0300 | INFO | [134,  3400] loss: 1.487
2025-02-25T13:04:41.221236+0300 | INFO | [134,  3500] loss: 1.489
2025-02-25T13:04:48.582357+0300 | INFO | [134,  3600] loss: 1.492
2025-02-25T13:04:56.966343+0300 | INFO | [134,  3700] loss: 1.495
2025-02-25T13:05:04.717907+0300 | INFO | [134,  3800] loss: 1.493
2025-02-25T13:05:14.269558+0300 | INFO | [134,  3900] loss: 1.490
2025-02-25T13:05:23.511081+0300 | INFO | [134,  4000] loss: 1.491
2025-02-25T13:05:31.103746+0300 | INFO | [134,  4100] loss: 1.486
2025-02-25T13:05:38.906518+0300 | INFO | [134,  4200] loss: 1.495
2025-02-25T13:05:46.660311+0300 | INFO | [134,  4300] loss: 1.489
2025-02-25T13:05:54.107086+0300 | INFO | [134,  4400] loss: 1.502
2025-02-25T13:06:01.893673+0300 | INFO | [134,  4500] loss: 1.486
2025-02-25T13:06:10.155730+0300 | INFO | [134,  4600] loss: 1.483
2025-02-25T13:06:17.822858+0300 | INFO | [134,  4700] loss: 1.487
2025-02-25T13:06:26.130317+0300 | INFO | [134,  4800] loss: 1.485
2025-02-25T13:06:35.375039+0300 | INFO | [134,  4900] loss: 1.502
2025-02-25T13:06:43.985742+0300 | DEBUG | Saving model to flat file storage. Save #134
2025-02-25T13:06:43.995794+0300 | INFO | Averaging client parameters
2025-02-25T13:06:44.002842+0300 | INFO | Updating parameters on client #0
2025-02-25T13:06:56.903318+0300 | DEBUG | Test set: Accuracy: 7847/10000 (78%)
2025-02-25T13:06:56.903318+0300 | DEBUG | Test set: Loss: 1.6750609874725342
2025-02-25T13:06:57.039901+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.81      1000
           1       0.91      0.92      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.65      0.58      0.61      1200
           4       0.77      0.80      0.78      1000
           5       0.49      0.61      0.54       800
           6       0.81      0.87      0.84      1000
           7       0.90      0.79      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.78      0.79     10000

2025-02-25T13:06:57.043903+0300 | DEBUG | Confusion Matrix:
[[819  12  45  12  15  13   4   7  48  25]
 [  7 917   2   5   1   1   5   0  14  48]
 [ 54   1 700  41  58  62  59  11   5   9]
 [ 23   9  52 692  53 276  59  20   7   9]
 [ 12   2  41  45 795  36  40  23   5   1]
 [  9   1  43 185  31 485  18  22   5   1]
 [ 10   1  28  39  19  26 871   3   2   1]
 [ 18   2  15  29  55  74   9 793   2   3]
 [ 45  19   9   6   4   9   4   3 883  18]
 [ 20  45   6   8   3   4   3   4  15 892]]
2025-02-25T13:06:57.045404+0300 | DEBUG | Class precision: [0.80530973 0.90882061 0.74388948 0.65160075 0.7688588  0.49188641
 0.8125     0.89503386 0.89553753 0.8857994 ]
2025-02-25T13:06:57.047422+0300 | DEBUG | Class recall: [0.819      0.917      0.7        0.57666667 0.795      0.60625
 0.871      0.793      0.883      0.892     ]
2025-02-25T13:06:57.049422+0300 | INFO | Training epoch #135 on client #0
2025-02-25T13:06:57.049422+0300 | DEBUG | Saving model to flat file storage. Save #135
2025-02-25T13:06:57.249155+0300 | INFO | [135,     0] loss: 0.015
2025-02-25T13:07:07.708270+0300 | INFO | [135,   100] loss: 1.485
2025-02-25T13:07:15.559598+0300 | INFO | [135,   200] loss: 1.479
2025-02-25T13:07:22.964829+0300 | INFO | [135,   300] loss: 1.485
2025-02-25T13:07:30.263654+0300 | INFO | [135,   400] loss: 1.494
2025-02-25T13:07:37.979971+0300 | INFO | [135,   500] loss: 1.488
2025-02-25T13:07:45.154972+0300 | INFO | [135,   600] loss: 1.488
2025-02-25T13:07:52.915940+0300 | INFO | [135,   700] loss: 1.499
2025-02-25T13:08:00.659655+0300 | INFO | [135,   800] loss: 1.490
2025-02-25T13:08:10.413991+0300 | INFO | [135,   900] loss: 1.501
2025-02-25T13:08:17.301487+0300 | INFO | [135,  1000] loss: 1.492
2025-02-25T13:08:25.327617+0300 | INFO | [135,  1100] loss: 1.488
2025-02-25T13:08:32.932990+0300 | INFO | [135,  1200] loss: 1.491
2025-02-25T13:08:41.167252+0300 | INFO | [135,  1300] loss: 1.494
2025-02-25T13:08:48.762520+0300 | INFO | [135,  1400] loss: 1.499
2025-02-25T13:08:56.954969+0300 | INFO | [135,  1500] loss: 1.500
2025-02-25T13:09:04.771546+0300 | INFO | [135,  1600] loss: 1.502
2025-02-25T13:09:12.729085+0300 | INFO | [135,  1700] loss: 1.490
2025-02-25T13:09:20.211692+0300 | INFO | [135,  1800] loss: 1.491
2025-02-25T13:09:28.118524+0300 | INFO | [135,  1900] loss: 1.486
2025-02-25T13:09:35.568891+0300 | INFO | [135,  2000] loss: 1.497
2025-02-25T13:09:43.564425+0300 | INFO | [135,  2100] loss: 1.486
2025-02-25T13:09:50.481980+0300 | INFO | [135,  2200] loss: 1.494
2025-02-25T13:09:59.117271+0300 | INFO | [135,  2300] loss: 1.489
2025-02-25T13:10:09.028595+0300 | INFO | [135,  2400] loss: 1.485
2025-02-25T13:10:17.172098+0300 | INFO | [135,  2500] loss: 1.485
2025-02-25T13:10:25.069706+0300 | INFO | [135,  2600] loss: 1.494
2025-02-25T13:10:32.914668+0300 | INFO | [135,  2700] loss: 1.485
2025-02-25T13:10:40.658074+0300 | INFO | [135,  2800] loss: 1.502
2025-02-25T13:10:47.832769+0300 | INFO | [135,  2900] loss: 1.493
2025-02-25T13:10:55.552985+0300 | INFO | [135,  3000] loss: 1.484
2025-02-25T13:11:04.239299+0300 | INFO | [135,  3100] loss: 1.509
2025-02-25T13:11:12.000684+0300 | INFO | [135,  3200] loss: 1.503
2025-02-25T13:11:20.009863+0300 | INFO | [135,  3300] loss: 1.484
2025-02-25T13:11:27.488209+0300 | INFO | [135,  3400] loss: 1.489
2025-02-25T13:11:35.640563+0300 | INFO | [135,  3500] loss: 1.489
2025-02-25T13:11:43.306993+0300 | INFO | [135,  3600] loss: 1.501
2025-02-25T13:11:53.581618+0300 | INFO | [135,  3700] loss: 1.489
2025-02-25T13:12:02.731475+0300 | INFO | [135,  3800] loss: 1.491
2025-02-25T13:12:10.785940+0300 | INFO | [135,  3900] loss: 1.498
2025-02-25T13:12:18.248033+0300 | INFO | [135,  4000] loss: 1.490
2025-02-25T13:12:26.239841+0300 | INFO | [135,  4100] loss: 1.492
2025-02-25T13:12:33.438995+0300 | INFO | [135,  4200] loss: 1.496
2025-02-25T13:12:42.204275+0300 | INFO | [135,  4300] loss: 1.481
2025-02-25T13:12:50.122244+0300 | INFO | [135,  4400] loss: 1.490
2025-02-25T13:13:00.933271+0300 | INFO | [135,  4500] loss: 1.487
2025-02-25T13:13:11.643214+0300 | INFO | [135,  4600] loss: 1.496
2025-02-25T13:13:19.056560+0300 | INFO | [135,  4700] loss: 1.485
2025-02-25T13:13:27.924764+0300 | INFO | [135,  4800] loss: 1.496
2025-02-25T13:13:36.747259+0300 | INFO | [135,  4900] loss: 1.503
2025-02-25T13:13:46.623434+0300 | DEBUG | Saving model to flat file storage. Save #135
2025-02-25T13:13:46.657065+0300 | INFO | Averaging client parameters
2025-02-25T13:13:46.663079+0300 | INFO | Updating parameters on client #0
2025-02-25T13:14:00.015393+0300 | DEBUG | Test set: Accuracy: 7868/10000 (79%)
2025-02-25T13:14:00.018420+0300 | DEBUG | Test set: Loss: 1.67360258102417
2025-02-25T13:14:00.090099+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.81      1000
           1       0.90      0.93      0.91      1000
           2       0.78      0.65      0.71      1000
           3       0.64      0.58      0.61      1200
           4       0.79      0.78      0.79      1000
           5       0.50      0.62      0.55       800
           6       0.82      0.87      0.84      1000
           7       0.87      0.83      0.85      1000
           8       0.88      0.90      0.89      1000
           9       0.90      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T13:14:00.092112+0300 | DEBUG | Confusion Matrix:
[[826  15  41  13  12  14   3   7  52  17]
 [  7 931   2   3   0   2   2   1  15  37]
 [ 59   2 651  50  64  79  62  18   7   8]
 [ 21  10  42 701  43 277  56  26  14  10]
 [ 14   2  35  49 784  37  40  30   7   2]
 [ 10   2  23 184  29 496  18  30   7   1]
 [ 10   2  25  38  19  26 869   4   5   2]
 [ 20   1   7  33  36  58   8 831   3   3]
 [ 39  15   5   7   4   5   4   2 903  16]
 [ 23  58   5   9   1   4   3   4  17 876]]
2025-02-25T13:14:00.093111+0300 | DEBUG | Class precision: [0.80272109 0.89691715 0.77870813 0.6448942  0.79032258 0.49699399
 0.81596244 0.87198321 0.87669903 0.90123457]
2025-02-25T13:14:00.094113+0300 | DEBUG | Class recall: [0.826      0.931      0.651      0.58416667 0.784      0.62
 0.869      0.831      0.903      0.876     ]
2025-02-25T13:14:00.164575+0300 | INFO | Training epoch #136 on client #0
2025-02-25T13:14:00.165722+0300 | DEBUG | Saving model to flat file storage. Save #136
2025-02-25T13:14:00.254793+0300 | INFO | [136,     0] loss: 0.015
2025-02-25T13:14:08.327302+0300 | INFO | [136,   100] loss: 1.494
2025-02-25T13:14:16.746105+0300 | INFO | [136,   200] loss: 1.499
2025-02-25T13:14:24.491265+0300 | INFO | [136,   300] loss: 1.487
2025-02-25T13:14:33.061565+0300 | INFO | [136,   400] loss: 1.489
2025-02-25T13:14:40.837917+0300 | INFO | [136,   500] loss: 1.495
2025-02-25T13:14:49.464668+0300 | INFO | [136,   600] loss: 1.492
2025-02-25T13:14:57.598325+0300 | INFO | [136,   700] loss: 1.494
2025-02-25T13:15:06.315178+0300 | INFO | [136,   800] loss: 1.490
2025-02-25T13:15:18.579597+0300 | INFO | [136,   900] loss: 1.491
2025-02-25T13:15:33.461208+0300 | INFO | [136,  1000] loss: 1.490
2025-02-25T13:15:42.688268+0300 | INFO | [136,  1100] loss: 1.496
2025-02-25T13:15:51.265867+0300 | INFO | [136,  1200] loss: 1.495
2025-02-25T13:16:00.389295+0300 | INFO | [136,  1300] loss: 1.490
2025-02-25T13:16:11.149232+0300 | INFO | [136,  1400] loss: 1.501
2025-02-25T13:16:21.473778+0300 | INFO | [136,  1500] loss: 1.490
2025-02-25T13:16:31.908941+0300 | INFO | [136,  1600] loss: 1.494
2025-02-25T13:16:42.957474+0300 | INFO | [136,  1700] loss: 1.478
2025-02-25T13:16:51.255747+0300 | INFO | [136,  1800] loss: 1.498
2025-02-25T13:17:00.278734+0300 | INFO | [136,  1900] loss: 1.494
2025-02-25T13:17:09.292787+0300 | INFO | [136,  2000] loss: 1.491
2025-02-25T13:17:18.061857+0300 | INFO | [136,  2100] loss: 1.496
2025-02-25T13:17:29.016559+0300 | INFO | [136,  2200] loss: 1.493
2025-02-25T13:17:37.968111+0300 | INFO | [136,  2300] loss: 1.491
2025-02-25T13:17:47.995960+0300 | INFO | [136,  2400] loss: 1.482
2025-02-25T13:17:57.269199+0300 | INFO | [136,  2500] loss: 1.494
2025-02-25T13:18:07.473544+0300 | INFO | [136,  2600] loss: 1.496
2025-02-25T13:18:21.945174+0300 | INFO | [136,  2700] loss: 1.491
2025-02-25T13:18:32.457096+0300 | INFO | [136,  2800] loss: 1.507
2025-02-25T13:18:40.771409+0300 | INFO | [136,  2900] loss: 1.500
2025-02-25T13:18:50.982802+0300 | INFO | [136,  3000] loss: 1.497
2025-02-25T13:19:01.036494+0300 | INFO | [136,  3100] loss: 1.490
2025-02-25T13:19:11.085466+0300 | INFO | [136,  3200] loss: 1.491
2025-02-25T13:19:19.600019+0300 | INFO | [136,  3300] loss: 1.505
2025-02-25T13:19:30.526097+0300 | INFO | [136,  3400] loss: 1.495
2025-02-25T13:19:39.541181+0300 | INFO | [136,  3500] loss: 1.479
2025-02-25T13:19:47.419423+0300 | INFO | [136,  3600] loss: 1.487
2025-02-25T13:19:55.551124+0300 | INFO | [136,  3700] loss: 1.496
2025-02-25T13:20:03.577001+0300 | INFO | [136,  3800] loss: 1.484
2025-02-25T13:20:11.526320+0300 | INFO | [136,  3900] loss: 1.485
2025-02-25T13:20:19.551005+0300 | INFO | [136,  4000] loss: 1.486
2025-02-25T13:20:27.614630+0300 | INFO | [136,  4100] loss: 1.493
2025-02-25T13:20:35.966968+0300 | INFO | [136,  4200] loss: 1.497
2025-02-25T13:20:45.803702+0300 | INFO | [136,  4300] loss: 1.490
2025-02-25T13:20:58.416474+0300 | INFO | [136,  4400] loss: 1.483
2025-02-25T13:21:08.967943+0300 | INFO | [136,  4500] loss: 1.493
2025-02-25T13:21:19.289138+0300 | INFO | [136,  4600] loss: 1.499
2025-02-25T13:21:29.245688+0300 | INFO | [136,  4700] loss: 1.483
2025-02-25T13:21:38.693368+0300 | INFO | [136,  4800] loss: 1.494
2025-02-25T13:21:49.966784+0300 | INFO | [136,  4900] loss: 1.489
2025-02-25T13:21:59.928885+0300 | DEBUG | Saving model to flat file storage. Save #136
2025-02-25T13:21:59.934948+0300 | INFO | Averaging client parameters
2025-02-25T13:21:59.942817+0300 | INFO | Updating parameters on client #0
2025-02-25T13:22:11.847811+0300 | DEBUG | Test set: Accuracy: 7871/10000 (79%)
2025-02-25T13:22:11.847811+0300 | DEBUG | Test set: Loss: 1.6727490425109863
2025-02-25T13:22:11.915047+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.67      0.57      0.61      1200
           4       0.79      0.79      0.79      1000
           5       0.51      0.63      0.56       800
           6       0.81      0.88      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.87      0.90      0.88      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T13:22:11.916413+0300 | DEBUG | Confusion Matrix:
[[821  14  46  14  14  11   5   8  46  21]
 [  6 928   3   4   0   1   5   1  16  36]
 [ 53   4 686  44  52  61  65  20   8   7]
 [ 24   7  56 682  48 272  58  28  16   9]
 [ 11   2  36  48 791  35  43  27   5   2]
 [ 11   1  31 166  28 501  17  36   7   2]
 [  5   2  31  33  19  23 875   4   7   1]
 [ 14   1  14  19  46  64   9 828   3   2]
 [ 41  16   6   6   6   5   3   4 896  17]
 [ 23  59   7   6   3   3   4   8  24 863]]
2025-02-25T13:22:11.918428+0300 | DEBUG | Class precision: [0.81367691 0.89748549 0.7489083  0.66731898 0.78550149 0.51331967
 0.80719557 0.85892116 0.87159533 0.89895833]
2025-02-25T13:22:11.919494+0300 | DEBUG | Class recall: [0.821      0.928      0.686      0.56833333 0.791      0.62625
 0.875      0.828      0.896      0.863     ]
2025-02-25T13:22:11.920867+0300 | INFO | Training epoch #137 on client #0
2025-02-25T13:22:11.922242+0300 | DEBUG | Saving model to flat file storage. Save #137
2025-02-25T13:22:12.015432+0300 | INFO | [137,     0] loss: 0.015
2025-02-25T13:22:22.173095+0300 | INFO | [137,   100] loss: 1.487
2025-02-25T13:22:34.047521+0300 | INFO | [137,   200] loss: 1.493
2025-02-25T13:22:43.857701+0300 | INFO | [137,   300] loss: 1.493
2025-02-25T13:22:53.514799+0300 | INFO | [137,   400] loss: 1.484
2025-02-25T13:23:02.345386+0300 | INFO | [137,   500] loss: 1.486
2025-02-25T13:23:13.999477+0300 | INFO | [137,   600] loss: 1.496
2025-02-25T13:23:24.313530+0300 | INFO | [137,   700] loss: 1.493
2025-02-25T13:23:34.613943+0300 | INFO | [137,   800] loss: 1.488
2025-02-25T13:23:43.710445+0300 | INFO | [137,   900] loss: 1.498
2025-02-25T13:23:51.875726+0300 | INFO | [137,  1000] loss: 1.487
2025-02-25T13:23:59.897634+0300 | INFO | [137,  1100] loss: 1.490
2025-02-25T13:24:07.775725+0300 | INFO | [137,  1200] loss: 1.494
2025-02-25T13:24:15.401148+0300 | INFO | [137,  1300] loss: 1.501
2025-02-25T13:24:23.267496+0300 | INFO | [137,  1400] loss: 1.502
2025-02-25T13:24:30.497676+0300 | INFO | [137,  1500] loss: 1.487
2025-02-25T13:24:38.920608+0300 | INFO | [137,  1600] loss: 1.487
2025-02-25T13:24:49.737374+0300 | INFO | [137,  1700] loss: 1.489
2025-02-25T13:24:59.224387+0300 | INFO | [137,  1800] loss: 1.485
2025-02-25T13:25:09.937735+0300 | INFO | [137,  1900] loss: 1.486
2025-02-25T13:25:18.726781+0300 | INFO | [137,  2000] loss: 1.485
2025-02-25T13:25:26.973099+0300 | INFO | [137,  2100] loss: 1.490
2025-02-25T13:25:34.928463+0300 | INFO | [137,  2200] loss: 1.494
2025-02-25T13:25:45.258856+0300 | INFO | [137,  2300] loss: 1.495
2025-02-25T13:25:54.617522+0300 | INFO | [137,  2400] loss: 1.489
2025-02-25T13:26:05.039497+0300 | INFO | [137,  2500] loss: 1.486
2025-02-25T13:26:13.946807+0300 | INFO | [137,  2600] loss: 1.487
2025-02-25T13:26:21.602503+0300 | INFO | [137,  2700] loss: 1.511
2025-02-25T13:26:30.422918+0300 | INFO | [137,  2800] loss: 1.494
2025-02-25T13:26:38.537698+0300 | INFO | [137,  2900] loss: 1.487
2025-02-25T13:26:47.435479+0300 | INFO | [137,  3000] loss: 1.487
2025-02-25T13:26:56.117902+0300 | INFO | [137,  3100] loss: 1.500
2025-02-25T13:27:07.166794+0300 | INFO | [137,  3200] loss: 1.490
2025-02-25T13:27:16.409492+0300 | INFO | [137,  3300] loss: 1.502
2025-02-25T13:27:26.360440+0300 | INFO | [137,  3400] loss: 1.491
2025-02-25T13:27:35.743787+0300 | INFO | [137,  3500] loss: 1.493
2025-02-25T13:27:44.262346+0300 | INFO | [137,  3600] loss: 1.491
2025-02-25T13:27:53.515999+0300 | INFO | [137,  3700] loss: 1.494
2025-02-25T13:28:02.290436+0300 | INFO | [137,  3800] loss: 1.484
2025-02-25T13:28:10.860175+0300 | INFO | [137,  3900] loss: 1.507
2025-02-25T13:28:20.101505+0300 | INFO | [137,  4000] loss: 1.492
2025-02-25T13:28:29.822550+0300 | INFO | [137,  4100] loss: 1.491
2025-02-25T13:28:41.258683+0300 | INFO | [137,  4200] loss: 1.486
2025-02-25T13:28:51.715980+0300 | INFO | [137,  4300] loss: 1.492
2025-02-25T13:29:00.153116+0300 | INFO | [137,  4400] loss: 1.505
2025-02-25T13:29:10.751978+0300 | INFO | [137,  4500] loss: 1.498
2025-02-25T13:29:18.701499+0300 | INFO | [137,  4600] loss: 1.489
2025-02-25T13:29:27.319341+0300 | INFO | [137,  4700] loss: 1.490
2025-02-25T13:29:35.432596+0300 | INFO | [137,  4800] loss: 1.496
2025-02-25T13:29:43.617957+0300 | INFO | [137,  4900] loss: 1.495
2025-02-25T13:29:51.036767+0300 | DEBUG | Saving model to flat file storage. Save #137
2025-02-25T13:29:51.046232+0300 | INFO | Averaging client parameters
2025-02-25T13:29:51.053366+0300 | INFO | Updating parameters on client #0
2025-02-25T13:30:02.659955+0300 | DEBUG | Test set: Accuracy: 7918/10000 (79%)
2025-02-25T13:30:02.659955+0300 | DEBUG | Test set: Loss: 1.6694718599319458
2025-02-25T13:30:02.723187+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.76      0.70      0.73      1000
           3       0.65      0.60      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.54      0.60      0.57       800
           6       0.82      0.86      0.84      1000
           7       0.88      0.83      0.85      1000
           8       0.90      0.88      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T13:30:02.724586+0300 | DEBUG | Confusion Matrix:
[[853  12  38  15  10  11   7   6  30  18]
 [ 13 903   4   6   1   1   7   1  14  50]
 [ 60   1 698  42  62  56  55  14   4   8]
 [ 31   4  55 715  55 234  57  26  13  10]
 [ 14   2  34  47 805  28  34  28   6   2]
 [ 13   1  34 190  28 481  13  32   6   2]
 [  8   1  31  35  26  22 865   4   6   2]
 [ 17   1  10  33  51  49   8 826   2   3]
 [ 56  14   6   8   5   6   3   1 883  18]
 [ 26  39   6   8   2   3   3   6  18 889]]
2025-02-25T13:30:02.724586+0300 | DEBUG | Class precision: [0.78185151 0.92331288 0.76200873 0.65059145 0.77033493 0.53984287
 0.82224335 0.875      0.89918534 0.88722555]
2025-02-25T13:30:02.726095+0300 | DEBUG | Class recall: [0.853      0.903      0.698      0.59583333 0.805      0.60125
 0.865      0.826      0.883      0.889     ]
2025-02-25T13:30:02.776789+0300 | INFO | Training epoch #138 on client #0
2025-02-25T13:30:02.777784+0300 | DEBUG | Saving model to flat file storage. Save #138
2025-02-25T13:30:02.858107+0300 | INFO | [138,     0] loss: 0.015
2025-02-25T13:30:13.538475+0300 | INFO | [138,   100] loss: 1.492
2025-02-25T13:30:24.852844+0300 | INFO | [138,   200] loss: 1.492
2025-02-25T13:30:33.455040+0300 | INFO | [138,   300] loss: 1.492
2025-02-25T13:30:41.152243+0300 | INFO | [138,   400] loss: 1.488
2025-02-25T13:30:50.057907+0300 | INFO | [138,   500] loss: 1.490
2025-02-25T13:30:59.321642+0300 | INFO | [138,   600] loss: 1.499
2025-02-25T13:31:07.989106+0300 | INFO | [138,   700] loss: 1.499
2025-02-25T13:31:16.624327+0300 | INFO | [138,   800] loss: 1.493
2025-02-25T13:31:25.695376+0300 | INFO | [138,   900] loss: 1.492
2025-02-25T13:31:35.207974+0300 | INFO | [138,  1000] loss: 1.494
2025-02-25T13:31:47.537124+0300 | INFO | [138,  1100] loss: 1.491
2025-02-25T13:31:56.366792+0300 | INFO | [138,  1200] loss: 1.498
2025-02-25T13:32:08.499989+0300 | INFO | [138,  1300] loss: 1.485
2025-02-25T13:32:17.544654+0300 | INFO | [138,  1400] loss: 1.490
2025-02-25T13:32:26.314656+0300 | INFO | [138,  1500] loss: 1.494
2025-02-25T13:32:35.036936+0300 | INFO | [138,  1600] loss: 1.491
2025-02-25T13:32:45.232630+0300 | INFO | [138,  1700] loss: 1.494
2025-02-25T13:32:54.643851+0300 | INFO | [138,  1800] loss: 1.485
2025-02-25T13:33:02.487466+0300 | INFO | [138,  1900] loss: 1.492
2025-02-25T13:33:10.871258+0300 | INFO | [138,  2000] loss: 1.482
2025-02-25T13:33:18.164478+0300 | INFO | [138,  2100] loss: 1.499
2025-02-25T13:33:26.356627+0300 | INFO | [138,  2200] loss: 1.492
2025-02-25T13:33:33.925620+0300 | INFO | [138,  2300] loss: 1.494
2025-02-25T13:33:42.181757+0300 | INFO | [138,  2400] loss: 1.492
2025-02-25T13:33:52.058964+0300 | INFO | [138,  2500] loss: 1.497
2025-02-25T13:34:01.914750+0300 | INFO | [138,  2600] loss: 1.489
2025-02-25T13:34:14.015119+0300 | INFO | [138,  2700] loss: 1.499
2025-02-25T13:34:23.788096+0300 | INFO | [138,  2800] loss: 1.484
2025-02-25T13:34:31.957238+0300 | INFO | [138,  2900] loss: 1.486
2025-02-25T13:34:42.875128+0300 | INFO | [138,  3000] loss: 1.496
2025-02-25T13:34:52.808220+0300 | INFO | [138,  3100] loss: 1.495
2025-02-25T13:35:01.218826+0300 | INFO | [138,  3200] loss: 1.487
2025-02-25T13:35:09.170677+0300 | INFO | [138,  3300] loss: 1.486
2025-02-25T13:35:17.158845+0300 | INFO | [138,  3400] loss: 1.494
2025-02-25T13:35:24.774826+0300 | INFO | [138,  3500] loss: 1.498
2025-02-25T13:35:33.253037+0300 | INFO | [138,  3600] loss: 1.492
2025-02-25T13:35:42.524098+0300 | INFO | [138,  3700] loss: 1.490
2025-02-25T13:35:52.638999+0300 | INFO | [138,  3800] loss: 1.498
2025-02-25T13:36:05.194390+0300 | INFO | [138,  3900] loss: 1.483
2025-02-25T13:36:14.829422+0300 | INFO | [138,  4000] loss: 1.498
2025-02-25T13:36:24.453490+0300 | INFO | [138,  4100] loss: 1.492
2025-02-25T13:36:32.122743+0300 | INFO | [138,  4200] loss: 1.500
2025-02-25T13:36:40.212435+0300 | INFO | [138,  4300] loss: 1.496
2025-02-25T13:36:48.260095+0300 | INFO | [138,  4400] loss: 1.483
2025-02-25T13:36:57.668031+0300 | INFO | [138,  4500] loss: 1.496
2025-02-25T13:37:08.572902+0300 | INFO | [138,  4600] loss: 1.502
2025-02-25T13:37:18.505008+0300 | INFO | [138,  4700] loss: 1.490
2025-02-25T13:37:27.838968+0300 | INFO | [138,  4800] loss: 1.493
2025-02-25T13:37:37.506030+0300 | INFO | [138,  4900] loss: 1.484
2025-02-25T13:37:45.562316+0300 | DEBUG | Saving model to flat file storage. Save #138
2025-02-25T13:37:45.569179+0300 | INFO | Averaging client parameters
2025-02-25T13:37:45.572177+0300 | INFO | Updating parameters on client #0
2025-02-25T13:37:57.361593+0300 | DEBUG | Test set: Accuracy: 7859/10000 (79%)
2025-02-25T13:37:57.363536+0300 | DEBUG | Test set: Loss: 1.6732538938522339
2025-02-25T13:37:57.429730+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.86      0.81      1000
           1       0.90      0.92      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.67      0.55      0.60      1200
           4       0.76      0.83      0.79      1000
           5       0.51      0.62      0.56       800
           6       0.83      0.85      0.84      1000
           7       0.87      0.80      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T13:37:57.430730+0300 | DEBUG | Confusion Matrix:
[[858  13  32  11  11  10   5   6  35  19]
 [ 10 924   1   4   1   1   5   1  14  39]
 [ 67   1 690  45  62  59  51  15   3   7]
 [ 34  11  55 661  65 277  53  25   9  10]
 [ 14   3  31  34 826  31  24  31   5   1]
 [ 13   1  33 168  35 495  19  29   6   1]
 [ 14   0  40  35  25  25 854   2   3   2]
 [ 24   2  12  22  57  68   8 804   2   1]
 [ 58  19   8   5   6   5   3   3 879  14]
 [ 32  52   7   6   3   3   3   8  18 868]]
2025-02-25T13:37:57.433028+0300 | DEBUG | Class precision: [0.7633452  0.9005848  0.75907591 0.66700303 0.75710357 0.50821355
 0.83317073 0.87012987 0.90246407 0.9022869 ]
2025-02-25T13:37:57.434028+0300 | DEBUG | Class recall: [0.858      0.924      0.69       0.55083333 0.826      0.61875
 0.854      0.804      0.879      0.868     ]
2025-02-25T13:37:57.435347+0300 | INFO | Training epoch #139 on client #0
2025-02-25T13:37:57.436363+0300 | DEBUG | Saving model to flat file storage. Save #139
2025-02-25T13:37:57.548717+0300 | INFO | [139,     0] loss: 0.015
2025-02-25T13:38:06.525106+0300 | INFO | [139,   100] loss: 1.488
2025-02-25T13:38:17.489440+0300 | INFO | [139,   200] loss: 1.495
2025-02-25T13:38:26.632260+0300 | INFO | [139,   300] loss: 1.493
2025-02-25T13:38:36.974724+0300 | INFO | [139,   400] loss: 1.488
2025-02-25T13:38:46.926036+0300 | INFO | [139,   500] loss: 1.493
2025-02-25T13:38:54.997915+0300 | INFO | [139,   600] loss: 1.490
2025-02-25T13:39:03.425889+0300 | INFO | [139,   700] loss: 1.494
2025-02-25T13:39:12.353850+0300 | INFO | [139,   800] loss: 1.485
2025-02-25T13:39:20.753383+0300 | INFO | [139,   900] loss: 1.491
2025-02-25T13:39:29.186815+0300 | INFO | [139,  1000] loss: 1.496
2025-02-25T13:39:38.527669+0300 | INFO | [139,  1100] loss: 1.489
2025-02-25T13:39:49.815159+0300 | INFO | [139,  1200] loss: 1.489
2025-02-25T13:39:59.308618+0300 | INFO | [139,  1300] loss: 1.493
2025-02-25T13:40:09.280293+0300 | INFO | [139,  1400] loss: 1.488
2025-02-25T13:40:17.150688+0300 | INFO | [139,  1500] loss: 1.509
2025-02-25T13:40:25.074461+0300 | INFO | [139,  1600] loss: 1.493
2025-02-25T13:40:33.491000+0300 | INFO | [139,  1700] loss: 1.491
2025-02-25T13:40:42.720619+0300 | INFO | [139,  1800] loss: 1.490
2025-02-25T13:40:52.809727+0300 | INFO | [139,  1900] loss: 1.494
2025-02-25T13:41:02.383586+0300 | INFO | [139,  2000] loss: 1.485
2025-02-25T13:41:11.822574+0300 | INFO | [139,  2100] loss: 1.500
2025-02-25T13:41:19.961455+0300 | INFO | [139,  2200] loss: 1.505
2025-02-25T13:41:28.553839+0300 | INFO | [139,  2300] loss: 1.493
2025-02-25T13:41:42.111240+0300 | INFO | [139,  2400] loss: 1.491
2025-02-25T13:41:50.814189+0300 | INFO | [139,  2500] loss: 1.496
2025-02-25T13:41:59.610666+0300 | INFO | [139,  2600] loss: 1.493
2025-02-25T13:42:08.361813+0300 | INFO | [139,  2700] loss: 1.492
2025-02-25T13:42:17.244108+0300 | INFO | [139,  2800] loss: 1.492
2025-02-25T13:42:26.744885+0300 | INFO | [139,  2900] loss: 1.498
2025-02-25T13:42:36.371046+0300 | INFO | [139,  3000] loss: 1.497
2025-02-25T13:42:50.843973+0300 | INFO | [139,  3100] loss: 1.494
2025-02-25T13:43:05.876949+0300 | INFO | [139,  3200] loss: 1.490
2025-02-25T13:43:16.137202+0300 | INFO | [139,  3300] loss: 1.487
2025-02-25T13:43:24.327423+0300 | INFO | [139,  3400] loss: 1.485
2025-02-25T13:43:39.131925+0300 | INFO | [139,  3500] loss: 1.490
2025-02-25T13:43:49.895093+0300 | INFO | [139,  3600] loss: 1.489
2025-02-25T13:44:00.687133+0300 | INFO | [139,  3700] loss: 1.487
2025-02-25T13:44:12.032979+0300 | INFO | [139,  3800] loss: 1.493
2025-02-25T13:44:22.159193+0300 | INFO | [139,  3900] loss: 1.486
2025-02-25T13:44:32.928454+0300 | INFO | [139,  4000] loss: 1.491
2025-02-25T13:44:43.725057+0300 | INFO | [139,  4100] loss: 1.493
2025-02-25T13:44:53.161406+0300 | INFO | [139,  4200] loss: 1.494
2025-02-25T13:45:01.290078+0300 | INFO | [139,  4300] loss: 1.494
2025-02-25T13:45:10.123174+0300 | INFO | [139,  4400] loss: 1.492
2025-02-25T13:45:17.374550+0300 | INFO | [139,  4500] loss: 1.490
2025-02-25T13:45:26.013030+0300 | INFO | [139,  4600] loss: 1.492
2025-02-25T13:45:35.262861+0300 | INFO | [139,  4700] loss: 1.494
2025-02-25T13:45:43.628905+0300 | INFO | [139,  4800] loss: 1.494
2025-02-25T13:45:52.024654+0300 | INFO | [139,  4900] loss: 1.488
2025-02-25T13:46:01.394887+0300 | DEBUG | Saving model to flat file storage. Save #139
2025-02-25T13:46:01.407780+0300 | INFO | Averaging client parameters
2025-02-25T13:46:01.443733+0300 | INFO | Updating parameters on client #0
2025-02-25T13:46:14.120700+0300 | DEBUG | Test set: Accuracy: 7849/10000 (78%)
2025-02-25T13:46:14.121695+0300 | DEBUG | Test set: Loss: 1.6740812063217163
2025-02-25T13:46:14.203769+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.78      0.67      0.72      1000
           3       0.67      0.55      0.60      1200
           4       0.77      0.81      0.79      1000
           5       0.49      0.65      0.56       800
           6       0.82      0.86      0.84      1000
           7       0.87      0.80      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.78      0.79     10000

2025-02-25T13:46:14.205811+0300 | DEBUG | Confusion Matrix:
[[836  12  35  10  11  12   6   8  50  20]
 [ 11 905   2   3   1   3   5   3  19  48]
 [ 59   1 674  42  63  77  52  17   7   8]
 [ 25   8  50 661  59 305  49  21  12  10]
 [ 16   1  31  42 805  39  30  28   6   2]
 [ 12   1  26 159  27 523  19  27   4   2]
 [ 10   1  26  43  23  28 861   3   4   1]
 [ 18   1   9  21  54  78  11 802   3   3]
 [ 42  16   5   5   4   5   5   1 899  18]
 [ 27  39   5   5   3   6   6   8  18 883]]
2025-02-25T13:46:14.208184+0300 | DEBUG | Class precision: [0.79166667 0.91878173 0.78099652 0.66700303 0.76666667 0.48605948
 0.82471264 0.87363834 0.87964775 0.88743719]
2025-02-25T13:46:14.209203+0300 | DEBUG | Class recall: [0.836      0.905      0.674      0.55083333 0.805      0.65375
 0.861      0.802      0.899      0.883     ]
2025-02-25T13:46:14.268224+0300 | INFO | Training epoch #140 on client #0
2025-02-25T13:46:14.269653+0300 | DEBUG | Saving model to flat file storage. Save #140
2025-02-25T13:46:14.471511+0300 | INFO | [140,     0] loss: 0.015
2025-02-25T13:46:22.429089+0300 | INFO | [140,   100] loss: 1.489
2025-02-25T13:46:33.325783+0300 | INFO | [140,   200] loss: 1.495
2025-02-25T13:46:42.104992+0300 | INFO | [140,   300] loss: 1.487
2025-02-25T13:46:51.619704+0300 | INFO | [140,   400] loss: 1.481
2025-02-25T13:47:03.975637+0300 | INFO | [140,   500] loss: 1.489
2025-02-25T13:47:14.558945+0300 | INFO | [140,   600] loss: 1.492
2025-02-25T13:47:25.559998+0300 | INFO | [140,   700] loss: 1.493
2025-02-25T13:47:35.157231+0300 | INFO | [140,   800] loss: 1.485
2025-02-25T13:47:45.596152+0300 | INFO | [140,   900] loss: 1.486
2025-02-25T13:47:54.596243+0300 | INFO | [140,  1000] loss: 1.496
2025-02-25T13:48:03.656437+0300 | INFO | [140,  1100] loss: 1.488
2025-02-25T13:48:15.032699+0300 | INFO | [140,  1200] loss: 1.497
2025-02-25T13:48:25.911034+0300 | INFO | [140,  1300] loss: 1.486
2025-02-25T13:48:37.437060+0300 | INFO | [140,  1400] loss: 1.490
2025-02-25T13:48:49.972498+0300 | INFO | [140,  1500] loss: 1.488
2025-02-25T13:49:03.580781+0300 | INFO | [140,  1600] loss: 1.493
2025-02-25T13:49:13.023593+0300 | INFO | [140,  1700] loss: 1.487
2025-02-25T13:49:21.938755+0300 | INFO | [140,  1800] loss: 1.487
2025-02-25T13:49:31.922535+0300 | INFO | [140,  1900] loss: 1.501
2025-02-25T13:49:40.674805+0300 | INFO | [140,  2000] loss: 1.491
2025-02-25T13:49:51.728386+0300 | INFO | [140,  2100] loss: 1.497
2025-02-25T13:50:06.802373+0300 | INFO | [140,  2200] loss: 1.494
2025-02-25T13:50:16.293080+0300 | INFO | [140,  2300] loss: 1.502
2025-02-25T13:50:24.847055+0300 | INFO | [140,  2400] loss: 1.487
2025-02-25T13:50:34.535235+0300 | INFO | [140,  2500] loss: 1.490
2025-02-25T13:50:45.112860+0300 | INFO | [140,  2600] loss: 1.490
2025-02-25T13:50:56.127267+0300 | INFO | [140,  2700] loss: 1.495
2025-02-25T13:51:05.049600+0300 | INFO | [140,  2800] loss: 1.492
2025-02-25T13:51:14.258296+0300 | INFO | [140,  2900] loss: 1.496
2025-02-25T13:51:25.432602+0300 | INFO | [140,  3000] loss: 1.496
2025-02-25T13:51:33.660637+0300 | INFO | [140,  3100] loss: 1.486
2025-02-25T13:51:41.212341+0300 | INFO | [140,  3200] loss: 1.497
2025-02-25T13:51:49.236885+0300 | INFO | [140,  3300] loss: 1.497
2025-02-25T13:51:58.794239+0300 | INFO | [140,  3400] loss: 1.499
2025-02-25T13:52:09.075687+0300 | INFO | [140,  3500] loss: 1.481
2025-02-25T13:52:17.087091+0300 | INFO | [140,  3600] loss: 1.496
2025-02-25T13:52:26.658640+0300 | INFO | [140,  3700] loss: 1.486
2025-02-25T13:52:37.048557+0300 | INFO | [140,  3800] loss: 1.500
2025-02-25T13:52:47.182675+0300 | INFO | [140,  3900] loss: 1.492
2025-02-25T13:52:59.028388+0300 | INFO | [140,  4000] loss: 1.500
2025-02-25T13:53:11.638525+0300 | INFO | [140,  4100] loss: 1.491
2025-02-25T13:53:19.851142+0300 | INFO | [140,  4200] loss: 1.495
2025-02-25T13:53:28.153522+0300 | INFO | [140,  4300] loss: 1.490
2025-02-25T13:53:36.873985+0300 | INFO | [140,  4400] loss: 1.493
2025-02-25T13:53:47.174169+0300 | INFO | [140,  4500] loss: 1.494
2025-02-25T13:53:57.220214+0300 | INFO | [140,  4600] loss: 1.488
2025-02-25T13:54:06.993970+0300 | INFO | [140,  4700] loss: 1.501
2025-02-25T13:54:15.273753+0300 | INFO | [140,  4800] loss: 1.499
2025-02-25T13:54:22.755696+0300 | INFO | [140,  4900] loss: 1.492
2025-02-25T13:54:31.471448+0300 | DEBUG | Saving model to flat file storage. Save #140
2025-02-25T13:54:31.480493+0300 | INFO | Averaging client parameters
2025-02-25T13:54:31.487010+0300 | INFO | Updating parameters on client #0
2025-02-25T13:54:45.275762+0300 | DEBUG | Test set: Accuracy: 7867/10000 (79%)
2025-02-25T13:54:45.276762+0300 | DEBUG | Test set: Loss: 1.6736469268798828
2025-02-25T13:54:45.326493+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.76      0.68      0.72      1000
           3       0.64      0.59      0.61      1200
           4       0.75      0.82      0.78      1000
           5       0.52      0.57      0.55       800
           6       0.84      0.86      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T13:54:45.327550+0300 | DEBUG | Confusion Matrix:
[[841  11  41  14  11   8   5   8  42  19]
 [  9 912   2   4   2   2   5   3  16  45]
 [ 59   2 684  45  70  60  50  16   4  10]
 [ 30   7  58 714  58 242  43  24  11  13]
 [ 16   1  29  49 820  28  25  27   4   1]
 [ 11   2  33 203  40 457  18  31   4   1]
 [  9   0  29  44  28  20 858   4   5   3]
 [ 24   2  10  33  61  56   8 802   1   3]
 [ 47  16   8   6   4   4   5   2 891  17]
 [ 26  40   7  10   2   0   4   5  18 888]]
2025-02-25T13:54:45.328908+0300 | DEBUG | Class precision: [0.78451493 0.918429   0.75915649 0.63636364 0.74817518 0.52109464
 0.8403526  0.86984816 0.89457831 0.888     ]
2025-02-25T13:54:45.329926+0300 | DEBUG | Class recall: [0.841   0.912   0.684   0.595   0.82    0.57125 0.858   0.802   0.891
 0.888  ]
2025-02-25T13:54:45.383848+0300 | INFO | Training epoch #141 on client #0
2025-02-25T13:54:45.384851+0300 | DEBUG | Saving model to flat file storage. Save #141
2025-02-25T13:54:45.506694+0300 | INFO | [141,     0] loss: 0.015
2025-02-25T13:54:55.209694+0300 | INFO | [141,   100] loss: 1.486
2025-02-25T13:55:06.221852+0300 | INFO | [141,   200] loss: 1.488
2025-02-25T13:55:17.736094+0300 | INFO | [141,   300] loss: 1.484
2025-02-25T13:55:30.206419+0300 | INFO | [141,   400] loss: 1.494
2025-02-25T13:55:40.978859+0300 | INFO | [141,   500] loss: 1.499
2025-02-25T13:55:49.786147+0300 | INFO | [141,   600] loss: 1.490
2025-02-25T13:55:59.187716+0300 | INFO | [141,   700] loss: 1.490
2025-02-25T13:56:05.725142+0300 | INFO | [141,   800] loss: 1.500
2025-02-25T13:56:11.732793+0300 | INFO | [141,   900] loss: 1.484
2025-02-25T13:56:17.951952+0300 | INFO | [141,  1000] loss: 1.490
2025-02-25T13:56:24.363844+0300 | INFO | [141,  1100] loss: 1.496
2025-02-25T13:56:30.171410+0300 | INFO | [141,  1200] loss: 1.489
2025-02-25T13:56:36.902422+0300 | INFO | [141,  1300] loss: 1.499
2025-02-25T13:56:42.816940+0300 | INFO | [141,  1400] loss: 1.491
2025-02-25T13:56:48.755055+0300 | INFO | [141,  1500] loss: 1.492
2025-02-25T13:56:56.726223+0300 | INFO | [141,  1600] loss: 1.489
2025-02-25T13:57:08.089358+0300 | INFO | [141,  1700] loss: 1.494
2025-02-25T13:57:21.955919+0300 | INFO | [141,  1800] loss: 1.484
2025-02-25T13:57:35.796510+0300 | INFO | [141,  1900] loss: 1.493
2025-02-25T13:57:48.924536+0300 | INFO | [141,  2000] loss: 1.487
2025-02-25T13:58:08.941294+0300 | INFO | [141,  2100] loss: 1.506
2025-02-25T13:58:23.583691+0300 | INFO | [141,  2200] loss: 1.503
2025-02-25T13:58:38.002736+0300 | INFO | [141,  2300] loss: 1.486
2025-02-25T13:58:51.676378+0300 | INFO | [141,  2400] loss: 1.488
2025-02-25T13:59:05.522437+0300 | INFO | [141,  2500] loss: 1.507
2025-02-25T13:59:19.962995+0300 | INFO | [141,  2600] loss: 1.498
2025-02-25T13:59:34.382112+0300 | INFO | [141,  2700] loss: 1.496
2025-02-25T13:59:49.404126+0300 | INFO | [141,  2800] loss: 1.499
2025-02-25T14:00:04.904818+0300 | INFO | [141,  2900] loss: 1.486
2025-02-25T14:00:21.259832+0300 | INFO | [141,  3000] loss: 1.480
2025-02-25T14:00:35.957425+0300 | INFO | [141,  3100] loss: 1.489
2025-02-25T14:00:50.496103+0300 | INFO | [141,  3200] loss: 1.492
2025-02-25T14:01:05.516683+0300 | INFO | [141,  3300] loss: 1.489
2025-02-25T14:01:19.772046+0300 | INFO | [141,  3400] loss: 1.496
2025-02-25T14:01:34.603203+0300 | INFO | [141,  3500] loss: 1.492
2025-02-25T14:01:50.550601+0300 | INFO | [141,  3600] loss: 1.493
2025-02-25T14:02:08.709568+0300 | INFO | [141,  3700] loss: 1.494
2025-02-25T14:02:23.307644+0300 | INFO | [141,  3800] loss: 1.497
2025-02-25T14:02:36.481086+0300 | INFO | [141,  3900] loss: 1.487
2025-02-25T14:02:50.072848+0300 | INFO | [141,  4000] loss: 1.496
2025-02-25T14:03:03.846810+0300 | INFO | [141,  4100] loss: 1.490
2025-02-25T14:03:18.334061+0300 | INFO | [141,  4200] loss: 1.488
2025-02-25T14:03:32.968429+0300 | INFO | [141,  4300] loss: 1.491
2025-02-25T14:03:47.989196+0300 | INFO | [141,  4400] loss: 1.488
2025-02-25T14:04:05.793604+0300 | INFO | [141,  4500] loss: 1.485
2025-02-25T14:04:22.059373+0300 | INFO | [141,  4600] loss: 1.481
2025-02-25T14:04:39.595463+0300 | INFO | [141,  4700] loss: 1.501
2025-02-25T14:04:56.618045+0300 | INFO | [141,  4800] loss: 1.496
2025-02-25T14:05:10.574408+0300 | INFO | [141,  4900] loss: 1.496
2025-02-25T14:05:27.088352+0300 | DEBUG | Saving model to flat file storage. Save #141
2025-02-25T14:05:27.116383+0300 | INFO | Averaging client parameters
2025-02-25T14:05:27.125159+0300 | INFO | Updating parameters on client #0
2025-02-25T14:05:48.219232+0300 | DEBUG | Test set: Accuracy: 7836/10000 (78%)
2025-02-25T14:05:48.222259+0300 | DEBUG | Test set: Loss: 1.6752710342407227
2025-02-25T14:05:48.362437+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.65      0.56      0.60      1200
           4       0.75      0.81      0.78      1000
           5       0.50      0.62      0.55       800
           6       0.84      0.85      0.85      1000
           7       0.87      0.79      0.83      1000
           8       0.87      0.90      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-25T14:05:48.366424+0300 | DEBUG | Confusion Matrix:
[[828  12  37  14  14  13   7   6  50  19]
 [ 10 907   2   4   3   2   4   2  19  47]
 [ 54   5 690  36  65  76  45  16   5   8]
 [ 28   5  59 673  63 274  51  22  16   9]
 [ 11   2  35  51 810  32  24  26   7   2]
 [ 11   1  33 170  32 496  19  33   4   1]
 [  8   1  32  40  28  22 855   4   7   3]
 [ 20   1  10  29  59  74  12 792   1   2]
 [ 37  18   5   8   5   7   4   2 900  14]
 [ 23  41   5   8   2   2   2   8  24 885]]
2025-02-25T14:05:48.369880+0300 | DEBUG | Class precision: [0.8038835  0.91339376 0.75991189 0.65150048 0.7493062  0.49699399
 0.83577713 0.86937431 0.87124879 0.89393939]
2025-02-25T14:05:48.375180+0300 | DEBUG | Class recall: [0.828      0.907      0.69       0.56083333 0.81       0.62
 0.855      0.792      0.9        0.885     ]
2025-02-25T14:05:48.377278+0300 | INFO | Training epoch #142 on client #0
2025-02-25T14:05:48.377993+0300 | DEBUG | Saving model to flat file storage. Save #142
2025-02-25T14:05:48.595723+0300 | INFO | [142,     0] loss: 0.015
2025-02-25T14:06:03.880728+0300 | INFO | [142,   100] loss: 1.498
2025-02-25T14:06:17.942695+0300 | INFO | [142,   200] loss: 1.491
2025-02-25T14:06:30.196700+0300 | INFO | [142,   300] loss: 1.487
2025-02-25T14:06:43.743390+0300 | INFO | [142,   400] loss: 1.494
2025-02-25T14:06:57.371748+0300 | INFO | [142,   500] loss: 1.497
2025-02-25T14:07:11.552420+0300 | INFO | [142,   600] loss: 1.492
2025-02-25T14:07:28.200405+0300 | INFO | [142,   700] loss: 1.496
2025-02-25T14:07:41.519740+0300 | INFO | [142,   800] loss: 1.489
2025-02-25T14:07:57.180665+0300 | INFO | [142,   900] loss: 1.497
2025-02-25T14:08:15.356492+0300 | INFO | [142,  1000] loss: 1.502
2025-02-25T14:08:32.782002+0300 | INFO | [142,  1100] loss: 1.483
2025-02-25T14:08:48.970531+0300 | INFO | [142,  1200] loss: 1.487
2025-02-25T14:09:03.332042+0300 | INFO | [142,  1300] loss: 1.490
2025-02-25T14:09:19.759153+0300 | INFO | [142,  1400] loss: 1.490
2025-02-25T14:09:34.140033+0300 | INFO | [142,  1500] loss: 1.498
2025-02-25T14:09:58.060078+0300 | INFO | [142,  1600] loss: 1.493
2025-02-25T14:10:12.653632+0300 | INFO | [142,  1700] loss: 1.490
2025-02-25T14:10:26.020635+0300 | INFO | [142,  1800] loss: 1.495
2025-02-25T14:10:40.191718+0300 | INFO | [142,  1900] loss: 1.490
2025-02-25T14:10:54.628509+0300 | INFO | [142,  2000] loss: 1.490
2025-02-25T14:11:11.454350+0300 | INFO | [142,  2100] loss: 1.499
2025-02-25T14:11:25.336361+0300 | INFO | [142,  2200] loss: 1.486
2025-02-25T14:11:41.594424+0300 | INFO | [142,  2300] loss: 1.495
2025-02-25T14:11:59.601058+0300 | INFO | [142,  2400] loss: 1.499
2025-02-25T14:12:13.888635+0300 | INFO | [142,  2500] loss: 1.490
2025-02-25T14:12:28.475076+0300 | INFO | [142,  2600] loss: 1.499
2025-02-25T14:12:45.045142+0300 | INFO | [142,  2700] loss: 1.481
2025-02-25T14:12:59.188685+0300 | INFO | [142,  2800] loss: 1.488
2025-02-25T14:13:12.856108+0300 | INFO | [142,  2900] loss: 1.486
2025-02-25T14:13:26.419751+0300 | INFO | [142,  3000] loss: 1.482
2025-02-25T14:13:40.919193+0300 | INFO | [142,  3100] loss: 1.491
2025-02-25T14:13:54.860681+0300 | INFO | [142,  3200] loss: 1.497
2025-02-25T14:14:08.972129+0300 | INFO | [142,  3300] loss: 1.482
2025-02-25T14:14:23.165199+0300 | INFO | [142,  3400] loss: 1.490
2025-02-25T14:14:41.429586+0300 | INFO | [142,  3500] loss: 1.496
2025-02-25T14:14:55.656773+0300 | INFO | [142,  3600] loss: 1.487
2025-02-25T14:15:09.474051+0300 | INFO | [142,  3700] loss: 1.488
2025-02-25T14:15:22.998098+0300 | INFO | [142,  3800] loss: 1.496
2025-02-25T14:15:38.197934+0300 | INFO | [142,  3900] loss: 1.498
2025-02-25T14:15:52.031634+0300 | INFO | [142,  4000] loss: 1.492
2025-02-25T14:16:07.548084+0300 | INFO | [142,  4100] loss: 1.494
2025-02-25T14:16:22.751894+0300 | INFO | [142,  4200] loss: 1.480
2025-02-25T14:16:38.328347+0300 | INFO | [142,  4300] loss: 1.493
2025-02-25T14:16:52.193084+0300 | INFO | [142,  4400] loss: 1.487
2025-02-25T14:17:06.968682+0300 | INFO | [142,  4500] loss: 1.496
2025-02-25T14:17:21.240933+0300 | INFO | [142,  4600] loss: 1.486
2025-02-25T14:17:35.768869+0300 | INFO | [142,  4700] loss: 1.494
2025-02-25T14:17:50.148295+0300 | INFO | [142,  4800] loss: 1.492
2025-02-25T14:18:04.016595+0300 | INFO | [142,  4900] loss: 1.487
2025-02-25T14:18:17.476784+0300 | DEBUG | Saving model to flat file storage. Save #142
2025-02-25T14:18:17.507946+0300 | INFO | Averaging client parameters
2025-02-25T14:18:17.521158+0300 | INFO | Updating parameters on client #0
2025-02-25T14:18:40.517988+0300 | DEBUG | Test set: Accuracy: 7888/10000 (79%)
2025-02-25T14:18:40.520136+0300 | DEBUG | Test set: Loss: 1.6713762283325195
2025-02-25T14:18:40.669180+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.93      0.91      0.92      1000
           2       0.78      0.67      0.72      1000
           3       0.64      0.60      0.62      1200
           4       0.80      0.78      0.79      1000
           5       0.52      0.59      0.55       800
           6       0.82      0.86      0.84      1000
           7       0.85      0.83      0.84      1000
           8       0.87      0.91      0.89      1000
           9       0.89      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T14:18:40.672659+0300 | DEBUG | Confusion Matrix:
[[845  11  32  11   9  11   7   7  46  21]
 [ 10 906   1   3   0   1   6   2  22  49]
 [ 62   4 672  52  53  58  62  21   8   8]
 [ 27   6  50 720  46 245  52  26  16  12]
 [ 16   2  34  50 781  32  34  42   8   1]
 [ 12   1  29 204  25 471  17  32   8   1]
 [  9   1  30  39  18  26 864   5   6   2]
 [ 22   1   5  27  39  62  11 827   3   3]
 [ 41  11   5   4   3   3   3   3 912  15]
 [ 22  35   5   9   2   2   4  10  21 890]]
2025-02-25T14:18:40.673685+0300 | DEBUG | Class precision: [0.79268293 0.92638037 0.77867903 0.64343164 0.80020492 0.51701427
 0.81509434 0.84820513 0.86857143 0.88822355]
2025-02-25T14:18:40.676346+0300 | DEBUG | Class recall: [0.845   0.906   0.672   0.6     0.781   0.58875 0.864   0.827   0.912
 0.89   ]
2025-02-25T14:18:40.736679+0300 | INFO | Training epoch #143 on client #0
2025-02-25T14:18:40.739269+0300 | DEBUG | Saving model to flat file storage. Save #143
2025-02-25T14:18:40.944299+0300 | INFO | [143,     0] loss: 0.015
2025-02-25T14:18:55.169970+0300 | INFO | [143,   100] loss: 1.483
2025-02-25T14:19:09.778350+0300 | INFO | [143,   200] loss: 1.488
2025-02-25T14:19:24.452615+0300 | INFO | [143,   300] loss: 1.489
2025-02-25T14:19:39.813482+0300 | INFO | [143,   400] loss: 1.500
2025-02-25T14:19:54.067034+0300 | INFO | [143,   500] loss: 1.491
2025-02-25T14:20:08.556166+0300 | INFO | [143,   600] loss: 1.485
2025-02-25T14:20:25.505896+0300 | INFO | [143,   700] loss: 1.493
2025-02-25T14:20:39.435485+0300 | INFO | [143,   800] loss: 1.495
2025-02-25T14:20:55.162598+0300 | INFO | [143,   900] loss: 1.488
2025-02-25T14:21:10.638700+0300 | INFO | [143,  1000] loss: 1.488
2025-02-25T14:21:30.788503+0300 | INFO | [143,  1100] loss: 1.491
2025-02-25T14:21:45.857708+0300 | INFO | [143,  1200] loss: 1.491
2025-02-25T14:22:01.925615+0300 | INFO | [143,  1300] loss: 1.497
2025-02-25T14:22:21.647730+0300 | INFO | [143,  1400] loss: 1.485
2025-02-25T14:22:36.983926+0300 | INFO | [143,  1500] loss: 1.483
2025-02-25T14:22:51.819013+0300 | INFO | [143,  1600] loss: 1.490
2025-02-25T14:23:06.387427+0300 | INFO | [143,  1700] loss: 1.488
2025-02-25T14:23:20.544376+0300 | INFO | [143,  1800] loss: 1.490
2025-02-25T14:23:34.863686+0300 | INFO | [143,  1900] loss: 1.500
2025-02-25T14:23:49.807214+0300 | INFO | [143,  2000] loss: 1.492
2025-02-25T14:24:04.348181+0300 | INFO | [143,  2100] loss: 1.497
2025-02-25T14:24:17.692527+0300 | INFO | [143,  2200] loss: 1.486
2025-02-25T14:24:30.774219+0300 | INFO | [143,  2300] loss: 1.485
2025-02-25T14:24:44.777436+0300 | INFO | [143,  2400] loss: 1.493
2025-02-25T14:24:58.561994+0300 | INFO | [143,  2500] loss: 1.498
2025-02-25T14:25:16.204428+0300 | INFO | [143,  2600] loss: 1.493
2025-02-25T14:25:30.874607+0300 | INFO | [143,  2700] loss: 1.492
2025-02-25T14:25:46.492723+0300 | INFO | [143,  2800] loss: 1.485
2025-02-25T14:26:02.362882+0300 | INFO | [143,  2900] loss: 1.490
2025-02-25T14:26:17.045234+0300 | INFO | [143,  3000] loss: 1.500
2025-02-25T14:26:35.325699+0300 | INFO | [143,  3100] loss: 1.491
2025-02-25T14:26:52.751840+0300 | INFO | [143,  3200] loss: 1.491
2025-02-25T14:27:06.590011+0300 | INFO | [143,  3300] loss: 1.495
2025-02-25T14:27:23.489636+0300 | INFO | [143,  3400] loss: 1.485
2025-02-25T14:27:41.987099+0300 | INFO | [143,  3500] loss: 1.496
2025-02-25T14:27:59.527473+0300 | INFO | [143,  3600] loss: 1.487
2025-02-25T14:28:19.882721+0300 | INFO | [143,  3700] loss: 1.496
2025-02-25T14:28:35.560715+0300 | INFO | [143,  3800] loss: 1.488
2025-02-25T14:28:50.750464+0300 | INFO | [143,  3900] loss: 1.496
2025-02-25T14:29:09.609141+0300 | INFO | [143,  4000] loss: 1.498
2025-02-25T14:29:26.145582+0300 | INFO | [143,  4100] loss: 1.503
2025-02-25T14:29:40.355449+0300 | INFO | [143,  4200] loss: 1.496
2025-02-25T14:29:53.394176+0300 | INFO | [143,  4300] loss: 1.486
2025-02-25T14:30:07.880577+0300 | INFO | [143,  4400] loss: 1.492
2025-02-25T14:30:21.634710+0300 | INFO | [143,  4500] loss: 1.498
2025-02-25T14:30:35.435015+0300 | INFO | [143,  4600] loss: 1.492
2025-02-25T14:30:49.424663+0300 | INFO | [143,  4700] loss: 1.490
2025-02-25T14:31:04.164882+0300 | INFO | [143,  4800] loss: 1.491
2025-02-25T14:31:18.306459+0300 | INFO | [143,  4900] loss: 1.495
2025-02-25T14:31:32.995898+0300 | DEBUG | Saving model to flat file storage. Save #143
2025-02-25T14:31:33.036011+0300 | INFO | Averaging client parameters
2025-02-25T14:31:33.045562+0300 | INFO | Updating parameters on client #0
2025-02-25T14:31:55.196523+0300 | DEBUG | Test set: Accuracy: 7910/10000 (79%)
2025-02-25T14:31:55.197519+0300 | DEBUG | Test set: Loss: 1.669893741607666
2025-02-25T14:31:55.318378+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.78      0.67      0.72      1000
           3       0.65      0.60      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.53      0.60      0.56       800
           6       0.83      0.86      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T14:31:55.321386+0300 | DEBUG | Confusion Matrix:
[[852  12  30  19  10   9   3   7  41  17]
 [  9 922   1   2   0   0   6   2  15  43]
 [ 64   1 666  48  62  65  61  17   7   9]
 [ 26   5  52 718  55 244  46  27  15  12]
 [ 16   1  37  46 809  25  31  27   7   1]
 [ 13   1  28 189  33 483  14  30   6   3]
 [ 11   3  27  38  29  21 858   6   6   1]
 [ 17   1   7  31  53  59   8 818   2   4]
 [ 44  17   4   5   2   4   3   2 901  18]
 [ 26  45   6   6   2   2   2   6  22 883]]
2025-02-25T14:31:55.325385+0300 | DEBUG | Class precision: [0.7903525  0.91468254 0.77622378 0.65154265 0.76682464 0.52960526
 0.83139535 0.86836518 0.8816047  0.89101917]
2025-02-25T14:31:55.329584+0300 | DEBUG | Class recall: [0.852      0.922      0.666      0.59833333 0.809      0.60375
 0.858      0.818      0.901      0.883     ]
2025-02-25T14:31:55.392295+0300 | INFO | Training epoch #144 on client #0
2025-02-25T14:31:55.393304+0300 | DEBUG | Saving model to flat file storage. Save #144
2025-02-25T14:31:55.534057+0300 | INFO | [144,     0] loss: 0.015
2025-02-25T14:32:12.737789+0300 | INFO | [144,   100] loss: 1.489
2025-02-25T14:32:26.729497+0300 | INFO | [144,   200] loss: 1.489
2025-02-25T14:32:41.011827+0300 | INFO | [144,   300] loss: 1.484
2025-02-25T14:32:55.481102+0300 | INFO | [144,   400] loss: 1.489
2025-02-25T14:33:07.346227+0300 | INFO | [144,   500] loss: 1.482
2025-02-25T14:33:20.834581+0300 | INFO | [144,   600] loss: 1.498
2025-02-25T14:33:33.177747+0300 | INFO | [144,   700] loss: 1.488
2025-02-25T14:33:51.067586+0300 | INFO | [144,   800] loss: 1.493
2025-02-25T14:34:06.157572+0300 | INFO | [144,   900] loss: 1.494
2025-02-25T14:34:21.188235+0300 | INFO | [144,  1000] loss: 1.487
2025-02-25T14:34:34.787149+0300 | INFO | [144,  1100] loss: 1.487
2025-02-25T14:34:48.799707+0300 | INFO | [144,  1200] loss: 1.486
2025-02-25T14:35:02.038329+0300 | INFO | [144,  1300] loss: 1.483
2025-02-25T14:35:15.975764+0300 | INFO | [144,  1400] loss: 1.495
2025-02-25T14:35:30.804919+0300 | INFO | [144,  1500] loss: 1.493
2025-02-25T14:35:45.634329+0300 | INFO | [144,  1600] loss: 1.483
2025-02-25T14:35:57.735639+0300 | INFO | [144,  1700] loss: 1.494
2025-02-25T14:36:14.334643+0300 | INFO | [144,  1800] loss: 1.493
2025-02-25T14:36:28.637148+0300 | INFO | [144,  1900] loss: 1.487
2025-02-25T14:36:46.229852+0300 | INFO | [144,  2000] loss: 1.494
2025-02-25T14:37:01.314897+0300 | INFO | [144,  2100] loss: 1.498
2025-02-25T14:37:16.818227+0300 | INFO | [144,  2200] loss: 1.491
2025-02-25T14:37:30.822938+0300 | INFO | [144,  2300] loss: 1.501
2025-02-25T14:37:45.237731+0300 | INFO | [144,  2400] loss: 1.491
2025-02-25T14:37:59.645902+0300 | INFO | [144,  2500] loss: 1.494
2025-02-25T14:38:15.023972+0300 | INFO | [144,  2600] loss: 1.492
2025-02-25T14:38:26.856522+0300 | INFO | [144,  2700] loss: 1.488
2025-02-25T14:38:40.605875+0300 | INFO | [144,  2800] loss: 1.501
2025-02-25T14:38:54.809323+0300 | INFO | [144,  2900] loss: 1.502
2025-02-25T14:39:08.492521+0300 | INFO | [144,  3000] loss: 1.502
2025-02-25T14:39:22.435526+0300 | INFO | [144,  3100] loss: 1.498
2025-02-25T14:39:32.800369+0300 | INFO | [144,  3200] loss: 1.490
2025-02-25T14:39:44.522409+0300 | INFO | [144,  3300] loss: 1.484
2025-02-25T14:39:58.112498+0300 | INFO | [144,  3400] loss: 1.489
2025-02-25T14:40:11.250015+0300 | INFO | [144,  3500] loss: 1.488
2025-02-25T14:40:24.525665+0300 | INFO | [144,  3600] loss: 1.491
2025-02-25T14:40:37.496687+0300 | INFO | [144,  3700] loss: 1.488
2025-02-25T14:40:51.610149+0300 | INFO | [144,  3800] loss: 1.497
2025-02-25T14:41:05.438387+0300 | INFO | [144,  3900] loss: 1.491
2025-02-25T14:41:19.391633+0300 | INFO | [144,  4000] loss: 1.493
2025-02-25T14:41:32.022381+0300 | INFO | [144,  4100] loss: 1.496
2025-02-25T14:41:45.176120+0300 | INFO | [144,  4200] loss: 1.485
2025-02-25T14:41:58.186609+0300 | INFO | [144,  4300] loss: 1.494
2025-02-25T14:42:10.361660+0300 | INFO | [144,  4400] loss: 1.498
2025-02-25T14:42:22.345230+0300 | INFO | [144,  4500] loss: 1.487
2025-02-25T14:42:36.065986+0300 | INFO | [144,  4600] loss: 1.487
2025-02-25T14:42:49.252905+0300 | INFO | [144,  4700] loss: 1.490
2025-02-25T14:43:02.217809+0300 | INFO | [144,  4800] loss: 1.497
2025-02-25T14:43:15.584608+0300 | INFO | [144,  4900] loss: 1.503
2025-02-25T14:43:28.226934+0300 | DEBUG | Saving model to flat file storage. Save #144
2025-02-25T14:43:28.250201+0300 | INFO | Averaging client parameters
2025-02-25T14:43:28.261339+0300 | INFO | Updating parameters on client #0
2025-02-25T14:43:48.287995+0300 | DEBUG | Test set: Accuracy: 7917/10000 (79%)
2025-02-25T14:43:48.292007+0300 | DEBUG | Test set: Loss: 1.6690757274627686
2025-02-25T14:43:48.407608+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.83      1000
           1       0.91      0.92      0.92      1000
           2       0.75      0.70      0.72      1000
           3       0.67      0.56      0.61      1200
           4       0.77      0.81      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.84      0.85      0.85      1000
           7       0.87      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T14:43:48.410608+0300 | DEBUG | Confusion Matrix:
[[853  12  36  15   7  10   4   6  37  20]
 [  7 922   1   3   0   0   4   1  11  51]
 [ 54   2 697  35  56  59  58  21   7  11]
 [ 28   5  62 671  61 270  47  26  15  15]
 [ 13   2  43  41 813  26  25  28   7   2]
 [ 13   1  35 162  31 499  18  30   6   5]
 [ 10   2  34  34  27  21 855   5   7   5]
 [ 18   3  10  27  53  56   7 818   3   5]
 [ 49  18   5   6   2   5   3   1 890  21]
 [ 21  42   6   3   2   2   1   5  19 899]]
2025-02-25T14:43:48.411722+0300 | DEBUG | Class precision: [0.80018762 0.91377602 0.75026911 0.67301906 0.77281369 0.52637131
 0.83659491 0.86928799 0.88822355 0.86943907]
2025-02-25T14:43:48.413737+0300 | DEBUG | Class recall: [0.853      0.922      0.697      0.55916667 0.813      0.62375
 0.855      0.818      0.89       0.899     ]
2025-02-25T14:43:48.468424+0300 | INFO | Training epoch #145 on client #0
2025-02-25T14:43:48.470919+0300 | DEBUG | Saving model to flat file storage. Save #145
2025-02-25T14:43:48.626249+0300 | INFO | [145,     0] loss: 0.015
2025-02-25T14:44:06.215958+0300 | INFO | [145,   100] loss: 1.497
2025-02-25T14:44:20.714418+0300 | INFO | [145,   200] loss: 1.497
2025-02-25T14:44:33.032671+0300 | INFO | [145,   300] loss: 1.488
2025-02-25T14:44:46.696707+0300 | INFO | [145,   400] loss: 1.495
2025-02-25T14:44:59.377660+0300 | INFO | [145,   500] loss: 1.492
2025-02-25T14:45:12.026729+0300 | INFO | [145,   600] loss: 1.499
2025-02-25T14:45:24.534144+0300 | INFO | [145,   700] loss: 1.489
2025-02-25T14:45:37.468774+0300 | INFO | [145,   800] loss: 1.488
2025-02-25T14:45:55.841682+0300 | INFO | [145,   900] loss: 1.489
2025-02-25T14:46:12.039703+0300 | INFO | [145,  1000] loss: 1.488
2025-02-25T14:46:25.186808+0300 | INFO | [145,  1100] loss: 1.496
2025-02-25T14:46:38.199377+0300 | INFO | [145,  1200] loss: 1.495
2025-02-25T14:46:51.800750+0300 | INFO | [145,  1300] loss: 1.498
2025-02-25T14:47:04.660209+0300 | INFO | [145,  1400] loss: 1.487
2025-02-25T14:47:17.950016+0300 | INFO | [145,  1500] loss: 1.493
2025-02-25T14:47:31.918018+0300 | INFO | [145,  1600] loss: 1.488
2025-02-25T14:47:43.975398+0300 | INFO | [145,  1700] loss: 1.485
2025-02-25T14:47:56.399449+0300 | INFO | [145,  1800] loss: 1.493
2025-02-25T14:48:09.980104+0300 | INFO | [145,  1900] loss: 1.489
2025-02-25T14:48:25.044859+0300 | INFO | [145,  2000] loss: 1.485
2025-02-25T14:48:39.318313+0300 | INFO | [145,  2100] loss: 1.491
2025-02-25T14:48:53.281163+0300 | INFO | [145,  2200] loss: 1.488
2025-02-25T14:49:08.228003+0300 | INFO | [145,  2300] loss: 1.487
2025-02-25T14:49:22.370519+0300 | INFO | [145,  2400] loss: 1.494
2025-02-25T14:49:35.904169+0300 | INFO | [145,  2500] loss: 1.482
2025-02-25T14:49:49.103837+0300 | INFO | [145,  2600] loss: 1.490
2025-02-25T14:50:03.410041+0300 | INFO | [145,  2700] loss: 1.490
2025-02-25T14:50:16.457292+0300 | INFO | [145,  2800] loss: 1.498
2025-02-25T14:50:29.783909+0300 | INFO | [145,  2900] loss: 1.495
2025-02-25T14:50:43.510023+0300 | INFO | [145,  3000] loss: 1.496
2025-02-25T14:50:56.902242+0300 | INFO | [145,  3100] loss: 1.492
2025-02-25T14:51:11.328104+0300 | INFO | [145,  3200] loss: 1.490
2025-02-25T14:51:24.434251+0300 | INFO | [145,  3300] loss: 1.495
2025-02-25T14:51:37.866356+0300 | INFO | [145,  3400] loss: 1.496
2025-02-25T14:51:52.310505+0300 | INFO | [145,  3500] loss: 1.483
2025-02-25T14:52:07.872189+0300 | INFO | [145,  3600] loss: 1.510
2025-02-25T14:52:23.509924+0300 | INFO | [145,  3700] loss: 1.495
2025-02-25T14:52:37.817868+0300 | INFO | [145,  3800] loss: 1.487
2025-02-25T14:52:48.443860+0300 | INFO | [145,  3900] loss: 1.494
2025-02-25T14:53:02.705835+0300 | INFO | [145,  4000] loss: 1.480
2025-02-25T14:53:18.212298+0300 | INFO | [145,  4100] loss: 1.490
2025-02-25T14:53:32.449728+0300 | INFO | [145,  4200] loss: 1.477
2025-02-25T14:53:46.249087+0300 | INFO | [145,  4300] loss: 1.501
2025-02-25T14:54:04.143423+0300 | INFO | [145,  4400] loss: 1.489
2025-02-25T14:54:17.964459+0300 | INFO | [145,  4500] loss: 1.498
2025-02-25T14:54:32.499985+0300 | INFO | [145,  4600] loss: 1.488
2025-02-25T14:54:54.383997+0300 | INFO | [145,  4700] loss: 1.493
2025-02-25T14:55:10.287894+0300 | INFO | [145,  4800] loss: 1.487
2025-02-25T14:55:24.372124+0300 | INFO | [145,  4900] loss: 1.498
2025-02-25T14:55:39.656310+0300 | DEBUG | Saving model to flat file storage. Save #145
2025-02-25T14:55:39.683548+0300 | INFO | Averaging client parameters
2025-02-25T14:55:39.694556+0300 | INFO | Updating parameters on client #0
2025-02-25T14:56:02.384721+0300 | DEBUG | Test set: Accuracy: 7884/10000 (79%)
2025-02-25T14:56:02.387721+0300 | DEBUG | Test set: Loss: 1.6714016199111938
2025-02-25T14:56:02.527703+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.86      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.78      0.68      0.73      1000
           3       0.65      0.56      0.61      1200
           4       0.75      0.82      0.79      1000
           5       0.55      0.57      0.56       800
           6       0.85      0.84      0.84      1000
           7       0.84      0.83      0.84      1000
           8       0.88      0.89      0.88      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T14:56:02.528905+0300 | DEBUG | Confusion Matrix:
[[865  15  34  12   8   7   3   6  34  16]
 [  9 911   1   2   1   0   4   2  17  53]
 [ 60   4 684  40  67  50  52  22   9  12]
 [ 40   8  48 676  72 230  48  35  20  23]
 [ 17   2  31  36 825  18  22  37  10   2]
 [ 14   0  39 191  30 456  15  43   7   5]
 [ 15   3  29  41  37  16 841   6   8   4]
 [ 23   2   8  30  50  40   3 835   4   5]
 [ 54  15   4   2   6   4   3   1 890  21]
 [ 25  43   3   3   2   1   0   4  18 901]]
2025-02-25T14:56:02.532480+0300 | DEBUG | Class precision: [0.77094474 0.90827517 0.77639047 0.65440465 0.75136612 0.55474453
 0.84863774 0.84258325 0.87512291 0.8646833 ]
2025-02-25T14:56:02.535491+0300 | DEBUG | Class recall: [0.865      0.911      0.684      0.56333333 0.825      0.57
 0.841      0.835      0.89       0.901     ]
2025-02-25T14:56:02.540007+0300 | INFO | Training epoch #146 on client #0
2025-02-25T14:56:02.541039+0300 | DEBUG | Saving model to flat file storage. Save #146
2025-02-25T14:56:02.825136+0300 | INFO | [146,     0] loss: 0.015
2025-02-25T14:56:18.044086+0300 | INFO | [146,   100] loss: 1.496
2025-02-25T14:56:32.882714+0300 | INFO | [146,   200] loss: 1.484
2025-02-25T14:56:47.592441+0300 | INFO | [146,   300] loss: 1.489
2025-02-25T14:56:59.926369+0300 | INFO | [146,   400] loss: 1.485
2025-02-25T14:57:13.302934+0300 | INFO | [146,   500] loss: 1.497
2025-02-25T14:57:27.385078+0300 | INFO | [146,   600] loss: 1.483
2025-02-25T14:57:41.155558+0300 | INFO | [146,   700] loss: 1.490
2025-02-25T14:57:55.655613+0300 | INFO | [146,   800] loss: 1.495
2025-02-25T14:58:09.693355+0300 | INFO | [146,   900] loss: 1.485
2025-02-25T14:58:24.538917+0300 | INFO | [146,  1000] loss: 1.494
2025-02-25T14:58:38.499432+0300 | INFO | [146,  1100] loss: 1.502
2025-02-25T14:58:51.789157+0300 | INFO | [146,  1200] loss: 1.487
2025-02-25T14:59:06.169776+0300 | INFO | [146,  1300] loss: 1.490
2025-02-25T14:59:19.602259+0300 | INFO | [146,  1400] loss: 1.487
2025-02-25T14:59:33.553405+0300 | INFO | [146,  1500] loss: 1.491
2025-02-25T14:59:47.237943+0300 | INFO | [146,  1600] loss: 1.496
2025-02-25T15:00:00.195271+0300 | INFO | [146,  1700] loss: 1.487
2025-02-25T15:00:15.644330+0300 | INFO | [146,  1800] loss: 1.491
2025-02-25T15:00:28.410676+0300 | INFO | [146,  1900] loss: 1.493
2025-02-25T15:00:41.710253+0300 | INFO | [146,  2000] loss: 1.486
2025-02-25T15:00:55.455600+0300 | INFO | [146,  2100] loss: 1.493
2025-02-25T15:01:08.995916+0300 | INFO | [146,  2200] loss: 1.496
2025-02-25T15:01:21.375413+0300 | INFO | [146,  2300] loss: 1.501
2025-02-25T15:01:35.527040+0300 | INFO | [146,  2400] loss: 1.500
2025-02-25T15:01:47.520409+0300 | INFO | [146,  2500] loss: 1.487
2025-02-25T15:02:00.727001+0300 | INFO | [146,  2600] loss: 1.487
2025-02-25T15:02:13.172229+0300 | INFO | [146,  2700] loss: 1.499
2025-02-25T15:02:24.609842+0300 | INFO | [146,  2800] loss: 1.492
2025-02-25T15:02:37.921906+0300 | INFO | [146,  2900] loss: 1.492
2025-02-25T15:02:50.158844+0300 | INFO | [146,  3000] loss: 1.496
2025-02-25T15:03:02.984736+0300 | INFO | [146,  3100] loss: 1.486
2025-02-25T15:03:16.526841+0300 | INFO | [146,  3200] loss: 1.485
2025-02-25T15:03:28.057837+0300 | INFO | [146,  3300] loss: 1.491
2025-02-25T15:03:41.125377+0300 | INFO | [146,  3400] loss: 1.494
2025-02-25T15:03:53.725616+0300 | INFO | [146,  3500] loss: 1.484
2025-02-25T15:04:08.790434+0300 | INFO | [146,  3600] loss: 1.493
2025-02-25T15:04:22.332025+0300 | INFO | [146,  3700] loss: 1.494
2025-02-25T15:04:36.102390+0300 | INFO | [146,  3800] loss: 1.486
2025-02-25T15:04:50.536825+0300 | INFO | [146,  3900] loss: 1.489
2025-02-25T15:05:03.952564+0300 | INFO | [146,  4000] loss: 1.489
2025-02-25T15:05:16.975367+0300 | INFO | [146,  4100] loss: 1.488
2025-02-25T15:05:31.377542+0300 | INFO | [146,  4200] loss: 1.491
2025-02-25T15:05:48.381453+0300 | INFO | [146,  4300] loss: 1.491
2025-02-25T15:06:03.657232+0300 | INFO | [146,  4400] loss: 1.494
2025-02-25T15:06:15.998963+0300 | INFO | [146,  4500] loss: 1.500
2025-02-25T15:06:29.906596+0300 | INFO | [146,  4600] loss: 1.493
2025-02-25T15:06:44.106919+0300 | INFO | [146,  4700] loss: 1.494
2025-02-25T15:07:01.199619+0300 | INFO | [146,  4800] loss: 1.492
2025-02-25T15:07:13.856843+0300 | INFO | [146,  4900] loss: 1.501
2025-02-25T15:07:31.007055+0300 | DEBUG | Saving model to flat file storage. Save #146
2025-02-25T15:07:31.036295+0300 | INFO | Averaging client parameters
2025-02-25T15:07:31.044229+0300 | INFO | Updating parameters on client #0
2025-02-25T15:07:52.890310+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-25T15:07:52.891315+0300 | DEBUG | Test set: Loss: 1.6712554693222046
2025-02-25T15:07:53.039149+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.92      0.92      0.92      1000
           2       0.76      0.70      0.73      1000
           3       0.62      0.59      0.61      1200
           4       0.78      0.80      0.79      1000
           5       0.52      0.59      0.55       800
           6       0.82      0.86      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T15:07:53.048205+0300 | DEBUG | Confusion Matrix:
[[834  10  46  21  12   8   5   7  37  20]
 [  7 915   1   4   0   0   8   2  13  50]
 [ 52   2 696  49  55  60  59  16   2   9]
 [ 25   4  53 709  46 261  53  27  11  11]
 [ 13   2  40  47 802  29  32  29   5   1]
 [ 10   0  32 204  30 475  15  28   5   1]
 [ 10   2  29  42  27  19 862   5   3   1]
 [ 19   1   9  41  47  52  11 816   2   2]
 [ 45  19   5  10   6   6   5   1 882  21]
 [ 25  45   6   8   2   4   3   6  18 883]]
2025-02-25T15:07:53.054185+0300 | DEBUG | Class precision: [0.80192308 0.915      0.75899673 0.6246696  0.78091529 0.51969365
 0.81861349 0.87086446 0.90184049 0.88388388]
2025-02-25T15:07:53.059541+0300 | DEBUG | Class recall: [0.834      0.915      0.696      0.59083333 0.802      0.59375
 0.862      0.816      0.882      0.883     ]
2025-02-25T15:07:53.123330+0300 | INFO | Training epoch #147 on client #0
2025-02-25T15:07:53.123330+0300 | DEBUG | Saving model to flat file storage. Save #147
2025-02-25T15:07:53.318818+0300 | INFO | [147,     0] loss: 0.016
2025-02-25T15:08:11.418474+0300 | INFO | [147,   100] loss: 1.491
2025-02-25T15:08:24.757564+0300 | INFO | [147,   200] loss: 1.486
2025-02-25T15:08:39.053087+0300 | INFO | [147,   300] loss: 1.496
2025-02-25T15:08:52.329402+0300 | INFO | [147,   400] loss: 1.494
2025-02-25T15:09:05.434327+0300 | INFO | [147,   500] loss: 1.486
2025-02-25T15:09:19.229084+0300 | INFO | [147,   600] loss: 1.499
2025-02-25T15:09:32.130948+0300 | INFO | [147,   700] loss: 1.482
2025-02-25T15:09:46.982707+0300 | INFO | [147,   800] loss: 1.491
2025-02-25T15:10:00.411060+0300 | INFO | [147,   900] loss: 1.491
2025-02-25T15:10:14.004910+0300 | INFO | [147,  1000] loss: 1.489
2025-02-25T15:10:28.190694+0300 | INFO | [147,  1100] loss: 1.494
2025-02-25T15:10:40.186974+0300 | INFO | [147,  1200] loss: 1.488
2025-02-25T15:10:52.989219+0300 | INFO | [147,  1300] loss: 1.489
2025-02-25T15:11:06.688555+0300 | INFO | [147,  1400] loss: 1.478
2025-02-25T15:11:20.425796+0300 | INFO | [147,  1500] loss: 1.491
2025-02-25T15:11:34.073185+0300 | INFO | [147,  1600] loss: 1.496
2025-02-25T15:11:47.636969+0300 | INFO | [147,  1700] loss: 1.492
2025-02-25T15:11:59.828905+0300 | INFO | [147,  1800] loss: 1.498
2025-02-25T15:12:13.024426+0300 | INFO | [147,  1900] loss: 1.497
2025-02-25T15:12:26.029745+0300 | INFO | [147,  2000] loss: 1.495
2025-02-25T15:12:39.256424+0300 | INFO | [147,  2100] loss: 1.486
2025-02-25T15:12:51.649306+0300 | INFO | [147,  2200] loss: 1.487
2025-02-25T15:13:04.571924+0300 | INFO | [147,  2300] loss: 1.491
2025-02-25T15:13:18.668468+0300 | INFO | [147,  2400] loss: 1.493
2025-02-25T15:13:34.223836+0300 | INFO | [147,  2500] loss: 1.490
2025-02-25T15:13:48.031687+0300 | INFO | [147,  2600] loss: 1.489
2025-02-25T15:14:04.988326+0300 | INFO | [147,  2700] loss: 1.491
2025-02-25T15:14:18.508082+0300 | INFO | [147,  2800] loss: 1.485
2025-02-25T15:14:31.521282+0300 | INFO | [147,  2900] loss: 1.493
2025-02-25T15:14:44.514092+0300 | INFO | [147,  3000] loss: 1.499
2025-02-25T15:14:58.024869+0300 | INFO | [147,  3100] loss: 1.493
2025-02-25T15:15:11.199292+0300 | INFO | [147,  3200] loss: 1.492
2025-02-25T15:15:24.257700+0300 | INFO | [147,  3300] loss: 1.490
2025-02-25T15:15:37.450998+0300 | INFO | [147,  3400] loss: 1.487
2025-02-25T15:15:51.196402+0300 | INFO | [147,  3500] loss: 1.497
2025-02-25T15:16:05.874697+0300 | INFO | [147,  3600] loss: 1.488
2025-02-25T15:16:19.090737+0300 | INFO | [147,  3700] loss: 1.485
2025-02-25T15:16:31.874877+0300 | INFO | [147,  3800] loss: 1.495
2025-02-25T15:16:47.300526+0300 | INFO | [147,  3900] loss: 1.489
2025-02-25T15:17:04.274030+0300 | INFO | [147,  4000] loss: 1.497
2025-02-25T15:17:17.379769+0300 | INFO | [147,  4100] loss: 1.487
2025-02-25T15:17:30.162804+0300 | INFO | [147,  4200] loss: 1.494
2025-02-25T15:17:43.467031+0300 | INFO | [147,  4300] loss: 1.486
2025-02-25T15:17:56.441710+0300 | INFO | [147,  4400] loss: 1.494
2025-02-25T15:18:09.212446+0300 | INFO | [147,  4500] loss: 1.499
2025-02-25T15:18:21.948988+0300 | INFO | [147,  4600] loss: 1.501
2025-02-25T15:18:40.550100+0300 | INFO | [147,  4700] loss: 1.486
2025-02-25T15:18:56.188361+0300 | INFO | [147,  4800] loss: 1.496
2025-02-25T15:19:12.401003+0300 | INFO | [147,  4900] loss: 1.493
2025-02-25T15:19:27.433208+0300 | DEBUG | Saving model to flat file storage. Save #147
2025-02-25T15:19:27.462702+0300 | INFO | Averaging client parameters
2025-02-25T15:19:27.476744+0300 | INFO | Updating parameters on client #0
2025-02-25T15:19:49.700215+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-25T15:19:49.702268+0300 | DEBUG | Test set: Loss: 1.6727181673049927
2025-02-25T15:19:49.839602+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.67      0.53      0.59      1200
           4       0.78      0.80      0.79      1000
           5       0.52      0.62      0.57       800
           6       0.81      0.87      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.87      0.90      0.88      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T15:19:49.842860+0300 | DEBUG | Confusion Matrix:
[[842  14  36  15   8   8   4   8  44  21]
 [  7 914   1   1   0   1   4   1  19  52]
 [ 59   5 684  37  57  62  62  16   8  10]
 [ 31  10  58 634  58 280  62  30  20  17]
 [ 13   3  41  34 797  31  35  37   7   2]
 [ 10   1  39 157  30 496  21  35   7   4]
 [ 13   2  28  35  19  16 871   5   7   4]
 [ 21   2   7  26  48  44  10 832   3   7]
 [ 40  15   6   5   4   5   3   2 899  21]
 [ 19  43   5   5   2   2   3   5  22 894]]
2025-02-25T15:19:49.845993+0300 | DEBUG | Class precision: [0.79810427 0.90584737 0.7558011  0.66807165 0.77908113 0.52486772
 0.81023256 0.85684861 0.86776062 0.86627907]
2025-02-25T15:19:49.847008+0300 | DEBUG | Class recall: [0.842      0.914      0.684      0.52833333 0.797      0.62
 0.871      0.832      0.899      0.894     ]
2025-02-25T15:19:49.898034+0300 | INFO | Training epoch #148 on client #0
2025-02-25T15:19:49.900038+0300 | DEBUG | Saving model to flat file storage. Save #148
2025-02-25T15:19:50.306995+0300 | INFO | [148,     0] loss: 0.016
2025-02-25T15:20:07.736089+0300 | INFO | [148,   100] loss: 1.488
2025-02-25T15:20:23.717936+0300 | INFO | [148,   200] loss: 1.496
2025-02-25T15:20:40.435311+0300 | INFO | [148,   300] loss: 1.490
2025-02-25T15:20:55.741770+0300 | INFO | [148,   400] loss: 1.484
2025-02-25T15:21:11.231254+0300 | INFO | [148,   500] loss: 1.492
2025-02-25T15:21:26.148585+0300 | INFO | [148,   600] loss: 1.489
2025-02-25T15:21:40.869692+0300 | INFO | [148,   700] loss: 1.488
2025-02-25T15:21:55.673976+0300 | INFO | [148,   800] loss: 1.497
2025-02-25T15:22:12.707152+0300 | INFO | [148,   900] loss: 1.485
2025-02-25T15:22:27.649533+0300 | INFO | [148,  1000] loss: 1.486
2025-02-25T15:22:42.591004+0300 | INFO | [148,  1100] loss: 1.484
2025-02-25T15:22:59.014881+0300 | INFO | [148,  1200] loss: 1.494
2025-02-25T15:23:16.462755+0300 | INFO | [148,  1300] loss: 1.495
2025-02-25T15:23:32.867941+0300 | INFO | [148,  1400] loss: 1.488
2025-02-25T15:23:48.337025+0300 | INFO | [148,  1500] loss: 1.488
2025-02-25T15:24:05.941870+0300 | INFO | [148,  1600] loss: 1.491
2025-02-25T15:24:22.315744+0300 | INFO | [148,  1700] loss: 1.491
2025-02-25T15:24:36.771406+0300 | INFO | [148,  1800] loss: 1.488
2025-02-25T15:24:51.734390+0300 | INFO | [148,  1900] loss: 1.487
2025-02-25T15:25:06.470516+0300 | INFO | [148,  2000] loss: 1.494
2025-02-25T15:25:21.601726+0300 | INFO | [148,  2100] loss: 1.499
2025-02-25T15:25:35.183052+0300 | INFO | [148,  2200] loss: 1.485
2025-02-25T15:25:50.208317+0300 | INFO | [148,  2300] loss: 1.488
2025-02-25T15:26:05.484344+0300 | INFO | [148,  2400] loss: 1.489
2025-02-25T15:26:21.978690+0300 | INFO | [148,  2500] loss: 1.486
2025-02-25T15:26:38.741421+0300 | INFO | [148,  2600] loss: 1.491
2025-02-25T15:26:56.550240+0300 | INFO | [148,  2700] loss: 1.487
2025-02-25T15:27:14.384971+0300 | INFO | [148,  2800] loss: 1.500
2025-02-25T15:27:31.426352+0300 | INFO | [148,  2900] loss: 1.490
2025-02-25T15:27:46.181733+0300 | INFO | [148,  3000] loss: 1.496
2025-02-25T15:28:00.544623+0300 | INFO | [148,  3100] loss: 1.495
2025-02-25T15:28:16.484157+0300 | INFO | [148,  3200] loss: 1.491
2025-02-25T15:28:31.825920+0300 | INFO | [148,  3300] loss: 1.490
2025-02-25T15:28:47.579980+0300 | INFO | [148,  3400] loss: 1.502
2025-02-25T15:29:03.019010+0300 | INFO | [148,  3500] loss: 1.490
2025-02-25T15:29:29.147806+0300 | INFO | [148,  3600] loss: 1.492
2025-02-25T15:29:47.500806+0300 | INFO | [148,  3700] loss: 1.494
2025-02-25T15:30:01.880424+0300 | INFO | [148,  3800] loss: 1.497
2025-02-25T15:30:17.994051+0300 | INFO | [148,  3900] loss: 1.494
2025-02-25T15:30:33.267890+0300 | INFO | [148,  4000] loss: 1.496
2025-02-25T15:30:47.724224+0300 | INFO | [148,  4100] loss: 1.498
2025-02-25T15:31:01.878069+0300 | INFO | [148,  4200] loss: 1.493
2025-02-25T15:31:16.271605+0300 | INFO | [148,  4300] loss: 1.481
2025-02-25T15:31:29.511498+0300 | INFO | [148,  4400] loss: 1.496
2025-02-25T15:31:45.781063+0300 | INFO | [148,  4500] loss: 1.494
2025-02-25T15:32:01.399613+0300 | INFO | [148,  4600] loss: 1.498
2025-02-25T15:32:16.685116+0300 | INFO | [148,  4700] loss: 1.491
2025-02-25T15:32:33.014893+0300 | INFO | [148,  4800] loss: 1.495
2025-02-25T15:32:48.774886+0300 | INFO | [148,  4900] loss: 1.496
2025-02-25T15:33:04.792563+0300 | DEBUG | Saving model to flat file storage. Save #148
2025-02-25T15:33:04.824283+0300 | INFO | Averaging client parameters
2025-02-25T15:33:04.830581+0300 | INFO | Updating parameters on client #0
2025-02-25T15:33:28.157381+0300 | DEBUG | Test set: Accuracy: 7881/10000 (79%)
2025-02-25T15:33:28.158383+0300 | DEBUG | Test set: Loss: 1.6726611852645874
2025-02-25T15:33:28.267780+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.83      1000
           1       0.92      0.90      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.66      0.57      0.61      1200
           4       0.75      0.82      0.78      1000
           5       0.51      0.61      0.56       800
           6       0.83      0.87      0.85      1000
           7       0.86      0.81      0.84      1000
           8       0.89      0.90      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T15:33:28.273821+0300 | DEBUG | Confusion Matrix:
[[835  10  44  15  14  11   5   7  38  21]
 [  7 903   1   4   0   0   9   2  21  53]
 [ 53   2 684  43  63  66  57  20   4   8]
 [ 20   5  52 679  68 278  47  26  13  12]
 [ 13   2  29  43 820  34  27  26   4   2]
 [  7   1  38 168  37 492  18  33   4   2]
 [  9   1  28  37  25  19 870   5   3   3]
 [ 13   2   9  31  59  58  10 810   3   5]
 [ 38  13   7   7   5   7   4   3 899  17]
 [ 24  38   7   6   3   3   3   5  22 889]]
2025-02-25T15:33:28.276921+0300 | DEBUG | Class precision: [0.81943081 0.92425793 0.76084538 0.65730881 0.74954296 0.50826446
 0.82857143 0.86446105 0.8892186  0.8784585 ]
2025-02-25T15:33:28.282316+0300 | DEBUG | Class recall: [0.835      0.903      0.684      0.56583333 0.82       0.615
 0.87       0.81       0.899      0.889     ]
2025-02-25T15:33:28.360461+0300 | INFO | Training epoch #149 on client #0
2025-02-25T15:33:28.360461+0300 | DEBUG | Saving model to flat file storage. Save #149
2025-02-25T15:33:28.763286+0300 | INFO | [149,     0] loss: 0.015
2025-02-25T15:33:45.335105+0300 | INFO | [149,   100] loss: 1.497
2025-02-25T15:34:01.731499+0300 | INFO | [149,   200] loss: 1.479
2025-02-25T15:34:18.885255+0300 | INFO | [149,   300] loss: 1.484
2025-02-25T15:34:35.194155+0300 | INFO | [149,   400] loss: 1.491
2025-02-25T15:34:52.262166+0300 | INFO | [149,   500] loss: 1.500
2025-02-25T15:35:08.978387+0300 | INFO | [149,   600] loss: 1.486
2025-02-25T15:35:25.518528+0300 | INFO | [149,   700] loss: 1.490
2025-02-25T15:35:41.984074+0300 | INFO | [149,   800] loss: 1.493
2025-02-25T15:35:58.135936+0300 | INFO | [149,   900] loss: 1.491
2025-02-25T15:36:16.224966+0300 | INFO | [149,  1000] loss: 1.489
2025-02-25T15:36:32.311816+0300 | INFO | [149,  1100] loss: 1.485
2025-02-25T15:36:49.060231+0300 | INFO | [149,  1200] loss: 1.484
2025-02-25T15:37:06.168767+0300 | INFO | [149,  1300] loss: 1.490
2025-02-25T15:37:21.780219+0300 | INFO | [149,  1400] loss: 1.492
2025-02-25T15:37:37.766492+0300 | INFO | [149,  1500] loss: 1.497
2025-02-25T15:37:54.535165+0300 | INFO | [149,  1600] loss: 1.486
2025-02-25T15:38:14.894253+0300 | INFO | [149,  1700] loss: 1.487
2025-02-25T15:38:31.003021+0300 | INFO | [149,  1800] loss: 1.496
2025-02-25T15:38:46.989962+0300 | INFO | [149,  1900] loss: 1.488
2025-02-25T15:39:03.086049+0300 | INFO | [149,  2000] loss: 1.490
2025-02-25T15:39:18.227785+0300 | INFO | [149,  2100] loss: 1.492
2025-02-25T15:39:32.803117+0300 | INFO | [149,  2200] loss: 1.489
2025-02-25T15:39:49.035133+0300 | INFO | [149,  2300] loss: 1.489
2025-02-25T15:40:03.822833+0300 | INFO | [149,  2400] loss: 1.488
2025-02-25T15:40:16.036152+0300 | INFO | [149,  2500] loss: 1.490
2025-02-25T15:40:31.973685+0300 | INFO | [149,  2600] loss: 1.492
2025-02-25T15:40:47.027940+0300 | INFO | [149,  2700] loss: 1.483
2025-02-25T15:41:02.217130+0300 | INFO | [149,  2800] loss: 1.482
2025-02-25T15:41:17.324235+0300 | INFO | [149,  2900] loss: 1.493
2025-02-25T15:41:35.000913+0300 | INFO | [149,  3000] loss: 1.490
2025-02-25T15:41:56.904673+0300 | INFO | [149,  3100] loss: 1.492
2025-02-25T15:42:12.459222+0300 | INFO | [149,  3200] loss: 1.485
2025-02-25T15:42:28.113202+0300 | INFO | [149,  3300] loss: 1.487
2025-02-25T15:42:42.845956+0300 | INFO | [149,  3400] loss: 1.498
2025-02-25T15:42:58.933085+0300 | INFO | [149,  3500] loss: 1.494
2025-02-25T15:43:15.382926+0300 | INFO | [149,  3600] loss: 1.484
2025-02-25T15:43:32.090779+0300 | INFO | [149,  3700] loss: 1.498
2025-02-25T15:43:47.772119+0300 | INFO | [149,  3800] loss: 1.497
2025-02-25T15:44:03.590713+0300 | INFO | [149,  3900] loss: 1.498
2025-02-25T15:44:20.576491+0300 | INFO | [149,  4000] loss: 1.506
2025-02-25T15:44:35.370103+0300 | INFO | [149,  4100] loss: 1.491
2025-02-25T15:44:53.410463+0300 | INFO | [149,  4200] loss: 1.484
2025-02-25T15:45:09.592279+0300 | INFO | [149,  4300] loss: 1.503
2025-02-25T15:45:24.593012+0300 | INFO | [149,  4400] loss: 1.487
2025-02-25T15:45:40.036342+0300 | INFO | [149,  4500] loss: 1.488
2025-02-25T15:45:54.242538+0300 | INFO | [149,  4600] loss: 1.490
2025-02-25T15:46:11.741617+0300 | INFO | [149,  4700] loss: 1.492
2025-02-25T15:46:27.625748+0300 | INFO | [149,  4800] loss: 1.496
2025-02-25T15:46:41.139152+0300 | INFO | [149,  4900] loss: 1.504
2025-02-25T15:46:53.925831+0300 | DEBUG | Saving model to flat file storage. Save #149
2025-02-25T15:46:53.960583+0300 | INFO | Averaging client parameters
2025-02-25T15:46:53.972862+0300 | INFO | Updating parameters on client #0
2025-02-25T15:47:14.483071+0300 | DEBUG | Test set: Accuracy: 7851/10000 (79%)
2025-02-25T15:47:14.484066+0300 | DEBUG | Test set: Loss: 1.6736971139907837
2025-02-25T15:47:14.650352+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.65      0.58      0.61      1200
           4       0.74      0.81      0.77      1000
           5       0.53      0.57      0.55       800
           6       0.81      0.86      0.83      1000
           7       0.85      0.82      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-25T15:47:14.654124+0300 | DEBUG | Confusion Matrix:
[[850  10  40  14  10   8   4   7  34  23]
 [  8 904   1   2   0   0   7   2  14  62]
 [ 63   2 681  39  64  50  71  21   3   6]
 [ 30   4  49 691  71 248  53  29  12  13]
 [ 14   2  29  42 806  25  39  36   6   1]
 [ 11   1  41 185  38 460  19  36   6   3]
 [ 12   1  26  40  26  23 863   5   2   2]
 [ 18   2  10  33  59  38   8 824   1   7]
 [ 49  18   7   8   6   6   2   3 881  20]
 [ 21  41   8   6   3   2   2   8  18 891]]
2025-02-25T15:47:14.656207+0300 | DEBUG | Class precision: [0.78996283 0.9177665  0.76345291 0.65188679 0.74422899 0.53488372
 0.80805243 0.84860968 0.90174002 0.86673152]
2025-02-25T15:47:14.657861+0300 | DEBUG | Class recall: [0.85       0.904      0.681      0.57583333 0.806      0.575
 0.863      0.824      0.881      0.891     ]
2025-02-25T15:47:14.661931+0300 | INFO | Training epoch #150 on client #0
2025-02-25T15:47:14.662929+0300 | DEBUG | Saving model to flat file storage. Save #150
2025-02-25T15:47:14.974142+0300 | INFO | [150,     0] loss: 0.015
2025-02-25T15:47:30.385578+0300 | INFO | [150,   100] loss: 1.492
2025-02-25T15:47:45.370194+0300 | INFO | [150,   200] loss: 1.495
2025-02-25T15:48:05.290436+0300 | INFO | [150,   300] loss: 1.491
2025-02-25T15:48:20.329694+0300 | INFO | [150,   400] loss: 1.490
2025-02-25T15:48:35.381438+0300 | INFO | [150,   500] loss: 1.491
2025-02-25T15:48:49.495710+0300 | INFO | [150,   600] loss: 1.487
2025-02-25T15:49:05.690226+0300 | INFO | [150,   700] loss: 1.492
2025-02-25T15:49:20.762875+0300 | INFO | [150,   800] loss: 1.496
2025-02-25T15:49:37.687207+0300 | INFO | [150,   900] loss: 1.493
2025-02-25T15:49:52.416696+0300 | INFO | [150,  1000] loss: 1.500
2025-02-25T15:50:07.065599+0300 | INFO | [150,  1100] loss: 1.501
2025-02-25T15:50:21.701588+0300 | INFO | [150,  1200] loss: 1.486
2025-02-25T15:50:38.091558+0300 | INFO | [150,  1300] loss: 1.488
2025-02-25T15:50:53.021794+0300 | INFO | [150,  1400] loss: 1.486
2025-02-25T15:51:08.640365+0300 | INFO | [150,  1500] loss: 1.498
2025-02-25T15:51:22.452787+0300 | INFO | [150,  1600] loss: 1.492
2025-02-25T15:51:34.346886+0300 | INFO | [150,  1700] loss: 1.482
2025-02-25T15:51:48.106344+0300 | INFO | [150,  1800] loss: 1.493
2025-02-25T15:52:05.270184+0300 | INFO | [150,  1900] loss: 1.487
2025-02-25T15:52:18.875484+0300 | INFO | [150,  2000] loss: 1.496
2025-02-25T15:52:32.156598+0300 | INFO | [150,  2100] loss: 1.493
2025-02-25T15:52:46.502460+0300 | INFO | [150,  2200] loss: 1.498
2025-02-25T15:53:00.382812+0300 | INFO | [150,  2300] loss: 1.495
2025-02-25T15:53:14.983038+0300 | INFO | [150,  2400] loss: 1.490
2025-02-25T15:53:33.870017+0300 | INFO | [150,  2500] loss: 1.493
2025-02-25T15:53:49.732426+0300 | INFO | [150,  2600] loss: 1.493
2025-02-25T15:54:02.885648+0300 | INFO | [150,  2700] loss: 1.481
2025-02-25T15:54:16.563139+0300 | INFO | [150,  2800] loss: 1.487
2025-02-25T15:54:30.805759+0300 | INFO | [150,  2900] loss: 1.494
2025-02-25T15:54:44.080751+0300 | INFO | [150,  3000] loss: 1.492
2025-02-25T15:54:57.857369+0300 | INFO | [150,  3100] loss: 1.495
2025-02-25T15:55:13.541303+0300 | INFO | [150,  3200] loss: 1.489
2025-02-25T15:55:28.404773+0300 | INFO | [150,  3300] loss: 1.490
2025-02-25T15:55:43.015898+0300 | INFO | [150,  3400] loss: 1.499
2025-02-25T15:55:58.293629+0300 | INFO | [150,  3500] loss: 1.492
2025-02-25T15:56:13.028033+0300 | INFO | [150,  3600] loss: 1.484
2025-02-25T15:56:27.338807+0300 | INFO | [150,  3700] loss: 1.482
2025-02-25T15:56:40.963492+0300 | INFO | [150,  3800] loss: 1.489
2025-02-25T15:56:54.353998+0300 | INFO | [150,  3900] loss: 1.484
2025-02-25T15:57:05.703238+0300 | INFO | [150,  4000] loss: 1.492
2025-02-25T15:57:20.700113+0300 | INFO | [150,  4100] loss: 1.491
2025-02-25T15:57:32.071039+0300 | INFO | [150,  4200] loss: 1.489
2025-02-25T15:57:46.886824+0300 | INFO | [150,  4300] loss: 1.489
2025-02-25T15:58:01.001142+0300 | INFO | [150,  4400] loss: 1.490
2025-02-25T15:58:16.614054+0300 | INFO | [150,  4500] loss: 1.488
2025-02-25T15:58:31.372106+0300 | INFO | [150,  4600] loss: 1.496
2025-02-25T15:58:46.248405+0300 | INFO | [150,  4700] loss: 1.487
2025-02-25T15:59:00.975186+0300 | INFO | [150,  4800] loss: 1.486
2025-02-25T15:59:15.825650+0300 | INFO | [150,  4900] loss: 1.491
2025-02-25T15:59:30.263144+0300 | DEBUG | Updating LR for optimizer
2025-02-25T15:59:30.265289+0300 | DEBUG | New LR: 1.25e-05
2025-02-25T15:59:30.266327+0300 | DEBUG | Saving model to flat file storage. Save #150
2025-02-25T15:59:30.293995+0300 | INFO | Averaging client parameters
2025-02-25T15:59:30.308321+0300 | INFO | Updating parameters on client #0
2025-02-25T15:59:51.600755+0300 | DEBUG | Test set: Accuracy: 7877/10000 (79%)
2025-02-25T15:59:51.602268+0300 | DEBUG | Test set: Loss: 1.6727848052978516
2025-02-25T15:59:51.728385+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.67      0.56      0.61      1200
           4       0.74      0.84      0.79      1000
           5       0.53      0.59      0.56       800
           6       0.83      0.86      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.87      0.90      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T15:59:51.735374+0300 | DEBUG | Confusion Matrix:
[[836  11  48  16  10   8   4   7  36  24]
 [  7 907   2   3   1   2   8   2  15  53]
 [ 58   4 690  35  75  51  55  18   5   9]
 [ 34   5  52 668  68 263  54  25  14  17]
 [ 16   2  28  34 840  27  24  23   4   2]
 [ 12   1  41 174  40 476  15  32   6   3]
 [ 13   1  29  34  30  20 863   5   4   1]
 [ 25   2  15  25  64  44   7 813   2   3]
 [ 48  15   6   7   7   7   3   2 884  21]
 [ 17  40   8   5   3   2   3   5  17 900]]
2025-02-25T15:59:51.736377+0300 | DEBUG | Class precision: [0.78424015 0.91801619 0.7508161  0.66733267 0.73813708 0.52888889
 0.83301158 0.8723176  0.89564336 0.87124879]
2025-02-25T15:59:51.738481+0300 | DEBUG | Class recall: [0.836      0.907      0.69       0.55666667 0.84       0.595
 0.863      0.813      0.884      0.9       ]
2025-02-25T15:59:51.809100+0300 | INFO | Training epoch #151 on client #0
2025-02-25T15:59:51.812100+0300 | DEBUG | Saving model to flat file storage. Save #151
2025-02-25T15:59:52.138972+0300 | INFO | [151,     0] loss: 0.015
2025-02-25T16:00:08.263363+0300 | INFO | [151,   100] loss: 1.488
2025-02-25T16:00:24.942225+0300 | INFO | [151,   200] loss: 1.493
2025-02-25T16:00:37.875561+0300 | INFO | [151,   300] loss: 1.494
2025-02-25T16:00:52.395903+0300 | INFO | [151,   400] loss: 1.488
2025-02-25T16:01:05.771120+0300 | INFO | [151,   500] loss: 1.494
2025-02-25T16:01:17.151290+0300 | INFO | [151,   600] loss: 1.495
2025-02-25T16:01:31.227156+0300 | INFO | [151,   700] loss: 1.492
2025-02-25T16:01:45.303387+0300 | INFO | [151,   800] loss: 1.494
2025-02-25T16:02:01.670308+0300 | INFO | [151,   900] loss: 1.494
2025-02-25T16:02:16.423931+0300 | INFO | [151,  1000] loss: 1.486
2025-02-25T16:02:28.438693+0300 | INFO | [151,  1100] loss: 1.488
2025-02-25T16:02:41.960577+0300 | INFO | [151,  1200] loss: 1.494
2025-02-25T16:02:56.083847+0300 | INFO | [151,  1300] loss: 1.495
2025-02-25T16:03:10.431236+0300 | INFO | [151,  1400] loss: 1.491
2025-02-25T16:03:24.151646+0300 | INFO | [151,  1500] loss: 1.483
2025-02-25T16:03:37.513134+0300 | INFO | [151,  1600] loss: 1.495
2025-02-25T16:03:53.643964+0300 | INFO | [151,  1700] loss: 1.485
2025-02-25T16:04:09.372510+0300 | INFO | [151,  1800] loss: 1.492
2025-02-25T16:04:24.242295+0300 | INFO | [151,  1900] loss: 1.494
2025-02-25T16:04:45.155692+0300 | INFO | [151,  2000] loss: 1.492
2025-02-25T16:05:02.866203+0300 | INFO | [151,  2100] loss: 1.501
2025-02-25T16:05:16.292449+0300 | INFO | [151,  2200] loss: 1.496
2025-02-25T16:05:29.305408+0300 | INFO | [151,  2300] loss: 1.491
2025-02-25T16:05:42.405284+0300 | INFO | [151,  2400] loss: 1.491
2025-02-25T16:05:56.289717+0300 | INFO | [151,  2500] loss: 1.491
2025-02-25T16:06:10.007355+0300 | INFO | [151,  2600] loss: 1.492
2025-02-25T16:06:23.346627+0300 | INFO | [151,  2700] loss: 1.492
2025-02-25T16:06:37.173984+0300 | INFO | [151,  2800] loss: 1.495
2025-02-25T16:06:50.691150+0300 | INFO | [151,  2900] loss: 1.498
2025-02-25T16:07:04.327488+0300 | INFO | [151,  3000] loss: 1.489
2025-02-25T16:07:16.884076+0300 | INFO | [151,  3100] loss: 1.481
2025-02-25T16:07:29.046800+0300 | INFO | [151,  3200] loss: 1.483
2025-02-25T16:07:42.248433+0300 | INFO | [151,  3300] loss: 1.487
2025-02-25T16:07:55.556265+0300 | INFO | [151,  3400] loss: 1.489
2025-02-25T16:08:10.993661+0300 | INFO | [151,  3500] loss: 1.480
2025-02-25T16:08:24.788272+0300 | INFO | [151,  3600] loss: 1.488
2025-02-25T16:08:39.401980+0300 | INFO | [151,  3700] loss: 1.488
2025-02-25T16:08:52.526146+0300 | INFO | [151,  3800] loss: 1.493
2025-02-25T16:09:08.743393+0300 | INFO | [151,  3900] loss: 1.485
2025-02-25T16:09:23.561521+0300 | INFO | [151,  4000] loss: 1.486
2025-02-25T16:09:38.479879+0300 | INFO | [151,  4100] loss: 1.486
2025-02-25T16:09:51.354681+0300 | INFO | [151,  4200] loss: 1.492
2025-02-25T16:10:04.453490+0300 | INFO | [151,  4300] loss: 1.486
2025-02-25T16:10:21.393985+0300 | INFO | [151,  4400] loss: 1.489
2025-02-25T16:10:34.748577+0300 | INFO | [151,  4500] loss: 1.489
2025-02-25T16:10:48.567294+0300 | INFO | [151,  4600] loss: 1.499
2025-02-25T16:11:01.983987+0300 | INFO | [151,  4700] loss: 1.502
2025-02-25T16:11:15.376006+0300 | INFO | [151,  4800] loss: 1.487
2025-02-25T16:11:30.166115+0300 | INFO | [151,  4900] loss: 1.489
2025-02-25T16:11:42.411201+0300 | DEBUG | Saving model to flat file storage. Save #151
2025-02-25T16:11:42.434816+0300 | INFO | Averaging client parameters
2025-02-25T16:11:42.442285+0300 | INFO | Updating parameters on client #0
2025-02-25T16:12:03.632433+0300 | DEBUG | Test set: Accuracy: 7879/10000 (79%)
2025-02-25T16:12:03.632433+0300 | DEBUG | Test set: Loss: 1.671493411064148
2025-02-25T16:12:03.780508+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.91      0.92      0.92      1000
           2       0.74      0.70      0.72      1000
           3       0.68      0.54      0.60      1200
           4       0.76      0.82      0.79      1000
           5       0.53      0.61      0.56       800
           6       0.82      0.87      0.84      1000
           7       0.87      0.81      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T16:12:03.784192+0300 | DEBUG | Confusion Matrix:
[[846  10  45  13   8   7   4   7  42  18]
 [ 10 922   2   2   0   0   7   2  16  39]
 [ 57   5 699  30  59  51  63  21   7   8]
 [ 35   6  62 643  65 282  51  24  17  15]
 [ 15   2  34  33 824  28  31  25   6   2]
 [ 13   1  46 160  35 488  19  30   6   2]
 [ 13   1  28  31  24  20 870   3   8   2]
 [ 22   1  19  28  59  44  10 810   3   4]
 [ 45  16   7   6   3   5   3   1 899  15]
 [ 26  48   8   5   2   3   3   7  20 878]]
2025-02-25T16:12:03.787954+0300 | DEBUG | Class precision: [0.7818854  0.91106719 0.73578947 0.67613039 0.76367006 0.52586207
 0.81998115 0.87096774 0.87792969 0.89318413]
2025-02-25T16:12:03.789008+0300 | DEBUG | Class recall: [0.846      0.922      0.699      0.53583333 0.824      0.61
 0.87       0.81       0.899      0.878     ]
2025-02-25T16:12:03.791223+0300 | INFO | Training epoch #152 on client #0
2025-02-25T16:12:03.792223+0300 | DEBUG | Saving model to flat file storage. Save #152
2025-02-25T16:12:04.043524+0300 | INFO | [152,     0] loss: 0.015
2025-02-25T16:12:18.163148+0300 | INFO | [152,   100] loss: 1.485
2025-02-25T16:12:32.356779+0300 | INFO | [152,   200] loss: 1.486
2025-02-25T16:12:48.026739+0300 | INFO | [152,   300] loss: 1.484
2025-02-25T16:13:01.829715+0300 | INFO | [152,   400] loss: 1.486
2025-02-25T16:13:17.694056+0300 | INFO | [152,   500] loss: 1.491
2025-02-25T16:13:30.046081+0300 | INFO | [152,   600] loss: 1.481
2025-02-25T16:13:43.561428+0300 | INFO | [152,   700] loss: 1.487
2025-02-25T16:13:56.640314+0300 | INFO | [152,   800] loss: 1.490
2025-02-25T16:14:10.518799+0300 | INFO | [152,   900] loss: 1.489
2025-02-25T16:14:23.800911+0300 | INFO | [152,  1000] loss: 1.489
2025-02-25T16:14:38.059505+0300 | INFO | [152,  1100] loss: 1.494
2025-02-25T16:14:52.326878+0300 | INFO | [152,  1200] loss: 1.497
2025-02-25T16:15:05.816166+0300 | INFO | [152,  1300] loss: 1.496
2025-02-25T16:15:22.988095+0300 | INFO | [152,  1400] loss: 1.492
2025-02-25T16:15:40.061233+0300 | INFO | [152,  1500] loss: 1.489
2025-02-25T16:15:56.332529+0300 | INFO | [152,  1600] loss: 1.487
2025-02-25T16:16:09.609596+0300 | INFO | [152,  1700] loss: 1.482
2025-02-25T16:16:23.453390+0300 | INFO | [152,  1800] loss: 1.487
2025-02-25T16:16:38.468333+0300 | INFO | [152,  1900] loss: 1.492
2025-02-25T16:16:52.205706+0300 | INFO | [152,  2000] loss: 1.487
2025-02-25T16:17:05.766662+0300 | INFO | [152,  2100] loss: 1.497
2025-02-25T16:17:19.745182+0300 | INFO | [152,  2200] loss: 1.495
2025-02-25T16:17:33.473211+0300 | INFO | [152,  2300] loss: 1.489
2025-02-25T16:17:46.674087+0300 | INFO | [152,  2400] loss: 1.500
2025-02-25T16:17:59.629685+0300 | INFO | [152,  2500] loss: 1.486
2025-02-25T16:18:12.931757+0300 | INFO | [152,  2600] loss: 1.490
2025-02-25T16:18:25.783686+0300 | INFO | [152,  2700] loss: 1.500
2025-02-25T16:18:41.417968+0300 | INFO | [152,  2800] loss: 1.488
2025-02-25T16:18:55.631925+0300 | INFO | [152,  2900] loss: 1.493
2025-02-25T16:19:08.971624+0300 | INFO | [152,  3000] loss: 1.491
2025-02-25T16:19:27.778685+0300 | INFO | [152,  3100] loss: 1.497
2025-02-25T16:19:42.519408+0300 | INFO | [152,  3200] loss: 1.499
2025-02-25T16:19:56.923880+0300 | INFO | [152,  3300] loss: 1.499
2025-02-25T16:20:11.560118+0300 | INFO | [152,  3400] loss: 1.488
2025-02-25T16:20:30.614122+0300 | INFO | [152,  3500] loss: 1.493
2025-02-25T16:20:43.949546+0300 | INFO | [152,  3600] loss: 1.490
2025-02-25T16:20:58.020548+0300 | INFO | [152,  3700] loss: 1.489
2025-02-25T16:21:11.688610+0300 | INFO | [152,  3800] loss: 1.486
2025-02-25T16:21:24.573198+0300 | INFO | [152,  3900] loss: 1.489
2025-02-25T16:21:38.558400+0300 | INFO | [152,  4000] loss: 1.488
2025-02-25T16:21:52.155506+0300 | INFO | [152,  4100] loss: 1.486
2025-02-25T16:22:06.422389+0300 | INFO | [152,  4200] loss: 1.488
2025-02-25T16:22:20.111008+0300 | INFO | [152,  4300] loss: 1.496
2025-02-25T16:22:34.102422+0300 | INFO | [152,  4400] loss: 1.501
2025-02-25T16:22:49.893350+0300 | INFO | [152,  4500] loss: 1.481
2025-02-25T16:23:04.705537+0300 | INFO | [152,  4600] loss: 1.492
2025-02-25T16:23:18.258641+0300 | INFO | [152,  4700] loss: 1.485
2025-02-25T16:23:31.164622+0300 | INFO | [152,  4800] loss: 1.486
2025-02-25T16:23:44.051663+0300 | INFO | [152,  4900] loss: 1.497
2025-02-25T16:23:57.430439+0300 | DEBUG | Saving model to flat file storage. Save #152
2025-02-25T16:23:57.460694+0300 | INFO | Averaging client parameters
2025-02-25T16:23:57.469897+0300 | INFO | Updating parameters on client #0
2025-02-25T16:24:16.891642+0300 | DEBUG | Test set: Accuracy: 7865/10000 (79%)
2025-02-25T16:24:16.892643+0300 | DEBUG | Test set: Loss: 1.673614501953125
2025-02-25T16:24:16.993056+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.91      0.92      0.91      1000
           2       0.71      0.72      0.72      1000
           3       0.66      0.55      0.60      1200
           4       0.77      0.82      0.79      1000
           5       0.52      0.60      0.56       800
           6       0.85      0.86      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.88      0.89      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T16:24:16.997065+0300 | DEBUG | Confusion Matrix:
[[853   9  41  14   8   7   5   7  41  15]
 [  9 917   2   6   0   1   7   2  16  40]
 [ 54   2 722  37  53  54  49  17   6   6]
 [ 33   6  67 659  60 278  47  23  17  10]
 [ 16   2  42  37 820  31  22  25   4   1]
 [ 14   1  54 170  27 483  14  29   6   2]
 [ 12   1  36  38  28  20 857   4   4   0]
 [ 24   2  27  30  60  48   6 799   2   2]
 [ 43  17  10   5   5   7   2   1 893  17]
 [ 30  49  11   6   2   3   5   7  25 862]]
2025-02-25T16:24:17.000069+0300 | DEBUG | Class precision: [0.78400735 0.91153082 0.71343874 0.65768463 0.77140169 0.51824034
 0.84516765 0.87417943 0.88067061 0.9026178 ]
2025-02-25T16:24:17.001072+0300 | DEBUG | Class recall: [0.853      0.917      0.722      0.54916667 0.82       0.60375
 0.857      0.799      0.893      0.862     ]
2025-02-25T16:24:17.058791+0300 | INFO | Training epoch #153 on client #0
2025-02-25T16:24:17.060048+0300 | DEBUG | Saving model to flat file storage. Save #153
2025-02-25T16:24:17.230020+0300 | INFO | [153,     0] loss: 0.015
2025-02-25T16:24:31.713008+0300 | INFO | [153,   100] loss: 1.485
2025-02-25T16:24:46.207959+0300 | INFO | [153,   200] loss: 1.479
2025-02-25T16:25:00.047834+0300 | INFO | [153,   300] loss: 1.500
2025-02-25T16:25:16.319262+0300 | INFO | [153,   400] loss: 1.501
2025-02-25T16:25:29.210869+0300 | INFO | [153,   500] loss: 1.481
2025-02-25T16:25:42.382936+0300 | INFO | [153,   600] loss: 1.485
2025-02-25T16:25:55.713740+0300 | INFO | [153,   700] loss: 1.487
2025-02-25T16:26:09.794810+0300 | INFO | [153,   800] loss: 1.490
2025-02-25T16:26:23.209112+0300 | INFO | [153,   900] loss: 1.489
2025-02-25T16:26:36.906825+0300 | INFO | [153,  1000] loss: 1.492
2025-02-25T16:26:49.880780+0300 | INFO | [153,  1100] loss: 1.492
2025-02-25T16:27:04.964448+0300 | INFO | [153,  1200] loss: 1.497
2025-02-25T16:27:24.413178+0300 | INFO | [153,  1300] loss: 1.489
2025-02-25T16:27:36.137205+0300 | INFO | [153,  1400] loss: 1.487
2025-02-25T16:27:52.509538+0300 | INFO | [153,  1500] loss: 1.487
2025-02-25T16:28:06.801251+0300 | INFO | [153,  1600] loss: 1.478
2025-02-25T16:28:20.655311+0300 | INFO | [153,  1700] loss: 1.479
2025-02-25T16:28:33.487905+0300 | INFO | [153,  1800] loss: 1.496
2025-02-25T16:28:43.808598+0300 | INFO | [153,  1900] loss: 1.497
2025-02-25T16:28:55.643283+0300 | INFO | [153,  2000] loss: 1.495
2025-02-25T16:29:09.720280+0300 | INFO | [153,  2100] loss: 1.502
2025-02-25T16:29:21.035492+0300 | INFO | [153,  2200] loss: 1.497
2025-02-25T16:29:33.337618+0300 | INFO | [153,  2300] loss: 1.488
2025-02-25T16:29:44.989471+0300 | INFO | [153,  2400] loss: 1.493
2025-02-25T16:29:57.441731+0300 | INFO | [153,  2500] loss: 1.486
2025-02-25T16:30:09.169424+0300 | INFO | [153,  2600] loss: 1.493
2025-02-25T16:30:21.800963+0300 | INFO | [153,  2700] loss: 1.492
2025-02-25T16:30:34.840943+0300 | INFO | [153,  2800] loss: 1.494
2025-02-25T16:30:48.078272+0300 | INFO | [153,  2900] loss: 1.482
2025-02-25T16:31:01.203512+0300 | INFO | [153,  3000] loss: 1.491
2025-02-25T16:31:14.406248+0300 | INFO | [153,  3100] loss: 1.490
2025-02-25T16:31:26.418465+0300 | INFO | [153,  3200] loss: 1.489
2025-02-25T16:31:40.064191+0300 | INFO | [153,  3300] loss: 1.491
2025-02-25T16:31:53.113069+0300 | INFO | [153,  3400] loss: 1.492
2025-02-25T16:32:06.804418+0300 | INFO | [153,  3500] loss: 1.490
2025-02-25T16:32:19.481988+0300 | INFO | [153,  3600] loss: 1.487
2025-02-25T16:32:32.155567+0300 | INFO | [153,  3700] loss: 1.480
2025-02-25T16:32:45.576357+0300 | INFO | [153,  3800] loss: 1.491
2025-02-25T16:32:59.155213+0300 | INFO | [153,  3900] loss: 1.494
2025-02-25T16:33:13.346356+0300 | INFO | [153,  4000] loss: 1.499
2025-02-25T16:33:25.640172+0300 | INFO | [153,  4100] loss: 1.492
2025-02-25T16:33:37.817073+0300 | INFO | [153,  4200] loss: 1.492
2025-02-25T16:33:50.900308+0300 | INFO | [153,  4300] loss: 1.491
2025-02-25T16:34:03.157899+0300 | INFO | [153,  4400] loss: 1.491
2025-02-25T16:34:16.087265+0300 | INFO | [153,  4500] loss: 1.483
2025-02-25T16:34:28.998913+0300 | INFO | [153,  4600] loss: 1.486
2025-02-25T16:34:38.918521+0300 | INFO | [153,  4700] loss: 1.499
2025-02-25T16:34:50.741474+0300 | INFO | [153,  4800] loss: 1.495
2025-02-25T16:35:01.228447+0300 | INFO | [153,  4900] loss: 1.491
2025-02-25T16:35:14.027596+0300 | DEBUG | Saving model to flat file storage. Save #153
2025-02-25T16:35:14.060919+0300 | INFO | Averaging client parameters
2025-02-25T16:35:14.078644+0300 | INFO | Updating parameters on client #0
2025-02-25T16:35:34.637720+0300 | DEBUG | Test set: Accuracy: 7888/10000 (79%)
2025-02-25T16:35:34.637720+0300 | DEBUG | Test set: Loss: 1.670538306236267
2025-02-25T16:35:34.737250+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.92      0.93      0.92      1000
           2       0.75      0.70      0.72      1000
           3       0.69      0.53      0.60      1200
           4       0.79      0.81      0.80      1000
           5       0.51      0.64      0.57       800
           6       0.84      0.85      0.84      1000
           7       0.84      0.84      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.88      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T16:35:34.741236+0300 | DEBUG | Confusion Matrix:
[[847   9  44  13   6   8   5   8  40  20]
 [  9 925   0   3   0   1   6   3  13  40]
 [ 58   3 703  32  52  61  56  24   6   5]
 [ 35   5  51 635  55 311  49  34  14  11]
 [ 14   2  37  36 812  34  26  34   4   1]
 [ 12   2  42 140  27 514  15  41   4   3]
 [ 14   1  32  37  26  27 850   6   6   1]
 [ 20   1  17  19  46  49   4 840   2   2]
 [ 48  16   8   6   5   6   2   3 885  21]
 [ 23  44   9   6   2   2   3  12  22 877]]
2025-02-25T16:35:34.747251+0300 | DEBUG | Class precision: [0.78425926 0.91765873 0.74549311 0.68500539 0.78758487 0.50740375
 0.83661417 0.8358209  0.88855422 0.89398573]
2025-02-25T16:35:34.750279+0300 | DEBUG | Class recall: [0.847      0.925      0.703      0.52916667 0.812      0.6425
 0.85       0.84       0.885      0.877     ]
2025-02-25T16:35:34.849027+0300 | INFO | Training epoch #154 on client #0
2025-02-25T16:35:34.850192+0300 | DEBUG | Saving model to flat file storage. Save #154
2025-02-25T16:35:35.242836+0300 | INFO | [154,     0] loss: 0.015
2025-02-25T16:35:50.151870+0300 | INFO | [154,   100] loss: 1.490
2025-02-25T16:36:04.363886+0300 | INFO | [154,   200] loss: 1.491
2025-02-25T16:36:17.289385+0300 | INFO | [154,   300] loss: 1.484
2025-02-25T16:36:30.025303+0300 | INFO | [154,   400] loss: 1.491
2025-02-25T16:36:43.270478+0300 | INFO | [154,   500] loss: 1.493
2025-02-25T16:36:57.492513+0300 | INFO | [154,   600] loss: 1.489
2025-02-25T16:37:10.568661+0300 | INFO | [154,   700] loss: 1.493
2025-02-25T16:37:29.295645+0300 | INFO | [154,   800] loss: 1.488
2025-02-25T16:37:41.012343+0300 | INFO | [154,   900] loss: 1.487
2025-02-25T16:37:51.610049+0300 | INFO | [154,  1000] loss: 1.490
2025-02-25T16:38:03.353622+0300 | INFO | [154,  1100] loss: 1.492
2025-02-25T16:38:15.289897+0300 | INFO | [154,  1200] loss: 1.487
2025-02-25T16:38:26.662266+0300 | INFO | [154,  1300] loss: 1.499
2025-02-25T16:38:41.406409+0300 | INFO | [154,  1400] loss: 1.491
2025-02-25T16:38:54.830031+0300 | INFO | [154,  1500] loss: 1.497
2025-02-25T16:39:08.419199+0300 | INFO | [154,  1600] loss: 1.491
2025-02-25T16:39:22.196420+0300 | INFO | [154,  1700] loss: 1.491
2025-02-25T16:39:35.493840+0300 | INFO | [154,  1800] loss: 1.495
2025-02-25T16:39:48.740312+0300 | INFO | [154,  1900] loss: 1.483
2025-02-25T16:40:02.140798+0300 | INFO | [154,  2000] loss: 1.478
2025-02-25T16:40:17.967195+0300 | INFO | [154,  2100] loss: 1.484
2025-02-25T16:40:31.475236+0300 | INFO | [154,  2200] loss: 1.492
2025-02-25T16:40:45.336454+0300 | INFO | [154,  2300] loss: 1.484
2025-02-25T16:40:59.583900+0300 | INFO | [154,  2400] loss: 1.497
2025-02-25T16:41:13.887081+0300 | INFO | [154,  2500] loss: 1.501
2025-02-25T16:41:27.266772+0300 | INFO | [154,  2600] loss: 1.504
2025-02-25T16:41:39.539123+0300 | INFO | [154,  2700] loss: 1.488
2025-02-25T16:41:52.127715+0300 | INFO | [154,  2800] loss: 1.484
2025-02-25T16:42:03.003195+0300 | INFO | [154,  2900] loss: 1.496
2025-02-25T16:42:14.924183+0300 | INFO | [154,  3000] loss: 1.482
2025-02-25T16:42:28.233475+0300 | INFO | [154,  3100] loss: 1.484
2025-02-25T16:42:41.168959+0300 | INFO | [154,  3200] loss: 1.493
2025-02-25T16:42:53.558078+0300 | INFO | [154,  3300] loss: 1.499
2025-02-25T16:43:07.297257+0300 | INFO | [154,  3400] loss: 1.485
2025-02-25T16:43:21.795659+0300 | INFO | [154,  3500] loss: 1.495
2025-02-25T16:43:33.759887+0300 | INFO | [154,  3600] loss: 1.484
2025-02-25T16:43:47.420765+0300 | INFO | [154,  3700] loss: 1.482
2025-02-25T16:44:01.228772+0300 | INFO | [154,  3800] loss: 1.498
2025-02-25T16:44:17.949504+0300 | INFO | [154,  3900] loss: 1.490
2025-02-25T16:44:31.735381+0300 | INFO | [154,  4000] loss: 1.495
2025-02-25T16:44:47.753970+0300 | INFO | [154,  4100] loss: 1.486
2025-02-25T16:45:01.839651+0300 | INFO | [154,  4200] loss: 1.490
2025-02-25T16:45:16.352663+0300 | INFO | [154,  4300] loss: 1.489
2025-02-25T16:45:31.508271+0300 | INFO | [154,  4400] loss: 1.486
2025-02-25T16:45:45.889058+0300 | INFO | [154,  4500] loss: 1.503
2025-02-25T16:46:01.495800+0300 | INFO | [154,  4600] loss: 1.494
2025-02-25T16:46:17.141005+0300 | INFO | [154,  4700] loss: 1.485
2025-02-25T16:46:31.815010+0300 | INFO | [154,  4800] loss: 1.485
2025-02-25T16:46:47.679838+0300 | INFO | [154,  4900] loss: 1.480
2025-02-25T16:47:02.067910+0300 | DEBUG | Saving model to flat file storage. Save #154
2025-02-25T16:47:02.106839+0300 | INFO | Averaging client parameters
2025-02-25T16:47:02.123352+0300 | INFO | Updating parameters on client #0
2025-02-25T16:47:27.746771+0300 | DEBUG | Test set: Accuracy: 7896/10000 (79%)
2025-02-25T16:47:27.749772+0300 | DEBUG | Test set: Loss: 1.6718525886535645
2025-02-25T16:47:27.878012+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.79      0.68      0.73      1000
           3       0.65      0.58      0.61      1200
           4       0.77      0.82      0.79      1000
           5       0.52      0.62      0.57       800
           6       0.84      0.85      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T16:47:27.880231+0300 | DEBUG | Confusion Matrix:
[[859  12  31  15   9   8   3   8  35  20]
 [  9 923   0   4   1   0   6   3  11  43]
 [ 62   2 676  45  66  65  53  21   3   7]
 [ 35   5  41 695  58 276  45  23  12  10]
 [ 15   2  27  40 820  33  26  32   4   1]
 [ 12   2  31 177  28 500  14  30   4   2]
 [ 13   1  28  45  30  24 852   3   4   0]
 [ 25   1  10  37  49  49   5 819   3   2]
 [ 47  17   8   6   6   6   2   4 884  20]
 [ 27  49   6   8   2   3   3  13  21 868]]
2025-02-25T16:47:27.881545+0300 | DEBUG | Class precision: [0.77807971 0.91025641 0.78787879 0.6483209  0.76707203 0.5186722
 0.8444004  0.85669456 0.9011213  0.89208633]
2025-02-25T16:47:27.882562+0300 | DEBUG | Class recall: [0.859      0.923      0.676      0.57916667 0.82       0.625
 0.852      0.819      0.884      0.868     ]
2025-02-25T16:47:27.886833+0300 | INFO | Training epoch #155 on client #0
2025-02-25T16:47:27.887834+0300 | DEBUG | Saving model to flat file storage. Save #155
2025-02-25T16:47:28.122340+0300 | INFO | [155,     0] loss: 0.015
2025-02-25T16:47:42.434002+0300 | INFO | [155,   100] loss: 1.485
2025-02-25T16:48:00.538923+0300 | INFO | [155,   200] loss: 1.493
2025-02-25T16:48:20.057461+0300 | INFO | [155,   300] loss: 1.477
2025-02-25T16:48:37.365011+0300 | INFO | [155,   400] loss: 1.494
2025-02-25T16:48:53.611475+0300 | INFO | [155,   500] loss: 1.490
2025-02-25T16:49:08.856395+0300 | INFO | [155,   600] loss: 1.481
2025-02-25T16:49:23.126257+0300 | INFO | [155,   700] loss: 1.493
2025-02-25T16:49:38.351878+0300 | INFO | [155,   800] loss: 1.489
2025-02-25T16:49:53.328979+0300 | INFO | [155,   900] loss: 1.492
2025-02-25T16:50:08.973489+0300 | INFO | [155,  1000] loss: 1.486
2025-02-25T16:50:26.964795+0300 | INFO | [155,  1100] loss: 1.496
2025-02-25T16:50:42.943148+0300 | INFO | [155,  1200] loss: 1.487
2025-02-25T16:51:01.263340+0300 | INFO | [155,  1300] loss: 1.485
2025-02-25T16:51:15.920224+0300 | INFO | [155,  1400] loss: 1.486
2025-02-25T16:51:29.245873+0300 | INFO | [155,  1500] loss: 1.495
2025-02-25T16:51:43.660575+0300 | INFO | [155,  1600] loss: 1.492
2025-02-25T16:51:58.137104+0300 | INFO | [155,  1700] loss: 1.495
2025-02-25T16:52:12.490000+0300 | INFO | [155,  1800] loss: 1.506
2025-02-25T16:52:26.312560+0300 | INFO | [155,  1900] loss: 1.492
2025-02-25T16:52:39.766457+0300 | INFO | [155,  2000] loss: 1.497
2025-02-25T16:52:54.401578+0300 | INFO | [155,  2100] loss: 1.487
2025-02-25T16:53:11.058707+0300 | INFO | [155,  2200] loss: 1.483
2025-02-25T16:53:27.306944+0300 | INFO | [155,  2300] loss: 1.487
2025-02-25T16:53:43.383885+0300 | INFO | [155,  2400] loss: 1.493
2025-02-25T16:53:58.912726+0300 | INFO | [155,  2500] loss: 1.488
2025-02-25T16:54:14.258793+0300 | INFO | [155,  2600] loss: 1.492
2025-02-25T16:54:28.929866+0300 | INFO | [155,  2700] loss: 1.480
2025-02-25T16:54:44.616772+0300 | INFO | [155,  2800] loss: 1.488
2025-02-25T16:54:59.969125+0300 | INFO | [155,  2900] loss: 1.494
2025-02-25T16:55:15.763100+0300 | INFO | [155,  3000] loss: 1.489
2025-02-25T16:55:30.255008+0300 | INFO | [155,  3100] loss: 1.483
2025-02-25T16:55:47.470426+0300 | INFO | [155,  3200] loss: 1.489
2025-02-25T16:56:01.616649+0300 | INFO | [155,  3300] loss: 1.481
2025-02-25T16:56:16.507699+0300 | INFO | [155,  3400] loss: 1.491
2025-02-25T16:56:34.315257+0300 | INFO | [155,  3500] loss: 1.482
2025-02-25T16:56:48.877165+0300 | INFO | [155,  3600] loss: 1.494
2025-02-25T16:57:03.185123+0300 | INFO | [155,  3700] loss: 1.496
2025-02-25T16:57:17.776287+0300 | INFO | [155,  3800] loss: 1.494
2025-02-25T16:57:33.723504+0300 | INFO | [155,  3900] loss: 1.485
2025-02-25T16:57:48.262101+0300 | INFO | [155,  4000] loss: 1.501
2025-02-25T16:58:02.626803+0300 | INFO | [155,  4100] loss: 1.486
2025-02-25T16:58:17.570318+0300 | INFO | [155,  4200] loss: 1.501
2025-02-25T16:58:33.503400+0300 | INFO | [155,  4300] loss: 1.491
2025-02-25T16:58:48.723387+0300 | INFO | [155,  4400] loss: 1.489
2025-02-25T16:59:07.004916+0300 | INFO | [155,  4500] loss: 1.497
2025-02-25T16:59:24.323110+0300 | INFO | [155,  4600] loss: 1.495
2025-02-25T16:59:39.812726+0300 | INFO | [155,  4700] loss: 1.491
2025-02-25T16:59:54.666358+0300 | INFO | [155,  4800] loss: 1.483
2025-02-25T17:00:16.957116+0300 | INFO | [155,  4900] loss: 1.497
2025-02-25T17:00:31.290440+0300 | DEBUG | Saving model to flat file storage. Save #155
2025-02-25T17:00:31.318489+0300 | INFO | Averaging client parameters
2025-02-25T17:00:31.333208+0300 | INFO | Updating parameters on client #0
2025-02-25T17:00:53.990250+0300 | DEBUG | Test set: Accuracy: 7906/10000 (79%)
2025-02-25T17:00:53.992658+0300 | DEBUG | Test set: Loss: 1.6699470281600952
2025-02-25T17:00:54.144717+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.91      0.92      1000
           2       0.77      0.69      0.73      1000
           3       0.64      0.60      0.62      1200
           4       0.77      0.82      0.79      1000
           5       0.54      0.59      0.56       800
           6       0.83      0.87      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T17:00:54.145709+0300 | DEBUG | Confusion Matrix:
[[840   9  40  14  12   9   4   7  43  22]
 [  7 913   0   5   1   0   6   2  18  48]
 [ 52   3 689  43  60  56  63  20   6   8]
 [ 29   5  51 715  55 242  50  24  16  13]
 [ 12   2  30  48 818  28  28  28   5   1]
 [ 11   1  33 196  31 473  20  27   5   3]
 [ 11   2  25  42  26  17 869   2   6   0]
 [ 21   2  14  40  49  49   6 814   3   2]
 [ 42  16   6   7   6   5   2   3 895  18]
 [ 24  40   8   9   2   2   4   8  23 880]]
2025-02-25T17:00:54.148142+0300 | DEBUG | Class precision: [0.80076263 0.91943605 0.76897321 0.63896336 0.77169811 0.5368899
 0.82604563 0.87058824 0.87745098 0.88442211]
2025-02-25T17:00:54.149202+0300 | DEBUG | Class recall: [0.84       0.913      0.689      0.59583333 0.818      0.59125
 0.869      0.814      0.895      0.88      ]
2025-02-25T17:00:54.211149+0300 | INFO | Training epoch #156 on client #0
2025-02-25T17:00:54.212149+0300 | DEBUG | Saving model to flat file storage. Save #156
2025-02-25T17:00:54.598251+0300 | INFO | [156,     0] loss: 0.015
2025-02-25T17:01:13.045190+0300 | INFO | [156,   100] loss: 1.491
2025-02-25T17:01:32.224998+0300 | INFO | [156,   200] loss: 1.485
2025-02-25T17:01:47.454297+0300 | INFO | [156,   300] loss: 1.485
2025-02-25T17:02:04.084076+0300 | INFO | [156,   400] loss: 1.483
2025-02-25T17:02:19.644804+0300 | INFO | [156,   500] loss: 1.499
2025-02-25T17:02:35.195723+0300 | INFO | [156,   600] loss: 1.487
2025-02-25T17:02:49.583997+0300 | INFO | [156,   700] loss: 1.494
2025-02-25T17:03:06.357121+0300 | INFO | [156,   800] loss: 1.487
2025-02-25T17:03:21.992556+0300 | INFO | [156,   900] loss: 1.486
2025-02-25T17:03:36.293852+0300 | INFO | [156,  1000] loss: 1.491
2025-02-25T17:03:51.058343+0300 | INFO | [156,  1100] loss: 1.483
2025-02-25T17:04:05.236574+0300 | INFO | [156,  1200] loss: 1.492
2025-02-25T17:04:20.685508+0300 | INFO | [156,  1300] loss: 1.490
2025-02-25T17:04:36.150705+0300 | INFO | [156,  1400] loss: 1.496
2025-02-25T17:04:51.037251+0300 | INFO | [156,  1500] loss: 1.500
2025-02-25T17:05:07.115210+0300 | INFO | [156,  1600] loss: 1.484
2025-02-25T17:05:21.614001+0300 | INFO | [156,  1700] loss: 1.492
2025-02-25T17:05:39.362778+0300 | INFO | [156,  1800] loss: 1.496
2025-02-25T17:05:54.789380+0300 | INFO | [156,  1900] loss: 1.486
2025-02-25T17:06:09.659428+0300 | INFO | [156,  2000] loss: 1.485
2025-02-25T17:06:23.716884+0300 | INFO | [156,  2100] loss: 1.483
2025-02-25T17:06:43.138123+0300 | INFO | [156,  2200] loss: 1.486
2025-02-25T17:06:57.425649+0300 | INFO | [156,  2300] loss: 1.492
2025-02-25T17:07:12.157897+0300 | INFO | [156,  2400] loss: 1.492
2025-02-25T17:07:27.901440+0300 | INFO | [156,  2500] loss: 1.497
2025-02-25T17:07:44.929190+0300 | INFO | [156,  2600] loss: 1.492
2025-02-25T17:07:59.336641+0300 | INFO | [156,  2700] loss: 1.493
2025-02-25T17:08:16.806982+0300 | INFO | [156,  2800] loss: 1.482
2025-02-25T17:08:32.205085+0300 | INFO | [156,  2900] loss: 1.486
2025-02-25T17:08:47.566570+0300 | INFO | [156,  3000] loss: 1.502
2025-02-25T17:09:02.839287+0300 | INFO | [156,  3100] loss: 1.488
2025-02-25T17:09:18.697072+0300 | INFO | [156,  3200] loss: 1.499
2025-02-25T17:09:34.521730+0300 | INFO | [156,  3300] loss: 1.491
2025-02-25T17:09:48.133251+0300 | INFO | [156,  3400] loss: 1.496
2025-02-25T17:10:02.869071+0300 | INFO | [156,  3500] loss: 1.486
2025-02-25T17:10:16.693313+0300 | INFO | [156,  3600] loss: 1.495
2025-02-25T17:10:31.783453+0300 | INFO | [156,  3700] loss: 1.487
2025-02-25T17:10:45.887924+0300 | INFO | [156,  3800] loss: 1.490
2025-02-25T17:11:01.434524+0300 | INFO | [156,  3900] loss: 1.482
2025-02-25T17:11:16.172277+0300 | INFO | [156,  4000] loss: 1.497
2025-02-25T17:11:31.279592+0300 | INFO | [156,  4100] loss: 1.488
2025-02-25T17:11:47.060747+0300 | INFO | [156,  4200] loss: 1.486
2025-02-25T17:12:03.967082+0300 | INFO | [156,  4300] loss: 1.484
2025-02-25T17:12:22.852104+0300 | INFO | [156,  4400] loss: 1.490
2025-02-25T17:12:37.185558+0300 | INFO | [156,  4500] loss: 1.483
2025-02-25T17:12:51.591871+0300 | INFO | [156,  4600] loss: 1.490
2025-02-25T17:13:05.168724+0300 | INFO | [156,  4700] loss: 1.494
2025-02-25T17:13:19.337448+0300 | INFO | [156,  4800] loss: 1.490
2025-02-25T17:13:34.980844+0300 | INFO | [156,  4900] loss: 1.493
2025-02-25T17:13:49.872340+0300 | DEBUG | Saving model to flat file storage. Save #156
2025-02-25T17:13:49.896866+0300 | INFO | Averaging client parameters
2025-02-25T17:13:49.909613+0300 | INFO | Updating parameters on client #0
2025-02-25T17:14:12.075649+0300 | DEBUG | Test set: Accuracy: 7911/10000 (79%)
2025-02-25T17:14:12.078062+0300 | DEBUG | Test set: Loss: 1.66950523853302
2025-02-25T17:14:12.193841+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.93      0.91      0.92      1000
           2       0.78      0.68      0.73      1000
           3       0.65      0.57      0.61      1200
           4       0.77      0.83      0.80      1000
           5       0.53      0.60      0.56       800
           6       0.83      0.88      0.85      1000
           7       0.85      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T17:14:12.195858+0300 | DEBUG | Confusion Matrix:
[[845   9  35  17  11   8   4   9  40  22]
 [  8 909   0   2   1   1   5   2  17  55]
 [ 57   3 680  39  61  59  63  22   7   9]
 [ 28   5  48 680  66 261  52  29  14  17]
 [ 11   2  28  42 829  21  25  35   5   2]
 [ 12   1  31 185  33 479  21  30   5   3]
 [  8   1  27  36  24  16 876   3   6   3]
 [ 22   2   9  33  49  45   9 823   4   4]
 [ 44  14   6   6   5   6   2   3 892  22]
 [ 23  36   6   5   2   1   3   9  17 898]]
2025-02-25T17:14:12.198037+0300 | DEBUG | Class precision: [0.79867675 0.92566191 0.7816092  0.6507177  0.76688252 0.53400223
 0.82641509 0.85284974 0.8857994  0.86763285]
2025-02-25T17:14:12.199035+0300 | DEBUG | Class recall: [0.845      0.909      0.68       0.56666667 0.829      0.59875
 0.876      0.823      0.892      0.898     ]
2025-02-25T17:14:12.248357+0300 | INFO | Training epoch #157 on client #0
2025-02-25T17:14:12.249742+0300 | DEBUG | Saving model to flat file storage. Save #157
2025-02-25T17:14:12.545965+0300 | INFO | [157,     0] loss: 0.016
2025-02-25T17:14:25.919486+0300 | INFO | [157,   100] loss: 1.485
2025-02-25T17:14:39.924463+0300 | INFO | [157,   200] loss: 1.491
2025-02-25T17:14:52.879579+0300 | INFO | [157,   300] loss: 1.490
2025-02-25T17:15:06.217627+0300 | INFO | [157,   400] loss: 1.492
2025-02-25T17:15:20.388555+0300 | INFO | [157,   500] loss: 1.492
2025-02-25T17:15:33.561514+0300 | INFO | [157,   600] loss: 1.492
2025-02-25T17:15:47.315988+0300 | INFO | [157,   700] loss: 1.486
2025-02-25T17:16:00.292427+0300 | INFO | [157,   800] loss: 1.488
2025-02-25T17:16:13.672556+0300 | INFO | [157,   900] loss: 1.486
2025-02-25T17:16:26.587510+0300 | INFO | [157,  1000] loss: 1.497
2025-02-25T17:16:37.357527+0300 | INFO | [157,  1100] loss: 1.492
2025-02-25T17:16:50.016479+0300 | INFO | [157,  1200] loss: 1.487
2025-02-25T17:17:00.069694+0300 | INFO | [157,  1300] loss: 1.498
2025-02-25T17:17:10.892311+0300 | INFO | [157,  1400] loss: 1.480
2025-02-25T17:17:23.499170+0300 | INFO | [157,  1500] loss: 1.485
2025-02-25T17:17:36.896728+0300 | INFO | [157,  1600] loss: 1.497
2025-02-25T17:17:50.502183+0300 | INFO | [157,  1700] loss: 1.494
2025-02-25T17:18:02.500094+0300 | INFO | [157,  1800] loss: 1.488
2025-02-25T17:18:12.426543+0300 | INFO | [157,  1900] loss: 1.485
2025-02-25T17:18:28.668079+0300 | INFO | [157,  2000] loss: 1.477
2025-02-25T17:18:41.729259+0300 | INFO | [157,  2100] loss: 1.483
2025-02-25T17:18:58.158822+0300 | INFO | [157,  2200] loss: 1.488
2025-02-25T17:19:13.424594+0300 | INFO | [157,  2300] loss: 1.489
2025-02-25T17:19:27.008007+0300 | INFO | [157,  2400] loss: 1.491
2025-02-25T17:19:39.579723+0300 | INFO | [157,  2500] loss: 1.485
2025-02-25T17:19:52.371602+0300 | INFO | [157,  2600] loss: 1.491
2025-02-25T17:20:07.869830+0300 | INFO | [157,  2700] loss: 1.484
2025-02-25T17:20:21.085113+0300 | INFO | [157,  2800] loss: 1.486
2025-02-25T17:20:35.660405+0300 | INFO | [157,  2900] loss: 1.501
2025-02-25T17:20:48.755391+0300 | INFO | [157,  3000] loss: 1.491
2025-02-25T17:21:05.185317+0300 | INFO | [157,  3100] loss: 1.494
2025-02-25T17:21:20.075263+0300 | INFO | [157,  3200] loss: 1.489
2025-02-25T17:21:33.473440+0300 | INFO | [157,  3300] loss: 1.481
2025-02-25T17:21:46.496058+0300 | INFO | [157,  3400] loss: 1.494
2025-02-25T17:21:59.831661+0300 | INFO | [157,  3500] loss: 1.492
2025-02-25T17:22:14.556215+0300 | INFO | [157,  3600] loss: 1.502
2025-02-25T17:22:29.073565+0300 | INFO | [157,  3700] loss: 1.494
2025-02-25T17:22:42.905691+0300 | INFO | [157,  3800] loss: 1.490
2025-02-25T17:23:00.240862+0300 | INFO | [157,  3900] loss: 1.496
2025-02-25T17:23:21.851890+0300 | INFO | [157,  4000] loss: 1.485
2025-02-25T17:23:34.592054+0300 | INFO | [157,  4100] loss: 1.482
2025-02-25T17:23:47.782757+0300 | INFO | [157,  4200] loss: 1.491
2025-02-25T17:23:59.483045+0300 | INFO | [157,  4300] loss: 1.501
2025-02-25T17:24:13.554872+0300 | INFO | [157,  4400] loss: 1.486
2025-02-25T17:24:28.499353+0300 | INFO | [157,  4500] loss: 1.495
2025-02-25T17:24:42.977882+0300 | INFO | [157,  4600] loss: 1.486
2025-02-25T17:24:57.188287+0300 | INFO | [157,  4700] loss: 1.492
2025-02-25T17:25:11.901227+0300 | INFO | [157,  4800] loss: 1.492
2025-02-25T17:25:25.861149+0300 | INFO | [157,  4900] loss: 1.487
2025-02-25T17:25:40.742625+0300 | DEBUG | Saving model to flat file storage. Save #157
2025-02-25T17:25:40.771893+0300 | INFO | Averaging client parameters
2025-02-25T17:25:40.778048+0300 | INFO | Updating parameters on client #0
2025-02-25T17:26:03.815490+0300 | DEBUG | Test set: Accuracy: 7892/10000 (79%)
2025-02-25T17:26:03.816694+0300 | DEBUG | Test set: Loss: 1.669919490814209
2025-02-25T17:26:03.971490+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.91      0.93      0.92      1000
           2       0.76      0.69      0.73      1000
           3       0.67      0.55      0.60      1200
           4       0.78      0.81      0.80      1000
           5       0.52      0.64      0.57       800
           6       0.83      0.88      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.88      0.88      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T17:26:03.973811+0300 | DEBUG | Confusion Matrix:
[[841  13  46  13   8   7   5  10  37  20]
 [  7 925   1   3   0   1   5   1  15  42]
 [ 52   4 695  38  58  56  66  18   5   8]
 [ 30   6  52 655  54 295  51  29  16  12]
 [ 12   2  33  38 813  34  30  33   4   1]
 [ 13   1  34 156  28 515  15  30   5   3]
 [ 11   4  27  34  22  18 875   3   5   1]
 [ 25   1  10  27  45  61   6 819   4   2]
 [ 52  17   8   7   6   7   2   2 880  19]
 [ 26  47   8   6   3   2   4  10  20 874]]
2025-02-25T17:26:03.976137+0300 | DEBUG | Class precision: [0.78671656 0.90686275 0.76039387 0.67041965 0.78399229 0.51706827
 0.82625118 0.85759162 0.88799193 0.89002037]
2025-02-25T17:26:03.978356+0300 | DEBUG | Class recall: [0.841      0.925      0.695      0.54583333 0.813      0.64375
 0.875      0.819      0.88       0.874     ]
2025-02-25T17:26:04.048698+0300 | INFO | Training epoch #158 on client #0
2025-02-25T17:26:04.052010+0300 | DEBUG | Saving model to flat file storage. Save #158
2025-02-25T17:26:04.429715+0300 | INFO | [158,     0] loss: 0.015
2025-02-25T17:26:19.105417+0300 | INFO | [158,   100] loss: 1.491
2025-02-25T17:26:32.939769+0300 | INFO | [158,   200] loss: 1.483
2025-02-25T17:26:47.079341+0300 | INFO | [158,   300] loss: 1.491
2025-02-25T17:27:00.963242+0300 | INFO | [158,   400] loss: 1.495
2025-02-25T17:27:16.265723+0300 | INFO | [158,   500] loss: 1.496
2025-02-25T17:27:32.871247+0300 | INFO | [158,   600] loss: 1.494
2025-02-25T17:27:49.126681+0300 | INFO | [158,   700] loss: 1.481
2025-02-25T17:28:03.609727+0300 | INFO | [158,   800] loss: 1.489
2025-02-25T17:28:17.544567+0300 | INFO | [158,   900] loss: 1.485
2025-02-25T17:28:33.086055+0300 | INFO | [158,  1000] loss: 1.488
2025-02-25T17:28:47.108166+0300 | INFO | [158,  1100] loss: 1.486
2025-02-25T17:29:01.876401+0300 | INFO | [158,  1200] loss: 1.496
2025-02-25T17:29:16.795591+0300 | INFO | [158,  1300] loss: 1.491
2025-02-25T17:29:31.963515+0300 | INFO | [158,  1400] loss: 1.480
2025-02-25T17:29:47.547552+0300 | INFO | [158,  1500] loss: 1.487
2025-02-25T17:30:06.015578+0300 | INFO | [158,  1600] loss: 1.485
2025-02-25T17:30:23.288390+0300 | INFO | [158,  1700] loss: 1.483
2025-02-25T17:30:38.922147+0300 | INFO | [158,  1800] loss: 1.492
2025-02-25T17:30:54.740808+0300 | INFO | [158,  1900] loss: 1.483
2025-02-25T17:31:09.897214+0300 | INFO | [158,  2000] loss: 1.490
2025-02-25T17:31:27.312816+0300 | INFO | [158,  2100] loss: 1.489
2025-02-25T17:31:42.826619+0300 | INFO | [158,  2200] loss: 1.498
2025-02-25T17:31:57.701029+0300 | INFO | [158,  2300] loss: 1.493
2025-02-25T17:32:13.106047+0300 | INFO | [158,  2400] loss: 1.482
2025-02-25T17:32:28.559526+0300 | INFO | [158,  2500] loss: 1.492
2025-02-25T17:32:42.662074+0300 | INFO | [158,  2600] loss: 1.485
2025-02-25T17:32:57.770429+0300 | INFO | [158,  2700] loss: 1.493
2025-02-25T17:33:12.978235+0300 | INFO | [158,  2800] loss: 1.495
2025-02-25T17:33:27.960826+0300 | INFO | [158,  2900] loss: 1.499
2025-02-25T17:33:42.445232+0300 | INFO | [158,  3000] loss: 1.485
2025-02-25T17:33:56.494969+0300 | INFO | [158,  3100] loss: 1.486
2025-02-25T17:34:11.114312+0300 | INFO | [158,  3200] loss: 1.498
2025-02-25T17:34:24.267781+0300 | INFO | [158,  3300] loss: 1.491
2025-02-25T17:34:40.077756+0300 | INFO | [158,  3400] loss: 1.504
2025-02-25T17:34:58.351098+0300 | INFO | [158,  3500] loss: 1.496
2025-02-25T17:35:13.373427+0300 | INFO | [158,  3600] loss: 1.486
2025-02-25T17:35:29.092440+0300 | INFO | [158,  3700] loss: 1.489
2025-02-25T17:35:42.896198+0300 | INFO | [158,  3800] loss: 1.485
2025-02-25T17:35:57.550921+0300 | INFO | [158,  3900] loss: 1.489
2025-02-25T17:36:12.534556+0300 | INFO | [158,  4000] loss: 1.492
2025-02-25T17:36:28.038838+0300 | INFO | [158,  4100] loss: 1.489
2025-02-25T17:36:43.005926+0300 | INFO | [158,  4200] loss: 1.486
2025-02-25T17:36:58.446905+0300 | INFO | [158,  4300] loss: 1.487
2025-02-25T17:37:14.344692+0300 | INFO | [158,  4400] loss: 1.484
2025-02-25T17:37:29.453084+0300 | INFO | [158,  4500] loss: 1.490
2025-02-25T17:37:44.160087+0300 | INFO | [158,  4600] loss: 1.493
2025-02-25T17:37:54.310180+0300 | INFO | [158,  4700] loss: 1.491
2025-02-25T17:38:06.559000+0300 | INFO | [158,  4800] loss: 1.487
2025-02-25T17:38:21.400879+0300 | INFO | [158,  4900] loss: 1.491
2025-02-25T17:38:35.245589+0300 | DEBUG | Saving model to flat file storage. Save #158
2025-02-25T17:38:35.277325+0300 | INFO | Averaging client parameters
2025-02-25T17:38:35.294841+0300 | INFO | Updating parameters on client #0
2025-02-25T17:38:55.694758+0300 | DEBUG | Test set: Accuracy: 7872/10000 (79%)
2025-02-25T17:38:55.696847+0300 | DEBUG | Test set: Loss: 1.6724085807800293
2025-02-25T17:38:55.815902+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.91      0.92      0.91      1000
           2       0.77      0.67      0.72      1000
           3       0.63      0.60      0.62      1200
           4       0.75      0.82      0.79      1000
           5       0.52      0.58      0.55       800
           6       0.81      0.88      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T17:38:55.818309+0300 | DEBUG | Confusion Matrix:
[[833  15  37  20  15  10   4   8  39  19]
 [  6 919   1   4   2   1   7   0  16  44]
 [ 56   3 668  46  66  57  75  18   4   7]
 [ 25   5  46 723  66 246  48  21  11   9]
 [  9   2  27  51 824  27  29  26   4   1]
 [ 10   1  33 206  30 466  19  27   5   3]
 [  5   3  27  40  23  19 875   2   5   1]
 [ 24   1   7  37  58  57  12 798   4   2]
 [ 43  14   8   4   6   7   2   3 892  21]
 [ 21  46   9   8   4   4   5   6  23 874]]
2025-02-25T17:38:55.819433+0300 | DEBUG | Class precision: [0.80717054 0.91080278 0.77404403 0.63476734 0.75319927 0.5212528
 0.81319703 0.87788779 0.889332   0.89092762]
2025-02-25T17:38:55.822639+0300 | DEBUG | Class recall: [0.833  0.919  0.668  0.6025 0.824  0.5825 0.875  0.798  0.892  0.874 ]
2025-02-25T17:38:55.884028+0300 | INFO | Training epoch #159 on client #0
2025-02-25T17:38:55.885026+0300 | DEBUG | Saving model to flat file storage. Save #159
2025-02-25T17:38:56.063463+0300 | INFO | [159,     0] loss: 0.016
2025-02-25T17:39:09.454711+0300 | INFO | [159,   100] loss: 1.487
2025-02-25T17:39:23.625294+0300 | INFO | [159,   200] loss: 1.478
2025-02-25T17:39:38.868873+0300 | INFO | [159,   300] loss: 1.495
2025-02-25T17:39:53.081644+0300 | INFO | [159,   400] loss: 1.495
2025-02-25T17:40:06.480906+0300 | INFO | [159,   500] loss: 1.490
2025-02-25T17:40:21.378386+0300 | INFO | [159,   600] loss: 1.502
2025-02-25T17:40:36.150084+0300 | INFO | [159,   700] loss: 1.498
2025-02-25T17:40:48.450572+0300 | INFO | [159,   800] loss: 1.489
2025-02-25T17:41:01.869149+0300 | INFO | [159,   900] loss: 1.484
2025-02-25T17:41:15.293819+0300 | INFO | [159,  1000] loss: 1.498
2025-02-25T17:41:28.355122+0300 | INFO | [159,  1100] loss: 1.490
2025-02-25T17:41:42.604050+0300 | INFO | [159,  1200] loss: 1.485
2025-02-25T17:41:56.386494+0300 | INFO | [159,  1300] loss: 1.489
2025-02-25T17:42:12.925514+0300 | INFO | [159,  1400] loss: 1.488
2025-02-25T17:42:28.560529+0300 | INFO | [159,  1500] loss: 1.493
2025-02-25T17:42:41.632233+0300 | INFO | [159,  1600] loss: 1.479
2025-02-25T17:42:55.619123+0300 | INFO | [159,  1700] loss: 1.491
2025-02-25T17:43:10.341675+0300 | INFO | [159,  1800] loss: 1.489
2025-02-25T17:43:25.102147+0300 | INFO | [159,  1900] loss: 1.495
2025-02-25T17:43:38.961538+0300 | INFO | [159,  2000] loss: 1.487
2025-02-25T17:43:52.892504+0300 | INFO | [159,  2100] loss: 1.497
2025-02-25T17:44:06.785921+0300 | INFO | [159,  2200] loss: 1.500
2025-02-25T17:44:20.822707+0300 | INFO | [159,  2300] loss: 1.484
2025-02-25T17:44:33.715772+0300 | INFO | [159,  2400] loss: 1.489
2025-02-25T17:44:47.994407+0300 | INFO | [159,  2500] loss: 1.487
2025-02-25T17:45:03.035026+0300 | INFO | [159,  2600] loss: 1.489
2025-02-25T17:45:17.734225+0300 | INFO | [159,  2700] loss: 1.498
2025-02-25T17:45:31.226391+0300 | INFO | [159,  2800] loss: 1.488
2025-02-25T17:45:50.428579+0300 | INFO | [159,  2900] loss: 1.485
2025-02-25T17:46:03.731679+0300 | INFO | [159,  3000] loss: 1.486
2025-02-25T17:46:17.193365+0300 | INFO | [159,  3100] loss: 1.497
2025-02-25T17:46:30.358788+0300 | INFO | [159,  3200] loss: 1.486
2025-02-25T17:46:44.030942+0300 | INFO | [159,  3300] loss: 1.485
2025-02-25T17:46:56.488210+0300 | INFO | [159,  3400] loss: 1.485
2025-02-25T17:47:10.667911+0300 | INFO | [159,  3500] loss: 1.490
2025-02-25T17:47:23.326680+0300 | INFO | [159,  3600] loss: 1.496
2025-02-25T17:47:35.939445+0300 | INFO | [159,  3700] loss: 1.491
2025-02-25T17:47:50.242620+0300 | INFO | [159,  3800] loss: 1.494
2025-02-25T17:48:05.852568+0300 | INFO | [159,  3900] loss: 1.490
2025-02-25T17:48:19.569892+0300 | INFO | [159,  4000] loss: 1.489
2025-02-25T17:48:32.096363+0300 | INFO | [159,  4100] loss: 1.490
2025-02-25T17:48:44.881519+0300 | INFO | [159,  4200] loss: 1.485
2025-02-25T17:48:57.939206+0300 | INFO | [159,  4300] loss: 1.491
2025-02-25T17:49:11.111202+0300 | INFO | [159,  4400] loss: 1.486
2025-02-25T17:49:24.104683+0300 | INFO | [159,  4500] loss: 1.490
2025-02-25T17:49:36.265792+0300 | INFO | [159,  4600] loss: 1.481
2025-02-25T17:49:49.608254+0300 | INFO | [159,  4700] loss: 1.488
2025-02-25T17:50:02.187356+0300 | INFO | [159,  4800] loss: 1.492
2025-02-25T17:50:15.636172+0300 | INFO | [159,  4900] loss: 1.490
2025-02-25T17:50:29.148355+0300 | DEBUG | Saving model to flat file storage. Save #159
2025-02-25T17:50:29.171361+0300 | INFO | Averaging client parameters
2025-02-25T17:50:29.181362+0300 | INFO | Updating parameters on client #0
2025-02-25T17:50:47.673015+0300 | DEBUG | Test set: Accuracy: 7891/10000 (79%)
2025-02-25T17:50:47.675022+0300 | DEBUG | Test set: Loss: 1.671022653579712
2025-02-25T17:50:47.772255+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.93      0.90      0.92      1000
           2       0.78      0.67      0.72      1000
           3       0.67      0.55      0.61      1200
           4       0.80      0.80      0.80      1000
           5       0.52      0.65      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.83      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.85      0.91      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T17:50:47.773781+0300 | DEBUG | Confusion Matrix:
[[854  10  33  13  10   8   3   7  38  24]
 [  9 902   0   2   1   0   4   0  17  65]
 [ 64   4 674  40  52  66  61  22   5  12]
 [ 38   4  51 664  51 284  46  27  16  19]
 [ 16   2  34  44 800  31  30  35   6   2]
 [ 12   1  29 156  25 520  15  32   6   4]
 [ 15   2  26  36  22  29 858   4   6   2]
 [ 27   1   7  24  39  62   5 826   4   5]
 [ 54  12   3   4   4   5   2   4 887  25]
 [ 19  33   5   6   2   4   1   7  17 906]]
2025-02-25T17:50:47.779608+0300 | DEBUG | Class precision: [0.77075812 0.92893924 0.78190255 0.67138524 0.79522863 0.51536174
 0.83707317 0.85684647 0.88522954 0.85150376]
2025-02-25T17:50:47.783586+0300 | DEBUG | Class recall: [0.854      0.902      0.674      0.55333333 0.8        0.65
 0.858      0.826      0.887      0.906     ]
2025-02-25T17:50:47.866909+0300 | INFO | Training epoch #160 on client #0
2025-02-25T17:50:47.867911+0300 | DEBUG | Saving model to flat file storage. Save #160
2025-02-25T17:50:48.183561+0300 | INFO | [160,     0] loss: 0.015
2025-02-25T17:51:02.313612+0300 | INFO | [160,   100] loss: 1.487
2025-02-25T17:51:16.256497+0300 | INFO | [160,   200] loss: 1.491
2025-02-25T17:51:28.846031+0300 | INFO | [160,   300] loss: 1.492
2025-02-25T17:51:42.456250+0300 | INFO | [160,   400] loss: 1.496
2025-02-25T17:51:55.476554+0300 | INFO | [160,   500] loss: 1.486
2025-02-25T17:52:09.011420+0300 | INFO | [160,   600] loss: 1.487
2025-02-25T17:52:22.291658+0300 | INFO | [160,   700] loss: 1.483
2025-02-25T17:52:34.658732+0300 | INFO | [160,   800] loss: 1.483
2025-02-25T17:52:47.244484+0300 | INFO | [160,   900] loss: 1.497
2025-02-25T17:53:00.340455+0300 | INFO | [160,  1000] loss: 1.499
2025-02-25T17:53:14.774326+0300 | INFO | [160,  1100] loss: 1.498
2025-02-25T17:53:27.815252+0300 | INFO | [160,  1200] loss: 1.487
2025-02-25T17:53:40.628304+0300 | INFO | [160,  1300] loss: 1.483
2025-02-25T17:53:53.078102+0300 | INFO | [160,  1400] loss: 1.495
2025-02-25T17:54:06.611031+0300 | INFO | [160,  1500] loss: 1.488
2025-02-25T17:54:19.594211+0300 | INFO | [160,  1600] loss: 1.495
2025-02-25T17:54:33.202635+0300 | INFO | [160,  1700] loss: 1.490
2025-02-25T17:54:46.255318+0300 | INFO | [160,  1800] loss: 1.492
2025-02-25T17:54:59.691714+0300 | INFO | [160,  1900] loss: 1.490
2025-02-25T17:55:12.508908+0300 | INFO | [160,  2000] loss: 1.481
2025-02-25T17:55:25.193522+0300 | INFO | [160,  2100] loss: 1.483
2025-02-25T17:55:37.998145+0300 | INFO | [160,  2200] loss: 1.495
2025-02-25T17:55:50.944512+0300 | INFO | [160,  2300] loss: 1.478
2025-02-25T17:56:08.335846+0300 | INFO | [160,  2400] loss: 1.478
2025-02-25T17:56:23.852675+0300 | INFO | [160,  2500] loss: 1.481
2025-02-25T17:56:36.946690+0300 | INFO | [160,  2600] loss: 1.488
2025-02-25T17:56:49.305145+0300 | INFO | [160,  2700] loss: 1.484
2025-02-25T17:57:04.152742+0300 | INFO | [160,  2800] loss: 1.495
2025-02-25T17:57:17.092693+0300 | INFO | [160,  2900] loss: 1.496
2025-02-25T17:57:29.744087+0300 | INFO | [160,  3000] loss: 1.487
2025-02-25T17:57:42.706458+0300 | INFO | [160,  3100] loss: 1.490
2025-02-25T17:57:55.437859+0300 | INFO | [160,  3200] loss: 1.488
2025-02-25T17:58:09.668186+0300 | INFO | [160,  3300] loss: 1.497
2025-02-25T17:58:23.032167+0300 | INFO | [160,  3400] loss: 1.487
2025-02-25T17:58:35.915884+0300 | INFO | [160,  3500] loss: 1.496
2025-02-25T17:58:48.767310+0300 | INFO | [160,  3600] loss: 1.477
2025-02-25T17:59:01.853471+0300 | INFO | [160,  3700] loss: 1.493
2025-02-25T17:59:17.021564+0300 | INFO | [160,  3800] loss: 1.495
2025-02-25T17:59:29.165978+0300 | INFO | [160,  3900] loss: 1.489
2025-02-25T17:59:41.842951+0300 | INFO | [160,  4000] loss: 1.496
2025-02-25T17:59:54.975435+0300 | INFO | [160,  4100] loss: 1.494
2025-02-25T18:00:10.292598+0300 | INFO | [160,  4200] loss: 1.490
2025-02-25T18:00:22.813911+0300 | INFO | [160,  4300] loss: 1.495
2025-02-25T18:00:35.368219+0300 | INFO | [160,  4400] loss: 1.497
2025-02-25T18:00:48.324490+0300 | INFO | [160,  4500] loss: 1.483
2025-02-25T18:01:01.703227+0300 | INFO | [160,  4600] loss: 1.491
2025-02-25T18:01:15.392641+0300 | INFO | [160,  4700] loss: 1.485
2025-02-25T18:01:28.365844+0300 | INFO | [160,  4800] loss: 1.492
2025-02-25T18:01:41.589468+0300 | INFO | [160,  4900] loss: 1.487
2025-02-25T18:01:57.719094+0300 | DEBUG | Saving model to flat file storage. Save #160
2025-02-25T18:01:57.756320+0300 | INFO | Averaging client parameters
2025-02-25T18:01:57.782187+0300 | INFO | Updating parameters on client #0
2025-02-25T18:02:19.853141+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-25T18:02:19.855668+0300 | DEBUG | Test set: Loss: 1.671696662902832
2025-02-25T18:02:19.956314+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.91      0.92      0.92      1000
           2       0.76      0.69      0.72      1000
           3       0.66      0.57      0.61      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.61      0.56       800
           6       0.83      0.85      0.84      1000
           7       0.86      0.82      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T18:02:19.958697+0300 | DEBUG | Confusion Matrix:
[[840  10  40  15  16   7   3   8  42  19]
 [  7 921   1   4   2   0   6   0  17  42]
 [ 58   6 691  36  59  57  60  18   5  10]
 [ 31   7  51 684  57 267  46  27  14  16]
 [ 12   2  37  41 808  31  28  34   6   1]
 [ 10   1  43 173  29 488  14  35   5   2]
 [ 10   3  27  43  28  23 855   4   5   2]
 [ 22   1  12  28  45  56   8 821   5   2]
 [ 43  14   5   6   3   7   2   4 895  21]
 [ 29  46   7   8   2   4   3   9  21 871]]
2025-02-25T18:02:19.960019+0300 | DEBUG | Class precision: [0.79096045 0.91097923 0.75601751 0.65895954 0.77025739 0.51914894
 0.83414634 0.85520833 0.8817734  0.88336714]
2025-02-25T18:02:19.962557+0300 | DEBUG | Class recall: [0.84  0.921 0.691 0.57  0.808 0.61  0.855 0.821 0.895 0.871]
2025-02-25T18:02:20.015264+0300 | INFO | Training epoch #161 on client #0
2025-02-25T18:02:20.017549+0300 | DEBUG | Saving model to flat file storage. Save #161
2025-02-25T18:02:20.328528+0300 | INFO | [161,     0] loss: 0.015
2025-02-25T18:02:33.679513+0300 | INFO | [161,   100] loss: 1.501
2025-02-25T18:02:46.047656+0300 | INFO | [161,   200] loss: 1.487
2025-02-25T18:03:00.712516+0300 | INFO | [161,   300] loss: 1.488
2025-02-25T18:03:15.327565+0300 | INFO | [161,   400] loss: 1.482
2025-02-25T18:03:30.996141+0300 | INFO | [161,   500] loss: 1.497
2025-02-25T18:03:46.053873+0300 | INFO | [161,   600] loss: 1.493
2025-02-25T18:04:01.491707+0300 | INFO | [161,   700] loss: 1.491
2025-02-25T18:04:18.029148+0300 | INFO | [161,   800] loss: 1.496
2025-02-25T18:04:34.232426+0300 | INFO | [161,   900] loss: 1.499
2025-02-25T18:04:48.986002+0300 | INFO | [161,  1000] loss: 1.489
2025-02-25T18:05:03.505484+0300 | INFO | [161,  1100] loss: 1.482
2025-02-25T18:05:13.884462+0300 | INFO | [161,  1200] loss: 1.491
2025-02-25T18:05:26.534855+0300 | INFO | [161,  1300] loss: 1.491
2025-02-25T18:05:42.453736+0300 | INFO | [161,  1400] loss: 1.483
2025-02-25T18:05:59.369941+0300 | INFO | [161,  1500] loss: 1.494
2025-02-25T18:06:10.781579+0300 | INFO | [161,  1600] loss: 1.482
2025-02-25T18:06:21.738751+0300 | INFO | [161,  1700] loss: 1.499
2025-02-25T18:06:38.555167+0300 | INFO | [161,  1800] loss: 1.490
2025-02-25T18:06:53.310452+0300 | INFO | [161,  1900] loss: 1.490
2025-02-25T18:07:11.403773+0300 | INFO | [161,  2000] loss: 1.490
2025-02-25T18:07:35.789712+0300 | INFO | [161,  2100] loss: 1.489
2025-02-25T18:07:51.365502+0300 | INFO | [161,  2200] loss: 1.482
2025-02-25T18:08:08.131118+0300 | INFO | [161,  2300] loss: 1.489
2025-02-25T18:08:23.867292+0300 | INFO | [161,  2400] loss: 1.489
2025-02-25T18:08:42.680647+0300 | INFO | [161,  2500] loss: 1.488
2025-02-25T18:08:58.955645+0300 | INFO | [161,  2600] loss: 1.492
2025-02-25T18:09:14.585281+0300 | INFO | [161,  2700] loss: 1.489
2025-02-25T18:09:29.323791+0300 | INFO | [161,  2800] loss: 1.495
2025-02-25T18:09:43.996789+0300 | INFO | [161,  2900] loss: 1.493
2025-02-25T18:09:58.864008+0300 | INFO | [161,  3000] loss: 1.496
2025-02-25T18:10:15.167273+0300 | INFO | [161,  3100] loss: 1.484
2025-02-25T18:10:29.803826+0300 | INFO | [161,  3200] loss: 1.482
2025-02-25T18:10:44.636988+0300 | INFO | [161,  3300] loss: 1.492
2025-02-25T18:10:59.909098+0300 | INFO | [161,  3400] loss: 1.488
2025-02-25T18:11:15.677248+0300 | INFO | [161,  3500] loss: 1.496
2025-02-25T18:11:30.971900+0300 | INFO | [161,  3600] loss: 1.489
2025-02-25T18:11:46.036762+0300 | INFO | [161,  3700] loss: 1.493
2025-02-25T18:12:01.225870+0300 | INFO | [161,  3800] loss: 1.490
2025-02-25T18:12:17.534755+0300 | INFO | [161,  3900] loss: 1.487
2025-02-25T18:12:34.039771+0300 | INFO | [161,  4000] loss: 1.487
2025-02-25T18:12:49.414577+0300 | INFO | [161,  4100] loss: 1.493
2025-02-25T18:13:04.319046+0300 | INFO | [161,  4200] loss: 1.481
2025-02-25T18:13:19.088271+0300 | INFO | [161,  4300] loss: 1.491
2025-02-25T18:13:33.816594+0300 | INFO | [161,  4400] loss: 1.485
2025-02-25T18:13:49.458755+0300 | INFO | [161,  4500] loss: 1.490
2025-02-25T18:14:05.178457+0300 | INFO | [161,  4600] loss: 1.495
2025-02-25T18:14:21.853007+0300 | INFO | [161,  4700] loss: 1.488
2025-02-25T18:14:37.477285+0300 | INFO | [161,  4800] loss: 1.490
2025-02-25T18:14:53.097158+0300 | INFO | [161,  4900] loss: 1.489
2025-02-25T18:15:09.688272+0300 | DEBUG | Saving model to flat file storage. Save #161
2025-02-25T18:15:09.711513+0300 | INFO | Averaging client parameters
2025-02-25T18:15:09.722002+0300 | INFO | Updating parameters on client #0
2025-02-25T18:15:31.165888+0300 | DEBUG | Test set: Accuracy: 7907/10000 (79%)
2025-02-25T18:15:31.167183+0300 | DEBUG | Test set: Loss: 1.6703829765319824
2025-02-25T18:15:31.292148+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.76      0.70      0.73      1000
           3       0.64      0.61      0.62      1200
           4       0.80      0.79      0.79      1000
           5       0.53      0.60      0.56       800
           6       0.85      0.85      0.85      1000
           7       0.86      0.83      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.89      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T18:15:31.301785+0300 | DEBUG | Confusion Matrix:
[[846   9  39  17  10   8   4   8  37  22]
 [  8 913   0   4   1   1   6   1  17  49]
 [ 56   6 696  43  55  58  52  20   7   7]
 [ 36   7  46 727  46 245  42  24  12  15]
 [ 14   2  38  59 788  29  24  38   7   1]
 [ 10   1  41 193  24 478  15  31   5   2]
 [ 13   3  29  45  22  22 855   4   6   1]
 [ 24   1  11  42  37  50   5 826   2   2]
 [ 50  16   5   4   3   6   2   4 887  23]
 [ 24  36   6   7   2   3   3   9  19 891]]
2025-02-25T18:15:31.307437+0300 | DEBUG | Class precision: [0.7826087  0.91851107 0.76399561 0.63716039 0.79757085 0.53111111
 0.84821429 0.85595855 0.88788789 0.87956565]
2025-02-25T18:15:31.309053+0300 | DEBUG | Class recall: [0.846      0.913      0.696      0.60583333 0.788      0.5975
 0.855      0.826      0.887      0.891     ]
2025-02-25T18:15:31.374142+0300 | INFO | Training epoch #162 on client #0
2025-02-25T18:15:31.375664+0300 | DEBUG | Saving model to flat file storage. Save #162
2025-02-25T18:15:31.736691+0300 | INFO | [162,     0] loss: 0.015
2025-02-25T18:15:46.827809+0300 | INFO | [162,   100] loss: 1.489
2025-02-25T18:16:02.447098+0300 | INFO | [162,   200] loss: 1.475
2025-02-25T18:16:17.183437+0300 | INFO | [162,   300] loss: 1.487
2025-02-25T18:16:32.114605+0300 | INFO | [162,   400] loss: 1.493
2025-02-25T18:16:47.029215+0300 | INFO | [162,   500] loss: 1.484
2025-02-25T18:17:03.850155+0300 | INFO | [162,   600] loss: 1.485
2025-02-25T18:17:21.548800+0300 | INFO | [162,   700] loss: 1.490
2025-02-25T18:17:36.469906+0300 | INFO | [162,   800] loss: 1.499
2025-02-25T18:17:51.265544+0300 | INFO | [162,   900] loss: 1.495
2025-02-25T18:18:06.484622+0300 | INFO | [162,  1000] loss: 1.488
2025-02-25T18:18:22.326028+0300 | INFO | [162,  1100] loss: 1.487
2025-02-25T18:18:38.530617+0300 | INFO | [162,  1200] loss: 1.490
2025-02-25T18:18:53.508470+0300 | INFO | [162,  1300] loss: 1.493
2025-02-25T18:19:08.834873+0300 | INFO | [162,  1400] loss: 1.488
2025-02-25T18:19:23.546841+0300 | INFO | [162,  1500] loss: 1.483
2025-02-25T18:19:40.390202+0300 | INFO | [162,  1600] loss: 1.483
2025-02-25T18:20:00.857881+0300 | INFO | [162,  1700] loss: 1.496
2025-02-25T18:20:15.726615+0300 | INFO | [162,  1800] loss: 1.482
2025-02-25T18:20:30.742121+0300 | INFO | [162,  1900] loss: 1.493
2025-02-25T18:20:45.613316+0300 | INFO | [162,  2000] loss: 1.491
2025-02-25T18:21:00.678032+0300 | INFO | [162,  2100] loss: 1.492
2025-02-25T18:21:15.326930+0300 | INFO | [162,  2200] loss: 1.482
2025-02-25T18:21:30.227984+0300 | INFO | [162,  2300] loss: 1.487
2025-02-25T18:21:45.606094+0300 | INFO | [162,  2400] loss: 1.492
2025-02-25T18:22:01.301839+0300 | INFO | [162,  2500] loss: 1.488
2025-02-25T18:22:15.538005+0300 | INFO | [162,  2600] loss: 1.495
2025-02-25T18:22:30.715893+0300 | INFO | [162,  2700] loss: 1.490
2025-02-25T18:22:47.371842+0300 | INFO | [162,  2800] loss: 1.491
2025-02-25T18:23:02.980780+0300 | INFO | [162,  2900] loss: 1.497
2025-02-25T18:23:19.540012+0300 | INFO | [162,  3000] loss: 1.493
2025-02-25T18:23:36.451932+0300 | INFO | [162,  3100] loss: 1.499
2025-02-25T18:23:53.062426+0300 | INFO | [162,  3200] loss: 1.498
2025-02-25T18:24:08.070683+0300 | INFO | [162,  3300] loss: 1.485
2025-02-25T18:24:26.175233+0300 | INFO | [162,  3400] loss: 1.475
2025-02-25T18:24:41.146862+0300 | INFO | [162,  3500] loss: 1.490
2025-02-25T18:24:55.752714+0300 | INFO | [162,  3600] loss: 1.480
2025-02-25T18:25:10.438568+0300 | INFO | [162,  3700] loss: 1.492
2025-02-25T18:25:25.009119+0300 | INFO | [162,  3800] loss: 1.500
2025-02-25T18:25:40.155314+0300 | INFO | [162,  3900] loss: 1.491
2025-02-25T18:25:54.879995+0300 | INFO | [162,  4000] loss: 1.492
2025-02-25T18:26:09.842279+0300 | INFO | [162,  4100] loss: 1.493
2025-02-25T18:26:24.765550+0300 | INFO | [162,  4200] loss: 1.496
2025-02-25T18:26:39.602666+0300 | INFO | [162,  4300] loss: 1.485
2025-02-25T18:26:54.082207+0300 | INFO | [162,  4400] loss: 1.488
2025-02-25T18:27:10.004672+0300 | INFO | [162,  4500] loss: 1.489
2025-02-25T18:27:24.569785+0300 | INFO | [162,  4600] loss: 1.495
2025-02-25T18:27:39.156576+0300 | INFO | [162,  4700] loss: 1.492
2025-02-25T18:27:53.754281+0300 | INFO | [162,  4800] loss: 1.493
2025-02-25T18:28:08.361260+0300 | INFO | [162,  4900] loss: 1.488
2025-02-25T18:28:23.490263+0300 | DEBUG | Saving model to flat file storage. Save #162
2025-02-25T18:28:23.517735+0300 | INFO | Averaging client parameters
2025-02-25T18:28:23.531332+0300 | INFO | Updating parameters on client #0
2025-02-25T18:28:46.661865+0300 | DEBUG | Test set: Accuracy: 7865/10000 (79%)
2025-02-25T18:28:46.663458+0300 | DEBUG | Test set: Loss: 1.6731265783309937
2025-02-25T18:28:46.798399+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.92      0.91      0.92      1000
           2       0.78      0.67      0.72      1000
           3       0.66      0.55      0.60      1200
           4       0.76      0.81      0.79      1000
           5       0.51      0.62      0.56       800
           6       0.82      0.87      0.84      1000
           7       0.87      0.81      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T18:28:46.801992+0300 | DEBUG | Confusion Matrix:
[[831  13  36  12  17  12   3   9  45  22]
 [  6 914   0   3   2   1   4   1  17  52]
 [ 57   5 670  36  65  66  65  18   7  11]
 [ 30   5  45 661  65 284  53  27  13  17]
 [ 14   2  28  44 815  34  31  26   5   1]
 [  9   1  36 166  29 498  22  31   5   3]
 [ 11   2  22  38  22  18 873   3   9   2]
 [ 21   1   8  33  47  58  12 813   2   5]
 [ 42  13   6   4   5   6   2   3 896  23]
 [ 18  41   6   7   3   3   2   7  19 894]]
2025-02-25T18:28:46.807068+0300 | DEBUG | Class precision: [0.79980751 0.91675025 0.78179697 0.65836653 0.76168224 0.50816327
 0.81818182 0.86673774 0.88015717 0.86796117]
2025-02-25T18:28:46.809412+0300 | DEBUG | Class recall: [0.831      0.914      0.67       0.55083333 0.815      0.6225
 0.873      0.813      0.896      0.894     ]
2025-02-25T18:28:46.871613+0300 | INFO | Training epoch #163 on client #0
2025-02-25T18:28:46.877355+0300 | DEBUG | Saving model to flat file storage. Save #163
2025-02-25T18:28:47.233570+0300 | INFO | [163,     0] loss: 0.015
2025-02-25T18:29:02.652696+0300 | INFO | [163,   100] loss: 1.488
2025-02-25T18:29:17.586990+0300 | INFO | [163,   200] loss: 1.488
2025-02-25T18:29:32.473692+0300 | INFO | [163,   300] loss: 1.492
2025-02-25T18:29:47.060648+0300 | INFO | [163,   400] loss: 1.487
2025-02-25T18:30:02.429190+0300 | INFO | [163,   500] loss: 1.485
2025-02-25T18:30:21.826016+0300 | INFO | [163,   600] loss: 1.493
2025-02-25T18:30:38.085849+0300 | INFO | [163,   700] loss: 1.492
2025-02-25T18:30:53.538013+0300 | INFO | [163,   800] loss: 1.495
2025-02-25T18:31:08.335657+0300 | INFO | [163,   900] loss: 1.490
2025-02-25T18:31:24.632507+0300 | INFO | [163,  1000] loss: 1.483
2025-02-25T18:31:41.358604+0300 | INFO | [163,  1100] loss: 1.485
2025-02-25T18:32:02.744927+0300 | INFO | [163,  1200] loss: 1.480
2025-02-25T18:32:18.148997+0300 | INFO | [163,  1300] loss: 1.493
2025-02-25T18:32:33.281301+0300 | INFO | [163,  1400] loss: 1.488
2025-02-25T18:32:48.388070+0300 | INFO | [163,  1500] loss: 1.492
2025-02-25T18:33:03.007050+0300 | INFO | [163,  1600] loss: 1.492
2025-02-25T18:33:17.746986+0300 | INFO | [163,  1700] loss: 1.493
2025-02-25T18:33:32.531136+0300 | INFO | [163,  1800] loss: 1.491
2025-02-25T18:33:47.819940+0300 | INFO | [163,  1900] loss: 1.493
2025-02-25T18:34:03.615601+0300 | INFO | [163,  2000] loss: 1.480
2025-02-25T18:34:19.474695+0300 | INFO | [163,  2100] loss: 1.484
2025-02-25T18:34:34.547612+0300 | INFO | [163,  2200] loss: 1.487
2025-02-25T18:34:49.913593+0300 | INFO | [163,  2300] loss: 1.488
2025-02-25T18:35:04.612120+0300 | INFO | [163,  2400] loss: 1.483
2025-02-25T18:35:21.671740+0300 | INFO | [163,  2500] loss: 1.497
2025-02-25T18:35:37.579277+0300 | INFO | [163,  2600] loss: 1.500
2025-02-25T18:35:52.393871+0300 | INFO | [163,  2700] loss: 1.492
2025-02-25T18:36:07.580975+0300 | INFO | [163,  2800] loss: 1.483
2025-02-25T18:36:23.283840+0300 | INFO | [163,  2900] loss: 1.493
2025-02-25T18:36:38.907040+0300 | INFO | [163,  3000] loss: 1.492
2025-02-25T18:36:54.424398+0300 | INFO | [163,  3100] loss: 1.487
2025-02-25T18:37:09.402879+0300 | INFO | [163,  3200] loss: 1.495
2025-02-25T18:37:26.871889+0300 | INFO | [163,  3300] loss: 1.494
2025-02-25T18:37:42.700077+0300 | INFO | [163,  3400] loss: 1.494
2025-02-25T18:37:57.342797+0300 | INFO | [163,  3500] loss: 1.487
2025-02-25T18:38:13.841105+0300 | INFO | [163,  3600] loss: 1.493
2025-02-25T18:38:28.358873+0300 | INFO | [163,  3700] loss: 1.486
2025-02-25T18:38:42.834561+0300 | INFO | [163,  3800] loss: 1.491
2025-02-25T18:38:55.499286+0300 | INFO | [163,  3900] loss: 1.487
2025-02-25T18:39:09.246621+0300 | INFO | [163,  4000] loss: 1.479
2025-02-25T18:39:23.072119+0300 | INFO | [163,  4100] loss: 1.500
2025-02-25T18:39:37.036731+0300 | INFO | [163,  4200] loss: 1.491
2025-02-25T18:39:45.853001+0300 | INFO | [163,  4300] loss: 1.489
2025-02-25T18:39:56.582798+0300 | INFO | [163,  4400] loss: 1.484
2025-02-25T18:40:12.394927+0300 | INFO | [163,  4500] loss: 1.492
2025-02-25T18:40:25.108455+0300 | INFO | [163,  4600] loss: 1.489
2025-02-25T18:40:38.194099+0300 | INFO | [163,  4700] loss: 1.492
2025-02-25T18:40:53.272684+0300 | INFO | [163,  4800] loss: 1.483
2025-02-25T18:41:08.665583+0300 | INFO | [163,  4900] loss: 1.483
2025-02-25T18:41:23.806434+0300 | DEBUG | Saving model to flat file storage. Save #163
2025-02-25T18:41:23.837392+0300 | INFO | Averaging client parameters
2025-02-25T18:41:23.848187+0300 | INFO | Updating parameters on client #0
2025-02-25T18:41:45.302077+0300 | DEBUG | Test set: Accuracy: 7881/10000 (79%)
2025-02-25T18:41:45.303082+0300 | DEBUG | Test set: Loss: 1.6714357137680054
2025-02-25T18:41:45.418007+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.90      0.93      0.91      1000
           2       0.78      0.68      0.73      1000
           3       0.65      0.56      0.60      1200
           4       0.79      0.80      0.80      1000
           5       0.51      0.62      0.56       800
           6       0.83      0.87      0.85      1000
           7       0.85      0.82      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T18:41:45.420484+0300 | DEBUG | Confusion Matrix:
[[848  14  34  15  13  11   2   8  36  19]
 [ 10 931   0   4   0   0   4   1  14  36]
 [ 63   8 678  40  55  67  54  21   6   8]
 [ 30   5  43 678  50 288  55  27  11  13]
 [ 15   2  28  49 800  33  30  37   4   2]
 [ 10   1  36 172  26 498  17  34   4   2]
 [ 14   3  25  36  19  20 872   3   7   1]
 [ 21   1   9  41  38  56   9 821   2   2]
 [ 49  18   7   4   4   8   2   3 885  20]
 [ 26  54   6   8   3   3   3   9  18 870]]
2025-02-25T18:41:45.423472+0300 | DEBUG | Class precision: [0.78084715 0.89778206 0.78290993 0.64756447 0.79365079 0.50609756
 0.83206107 0.85165975 0.89665653 0.89414183]
2025-02-25T18:41:45.425481+0300 | DEBUG | Class recall: [0.848  0.931  0.678  0.565  0.8    0.6225 0.872  0.821  0.885  0.87  ]
2025-02-25T18:41:45.482750+0300 | INFO | Training epoch #164 on client #0
2025-02-25T18:41:45.484914+0300 | DEBUG | Saving model to flat file storage. Save #164
2025-02-25T18:41:50.385185+0300 | INFO | [164,     0] loss: 0.015
2025-02-25T18:42:05.579891+0300 | INFO | [164,   100] loss: 1.493
2025-02-25T18:42:21.205086+0300 | INFO | [164,   200] loss: 1.490
2025-02-25T18:42:35.666409+0300 | INFO | [164,   300] loss: 1.497
2025-02-25T18:42:49.812638+0300 | INFO | [164,   400] loss: 1.491
2025-02-25T18:43:04.298736+0300 | INFO | [164,   500] loss: 1.489
2025-02-25T18:43:18.657876+0300 | INFO | [164,   600] loss: 1.492
2025-02-25T18:43:40.293850+0300 | INFO | [164,   700] loss: 1.492
2025-02-25T18:43:54.187370+0300 | INFO | [164,   800] loss: 1.488
2025-02-25T18:44:08.987495+0300 | INFO | [164,   900] loss: 1.495
2025-02-25T18:44:24.596503+0300 | INFO | [164,  1000] loss: 1.490
2025-02-25T18:44:37.953925+0300 | INFO | [164,  1100] loss: 1.496
2025-02-25T18:44:52.772071+0300 | INFO | [164,  1200] loss: 1.493
2025-02-25T18:45:06.979396+0300 | INFO | [164,  1300] loss: 1.488
2025-02-25T18:45:22.257538+0300 | INFO | [164,  1400] loss: 1.495
2025-02-25T18:45:36.980641+0300 | INFO | [164,  1500] loss: 1.490
2025-02-25T18:45:52.752535+0300 | INFO | [164,  1600] loss: 1.490
2025-02-25T18:46:08.358671+0300 | INFO | [164,  1700] loss: 1.479
2025-02-25T18:46:24.212064+0300 | INFO | [164,  1800] loss: 1.485
2025-02-25T18:46:43.110347+0300 | INFO | [164,  1900] loss: 1.490
2025-02-25T18:46:58.382105+0300 | INFO | [164,  2000] loss: 1.479
2025-02-25T18:47:14.967824+0300 | INFO | [164,  2100] loss: 1.485
2025-02-25T18:47:31.259024+0300 | INFO | [164,  2200] loss: 1.487
2025-02-25T18:47:47.980060+0300 | INFO | [164,  2300] loss: 1.493
2025-02-25T18:48:03.700729+0300 | INFO | [164,  2400] loss: 1.497
2025-02-25T18:48:19.699771+0300 | INFO | [164,  2500] loss: 1.490
2025-02-25T18:48:34.048862+0300 | INFO | [164,  2600] loss: 1.499
2025-02-25T18:48:52.027772+0300 | INFO | [164,  2700] loss: 1.488
2025-02-25T18:49:05.179062+0300 | INFO | [164,  2800] loss: 1.486
2025-02-25T18:49:19.676701+0300 | INFO | [164,  2900] loss: 1.490
2025-02-25T18:49:32.497125+0300 | INFO | [164,  3000] loss: 1.495
2025-02-25T18:49:47.294463+0300 | INFO | [164,  3100] loss: 1.493
2025-02-25T18:50:01.716033+0300 | INFO | [164,  3200] loss: 1.491
2025-02-25T18:50:15.923768+0300 | INFO | [164,  3300] loss: 1.485
2025-02-25T18:50:32.496561+0300 | INFO | [164,  3400] loss: 1.487
2025-02-25T18:50:42.588498+0300 | INFO | [164,  3500] loss: 1.485
2025-02-25T18:50:55.684236+0300 | INFO | [164,  3600] loss: 1.481
2025-02-25T18:51:09.593275+0300 | INFO | [164,  3700] loss: 1.492
2025-02-25T18:51:24.383987+0300 | INFO | [164,  3800] loss: 1.484
2025-02-25T18:51:37.919157+0300 | INFO | [164,  3900] loss: 1.491
2025-02-25T18:51:50.769318+0300 | INFO | [164,  4000] loss: 1.491
2025-02-25T18:52:04.570651+0300 | INFO | [164,  4100] loss: 1.490
2025-02-25T18:52:18.532386+0300 | INFO | [164,  4200] loss: 1.485
2025-02-25T18:52:31.025429+0300 | INFO | [164,  4300] loss: 1.481
2025-02-25T18:52:44.197060+0300 | INFO | [164,  4400] loss: 1.488
2025-02-25T18:52:57.772841+0300 | INFO | [164,  4500] loss: 1.489
2025-02-25T18:53:12.506653+0300 | INFO | [164,  4600] loss: 1.484
2025-02-25T18:53:26.756077+0300 | INFO | [164,  4700] loss: 1.486
2025-02-25T18:53:40.290887+0300 | INFO | [164,  4800] loss: 1.488
2025-02-25T18:53:53.071000+0300 | INFO | [164,  4900] loss: 1.496
2025-02-25T18:54:06.372230+0300 | DEBUG | Saving model to flat file storage. Save #164
2025-02-25T18:54:06.398862+0300 | INFO | Averaging client parameters
2025-02-25T18:54:06.403535+0300 | INFO | Updating parameters on client #0
2025-02-25T18:54:28.508921+0300 | DEBUG | Test set: Accuracy: 7897/10000 (79%)
2025-02-25T18:54:28.510988+0300 | DEBUG | Test set: Loss: 1.670444130897522
2025-02-25T18:54:28.642779+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.78      0.69      0.73      1000
           3       0.63      0.60      0.61      1200
           4       0.78      0.81      0.80      1000
           5       0.54      0.58      0.56       800
           6       0.82      0.87      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T18:54:28.644081+0300 | DEBUG | Confusion Matrix:
[[858   9  36  17   9   9   6   7  33  16]
 [  8 912   1   6   0   1   9   1  19  43]
 [ 65   4 690  44  57  54  57  16   8   5]
 [ 27   6  48 718  55 243  55  23  14  11]
 [ 14   2  29  50 807  27  31  35   4   1]
 [ 12   1  36 199  30 463  19  34   5   1]
 [ 12   2  24  41  19  18 873   4   6   1]
 [ 23   1  11  46  44  39  10 823   2   1]
 [ 48  13   7   6   4   6   2   3 892  19]
 [ 29  51   7   9   4   3   4  12  20 861]]
2025-02-25T18:54:28.646625+0300 | DEBUG | Class precision: [0.78284672 0.91108891 0.77615298 0.63204225 0.78425656 0.53650058
 0.81894934 0.85908142 0.889332   0.89781022]
2025-02-25T18:54:28.652631+0300 | DEBUG | Class recall: [0.858      0.912      0.69       0.59833333 0.807      0.57875
 0.873      0.823      0.892      0.861     ]
2025-02-25T18:54:28.733225+0300 | INFO | Training epoch #165 on client #0
2025-02-25T18:54:28.736251+0300 | DEBUG | Saving model to flat file storage. Save #165
2025-02-25T18:54:28.924825+0300 | INFO | [165,     0] loss: 0.015
2025-02-25T18:54:42.841420+0300 | INFO | [165,   100] loss: 1.497
2025-02-25T18:54:57.876863+0300 | INFO | [165,   200] loss: 1.488
2025-02-25T18:55:20.042554+0300 | INFO | [165,   300] loss: 1.478
2025-02-25T18:55:35.051514+0300 | INFO | [165,   400] loss: 1.495
2025-02-25T18:55:57.803933+0300 | INFO | [165,   500] loss: 1.486
2025-02-25T18:56:14.133391+0300 | INFO | [165,   600] loss: 1.486
2025-02-25T18:56:29.194244+0300 | INFO | [165,   700] loss: 1.488
2025-02-25T18:56:44.575064+0300 | INFO | [165,   800] loss: 1.489
2025-02-25T18:57:01.164736+0300 | INFO | [165,   900] loss: 1.486
2025-02-25T18:57:16.247585+0300 | INFO | [165,  1000] loss: 1.489
2025-02-25T18:57:35.631457+0300 | INFO | [165,  1100] loss: 1.480
2025-02-25T18:57:57.751841+0300 | INFO | [165,  1200] loss: 1.482
2025-02-25T18:58:12.337912+0300 | INFO | [165,  1300] loss: 1.486
2025-02-25T18:58:27.300641+0300 | INFO | [165,  1400] loss: 1.480
2025-02-25T18:58:43.540841+0300 | INFO | [165,  1500] loss: 1.488
2025-02-25T18:58:59.098778+0300 | INFO | [165,  1600] loss: 1.505
2025-02-25T18:59:14.479330+0300 | INFO | [165,  1700] loss: 1.486
2025-02-25T18:59:29.544693+0300 | INFO | [165,  1800] loss: 1.496
2025-02-25T18:59:44.879118+0300 | INFO | [165,  1900] loss: 1.493
2025-02-25T19:00:00.142290+0300 | INFO | [165,  2000] loss: 1.490
2025-02-25T19:00:17.389897+0300 | INFO | [165,  2100] loss: 1.492
2025-02-25T19:00:34.093034+0300 | INFO | [165,  2200] loss: 1.493
2025-02-25T19:00:49.483249+0300 | INFO | [165,  2300] loss: 1.498
2025-02-25T19:01:05.305592+0300 | INFO | [165,  2400] loss: 1.485
2025-02-25T19:01:20.306599+0300 | INFO | [165,  2500] loss: 1.487
2025-02-25T19:01:36.148279+0300 | INFO | [165,  2600] loss: 1.496
2025-02-25T19:01:51.386059+0300 | INFO | [165,  2700] loss: 1.488
2025-02-25T19:02:07.144146+0300 | INFO | [165,  2800] loss: 1.483
2025-02-25T19:02:22.283961+0300 | INFO | [165,  2900] loss: 1.489
2025-02-25T19:02:37.596156+0300 | INFO | [165,  3000] loss: 1.494
2025-02-25T19:02:52.277614+0300 | INFO | [165,  3100] loss: 1.489
2025-02-25T19:03:05.736056+0300 | INFO | [165,  3200] loss: 1.490
2025-02-25T19:03:24.560573+0300 | INFO | [165,  3300] loss: 1.491
2025-02-25T19:03:39.798818+0300 | INFO | [165,  3400] loss: 1.485
2025-02-25T19:03:54.621158+0300 | INFO | [165,  3500] loss: 1.478
2025-02-25T19:04:11.068658+0300 | INFO | [165,  3600] loss: 1.493
2025-02-25T19:04:27.042067+0300 | INFO | [165,  3700] loss: 1.484
2025-02-25T19:04:43.601944+0300 | INFO | [165,  3800] loss: 1.487
2025-02-25T19:04:59.187703+0300 | INFO | [165,  3900] loss: 1.490
2025-02-25T19:05:14.503898+0300 | INFO | [165,  4000] loss: 1.495
2025-02-25T19:05:29.482643+0300 | INFO | [165,  4100] loss: 1.493
2025-02-25T19:05:44.648722+0300 | INFO | [165,  4200] loss: 1.489
2025-02-25T19:06:00.478102+0300 | INFO | [165,  4300] loss: 1.492
2025-02-25T19:06:15.701265+0300 | INFO | [165,  4400] loss: 1.495
2025-02-25T19:06:30.663061+0300 | INFO | [165,  4500] loss: 1.491
2025-02-25T19:06:45.659671+0300 | INFO | [165,  4600] loss: 1.497
2025-02-25T19:07:00.686770+0300 | INFO | [165,  4700] loss: 1.496
2025-02-25T19:07:17.743436+0300 | INFO | [165,  4800] loss: 1.493
2025-02-25T19:07:40.793403+0300 | INFO | [165,  4900] loss: 1.481
2025-02-25T19:07:57.082420+0300 | DEBUG | Saving model to flat file storage. Save #165
2025-02-25T19:07:57.114408+0300 | INFO | Averaging client parameters
2025-02-25T19:07:57.129891+0300 | INFO | Updating parameters on client #0
2025-02-25T19:08:21.211346+0300 | DEBUG | Test set: Accuracy: 7890/10000 (79%)
2025-02-25T19:08:21.213725+0300 | DEBUG | Test set: Loss: 1.6703859567642212
2025-02-25T19:08:21.359882+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.90      0.93      0.92      1000
           2       0.78      0.68      0.73      1000
           3       0.67      0.56      0.61      1200
           4       0.76      0.82      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.82      0.88      0.84      1000
           7       0.84      0.83      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T19:08:21.361923+0300 | DEBUG | Confusion Matrix:
[[843  12  38  16  12  11   4  11  35  18]
 [  8 932   1   4   0   0   6   1  10  38]
 [ 54   4 680  34  61  59  67  26   6   9]
 [ 26   5  42 666  63 282  58  31  13  14]
 [ 12   2  28  41 820  27  32  33   4   1]
 [ 11   2  37 155  35 504  16  34   4   2]
 [  7   3  25  36  23  19 875   4   6   2]
 [ 18   1   9  31  50  52   7 828   2   2]
 [ 51  19   7   4   5   8   3   3 878  22]
 [ 24  54   6   8   4   5   5  10  20 864]]
2025-02-25T19:08:21.363725+0300 | DEBUG | Class precision: [0.79981025 0.90135397 0.77892325 0.66934673 0.76421249 0.52119959
 0.81547064 0.8440367  0.89775051 0.88888889]
2025-02-25T19:08:21.367252+0300 | DEBUG | Class recall: [0.843 0.932 0.68  0.555 0.82  0.63  0.875 0.828 0.878 0.864]
2025-02-25T19:08:21.450748+0300 | INFO | Training epoch #166 on client #0
2025-02-25T19:08:21.451748+0300 | DEBUG | Saving model to flat file storage. Save #166
2025-02-25T19:08:21.877836+0300 | INFO | [166,     0] loss: 0.015
2025-02-25T19:08:38.295965+0300 | INFO | [166,   100] loss: 1.491
2025-02-25T19:08:54.699844+0300 | INFO | [166,   200] loss: 1.484
2025-02-25T19:09:11.596025+0300 | INFO | [166,   300] loss: 1.496
2025-02-25T19:09:26.693642+0300 | INFO | [166,   400] loss: 1.493
2025-02-25T19:09:41.915080+0300 | INFO | [166,   500] loss: 1.497
2025-02-25T19:09:56.531869+0300 | INFO | [166,   600] loss: 1.499
2025-02-25T19:10:11.872769+0300 | INFO | [166,   700] loss: 1.481
2025-02-25T19:10:28.820688+0300 | INFO | [166,   800] loss: 1.484
2025-02-25T19:10:43.164183+0300 | INFO | [166,   900] loss: 1.491
2025-02-25T19:10:57.728927+0300 | INFO | [166,  1000] loss: 1.489
2025-02-25T19:11:12.004822+0300 | INFO | [166,  1100] loss: 1.486
2025-02-25T19:11:26.516635+0300 | INFO | [166,  1200] loss: 1.496
2025-02-25T19:11:41.156368+0300 | INFO | [166,  1300] loss: 1.493
2025-02-25T19:11:56.341074+0300 | INFO | [166,  1400] loss: 1.490
2025-02-25T19:12:11.044778+0300 | INFO | [166,  1500] loss: 1.487
2025-02-25T19:12:25.833011+0300 | INFO | [166,  1600] loss: 1.489
2025-02-25T19:12:40.125878+0300 | INFO | [166,  1700] loss: 1.486
2025-02-25T19:12:54.652884+0300 | INFO | [166,  1800] loss: 1.487
2025-02-25T19:13:09.616365+0300 | INFO | [166,  1900] loss: 1.490
2025-02-25T19:13:24.355354+0300 | INFO | [166,  2000] loss: 1.493
2025-02-25T19:13:38.858024+0300 | INFO | [166,  2100] loss: 1.490
2025-02-25T19:13:53.079364+0300 | INFO | [166,  2200] loss: 1.485
2025-02-25T19:14:07.687996+0300 | INFO | [166,  2300] loss: 1.485
2025-02-25T19:14:22.129607+0300 | INFO | [166,  2400] loss: 1.495
2025-02-25T19:14:36.668118+0300 | INFO | [166,  2500] loss: 1.483
2025-02-25T19:14:50.739193+0300 | INFO | [166,  2600] loss: 1.487
2025-02-25T19:15:03.832969+0300 | INFO | [166,  2700] loss: 1.501
2025-02-25T19:15:17.017198+0300 | INFO | [166,  2800] loss: 1.479
2025-02-25T19:15:30.038701+0300 | INFO | [166,  2900] loss: 1.485
2025-02-25T19:15:45.007449+0300 | INFO | [166,  3000] loss: 1.500
2025-02-25T19:15:59.163225+0300 | INFO | [166,  3100] loss: 1.489
2025-02-25T19:16:13.495211+0300 | INFO | [166,  3200] loss: 1.491
2025-02-25T19:16:28.299926+0300 | INFO | [166,  3300] loss: 1.487
2025-02-25T19:16:42.919925+0300 | INFO | [166,  3400] loss: 1.490
2025-02-25T19:16:57.485455+0300 | INFO | [166,  3500] loss: 1.488
2025-02-25T19:17:12.651333+0300 | INFO | [166,  3600] loss: 1.491
2025-02-25T19:17:27.163294+0300 | INFO | [166,  3700] loss: 1.496
2025-02-25T19:17:41.280233+0300 | INFO | [166,  3800] loss: 1.481
2025-02-25T19:17:55.149032+0300 | INFO | [166,  3900] loss: 1.492
2025-02-25T19:18:09.366292+0300 | INFO | [166,  4000] loss: 1.494
2025-02-25T19:18:23.277174+0300 | INFO | [166,  4100] loss: 1.494
2025-02-25T19:18:37.672331+0300 | INFO | [166,  4200] loss: 1.484
2025-02-25T19:19:00.311008+0300 | INFO | [166,  4300] loss: 1.492
2025-02-25T19:19:15.610582+0300 | INFO | [166,  4400] loss: 1.490
2025-02-25T19:19:30.072182+0300 | INFO | [166,  4500] loss: 1.497
2025-02-25T19:19:48.462502+0300 | INFO | [166,  4600] loss: 1.487
2025-02-25T19:20:04.639350+0300 | INFO | [166,  4700] loss: 1.498
2025-02-25T19:20:18.878866+0300 | INFO | [166,  4800] loss: 1.485
2025-02-25T19:20:33.521903+0300 | INFO | [166,  4900] loss: 1.480
2025-02-25T19:20:47.778034+0300 | DEBUG | Saving model to flat file storage. Save #166
2025-02-25T19:20:47.814966+0300 | INFO | Averaging client parameters
2025-02-25T19:20:47.833601+0300 | INFO | Updating parameters on client #0
2025-02-25T19:21:08.876464+0300 | DEBUG | Test set: Accuracy: 7901/10000 (79%)
2025-02-25T19:21:08.878491+0300 | DEBUG | Test set: Loss: 1.669918417930603
2025-02-25T19:21:09.017534+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.92      0.92      0.92      1000
           2       0.75      0.71      0.73      1000
           3       0.65      0.59      0.62      1200
           4       0.76      0.82      0.79      1000
           5       0.54      0.57      0.55       800
           6       0.83      0.86      0.85      1000
           7       0.86      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T19:21:09.018539+0300 | DEBUG | Confusion Matrix:
[[852   8  40  16  10  10   5   7  34  18]
 [  8 916   1   5   1   1   7   1  19  41]
 [ 59   2 706  39  59  53  53  17   6   6]
 [ 31   7  55 710  65 231  50  24  13  14]
 [ 15   2  34  39 824  21  32  27   5   1]
 [ 12   1  43 196  33 453  19  35   6   2]
 [ 13   1  30  37  28  16 865   3   7   0]
 [ 24   1  13  38  60  41   8 811   2   2]
 [ 49  12   8   4   5   6   3   3 889  21]
 [ 27  41   6   8   4   4   5  10  20 875]]
2025-02-25T19:21:09.020000+0300 | DEBUG | Class precision: [0.78165138 0.92431887 0.7542735  0.65018315 0.75665748 0.54186603
 0.82617001 0.86460554 0.88811189 0.89285714]
2025-02-25T19:21:09.021575+0300 | DEBUG | Class recall: [0.852      0.916      0.706      0.59166667 0.824      0.56625
 0.865      0.811      0.889      0.875     ]
2025-02-25T19:21:09.024747+0300 | INFO | Training epoch #167 on client #0
2025-02-25T19:21:09.026050+0300 | DEBUG | Saving model to flat file storage. Save #167
2025-02-25T19:21:09.244487+0300 | INFO | [167,     0] loss: 0.015
2025-02-25T19:21:25.668909+0300 | INFO | [167,   100] loss: 1.490
2025-02-25T19:21:40.231805+0300 | INFO | [167,   200] loss: 1.485
2025-02-25T19:21:54.486328+0300 | INFO | [167,   300] loss: 1.489
2025-02-25T19:22:08.875604+0300 | INFO | [167,   400] loss: 1.488
2025-02-25T19:22:23.070162+0300 | INFO | [167,   500] loss: 1.498
2025-02-25T19:22:37.439727+0300 | INFO | [167,   600] loss: 1.479
2025-02-25T19:22:52.453010+0300 | INFO | [167,   700] loss: 1.491
2025-02-25T19:23:07.021760+0300 | INFO | [167,   800] loss: 1.487
2025-02-25T19:23:21.005793+0300 | INFO | [167,   900] loss: 1.492
2025-02-25T19:23:35.323015+0300 | INFO | [167,  1000] loss: 1.486
2025-02-25T19:23:49.744548+0300 | INFO | [167,  1100] loss: 1.489
2025-02-25T19:24:03.260134+0300 | INFO | [167,  1200] loss: 1.486
2025-02-25T19:24:17.277765+0300 | INFO | [167,  1300] loss: 1.496
2025-02-25T19:24:32.707284+0300 | INFO | [167,  1400] loss: 1.479
2025-02-25T19:24:47.371110+0300 | INFO | [167,  1500] loss: 1.483
2025-02-25T19:25:03.463095+0300 | INFO | [167,  1600] loss: 1.487
2025-02-25T19:25:20.576454+0300 | INFO | [167,  1700] loss: 1.493
2025-02-25T19:25:35.112305+0300 | INFO | [167,  1800] loss: 1.492
2025-02-25T19:25:47.886775+0300 | INFO | [167,  1900] loss: 1.483
2025-02-25T19:26:00.579555+0300 | INFO | [167,  2000] loss: 1.484
2025-02-25T19:26:13.693153+0300 | INFO | [167,  2100] loss: 1.491
2025-02-25T19:26:28.717307+0300 | INFO | [167,  2200] loss: 1.495
2025-02-25T19:26:40.889055+0300 | INFO | [167,  2300] loss: 1.494
2025-02-25T19:26:53.651674+0300 | INFO | [167,  2400] loss: 1.486
2025-02-25T19:27:08.896220+0300 | INFO | [167,  2500] loss: 1.487
2025-02-25T19:27:25.769753+0300 | INFO | [167,  2600] loss: 1.498
2025-02-25T19:27:39.585060+0300 | INFO | [167,  2700] loss: 1.486
2025-02-25T19:27:52.544319+0300 | INFO | [167,  2800] loss: 1.485
2025-02-25T19:28:04.731265+0300 | INFO | [167,  2900] loss: 1.497
2025-02-25T19:28:18.016973+0300 | INFO | [167,  3000] loss: 1.490
2025-02-25T19:28:32.380224+0300 | INFO | [167,  3100] loss: 1.491
2025-02-25T19:28:45.715006+0300 | INFO | [167,  3200] loss: 1.497
2025-02-25T19:28:59.000657+0300 | INFO | [167,  3300] loss: 1.496
2025-02-25T19:29:19.988384+0300 | INFO | [167,  3400] loss: 1.480
2025-02-25T19:29:34.626008+0300 | INFO | [167,  3500] loss: 1.489
2025-02-25T19:29:52.431885+0300 | INFO | [167,  3600] loss: 1.482
2025-02-25T19:30:06.103146+0300 | INFO | [167,  3700] loss: 1.495
2025-02-25T19:30:22.188426+0300 | INFO | [167,  3800] loss: 1.490
2025-02-25T19:30:36.801197+0300 | INFO | [167,  3900] loss: 1.484
2025-02-25T19:30:53.139804+0300 | INFO | [167,  4000] loss: 1.501
2025-02-25T19:31:06.811803+0300 | INFO | [167,  4100] loss: 1.485
2025-02-25T19:31:21.494889+0300 | INFO | [167,  4200] loss: 1.499
2025-02-25T19:31:36.099455+0300 | INFO | [167,  4300] loss: 1.488
2025-02-25T19:31:50.872384+0300 | INFO | [167,  4400] loss: 1.494
2025-02-25T19:32:05.946109+0300 | INFO | [167,  4500] loss: 1.483
2025-02-25T19:32:19.224506+0300 | INFO | [167,  4600] loss: 1.492
2025-02-25T19:32:32.182612+0300 | INFO | [167,  4700] loss: 1.497
2025-02-25T19:32:44.820685+0300 | INFO | [167,  4800] loss: 1.487
2025-02-25T19:32:57.816352+0300 | INFO | [167,  4900] loss: 1.474
2025-02-25T19:33:11.285989+0300 | DEBUG | Saving model to flat file storage. Save #167
2025-02-25T19:33:11.315663+0300 | INFO | Averaging client parameters
2025-02-25T19:33:11.328285+0300 | INFO | Updating parameters on client #0
2025-02-25T19:33:30.444579+0300 | DEBUG | Test set: Accuracy: 7916/10000 (79%)
2025-02-25T19:33:30.446595+0300 | DEBUG | Test set: Loss: 1.6687562465667725
2025-02-25T19:33:30.559592+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.93      0.90      0.92      1000
           2       0.76      0.70      0.73      1000
           3       0.65      0.60      0.62      1200
           4       0.77      0.82      0.79      1000
           5       0.52      0.61      0.56       800
           6       0.85      0.85      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.89      0.90      0.89      1000
           9       0.88      0.90      0.89      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T19:33:30.560736+0300 | DEBUG | Confusion Matrix:
[[839   9  41  22  10  10   5   7  36  21]
 [  6 902   1   5   1   2   7   1  22  53]
 [ 55   3 704  40  61  59  45  17   7   9]
 [ 28   5  51 717  56 254  41  22  13  13]
 [ 12   2  33  47 821  28  24  26   5   2]
 [ 10   1  41 181  31 488  13  28   6   1]
 [ 11   1  35  42  27  21 853   4   5   1]
 [ 21   1  14  40  58  59   6 797   2   2]
 [ 41  12   7   5   5   7   2   2 898  21]
 [ 18  35   5   8   2   4   3   9  19 897]]
2025-02-25T19:33:30.562109+0300 | DEBUG | Class precision: [0.80595581 0.92893924 0.75536481 0.64769648 0.76585821 0.52360515
 0.85385385 0.87294633 0.88647581 0.87941176]
2025-02-25T19:33:30.565464+0300 | DEBUG | Class recall: [0.839  0.902  0.704  0.5975 0.821  0.61   0.853  0.797  0.898  0.897 ]
2025-02-25T19:33:30.619575+0300 | INFO | Training epoch #168 on client #0
2025-02-25T19:33:30.621592+0300 | DEBUG | Saving model to flat file storage. Save #168
2025-02-25T19:33:30.781708+0300 | INFO | [168,     0] loss: 0.015
2025-02-25T19:33:44.535708+0300 | INFO | [168,   100] loss: 1.489
2025-02-25T19:33:58.019805+0300 | INFO | [168,   200] loss: 1.496
2025-02-25T19:34:12.957321+0300 | INFO | [168,   300] loss: 1.479
2025-02-25T19:34:27.731355+0300 | INFO | [168,   400] loss: 1.481
2025-02-25T19:34:41.983071+0300 | INFO | [168,   500] loss: 1.486
2025-02-25T19:34:55.462700+0300 | INFO | [168,   600] loss: 1.495
2025-02-25T19:35:08.357304+0300 | INFO | [168,   700] loss: 1.489
2025-02-25T19:35:21.601009+0300 | INFO | [168,   800] loss: 1.493
2025-02-25T19:35:35.050070+0300 | INFO | [168,   900] loss: 1.486
2025-02-25T19:35:47.877396+0300 | INFO | [168,  1000] loss: 1.482
2025-02-25T19:36:00.794055+0300 | INFO | [168,  1100] loss: 1.488
2025-02-25T19:36:13.954402+0300 | INFO | [168,  1200] loss: 1.495
2025-02-25T19:36:27.083787+0300 | INFO | [168,  1300] loss: 1.496
2025-02-25T19:36:40.468711+0300 | INFO | [168,  1400] loss: 1.496
2025-02-25T19:36:54.677150+0300 | INFO | [168,  1500] loss: 1.482
2025-02-25T19:37:07.151212+0300 | INFO | [168,  1600] loss: 1.492
2025-02-25T19:37:20.180262+0300 | INFO | [168,  1700] loss: 1.485
2025-02-25T19:37:36.332890+0300 | INFO | [168,  1800] loss: 1.483
2025-02-25T19:37:49.964912+0300 | INFO | [168,  1900] loss: 1.486
2025-02-25T19:38:03.402979+0300 | INFO | [168,  2000] loss: 1.488
2025-02-25T19:38:18.175650+0300 | INFO | [168,  2100] loss: 1.486
2025-02-25T19:38:32.050566+0300 | INFO | [168,  2200] loss: 1.490
2025-02-25T19:38:44.962830+0300 | INFO | [168,  2300] loss: 1.482
2025-02-25T19:38:58.006878+0300 | INFO | [168,  2400] loss: 1.483
2025-02-25T19:39:11.846122+0300 | INFO | [168,  2500] loss: 1.490
2025-02-25T19:39:24.913268+0300 | INFO | [168,  2600] loss: 1.493
2025-02-25T19:39:37.584891+0300 | INFO | [168,  2700] loss: 1.496
2025-02-25T19:39:51.405618+0300 | INFO | [168,  2800] loss: 1.489
2025-02-25T19:40:03.439211+0300 | INFO | [168,  2900] loss: 1.489
2025-02-25T19:40:15.114718+0300 | INFO | [168,  3000] loss: 1.493
2025-02-25T19:40:27.766979+0300 | INFO | [168,  3100] loss: 1.484
2025-02-25T19:40:45.152796+0300 | INFO | [168,  3200] loss: 1.493
2025-02-25T19:41:00.121926+0300 | INFO | [168,  3300] loss: 1.492
2025-02-25T19:41:13.419108+0300 | INFO | [168,  3400] loss: 1.488
2025-02-25T19:41:28.384402+0300 | INFO | [168,  3500] loss: 1.499
2025-02-25T19:41:43.538894+0300 | INFO | [168,  3600] loss: 1.487
2025-02-25T19:41:58.067021+0300 | INFO | [168,  3700] loss: 1.498
2025-02-25T19:42:10.892465+0300 | INFO | [168,  3800] loss: 1.492
2025-02-25T19:42:22.535746+0300 | INFO | [168,  3900] loss: 1.491
2025-02-25T19:42:33.896638+0300 | INFO | [168,  4000] loss: 1.485
2025-02-25T19:42:45.356800+0300 | INFO | [168,  4100] loss: 1.501
2025-02-25T19:42:56.718327+0300 | INFO | [168,  4200] loss: 1.493
2025-02-25T19:43:09.754033+0300 | INFO | [168,  4300] loss: 1.495
2025-02-25T19:43:21.502492+0300 | INFO | [168,  4400] loss: 1.486
2025-02-25T19:43:34.230474+0300 | INFO | [168,  4500] loss: 1.484
2025-02-25T19:43:47.109417+0300 | INFO | [168,  4600] loss: 1.490
2025-02-25T19:43:59.494295+0300 | INFO | [168,  4700] loss: 1.485
2025-02-25T19:44:15.766330+0300 | INFO | [168,  4800] loss: 1.490
2025-02-25T19:44:28.716137+0300 | INFO | [168,  4900] loss: 1.488
2025-02-25T19:44:40.707165+0300 | DEBUG | Saving model to flat file storage. Save #168
2025-02-25T19:44:40.737616+0300 | INFO | Averaging client parameters
2025-02-25T19:44:40.751025+0300 | INFO | Updating parameters on client #0
2025-02-25T19:45:00.013517+0300 | DEBUG | Test set: Accuracy: 7916/10000 (79%)
2025-02-25T19:45:00.016406+0300 | DEBUG | Test set: Loss: 1.669357419013977
2025-02-25T19:45:00.155990+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.86      0.81      1000
           1       0.92      0.92      0.92      1000
           2       0.78      0.69      0.73      1000
           3       0.66      0.59      0.62      1200
           4       0.76      0.83      0.79      1000
           5       0.55      0.59      0.57       800
           6       0.85      0.85      0.85      1000
           7       0.84      0.83      0.83      1000
           8       0.90      0.88      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T19:45:00.158749+0300 | DEBUG | Confusion Matrix:
[[861   8  34  16  10   7   4   9  31  20]
 [ 10 917   1   3   1   1   6   1  15  45]
 [ 65   4 686  35  68  53  53  22   6   8]
 [ 35   7  54 707  63 236  42  31  11  14]
 [ 16   2  28  36 827  26  23  36   4   2]
 [ 14   1  37 181  32 471  15  41   6   2]
 [ 19   2  26  41  27  19 853   5   6   2]
 [ 26   1  10  37  46  38   6 830   2   4]
 [ 56  14   4   4   6   6   2   4 883  21]
 [ 26  44   4   9   2   3   3  12  16 881]]
2025-02-25T19:45:00.163248+0300 | DEBUG | Class precision: [0.76329787 0.917      0.7760181  0.66136576 0.76432532 0.54767442
 0.84707051 0.83753784 0.90102041 0.88188188]
2025-02-25T19:45:00.165305+0300 | DEBUG | Class recall: [0.861      0.917      0.686      0.58916667 0.827      0.58875
 0.853      0.83       0.883      0.881     ]
2025-02-25T19:45:00.228468+0300 | INFO | Training epoch #169 on client #0
2025-02-25T19:45:00.229787+0300 | DEBUG | Saving model to flat file storage. Save #169
2025-02-25T19:45:00.405427+0300 | INFO | [169,     0] loss: 0.016
2025-02-25T19:45:12.643004+0300 | INFO | [169,   100] loss: 1.487
2025-02-25T19:45:26.972052+0300 | INFO | [169,   200] loss: 1.488
2025-02-25T19:45:38.841312+0300 | INFO | [169,   300] loss: 1.482
2025-02-25T19:45:53.121287+0300 | INFO | [169,   400] loss: 1.487
2025-02-25T19:46:05.794451+0300 | INFO | [169,   500] loss: 1.484
2025-02-25T19:46:19.284399+0300 | INFO | [169,   600] loss: 1.487
2025-02-25T19:46:32.409615+0300 | INFO | [169,   700] loss: 1.503
2025-02-25T19:46:46.228681+0300 | INFO | [169,   800] loss: 1.486
2025-02-25T19:47:02.474949+0300 | INFO | [169,   900] loss: 1.492
2025-02-25T19:47:16.072153+0300 | INFO | [169,  1000] loss: 1.484
2025-02-25T19:47:28.765739+0300 | INFO | [169,  1100] loss: 1.488
2025-02-25T19:47:41.422821+0300 | INFO | [169,  1200] loss: 1.490
2025-02-25T19:47:56.486054+0300 | INFO | [169,  1300] loss: 1.487
2025-02-25T19:48:09.611924+0300 | INFO | [169,  1400] loss: 1.492
2025-02-25T19:48:23.232428+0300 | INFO | [169,  1500] loss: 1.500
2025-02-25T19:48:37.182776+0300 | INFO | [169,  1600] loss: 1.497
2025-02-25T19:48:52.415360+0300 | INFO | [169,  1700] loss: 1.482
2025-02-25T19:49:05.757965+0300 | INFO | [169,  1800] loss: 1.487
2025-02-25T19:49:19.844538+0300 | INFO | [169,  1900] loss: 1.478
2025-02-25T19:49:32.744467+0300 | INFO | [169,  2000] loss: 1.477
2025-02-25T19:49:45.583930+0300 | INFO | [169,  2100] loss: 1.482
2025-02-25T19:49:58.376747+0300 | INFO | [169,  2200] loss: 1.487
2025-02-25T19:50:12.363577+0300 | INFO | [169,  2300] loss: 1.486
2025-02-25T19:50:26.754665+0300 | INFO | [169,  2400] loss: 1.486
2025-02-25T19:50:41.974113+0300 | INFO | [169,  2500] loss: 1.484
2025-02-25T19:50:57.377236+0300 | INFO | [169,  2600] loss: 1.486
2025-02-25T19:51:14.529861+0300 | INFO | [169,  2700] loss: 1.482
2025-02-25T19:51:33.320686+0300 | INFO | [169,  2800] loss: 1.487
2025-02-25T19:51:47.630882+0300 | INFO | [169,  2900] loss: 1.491
2025-02-25T19:52:04.029678+0300 | INFO | [169,  3000] loss: 1.486
2025-02-25T19:52:18.328784+0300 | INFO | [169,  3100] loss: 1.495
2025-02-25T19:52:33.402390+0300 | INFO | [169,  3200] loss: 1.495
2025-02-25T19:52:48.126682+0300 | INFO | [169,  3300] loss: 1.489
2025-02-25T19:53:03.005558+0300 | INFO | [169,  3400] loss: 1.500
2025-02-25T19:53:18.938966+0300 | INFO | [169,  3500] loss: 1.492
2025-02-25T19:53:35.049630+0300 | INFO | [169,  3600] loss: 1.488
2025-02-25T19:53:51.052380+0300 | INFO | [169,  3700] loss: 1.489
2025-02-25T19:54:05.738071+0300 | INFO | [169,  3800] loss: 1.492
2025-02-25T19:54:19.772930+0300 | INFO | [169,  3900] loss: 1.492
2025-02-25T19:54:33.758291+0300 | INFO | [169,  4000] loss: 1.491
2025-02-25T19:54:48.113952+0300 | INFO | [169,  4100] loss: 1.502
2025-02-25T19:55:02.386607+0300 | INFO | [169,  4200] loss: 1.501
2025-02-25T19:55:18.001904+0300 | INFO | [169,  4300] loss: 1.484
2025-02-25T19:55:34.692311+0300 | INFO | [169,  4400] loss: 1.483
2025-02-25T19:55:48.829769+0300 | INFO | [169,  4500] loss: 1.489
2025-02-25T19:56:03.023331+0300 | INFO | [169,  4600] loss: 1.493
2025-02-25T19:56:16.082174+0300 | INFO | [169,  4700] loss: 1.495
2025-02-25T19:56:29.164565+0300 | INFO | [169,  4800] loss: 1.498
2025-02-25T19:56:44.344538+0300 | INFO | [169,  4900] loss: 1.489
2025-02-25T19:56:57.744144+0300 | DEBUG | Saving model to flat file storage. Save #169
2025-02-25T19:56:57.775581+0300 | INFO | Averaging client parameters
2025-02-25T19:56:57.787666+0300 | INFO | Updating parameters on client #0
2025-02-25T19:57:17.563724+0300 | DEBUG | Test set: Accuracy: 7916/10000 (79%)
2025-02-25T19:57:17.564740+0300 | DEBUG | Test set: Loss: 1.669371485710144
2025-02-25T19:57:17.678086+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.76      0.70      0.73      1000
           3       0.64      0.59      0.61      1200
           4       0.80      0.80      0.80      1000
           5       0.53      0.60      0.56       800
           6       0.85      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T19:57:17.679782+0300 | DEBUG | Confusion Matrix:
[[850  12  35  18   7   9   4   7  36  22]
 [  5 913   1   3   1   1   5   1  19  51]
 [ 54   5 699  48  49  61  50  17   6  11]
 [ 29   6  58 703  47 252  42  30  16  17]
 [ 14   2  37  50 800  29  27  34   5   2]
 [ 12   1  42 187  23 478  13  34   6   4]
 [ 13   2  32  41  23  18 859   3   7   2]
 [ 23   1  13  34  43  52   4 825   2   3]
 [ 44  14   3   6   5   7   2   2 893  24]
 [ 19  44   4   7   2   2   4   9  13 896]]
2025-02-25T19:57:17.681336+0300 | DEBUG | Class precision: [0.79962371 0.913      0.75649351 0.64083865 0.8        0.52585259
 0.85049505 0.85758836 0.89032901 0.86821705]
2025-02-25T19:57:17.683787+0300 | DEBUG | Class recall: [0.85       0.913      0.699      0.58583333 0.8        0.5975
 0.859      0.825      0.893      0.896     ]
2025-02-25T19:57:17.743723+0300 | INFO | Training epoch #170 on client #0
2025-02-25T19:57:17.745749+0300 | DEBUG | Saving model to flat file storage. Save #170
2025-02-25T19:57:17.918308+0300 | INFO | [170,     0] loss: 0.015
2025-02-25T19:57:30.493666+0300 | INFO | [170,   100] loss: 1.487
2025-02-25T19:57:45.128470+0300 | INFO | [170,   200] loss: 1.483
2025-02-25T19:58:00.390677+0300 | INFO | [170,   300] loss: 1.491
2025-02-25T19:58:13.986772+0300 | INFO | [170,   400] loss: 1.493
2025-02-25T19:58:27.048169+0300 | INFO | [170,   500] loss: 1.492
2025-02-25T19:58:40.533561+0300 | INFO | [170,   600] loss: 1.495
2025-02-25T19:58:54.779229+0300 | INFO | [170,   700] loss: 1.488
2025-02-25T19:59:08.091055+0300 | INFO | [170,   800] loss: 1.479
2025-02-25T19:59:20.235950+0300 | INFO | [170,   900] loss: 1.487
2025-02-25T19:59:33.231840+0300 | INFO | [170,  1000] loss: 1.491
2025-02-25T19:59:47.107495+0300 | INFO | [170,  1100] loss: 1.488
2025-02-25T20:00:00.684834+0300 | INFO | [170,  1200] loss: 1.499
2025-02-25T20:00:15.770482+0300 | INFO | [170,  1300] loss: 1.498
2025-02-25T20:00:29.109940+0300 | INFO | [170,  1400] loss: 1.486
2025-02-25T20:00:45.312136+0300 | INFO | [170,  1500] loss: 1.494
2025-02-25T20:00:58.355772+0300 | INFO | [170,  1600] loss: 1.485
2025-02-25T20:01:11.324872+0300 | INFO | [170,  1700] loss: 1.492
2025-02-25T20:01:24.274113+0300 | INFO | [170,  1800] loss: 1.485
2025-02-25T20:01:36.740898+0300 | INFO | [170,  1900] loss: 1.500
2025-02-25T20:01:53.129247+0300 | INFO | [170,  2000] loss: 1.480
2025-02-25T20:02:05.673551+0300 | INFO | [170,  2100] loss: 1.496
2025-02-25T20:02:23.036726+0300 | INFO | [170,  2200] loss: 1.485
2025-02-25T20:02:35.790311+0300 | INFO | [170,  2300] loss: 1.494
2025-02-25T20:02:48.060703+0300 | INFO | [170,  2400] loss: 1.491
2025-02-25T20:03:00.657004+0300 | INFO | [170,  2500] loss: 1.479
2025-02-25T20:03:14.262686+0300 | INFO | [170,  2600] loss: 1.489
2025-02-25T20:03:27.392180+0300 | INFO | [170,  2700] loss: 1.494
2025-02-25T20:03:40.787469+0300 | INFO | [170,  2800] loss: 1.483
2025-02-25T20:03:53.918048+0300 | INFO | [170,  2900] loss: 1.493
2025-02-25T20:04:07.028193+0300 | INFO | [170,  3000] loss: 1.490
2025-02-25T20:04:16.852286+0300 | INFO | [170,  3100] loss: 1.485
2025-02-25T20:04:27.969911+0300 | INFO | [170,  3200] loss: 1.488
2025-02-25T20:04:43.461713+0300 | INFO | [170,  3300] loss: 1.487
2025-02-25T20:04:56.864594+0300 | INFO | [170,  3400] loss: 1.494
2025-02-25T20:05:09.607318+0300 | INFO | [170,  3500] loss: 1.488
2025-02-25T20:05:22.214355+0300 | INFO | [170,  3600] loss: 1.484
2025-02-25T20:05:36.368134+0300 | INFO | [170,  3700] loss: 1.491
2025-02-25T20:05:51.503129+0300 | INFO | [170,  3800] loss: 1.492
2025-02-25T20:06:05.914516+0300 | INFO | [170,  3900] loss: 1.487
2025-02-25T20:06:19.943158+0300 | INFO | [170,  4000] loss: 1.489
2025-02-25T20:06:33.100057+0300 | INFO | [170,  4100] loss: 1.483
2025-02-25T20:06:45.983312+0300 | INFO | [170,  4200] loss: 1.497
2025-02-25T20:06:58.518968+0300 | INFO | [170,  4300] loss: 1.493
2025-02-25T20:07:12.707738+0300 | INFO | [170,  4400] loss: 1.486
2025-02-25T20:07:25.934869+0300 | INFO | [170,  4500] loss: 1.488
2025-02-25T20:07:39.026277+0300 | INFO | [170,  4600] loss: 1.482
2025-02-25T20:07:51.412391+0300 | INFO | [170,  4700] loss: 1.493
2025-02-25T20:08:05.906998+0300 | INFO | [170,  4800] loss: 1.493
2025-02-25T20:08:20.482785+0300 | INFO | [170,  4900] loss: 1.489
2025-02-25T20:08:35.378289+0300 | DEBUG | Saving model to flat file storage. Save #170
2025-02-25T20:08:35.413178+0300 | INFO | Averaging client parameters
2025-02-25T20:08:35.427662+0300 | INFO | Updating parameters on client #0
2025-02-25T20:08:54.823798+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-25T20:08:54.823798+0300 | DEBUG | Test set: Loss: 1.6717560291290283
2025-02-25T20:08:54.943093+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.91      0.93      0.92      1000
           2       0.76      0.69      0.72      1000
           3       0.64      0.60      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.51      0.60      0.55       800
           6       0.84      0.86      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.90      0.89      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T20:08:54.945092+0300 | DEBUG | Confusion Matrix:
[[835  11  41  20  10  12   4   9  39  19]
 [  6 926   1   4   1   0   6   2  17  37]
 [ 53   3 687  44  61  64  57  17   6   8]
 [ 28   6  51 719  54 259  40  20  11  12]
 [ 13   2  34  48 813  30  26  27   5   2]
 [  9   1  37 190  31 481  13  31   4   3]
 [ 10   2  29  45  26  18 861   3   4   2]
 [ 21   1  13  41  51  61   6 800   2   4]
 [ 43  14   7   8   5   7   2   3 889  22]
 [ 27  53   6   9   3   3   5  11  16 867]]
2025-02-25T20:08:54.947037+0300 | DEBUG | Class precision: [0.79904306 0.90873405 0.75827815 0.63741135 0.77061611 0.5144385
 0.84411765 0.86673889 0.89526687 0.88831967]
2025-02-25T20:08:54.948052+0300 | DEBUG | Class recall: [0.835      0.926      0.687      0.59916667 0.813      0.60125
 0.861      0.8        0.889      0.867     ]
2025-02-25T20:08:54.953617+0300 | INFO | Training epoch #171 on client #0
2025-02-25T20:08:54.958273+0300 | DEBUG | Saving model to flat file storage. Save #171
2025-02-25T20:08:55.228484+0300 | INFO | [171,     0] loss: 0.015
2025-02-25T20:09:08.618550+0300 | INFO | [171,   100] loss: 1.481
2025-02-25T20:09:20.259478+0300 | INFO | [171,   200] loss: 1.493
2025-02-25T20:09:33.703497+0300 | INFO | [171,   300] loss: 1.485
2025-02-25T20:09:44.465497+0300 | INFO | [171,   400] loss: 1.487
2025-02-25T20:09:54.552718+0300 | INFO | [171,   500] loss: 1.484
2025-02-25T20:10:05.973577+0300 | INFO | [171,   600] loss: 1.484
2025-02-25T20:10:18.429234+0300 | INFO | [171,   700] loss: 1.481
2025-02-25T20:10:31.741825+0300 | INFO | [171,   800] loss: 1.491
2025-02-25T20:10:44.057238+0300 | INFO | [171,   900] loss: 1.482
2025-02-25T20:10:57.108561+0300 | INFO | [171,  1000] loss: 1.487
2025-02-25T20:11:11.153324+0300 | INFO | [171,  1100] loss: 1.479
2025-02-25T20:11:26.832458+0300 | INFO | [171,  1200] loss: 1.484
2025-02-25T20:11:40.850122+0300 | INFO | [171,  1300] loss: 1.492
2025-02-25T20:11:55.203828+0300 | INFO | [171,  1400] loss: 1.496
2025-02-25T20:12:09.466828+0300 | INFO | [171,  1500] loss: 1.492
2025-02-25T20:12:22.781711+0300 | INFO | [171,  1600] loss: 1.491
2025-02-25T20:12:39.910745+0300 | INFO | [171,  1700] loss: 1.489
2025-02-25T20:12:54.978861+0300 | INFO | [171,  1800] loss: 1.496
2025-02-25T20:13:09.887253+0300 | INFO | [171,  1900] loss: 1.487
2025-02-25T20:13:22.733994+0300 | INFO | [171,  2000] loss: 1.493
2025-02-25T20:13:34.458993+0300 | INFO | [171,  2100] loss: 1.500
2025-02-25T20:13:46.741455+0300 | INFO | [171,  2200] loss: 1.484
2025-02-25T20:14:00.218363+0300 | INFO | [171,  2300] loss: 1.496
2025-02-25T20:14:11.418380+0300 | INFO | [171,  2400] loss: 1.489
2025-02-25T20:14:24.550607+0300 | INFO | [171,  2500] loss: 1.492
2025-02-25T20:14:40.859822+0300 | INFO | [171,  2600] loss: 1.480
2025-02-25T20:14:54.022795+0300 | INFO | [171,  2700] loss: 1.493
2025-02-25T20:15:07.259807+0300 | INFO | [171,  2800] loss: 1.484
2025-02-25T20:15:19.534665+0300 | INFO | [171,  2900] loss: 1.489
2025-02-25T20:15:35.211567+0300 | INFO | [171,  3000] loss: 1.491
2025-02-25T20:15:47.866820+0300 | INFO | [171,  3100] loss: 1.493
2025-02-25T20:16:00.131877+0300 | INFO | [171,  3200] loss: 1.492
2025-02-25T20:16:13.597790+0300 | INFO | [171,  3300] loss: 1.492
2025-02-25T20:16:27.368122+0300 | INFO | [171,  3400] loss: 1.485
2025-02-25T20:16:40.302415+0300 | INFO | [171,  3500] loss: 1.488
2025-02-25T20:16:52.185615+0300 | INFO | [171,  3600] loss: 1.496
2025-02-25T20:17:03.831471+0300 | INFO | [171,  3700] loss: 1.496
2025-02-25T20:17:16.756107+0300 | INFO | [171,  3800] loss: 1.491
2025-02-25T20:17:29.745658+0300 | INFO | [171,  3900] loss: 1.489
2025-02-25T20:17:41.902616+0300 | INFO | [171,  4000] loss: 1.492
2025-02-25T20:17:54.189884+0300 | INFO | [171,  4100] loss: 1.489
2025-02-25T20:18:06.254785+0300 | INFO | [171,  4200] loss: 1.497
2025-02-25T20:18:18.648784+0300 | INFO | [171,  4300] loss: 1.487
2025-02-25T20:18:29.981862+0300 | INFO | [171,  4400] loss: 1.485
2025-02-25T20:18:43.772845+0300 | INFO | [171,  4500] loss: 1.492
2025-02-25T20:18:55.204837+0300 | INFO | [171,  4600] loss: 1.490
2025-02-25T20:19:08.692640+0300 | INFO | [171,  4700] loss: 1.488
2025-02-25T20:19:22.042804+0300 | INFO | [171,  4800] loss: 1.496
2025-02-25T20:19:34.515931+0300 | INFO | [171,  4900] loss: 1.480
2025-02-25T20:19:46.985069+0300 | DEBUG | Saving model to flat file storage. Save #171
2025-02-25T20:19:47.020701+0300 | INFO | Averaging client parameters
2025-02-25T20:19:47.033852+0300 | INFO | Updating parameters on client #0
2025-02-25T20:20:07.266146+0300 | DEBUG | Test set: Accuracy: 7896/10000 (79%)
2025-02-25T20:20:07.267356+0300 | DEBUG | Test set: Loss: 1.6710795164108276
2025-02-25T20:20:07.391584+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.65      0.58      0.61      1200
           4       0.79      0.81      0.80      1000
           5       0.51      0.60      0.55       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T20:20:07.394602+0300 | DEBUG | Confusion Matrix:
[[847  12  42  13   9  10   4   8  33  22]
 [  7 929   1   3   0   0   4   1  15  40]
 [ 54   6 691  39  58  64  58  15   7   8]
 [ 28   8  51 693  49 270  49  27  13  12]
 [ 14   2  35  45 809  31  27  32   4   1]
 [ 13   1  39 183  27 483  13  35   5   1]
 [ 13   2  27  42  24  19 863   3   6   1]
 [ 19   1  14  41  42  53   5 821   2   2]
 [ 48  16   6   6   3   8   2   3 885  23]
 [ 20  56   5   8   2   6   3  10  15 875]]
2025-02-25T20:20:07.395601+0300 | DEBUG | Class precision: [0.79680151 0.89932236 0.75850714 0.64585275 0.79081134 0.51165254
 0.83949416 0.85968586 0.89847716 0.88832487]
2025-02-25T20:20:07.397508+0300 | DEBUG | Class recall: [0.847   0.929   0.691   0.5775  0.809   0.60375 0.863   0.821   0.885
 0.875  ]
2025-02-25T20:20:07.398526+0300 | INFO | Training epoch #172 on client #0
2025-02-25T20:20:07.401792+0300 | DEBUG | Saving model to flat file storage. Save #172
2025-02-25T20:20:07.626551+0300 | INFO | [172,     0] loss: 0.015
2025-02-25T20:20:20.907054+0300 | INFO | [172,   100] loss: 1.493
2025-02-25T20:20:34.146220+0300 | INFO | [172,   200] loss: 1.492
2025-02-25T20:20:49.193060+0300 | INFO | [172,   300] loss: 1.493
2025-02-25T20:21:02.981836+0300 | INFO | [172,   400] loss: 1.491
2025-02-25T20:21:16.125256+0300 | INFO | [172,   500] loss: 1.491
2025-02-25T20:21:28.854790+0300 | INFO | [172,   600] loss: 1.486
2025-02-25T20:21:44.291552+0300 | INFO | [172,   700] loss: 1.484
2025-02-25T20:21:59.309888+0300 | INFO | [172,   800] loss: 1.486
2025-02-25T20:22:12.471795+0300 | INFO | [172,   900] loss: 1.488
2025-02-25T20:22:24.803285+0300 | INFO | [172,  1000] loss: 1.487
2025-02-25T20:22:38.313614+0300 | INFO | [172,  1100] loss: 1.487
2025-02-25T20:22:50.799379+0300 | INFO | [172,  1200] loss: 1.489
2025-02-25T20:23:10.193465+0300 | INFO | [172,  1300] loss: 1.488
2025-02-25T20:23:24.903457+0300 | INFO | [172,  1400] loss: 1.494
2025-02-25T20:23:37.869217+0300 | INFO | [172,  1500] loss: 1.498
2025-02-25T20:23:52.808890+0300 | INFO | [172,  1600] loss: 1.493
2025-02-25T20:24:07.424279+0300 | INFO | [172,  1700] loss: 1.496
2025-02-25T20:24:21.143897+0300 | INFO | [172,  1800] loss: 1.492
2025-02-25T20:24:33.966136+0300 | INFO | [172,  1900] loss: 1.495
2025-02-25T20:24:46.517241+0300 | INFO | [172,  2000] loss: 1.483
2025-02-25T20:24:59.057855+0300 | INFO | [172,  2100] loss: 1.495
2025-02-25T20:25:12.312484+0300 | INFO | [172,  2200] loss: 1.497
2025-02-25T20:25:25.923863+0300 | INFO | [172,  2300] loss: 1.494
2025-02-25T20:25:38.781320+0300 | INFO | [172,  2400] loss: 1.487
2025-02-25T20:25:52.005826+0300 | INFO | [172,  2500] loss: 1.486
2025-02-25T20:26:05.252807+0300 | INFO | [172,  2600] loss: 1.487
2025-02-25T20:26:17.818775+0300 | INFO | [172,  2700] loss: 1.486
2025-02-25T20:26:30.492446+0300 | INFO | [172,  2800] loss: 1.489
2025-02-25T20:26:42.906962+0300 | INFO | [172,  2900] loss: 1.490
2025-02-25T20:26:55.302537+0300 | INFO | [172,  3000] loss: 1.497
2025-02-25T20:27:08.149114+0300 | INFO | [172,  3100] loss: 1.496
2025-02-25T20:27:23.207760+0300 | INFO | [172,  3200] loss: 1.484
2025-02-25T20:27:35.990726+0300 | INFO | [172,  3300] loss: 1.493
2025-02-25T20:27:48.315302+0300 | INFO | [172,  3400] loss: 1.487
2025-02-25T20:28:00.675086+0300 | INFO | [172,  3500] loss: 1.479
2025-02-25T20:28:13.524201+0300 | INFO | [172,  3600] loss: 1.498
2025-02-25T20:28:27.846010+0300 | INFO | [172,  3700] loss: 1.489
2025-02-25T20:28:39.882541+0300 | INFO | [172,  3800] loss: 1.487
2025-02-25T20:28:51.408654+0300 | INFO | [172,  3900] loss: 1.490
2025-02-25T20:29:03.087164+0300 | INFO | [172,  4000] loss: 1.489
2025-02-25T20:29:16.212061+0300 | INFO | [172,  4100] loss: 1.491
2025-02-25T20:29:28.793037+0300 | INFO | [172,  4200] loss: 1.488
2025-02-25T20:29:40.587996+0300 | INFO | [172,  4300] loss: 1.491
2025-02-25T20:29:52.274930+0300 | INFO | [172,  4400] loss: 1.482
2025-02-25T20:30:04.549864+0300 | INFO | [172,  4500] loss: 1.488
2025-02-25T20:30:16.406476+0300 | INFO | [172,  4600] loss: 1.483
2025-02-25T20:30:27.856532+0300 | INFO | [172,  4700] loss: 1.480
2025-02-25T20:30:39.527979+0300 | INFO | [172,  4800] loss: 1.483
2025-02-25T20:30:51.412321+0300 | INFO | [172,  4900] loss: 1.488
2025-02-25T20:31:03.769707+0300 | DEBUG | Saving model to flat file storage. Save #172
2025-02-25T20:31:03.801641+0300 | INFO | Averaging client parameters
2025-02-25T20:31:03.810245+0300 | INFO | Updating parameters on client #0
2025-02-25T20:31:24.060104+0300 | DEBUG | Test set: Accuracy: 7897/10000 (79%)
2025-02-25T20:31:24.062578+0300 | DEBUG | Test set: Loss: 1.669585108757019
2025-02-25T20:31:24.183108+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.63      0.60      0.62      1200
           4       0.78      0.81      0.80      1000
           5       0.53      0.57      0.55       800
           6       0.86      0.85      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T20:31:24.187083+0300 | DEBUG | Confusion Matrix:
[[837   7  46  19  10   8   5   8  35  25]
 [  7 907   0   4   1   0   8   1  15  57]
 [ 51   3 706  46  57  58  45  17   7  10]
 [ 29   6  56 722  53 234  41  31  11  17]
 [ 13   2  32  46 814  27  24  35   6   1]
 [ 11   1  38 207  29 453  12  38   4   7]
 [ 12   1  32  47  29  19 846   5   6   3]
 [ 23   1  15  40  41  41   3 830   2   4]
 [ 45  14   8   6   4   7   2   4 886  24]
 [ 19  43   4   8   3   3   2   8  14 896]]
2025-02-25T20:31:24.188579+0300 | DEBUG | Class precision: [0.79942693 0.92081218 0.75346852 0.63056769 0.78194044 0.53294118
 0.8562753  0.84953941 0.89858012 0.85823755]
2025-02-25T20:31:24.191208+0300 | DEBUG | Class recall: [0.837      0.907      0.706      0.60166667 0.814      0.56625
 0.846      0.83       0.886      0.896     ]
2025-02-25T20:31:24.239639+0300 | INFO | Training epoch #173 on client #0
2025-02-25T20:31:24.242642+0300 | DEBUG | Saving model to flat file storage. Save #173
2025-02-25T20:31:24.397348+0300 | INFO | [173,     0] loss: 0.015
2025-02-25T20:31:38.830237+0300 | INFO | [173,   100] loss: 1.481
2025-02-25T20:31:50.969443+0300 | INFO | [173,   200] loss: 1.492
2025-02-25T20:32:02.728216+0300 | INFO | [173,   300] loss: 1.486
2025-02-25T20:32:14.461277+0300 | INFO | [173,   400] loss: 1.493
2025-02-25T20:32:26.814406+0300 | INFO | [173,   500] loss: 1.485
2025-02-25T20:32:38.601693+0300 | INFO | [173,   600] loss: 1.490
2025-02-25T20:32:52.684376+0300 | INFO | [173,   700] loss: 1.496
2025-02-25T20:33:08.586905+0300 | INFO | [173,   800] loss: 1.494
2025-02-25T20:33:19.872481+0300 | INFO | [173,   900] loss: 1.487
2025-02-25T20:33:32.384444+0300 | INFO | [173,  1000] loss: 1.481
2025-02-25T20:33:46.422033+0300 | INFO | [173,  1100] loss: 1.485
2025-02-25T20:33:58.610406+0300 | INFO | [173,  1200] loss: 1.489
2025-02-25T20:34:10.200335+0300 | INFO | [173,  1300] loss: 1.487
2025-02-25T20:34:21.901948+0300 | INFO | [173,  1400] loss: 1.489
2025-02-25T20:34:34.011318+0300 | INFO | [173,  1500] loss: 1.483
2025-02-25T20:34:49.489050+0300 | INFO | [173,  1600] loss: 1.482
2025-02-25T20:35:09.525599+0300 | INFO | [173,  1700] loss: 1.493
2025-02-25T20:35:27.182124+0300 | INFO | [173,  1800] loss: 1.485
2025-02-25T20:35:43.482970+0300 | INFO | [173,  1900] loss: 1.498
2025-02-25T20:35:57.509400+0300 | INFO | [173,  2000] loss: 1.494
2025-02-25T20:36:10.496585+0300 | INFO | [173,  2100] loss: 1.489
2025-02-25T20:36:23.496583+0300 | INFO | [173,  2200] loss: 1.488
2025-02-25T20:36:37.074138+0300 | INFO | [173,  2300] loss: 1.496
2025-02-25T20:36:51.564711+0300 | INFO | [173,  2400] loss: 1.497
2025-02-25T20:37:05.725699+0300 | INFO | [173,  2500] loss: 1.494
2025-02-25T20:37:19.802637+0300 | INFO | [173,  2600] loss: 1.485
2025-02-25T20:37:32.392743+0300 | INFO | [173,  2700] loss: 1.487
2025-02-25T20:37:44.676417+0300 | INFO | [173,  2800] loss: 1.495
2025-02-25T20:37:56.219784+0300 | INFO | [173,  2900] loss: 1.496
2025-02-25T20:38:09.166998+0300 | INFO | [173,  3000] loss: 1.487
2025-02-25T20:38:22.226500+0300 | INFO | [173,  3100] loss: 1.485
2025-02-25T20:38:36.774464+0300 | INFO | [173,  3200] loss: 1.494
2025-02-25T20:38:49.965433+0300 | INFO | [173,  3300] loss: 1.490
2025-02-25T20:39:01.550292+0300 | INFO | [173,  3400] loss: 1.484
2025-02-25T20:39:11.511017+0300 | INFO | [173,  3500] loss: 1.486
2025-02-25T20:39:22.005146+0300 | INFO | [173,  3600] loss: 1.486
2025-02-25T20:39:34.089616+0300 | INFO | [173,  3700] loss: 1.490
2025-02-25T20:39:51.675308+0300 | INFO | [173,  3800] loss: 1.482
2025-02-25T20:40:08.953416+0300 | INFO | [173,  3900] loss: 1.494
2025-02-25T20:40:20.092032+0300 | INFO | [173,  4000] loss: 1.490
2025-02-25T20:40:29.967421+0300 | INFO | [173,  4100] loss: 1.494
2025-02-25T20:40:41.762076+0300 | INFO | [173,  4200] loss: 1.486
2025-02-25T20:40:53.436675+0300 | INFO | [173,  4300] loss: 1.487
2025-02-25T20:41:05.642615+0300 | INFO | [173,  4400] loss: 1.480
2025-02-25T20:41:17.397512+0300 | INFO | [173,  4500] loss: 1.494
2025-02-25T20:41:29.045489+0300 | INFO | [173,  4600] loss: 1.496
2025-02-25T20:41:41.769001+0300 | INFO | [173,  4700] loss: 1.486
2025-02-25T20:41:54.337044+0300 | INFO | [173,  4800] loss: 1.490
2025-02-25T20:42:08.022258+0300 | INFO | [173,  4900] loss: 1.489
2025-02-25T20:42:22.454094+0300 | DEBUG | Saving model to flat file storage. Save #173
2025-02-25T20:42:22.481448+0300 | INFO | Averaging client parameters
2025-02-25T20:42:22.493859+0300 | INFO | Updating parameters on client #0
2025-02-25T20:42:39.415583+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-25T20:42:39.416602+0300 | DEBUG | Test set: Loss: 1.6725293397903442
2025-02-25T20:42:39.514016+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.91      0.92      0.91      1000
           2       0.78      0.66      0.72      1000
           3       0.64      0.60      0.62      1200
           4       0.80      0.80      0.80      1000
           5       0.51      0.65      0.57       800
           6       0.82      0.88      0.85      1000
           7       0.88      0.78      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T20:42:39.517300+0300 | DEBUG | Confusion Matrix:
[[834  10  38  24   9  12   6   6  38  23]
 [  6 915   1   5   0   0   9   1  19  44]
 [ 55   5 662  50  56  75  67  14   8   8]
 [ 25   7  41 717  44 269  51  19  13  14]
 [ 14   2  29  51 799  38  36  24   6   1]
 [ 11   1  27 174  20 518  17  26   4   2]
 [  7   2  23  48  16  19 877   2   4   2]
 [ 21   1  11  44  48  76   6 783   3   7]
 [ 46  12   7   7   4   8   2   2 894  18]
 [ 20  50   5   9   2   5   4   9  17 879]]
2025-02-25T20:42:39.519306+0300 | DEBUG | Class precision: [0.8026949  0.91044776 0.78436019 0.63507529 0.8006012  0.50784314
 0.81581395 0.88374718 0.88866799 0.88076152]
2025-02-25T20:42:39.520300+0300 | DEBUG | Class recall: [0.834  0.915  0.662  0.5975 0.799  0.6475 0.877  0.783  0.894  0.879 ]
2025-02-25T20:42:39.567655+0300 | INFO | Training epoch #174 on client #0
2025-02-25T20:42:39.570088+0300 | DEBUG | Saving model to flat file storage. Save #174
2025-02-25T20:42:39.702765+0300 | INFO | [174,     0] loss: 0.015
2025-02-25T20:42:53.113986+0300 | INFO | [174,   100] loss: 1.481
2025-02-25T20:43:53.043868+0300 | INFO | [174,   200] loss: 1.488
2025-02-25T20:44:39.828858+0300 | INFO | [174,   300] loss: 1.489
2025-02-25T20:45:37.636117+0300 | INFO | [174,   400] loss: 1.488
2025-02-25T20:46:44.428791+0300 | INFO | [174,   500] loss: 1.489
2025-02-25T20:47:34.728311+0300 | INFO | [174,   600] loss: 1.481
2025-02-25T20:48:24.036598+0300 | INFO | [174,   700] loss: 1.495
2025-02-25T20:49:13.114242+0300 | INFO | [174,   800] loss: 1.487
2025-02-25T20:50:01.976118+0300 | INFO | [174,   900] loss: 1.497
2025-02-25T20:50:49.950865+0300 | INFO | [174,  1000] loss: 1.484
2025-02-25T20:51:40.710732+0300 | INFO | [174,  1100] loss: 1.492
2025-02-25T20:52:27.532076+0300 | INFO | [174,  1200] loss: 1.490
2025-02-25T20:53:17.774190+0300 | INFO | [174,  1300] loss: 1.483
2025-02-25T20:54:05.157108+0300 | INFO | [174,  1400] loss: 1.491
2025-02-25T20:54:57.449731+0300 | INFO | [174,  1500] loss: 1.486
2025-02-25T20:55:52.127134+0300 | INFO | [174,  1600] loss: 1.494
2025-02-25T20:56:46.567204+0300 | INFO | [174,  1700] loss: 1.485
2025-02-25T20:57:42.492507+0300 | INFO | [174,  1800] loss: 1.486
2025-02-25T20:58:38.422426+0300 | INFO | [174,  1900] loss: 1.480
2025-02-25T20:59:33.955358+0300 | INFO | [174,  2000] loss: 1.489
2025-02-25T21:00:28.591006+0300 | INFO | [174,  2100] loss: 1.493
2025-02-25T21:01:28.463089+0300 | INFO | [174,  2200] loss: 1.495
2025-02-25T21:02:23.197828+0300 | INFO | [174,  2300] loss: 1.495
2025-02-25T21:03:22.797065+0300 | INFO | [174,  2400] loss: 1.486
2025-02-25T21:04:12.180908+0300 | INFO | [174,  2500] loss: 1.487
2025-02-25T21:05:00.651278+0300 | INFO | [174,  2600] loss: 1.488
2025-02-25T21:05:49.586317+0300 | INFO | [174,  2700] loss: 1.491
2025-02-25T21:06:39.197507+0300 | INFO | [174,  2800] loss: 1.494
2025-02-25T21:07:27.820264+0300 | INFO | [174,  2900] loss: 1.488
2025-02-25T21:08:19.337593+0300 | INFO | [174,  3000] loss: 1.497
2025-02-25T21:09:06.824142+0300 | INFO | [174,  3100] loss: 1.493
2025-02-25T21:09:56.891761+0300 | INFO | [174,  3200] loss: 1.492
2025-02-25T21:10:50.006579+0300 | INFO | [174,  3300] loss: 1.495
2025-02-25T21:11:37.256658+0300 | INFO | [174,  3400] loss: 1.495
2025-02-25T21:12:22.789473+0300 | INFO | [174,  3500] loss: 1.488
2025-02-25T21:13:11.259247+0300 | INFO | [174,  3600] loss: 1.486
2025-02-25T21:13:58.008851+0300 | INFO | [174,  3700] loss: 1.486
2025-02-25T21:14:44.626409+0300 | INFO | [174,  3800] loss: 1.486
2025-02-25T21:15:34.434163+0300 | INFO | [174,  3900] loss: 1.488
2025-02-25T21:16:20.367855+0300 | INFO | [174,  4000] loss: 1.482
2025-02-25T21:17:06.313356+0300 | INFO | [174,  4100] loss: 1.487
2025-02-25T21:17:52.225995+0300 | INFO | [174,  4200] loss: 1.486
2025-02-25T21:18:39.196787+0300 | INFO | [174,  4300] loss: 1.499
2025-02-25T21:19:25.940400+0300 | INFO | [174,  4400] loss: 1.497
2025-02-25T21:20:11.749667+0300 | INFO | [174,  4500] loss: 1.488
2025-02-25T21:20:58.561674+0300 | INFO | [174,  4600] loss: 1.482
2025-02-25T21:21:45.103786+0300 | INFO | [174,  4700] loss: 1.495
2025-02-25T21:22:31.746204+0300 | INFO | [174,  4800] loss: 1.500
2025-02-25T21:23:45.438069+0300 | INFO | [174,  4900] loss: 1.481
2025-02-25T21:24:30.992930+0300 | DEBUG | Saving model to flat file storage. Save #174
2025-02-25T21:24:31.020248+0300 | INFO | Averaging client parameters
2025-02-25T21:24:31.086831+0300 | INFO | Updating parameters on client #0
2025-02-25T21:25:20.855721+0300 | DEBUG | Test set: Accuracy: 7890/10000 (79%)
2025-02-25T21:25:20.860625+0300 | DEBUG | Test set: Loss: 1.671270728111267
2025-02-25T21:25:21.011410+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.64      0.61      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.51      0.60      0.55       800
           6       0.84      0.86      0.85      1000
           7       0.87      0.80      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T21:25:21.014414+0300 | DEBUG | Confusion Matrix:
[[846  13  40  18   8   9   4   5  36  21]
 [  6 922   1   5   1   0   8   1  17  39]
 [ 56   6 693  47  54  61  53  17   7   6]
 [ 29   5  48 729  47 252  45  19  14  12]
 [ 16   2  33  54 794  33  29  31   7   1]
 [ 13   2  37 192  26 477  13  33   5   2]
 [ 11   2  25  49  21  20 864   2   5   1]
 [ 23   1  14  37  46  63   5 804   4   3]
 [ 49  15   4   6   3   8   2   2 894  17]
 [ 23  58   5   9   2   4   4   8  20 867]]
2025-02-25T21:25:21.017550+0300 | DEBUG | Class precision: [0.7891791  0.89863548 0.77       0.63612565 0.79241517 0.51456311
 0.8412853  0.87201735 0.88602577 0.89473684]
2025-02-25T21:25:21.019569+0300 | DEBUG | Class recall: [0.846   0.922   0.693   0.6075  0.794   0.59625 0.864   0.804   0.894
 0.867  ]
2025-02-25T21:25:21.023566+0300 | INFO | Training epoch #175 on client #0
2025-02-25T21:25:21.025566+0300 | DEBUG | Saving model to flat file storage. Save #175
2025-02-25T21:25:21.518916+0300 | INFO | [175,     0] loss: 0.015
2025-02-25T21:26:08.814135+0300 | INFO | [175,   100] loss: 1.495
2025-02-25T21:26:55.758462+0300 | INFO | [175,   200] loss: 1.493
2025-02-25T21:27:43.448220+0300 | INFO | [175,   300] loss: 1.489
2025-02-25T21:28:30.639940+0300 | INFO | [175,   400] loss: 1.483
2025-02-25T21:29:16.292939+0300 | INFO | [175,   500] loss: 1.491
2025-02-25T21:30:06.569168+0300 | INFO | [175,   600] loss: 1.490
2025-02-25T21:30:54.164043+0300 | INFO | [175,   700] loss: 1.487
2025-02-25T21:31:41.086083+0300 | INFO | [175,   800] loss: 1.488
2025-02-25T21:32:27.786480+0300 | INFO | [175,   900] loss: 1.482
2025-02-25T21:33:14.133733+0300 | INFO | [175,  1000] loss: 1.484
2025-02-25T21:34:03.033805+0300 | INFO | [175,  1100] loss: 1.487
2025-02-25T21:34:49.799097+0300 | INFO | [175,  1200] loss: 1.492
2025-02-25T21:35:36.073899+0300 | INFO | [175,  1300] loss: 1.502
2025-02-25T21:36:22.116626+0300 | INFO | [175,  1400] loss: 1.480
2025-02-25T21:37:08.208613+0300 | INFO | [175,  1500] loss: 1.493
2025-02-25T21:38:35.184938+0300 | INFO | [175,  1600] loss: 1.489
2025-02-25T21:39:43.519927+0300 | INFO | [175,  1700] loss: 1.491
2025-02-25T21:40:37.896748+0300 | INFO | [175,  1800] loss: 1.485
2025-02-25T21:41:34.633974+0300 | INFO | [175,  1900] loss: 1.491
2025-02-25T21:42:27.205176+0300 | INFO | [175,  2000] loss: 1.482
2025-02-25T21:43:24.830373+0300 | INFO | [175,  2100] loss: 1.488
2025-02-25T21:44:16.764611+0300 | INFO | [175,  2200] loss: 1.492
2025-02-25T21:45:13.289320+0300 | INFO | [175,  2300] loss: 1.489
2025-02-25T21:46:04.098155+0300 | INFO | [175,  2400] loss: 1.490
2025-02-25T21:46:54.859653+0300 | INFO | [175,  2500] loss: 1.488
2025-02-25T21:47:44.840283+0300 | INFO | [175,  2600] loss: 1.494
2025-02-25T21:48:35.466495+0300 | INFO | [175,  2700] loss: 1.488
2025-02-25T21:49:25.030917+0300 | INFO | [175,  2800] loss: 1.489
2025-02-25T21:50:17.899193+0300 | INFO | [175,  2900] loss: 1.482
2025-02-25T21:51:06.784915+0300 | INFO | [175,  3000] loss: 1.486
2025-02-25T21:51:59.009203+0300 | INFO | [175,  3100] loss: 1.491
2025-02-25T21:52:46.189620+0300 | INFO | [175,  3200] loss: 1.491
2025-02-25T21:53:36.925369+0300 | INFO | [175,  3300] loss: 1.490
2025-02-25T21:54:24.927875+0300 | INFO | [175,  3400] loss: 1.494
2025-02-25T21:55:14.855702+0300 | INFO | [175,  3500] loss: 1.499
2025-02-25T21:56:01.646418+0300 | INFO | [175,  3600] loss: 1.483
2025-02-25T21:56:51.118401+0300 | INFO | [175,  3700] loss: 1.488
2025-02-25T21:57:39.326971+0300 | INFO | [175,  3800] loss: 1.487
2025-02-25T21:58:29.351859+0300 | INFO | [175,  3900] loss: 1.492
2025-02-25T21:59:22.768875+0300 | INFO | [175,  4000] loss: 1.491
2025-02-25T22:00:10.835725+0300 | INFO | [175,  4100] loss: 1.483
2025-02-25T22:01:05.843648+0300 | INFO | [175,  4200] loss: 1.502
2025-02-25T22:02:14.333301+0300 | INFO | [175,  4300] loss: 1.491
2025-02-25T22:03:05.113263+0300 | INFO | [175,  4400] loss: 1.492
2025-02-25T22:04:02.992071+0300 | INFO | [175,  4500] loss: 1.485
2025-02-25T22:05:01.344312+0300 | INFO | [175,  4600] loss: 1.493
2025-02-25T22:06:01.517427+0300 | INFO | [175,  4700] loss: 1.488
2025-02-25T22:07:18.656003+0300 | INFO | [175,  4800] loss: 1.493
2025-02-25T22:08:27.323364+0300 | INFO | [175,  4900] loss: 1.480
2025-02-25T22:09:36.897036+0300 | DEBUG | Saving model to flat file storage. Save #175
2025-02-25T22:09:36.937037+0300 | INFO | Averaging client parameters
2025-02-25T22:09:36.949926+0300 | INFO | Updating parameters on client #0
2025-02-25T22:09:53.029394+0300 | DEBUG | Test set: Accuracy: 7908/10000 (79%)
2025-02-25T22:09:53.030388+0300 | DEBUG | Test set: Loss: 1.6699509620666504
2025-02-25T22:09:53.128987+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.76      0.69      0.73      1000
           3       0.65      0.58      0.62      1200
           4       0.78      0.81      0.80      1000
           5       0.52      0.63      0.57       800
           6       0.82      0.87      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T22:09:53.131962+0300 | DEBUG | Confusion Matrix:
[[837  14  39  17  12  13   4   8  33  23]
 [  8 928   0   5   0   0   7   1  11  40]
 [ 53   5 691  41  59  62  62  13   7   7]
 [ 25   7  54 696  53 265  51  24  10  15]
 [ 13   2  33  48 807  32  34  25   5   1]
 [ 12   2  35 166  28 505  16  31   3   2]
 [ 10   2  28  43  20  18 871   3   3   2]
 [ 19   1  13  34  45  66   6 810   2   4]
 [ 47  14   8   5   4   7   5   3 887  20]
 [ 22  55   5   8   2   4   5   8  15 876]]
2025-02-25T22:09:53.133021+0300 | DEBUG | Class precision: [0.8001912  0.90097087 0.76269316 0.65475071 0.78349515 0.51954733
 0.82092366 0.87473002 0.90881148 0.88484848]
2025-02-25T22:09:53.133977+0300 | DEBUG | Class recall: [0.837   0.928   0.691   0.58    0.807   0.63125 0.871   0.81    0.887
 0.876  ]
2025-02-25T22:09:53.183113+0300 | INFO | Training epoch #176 on client #0
2025-02-25T22:09:53.184735+0300 | DEBUG | Saving model to flat file storage. Save #176
2025-02-25T22:09:53.309613+0300 | INFO | [176,     0] loss: 0.015
2025-02-25T22:10:03.528243+0300 | INFO | [176,   100] loss: 1.489
2025-02-25T22:10:13.429379+0300 | INFO | [176,   200] loss: 1.491
2025-02-25T22:10:23.314621+0300 | INFO | [176,   300] loss: 1.491
2025-02-25T22:10:34.378494+0300 | INFO | [176,   400] loss: 1.484
2025-02-25T22:10:43.980120+0300 | INFO | [176,   500] loss: 1.482
2025-02-25T22:10:54.711594+0300 | INFO | [176,   600] loss: 1.484
2025-02-25T22:11:05.416302+0300 | INFO | [176,   700] loss: 1.494
2025-02-25T22:11:14.775321+0300 | INFO | [176,   800] loss: 1.484
2025-02-25T22:11:27.884339+0300 | INFO | [176,   900] loss: 1.489
2025-02-25T22:11:37.653436+0300 | INFO | [176,  1000] loss: 1.487
2025-02-25T22:11:46.798022+0300 | INFO | [176,  1100] loss: 1.495
2025-02-25T22:11:56.337196+0300 | INFO | [176,  1200] loss: 1.480
2025-02-25T22:12:09.124965+0300 | INFO | [176,  1300] loss: 1.487
2025-02-25T22:12:18.430757+0300 | INFO | [176,  1400] loss: 1.491
2025-02-25T22:12:27.750688+0300 | INFO | [176,  1500] loss: 1.492
2025-02-25T22:12:37.157510+0300 | INFO | [176,  1600] loss: 1.489
2025-02-25T22:12:46.613559+0300 | INFO | [176,  1700] loss: 1.493
2025-02-25T22:12:56.149780+0300 | INFO | [176,  1800] loss: 1.494
2025-02-25T22:13:05.294543+0300 | INFO | [176,  1900] loss: 1.499
2025-02-25T22:13:14.625511+0300 | INFO | [176,  2000] loss: 1.486
2025-02-25T22:13:26.467268+0300 | INFO | [176,  2100] loss: 1.491
2025-02-25T22:13:36.306582+0300 | INFO | [176,  2200] loss: 1.485
2025-02-25T22:13:46.167564+0300 | INFO | [176,  2300] loss: 1.491
2025-02-25T22:13:55.856784+0300 | INFO | [176,  2400] loss: 1.485
2025-02-25T22:14:05.354406+0300 | INFO | [176,  2500] loss: 1.485
2025-02-25T22:14:14.689199+0300 | INFO | [176,  2600] loss: 1.489
2025-02-25T22:14:24.411874+0300 | INFO | [176,  2700] loss: 1.493
2025-02-25T22:14:34.056295+0300 | INFO | [176,  2800] loss: 1.483
2025-02-25T22:14:43.782844+0300 | INFO | [176,  2900] loss: 1.485
2025-02-25T22:14:53.518856+0300 | INFO | [176,  3000] loss: 1.477
2025-02-25T22:15:03.086962+0300 | INFO | [176,  3100] loss: 1.482
2025-02-25T22:15:12.846659+0300 | INFO | [176,  3200] loss: 1.488
2025-02-25T22:16:10.058917+0300 | INFO | [176,  3300] loss: 1.488
2025-02-25T22:17:10.703351+0300 | INFO | [176,  3400] loss: 1.494
2025-02-25T22:18:07.463776+0300 | INFO | [176,  3500] loss: 1.484
2025-02-25T22:19:05.334029+0300 | INFO | [176,  3600] loss: 1.501
2025-02-25T22:20:29.275870+0300 | INFO | [176,  3700] loss: 1.490
2025-02-25T22:21:35.447825+0300 | INFO | [176,  3800] loss: 1.493
2025-02-25T22:22:39.081767+0300 | INFO | [176,  3900] loss: 1.495
2025-02-25T22:23:39.806113+0300 | INFO | [176,  4000] loss: 1.482
2025-02-25T22:24:37.443938+0300 | INFO | [176,  4100] loss: 1.494
2025-02-25T22:25:34.062532+0300 | INFO | [176,  4200] loss: 1.490
2025-02-25T22:26:34.248334+0300 | INFO | [176,  4300] loss: 1.490
2025-02-25T22:27:31.636014+0300 | INFO | [176,  4400] loss: 1.490
2025-02-25T22:28:30.503861+0300 | INFO | [176,  4500] loss: 1.483
2025-02-25T22:29:27.893612+0300 | INFO | [176,  4600] loss: 1.489
2025-02-25T22:30:23.622021+0300 | INFO | [176,  4700] loss: 1.504
2025-02-25T22:31:29.810393+0300 | INFO | [176,  4800] loss: 1.494
2025-02-25T22:32:24.787309+0300 | INFO | [176,  4900] loss: 1.490
2025-02-25T22:33:41.195616+0300 | DEBUG | Saving model to flat file storage. Save #176
2025-02-25T22:33:41.223619+0300 | INFO | Averaging client parameters
2025-02-25T22:33:41.258077+0300 | INFO | Updating parameters on client #0
2025-02-25T22:34:43.034982+0300 | DEBUG | Test set: Accuracy: 7887/10000 (79%)
2025-02-25T22:34:43.036954+0300 | DEBUG | Test set: Loss: 1.6714372634887695
2025-02-25T22:34:43.188805+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.78      0.67      0.72      1000
           3       0.63      0.61      0.62      1200
           4       0.77      0.82      0.79      1000
           5       0.54      0.55      0.55       800
           6       0.82      0.88      0.85      1000
           7       0.86      0.81      0.83      1000
           8       0.91      0.89      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T22:34:43.194789+0300 | DEBUG | Confusion Matrix:
[[842  14  38  17  14   9   4   7  28  27]
 [  6 920   0   4   0   0   8   1  13  48]
 [ 63   6 671  51  65  50  61  17   7   9]
 [ 28   6  43 734  61 220  54  27  11  16]
 [ 13   2  27  48 820  25  32  27   5   1]
 [ 12   2  38 214  29 439  17  42   4   3]
 [ 14   2  21  41  23  17 876   1   3   2]
 [ 20   1  11  42  51  43   9 813   4   6]
 [ 51  15   4   6   5   5   3   4 885  22]
 [ 17  51   3   7   3   2   4   9  17 887]]
2025-02-25T22:34:43.196888+0300 | DEBUG | Class precision: [0.78986867 0.90284593 0.7838785  0.63058419 0.76563959 0.54197531
 0.82022472 0.85759494 0.90583419 0.86875612]
2025-02-25T22:34:43.198819+0300 | DEBUG | Class recall: [0.842      0.92       0.671      0.61166667 0.82       0.54875
 0.876      0.813      0.885      0.887     ]
2025-02-25T22:34:43.200791+0300 | INFO | Training epoch #177 on client #0
2025-02-25T22:34:43.202792+0300 | DEBUG | Saving model to flat file storage. Save #177
2025-02-25T22:34:44.169752+0300 | INFO | [177,     0] loss: 0.015
2025-02-25T22:35:52.296959+0300 | INFO | [177,   100] loss: 1.483
2025-02-25T22:36:34.650929+0300 | INFO | [177,   200] loss: 1.488
2025-02-25T22:37:15.406170+0300 | INFO | [177,   300] loss: 1.496
2025-02-25T22:38:00.596994+0300 | INFO | [177,   400] loss: 1.505
2025-02-25T22:38:53.997987+0300 | INFO | [177,   500] loss: 1.487
2025-02-25T22:40:09.834012+0300 | INFO | [177,   600] loss: 1.487
2025-02-25T22:41:24.091835+0300 | INFO | [177,   700] loss: 1.490
2025-02-25T22:42:26.530060+0300 | INFO | [177,   800] loss: 1.489
2025-02-25T22:43:34.546588+0300 | INFO | [177,   900] loss: 1.489
2025-02-25T22:44:47.149810+0300 | INFO | [177,  1000] loss: 1.482
2025-02-25T22:46:07.963260+0300 | INFO | [177,  1100] loss: 1.496
2025-02-25T22:47:26.442145+0300 | INFO | [177,  1200] loss: 1.490
2025-02-25T22:48:16.893437+0300 | INFO | [177,  1300] loss: 1.488
2025-02-25T22:48:53.987494+0300 | INFO | [177,  1400] loss: 1.489
2025-02-25T22:49:22.567568+0300 | INFO | [177,  1500] loss: 1.494
2025-02-25T22:50:07.845861+0300 | INFO | [177,  1600] loss: 1.490
2025-02-25T22:51:19.511372+0300 | INFO | [177,  1700] loss: 1.491
2025-02-25T22:52:29.660352+0300 | INFO | [177,  1800] loss: 1.486
2025-02-25T22:53:45.281662+0300 | INFO | [177,  1900] loss: 1.481
2025-02-25T22:54:57.449015+0300 | INFO | [177,  2000] loss: 1.484
2025-02-25T22:56:03.795556+0300 | INFO | [177,  2100] loss: 1.486
2025-02-25T22:57:18.511836+0300 | INFO | [177,  2200] loss: 1.483
2025-02-25T22:58:28.447476+0300 | INFO | [177,  2300] loss: 1.489
2025-02-25T22:59:31.141294+0300 | INFO | [177,  2400] loss: 1.489
2025-02-25T23:00:34.338601+0300 | INFO | [177,  2500] loss: 1.487
2025-02-25T23:01:40.012931+0300 | INFO | [177,  2600] loss: 1.483
2025-02-25T23:02:59.670726+0300 | INFO | [177,  2700] loss: 1.482
2025-02-25T23:04:15.385009+0300 | INFO | [177,  2800] loss: 1.491
2025-02-25T23:05:48.344999+0300 | INFO | [177,  2900] loss: 1.484
2025-02-25T23:06:48.511268+0300 | INFO | [177,  3000] loss: 1.494
2025-02-25T23:08:37.145381+0300 | INFO | [177,  3100] loss: 1.492
2025-02-25T23:10:21.519340+0300 | INFO | [177,  3200] loss: 1.493
2025-02-25T23:11:27.498224+0300 | INFO | [177,  3300] loss: 1.492
2025-02-25T23:11:51.013936+0300 | INFO | [177,  3400] loss: 1.492
2025-02-25T23:12:23.104941+0300 | INFO | [177,  3500] loss: 1.490
2025-02-25T23:13:18.210346+0300 | INFO | [177,  3600] loss: 1.487
2025-02-25T23:15:31.722507+0300 | INFO | [177,  3700] loss: 1.484
2025-02-25T23:16:25.850996+0300 | INFO | [177,  3800] loss: 1.485
2025-02-25T23:17:38.733920+0300 | INFO | [177,  3900] loss: 1.490
2025-02-25T23:17:49.455922+0300 | INFO | [177,  4000] loss: 1.491
2025-02-25T23:18:00.095990+0300 | INFO | [177,  4100] loss: 1.497
2025-02-25T23:18:09.857756+0300 | INFO | [177,  4200] loss: 1.489
2025-02-25T23:18:19.854481+0300 | INFO | [177,  4300] loss: 1.482
2025-02-25T23:18:29.655440+0300 | INFO | [177,  4400] loss: 1.486
2025-02-25T23:18:39.263501+0300 | INFO | [177,  4500] loss: 1.485
2025-02-25T23:18:48.685833+0300 | INFO | [177,  4600] loss: 1.486
2025-02-25T23:18:58.041978+0300 | INFO | [177,  4700] loss: 1.493
2025-02-25T23:19:07.208526+0300 | INFO | [177,  4800] loss: 1.499
2025-02-25T23:19:16.250373+0300 | INFO | [177,  4900] loss: 1.485
2025-02-25T23:19:25.250430+0300 | DEBUG | Saving model to flat file storage. Save #177
2025-02-25T23:19:25.281322+0300 | INFO | Averaging client parameters
2025-02-25T23:19:25.291411+0300 | INFO | Updating parameters on client #0
2025-02-25T23:19:39.268572+0300 | DEBUG | Test set: Accuracy: 7869/10000 (79%)
2025-02-25T23:19:39.270465+0300 | DEBUG | Test set: Loss: 1.6726515293121338
2025-02-25T23:19:39.352082+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.78      0.66      0.71      1000
           3       0.66      0.57      0.61      1200
           4       0.76      0.83      0.79      1000
           5       0.52      0.59      0.55       800
           6       0.82      0.87      0.85      1000
           7       0.85      0.82      0.84      1000
           8       0.87      0.90      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T23:19:39.357071+0300 | DEBUG | Confusion Matrix:
[[839  11  37  15  14  11   3   9  37  24]
 [  6 904   0   5   2   0   7   1  24  51]
 [ 59   5 661  41  69  67  60  18   8  12]
 [ 24   6  51 684  64 259  51  30  14  17]
 [ 12   2  26  37 830  26  32  28   6   1]
 [ 13   1  35 173  33 476  18  42   6   3]
 [ 14   1  25  38  21  17 872   2   8   2]
 [ 20   1   8  26  54  51   9 822   5   4]
 [ 45  11   4   4   5   4   4   4 897  22]
 [ 23  41   4   6   2   5   4  10  21 884]]
2025-02-25T23:19:39.360165+0300 | DEBUG | Class precision: [0.79526066 0.91963377 0.77673325 0.66472303 0.75868373 0.51965066
 0.82264151 0.85093168 0.87426901 0.86666667]
2025-02-25T23:19:39.362176+0300 | DEBUG | Class recall: [0.839 0.904 0.661 0.57  0.83  0.595 0.872 0.822 0.897 0.884]
2025-02-25T23:19:39.409174+0300 | INFO | Training epoch #178 on client #0
2025-02-25T23:19:39.411058+0300 | DEBUG | Saving model to flat file storage. Save #178
2025-02-25T23:19:39.524362+0300 | INFO | [178,     0] loss: 0.015
2025-02-25T23:19:48.580694+0300 | INFO | [178,   100] loss: 1.483
2025-02-25T23:19:57.633628+0300 | INFO | [178,   200] loss: 1.481
2025-02-25T23:20:06.912278+0300 | INFO | [178,   300] loss: 1.481
2025-02-25T23:20:16.092208+0300 | INFO | [178,   400] loss: 1.495
2025-02-25T23:20:25.766763+0300 | INFO | [178,   500] loss: 1.488
2025-02-25T23:20:37.114987+0300 | INFO | [178,   600] loss: 1.489
2025-02-25T23:20:46.072229+0300 | INFO | [178,   700] loss: 1.492
2025-02-25T23:20:54.918146+0300 | INFO | [178,   800] loss: 1.491
2025-02-25T23:21:03.858492+0300 | INFO | [178,   900] loss: 1.493
2025-02-25T23:21:15.313532+0300 | INFO | [178,  1000] loss: 1.480
2025-02-25T23:21:25.423701+0300 | INFO | [178,  1100] loss: 1.492
2025-02-25T23:21:34.676071+0300 | INFO | [178,  1200] loss: 1.502
2025-02-25T23:21:43.605614+0300 | INFO | [178,  1300] loss: 1.494
2025-02-25T23:21:52.824447+0300 | INFO | [178,  1400] loss: 1.486
2025-02-25T23:22:02.009793+0300 | INFO | [178,  1500] loss: 1.491
2025-02-25T23:22:10.953111+0300 | INFO | [178,  1600] loss: 1.494
2025-02-25T23:22:20.161358+0300 | INFO | [178,  1700] loss: 1.489
2025-02-25T23:22:29.359772+0300 | INFO | [178,  1800] loss: 1.490
2025-02-25T23:22:41.189057+0300 | INFO | [178,  1900] loss: 1.484
2025-02-25T23:22:50.023269+0300 | INFO | [178,  2000] loss: 1.488
2025-02-25T23:22:58.931500+0300 | INFO | [178,  2100] loss: 1.493
2025-02-25T23:23:09.322081+0300 | INFO | [178,  2200] loss: 1.495
2025-02-25T23:23:20.844091+0300 | INFO | [178,  2300] loss: 1.487
2025-02-25T23:23:30.056877+0300 | INFO | [178,  2400] loss: 1.490
2025-02-25T23:23:39.144840+0300 | INFO | [178,  2500] loss: 1.486
2025-02-25T23:23:49.241515+0300 | INFO | [178,  2600] loss: 1.490
2025-02-25T23:24:02.075872+0300 | INFO | [178,  2700] loss: 1.482
2025-02-25T23:24:11.422893+0300 | INFO | [178,  2800] loss: 1.485
2025-02-25T23:24:20.613050+0300 | INFO | [178,  2900] loss: 1.492
2025-02-25T23:24:29.793331+0300 | INFO | [178,  3000] loss: 1.490
2025-02-25T23:24:38.919687+0300 | INFO | [178,  3100] loss: 1.482
2025-02-25T23:24:47.896653+0300 | INFO | [178,  3200] loss: 1.482
2025-02-25T23:24:56.947954+0300 | INFO | [178,  3300] loss: 1.489
2025-02-25T23:25:06.149083+0300 | INFO | [178,  3400] loss: 1.501
2025-02-25T23:25:15.272289+0300 | INFO | [178,  3500] loss: 1.496
2025-02-25T23:25:24.340383+0300 | INFO | [178,  3600] loss: 1.490
2025-02-25T23:25:33.431505+0300 | INFO | [178,  3700] loss: 1.495
2025-02-25T23:25:42.933758+0300 | INFO | [178,  3800] loss: 1.500
2025-02-25T23:25:52.423344+0300 | INFO | [178,  3900] loss: 1.483
2025-02-25T23:26:01.591633+0300 | INFO | [178,  4000] loss: 1.487
2025-02-25T23:26:10.752776+0300 | INFO | [178,  4100] loss: 1.483
2025-02-25T23:26:19.695262+0300 | INFO | [178,  4200] loss: 1.481
2025-02-25T23:26:28.765557+0300 | INFO | [178,  4300] loss: 1.491
2025-02-25T23:26:37.829695+0300 | INFO | [178,  4400] loss: 1.488
2025-02-25T23:26:46.774539+0300 | INFO | [178,  4500] loss: 1.496
2025-02-25T23:26:55.681575+0300 | INFO | [178,  4600] loss: 1.485
2025-02-25T23:27:05.747792+0300 | INFO | [178,  4700] loss: 1.484
2025-02-25T23:27:14.769538+0300 | INFO | [178,  4800] loss: 1.497
2025-02-25T23:27:23.872509+0300 | INFO | [178,  4900] loss: 1.501
2025-02-25T23:27:32.797538+0300 | DEBUG | Saving model to flat file storage. Save #178
2025-02-25T23:27:32.820169+0300 | INFO | Averaging client parameters
2025-02-25T23:27:32.828166+0300 | INFO | Updating parameters on client #0
2025-02-25T23:27:46.443847+0300 | DEBUG | Test set: Accuracy: 7884/10000 (79%)
2025-02-25T23:27:46.444851+0300 | DEBUG | Test set: Loss: 1.6713300943374634
2025-02-25T23:27:46.532434+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.67      0.57      0.62      1200
           4       0.75      0.83      0.79      1000
           5       0.52      0.62      0.57       800
           6       0.84      0.87      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T23:27:46.535433+0300 | DEBUG | Confusion Matrix:
[[848  10  43  13  13  10   3   9  33  18]
 [  9 906   1   4   2   0   6   3  22  47]
 [ 56   4 685  39  66  66  57  15   4   8]
 [ 27   6  60 686  62 263  47  25  12  12]
 [ 10   2  30  37 831  31  28  24   6   1]
 [ 13   1  34 171  32 499  15  30   4   1]
 [  8   1  30  35  25  21 871   2   5   2]
 [ 16   1  11  33  65  65   7 795   4   3]
 [ 49  11  10   4   5   5   4   4 887  21]
 [ 26  41   5   6   5   6   4  12  19 876]]
2025-02-25T23:27:46.536437+0300 | DEBUG | Class precision: [0.79849341 0.92166836 0.75357536 0.66731518 0.75135624 0.51656315
 0.83589251 0.86507073 0.89056225 0.88574317]
2025-02-25T23:27:46.539426+0300 | DEBUG | Class recall: [0.848      0.906      0.685      0.57166667 0.831      0.62375
 0.871      0.795      0.887      0.876     ]
2025-02-25T23:27:46.578438+0300 | INFO | Training epoch #179 on client #0
2025-02-25T23:27:46.579437+0300 | DEBUG | Saving model to flat file storage. Save #179
2025-02-25T23:27:46.700275+0300 | INFO | [179,     0] loss: 0.015
2025-02-25T23:27:55.840254+0300 | INFO | [179,   100] loss: 1.496
2025-02-25T23:28:05.266079+0300 | INFO | [179,   200] loss: 1.499
2025-02-25T23:28:14.436378+0300 | INFO | [179,   300] loss: 1.486
2025-02-25T23:28:24.616810+0300 | INFO | [179,   400] loss: 1.499
2025-02-25T23:28:33.827787+0300 | INFO | [179,   500] loss: 1.484
2025-02-25T23:28:43.461980+0300 | INFO | [179,   600] loss: 1.498
2025-02-25T23:28:53.352526+0300 | INFO | [179,   700] loss: 1.482
2025-02-25T23:29:02.943513+0300 | INFO | [179,   800] loss: 1.492
2025-02-25T23:29:13.022635+0300 | INFO | [179,   900] loss: 1.488
2025-02-25T23:29:23.322559+0300 | INFO | [179,  1000] loss: 1.487
2025-02-25T23:29:32.857494+0300 | INFO | [179,  1100] loss: 1.486
2025-02-25T23:29:43.164030+0300 | INFO | [179,  1200] loss: 1.482
2025-02-25T23:29:52.983703+0300 | INFO | [179,  1300] loss: 1.492
2025-02-25T23:30:03.723890+0300 | INFO | [179,  1400] loss: 1.484
2025-02-25T23:30:14.525691+0300 | INFO | [179,  1500] loss: 1.498
2025-02-25T23:30:24.681594+0300 | INFO | [179,  1600] loss: 1.490
2025-02-25T23:30:35.286843+0300 | INFO | [179,  1700] loss: 1.495
2025-02-25T23:30:46.574484+0300 | INFO | [179,  1800] loss: 1.494
2025-02-25T23:30:56.284577+0300 | INFO | [179,  1900] loss: 1.487
2025-02-25T23:31:07.204528+0300 | INFO | [179,  2000] loss: 1.487
2025-02-25T23:31:24.283812+0300 | INFO | [179,  2100] loss: 1.483
2025-02-25T23:31:35.696232+0300 | INFO | [179,  2200] loss: 1.479
2025-02-25T23:31:45.527680+0300 | INFO | [179,  2300] loss: 1.487
2025-02-25T23:31:56.241210+0300 | INFO | [179,  2400] loss: 1.490
2025-02-25T23:32:07.216519+0300 | INFO | [179,  2500] loss: 1.483
2025-02-25T23:32:17.186599+0300 | INFO | [179,  2600] loss: 1.486
2025-02-25T23:32:28.009453+0300 | INFO | [179,  2700] loss: 1.498
2025-02-25T23:32:40.001469+0300 | INFO | [179,  2800] loss: 1.495
2025-02-25T23:32:49.826490+0300 | INFO | [179,  2900] loss: 1.487
2025-02-25T23:33:00.233738+0300 | INFO | [179,  3000] loss: 1.495
2025-02-25T23:33:10.975751+0300 | INFO | [179,  3100] loss: 1.490
2025-02-25T23:33:21.078777+0300 | INFO | [179,  3200] loss: 1.488
2025-02-25T23:33:31.869431+0300 | INFO | [179,  3300] loss: 1.484
2025-02-25T23:33:43.010868+0300 | INFO | [179,  3400] loss: 1.486
2025-02-25T23:33:53.072614+0300 | INFO | [179,  3500] loss: 1.490
2025-02-25T23:34:04.059706+0300 | INFO | [179,  3600] loss: 1.484
2025-02-25T23:34:14.619842+0300 | INFO | [179,  3700] loss: 1.482
2025-02-25T23:34:25.162561+0300 | INFO | [179,  3800] loss: 1.484
2025-02-25T23:34:35.599586+0300 | INFO | [179,  3900] loss: 1.493
2025-02-25T23:34:46.771099+0300 | INFO | [179,  4000] loss: 1.487
2025-02-25T23:34:56.760768+0300 | INFO | [179,  4100] loss: 1.491
2025-02-25T23:35:07.469550+0300 | INFO | [179,  4200] loss: 1.485
2025-02-25T23:35:18.063590+0300 | INFO | [179,  4300] loss: 1.487
2025-02-25T23:35:27.801849+0300 | INFO | [179,  4400] loss: 1.501
2025-02-25T23:35:38.452560+0300 | INFO | [179,  4500] loss: 1.481
2025-02-25T23:35:49.809603+0300 | INFO | [179,  4600] loss: 1.494
2025-02-25T23:35:59.674939+0300 | INFO | [179,  4700] loss: 1.490
2025-02-25T23:36:10.391893+0300 | INFO | [179,  4800] loss: 1.480
2025-02-25T23:36:22.826023+0300 | INFO | [179,  4900] loss: 1.492
2025-02-25T23:36:33.385967+0300 | DEBUG | Saving model to flat file storage. Save #179
2025-02-25T23:36:33.413997+0300 | INFO | Averaging client parameters
2025-02-25T23:36:33.429545+0300 | INFO | Updating parameters on client #0
2025-02-25T23:36:49.303044+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-25T23:36:49.306040+0300 | DEBUG | Test set: Loss: 1.6721402406692505
2025-02-25T23:36:49.416485+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.84      0.81      1000
           1       0.91      0.92      0.92      1000
           2       0.77      0.67      0.72      1000
           3       0.65      0.59      0.62      1200
           4       0.78      0.81      0.79      1000
           5       0.52      0.58      0.55       800
           6       0.83      0.87      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T23:36:49.418488+0300 | DEBUG | Confusion Matrix:
[[842  13  38  15  10  11   3   7  40  21]
 [  5 919   0   4   0   0   5   1  19  47]
 [ 62   5 668  44  60  64  62  18   7  10]
 [ 33   7  53 710  50 246  48  23  14  16]
 [ 14   2  33  45 805  28  31  33   8   1]
 [ 13   1  30 193  31 468  17  38   7   2]
 [ 12   2  27  37  24  17 871   2   6   2]
 [ 21   1   9  33  45  58   7 817   4   5]
 [ 47  11   4   5   4   4   5   2 895  23]
 [ 26  44   4   6   4   4   4   9  19 880]]
2025-02-25T23:36:49.419491+0300 | DEBUG | Class precision: [0.78325581 0.91442786 0.77136259 0.65018315 0.77928364 0.52
 0.82716049 0.86       0.87831207 0.87388282]
2025-02-25T23:36:49.420471+0300 | DEBUG | Class recall: [0.842      0.919      0.668      0.59166667 0.805      0.585
 0.871      0.817      0.895      0.88      ]
2025-02-25T23:36:49.476080+0300 | INFO | Training epoch #180 on client #0
2025-02-25T23:36:49.479081+0300 | DEBUG | Saving model to flat file storage. Save #180
2025-02-25T23:36:49.626922+0300 | INFO | [180,     0] loss: 0.015
2025-02-25T23:37:00.791041+0300 | INFO | [180,   100] loss: 1.485
2025-02-25T23:37:11.978352+0300 | INFO | [180,   200] loss: 1.480
2025-02-25T23:37:22.243215+0300 | INFO | [180,   300] loss: 1.496
2025-02-25T23:37:33.879234+0300 | INFO | [180,   400] loss: 1.495
2025-02-25T23:37:44.470631+0300 | INFO | [180,   500] loss: 1.494
2025-02-25T23:37:54.983455+0300 | INFO | [180,   600] loss: 1.486
2025-02-25T23:38:05.900186+0300 | INFO | [180,   700] loss: 1.482
2025-02-25T23:38:17.057678+0300 | INFO | [180,   800] loss: 1.492
2025-02-25T23:38:27.837677+0300 | INFO | [180,   900] loss: 1.487
2025-02-25T23:38:37.817396+0300 | INFO | [180,  1000] loss: 1.486
2025-02-25T23:38:48.659199+0300 | INFO | [180,  1100] loss: 1.487
2025-02-25T23:38:59.258009+0300 | INFO | [180,  1200] loss: 1.488
2025-02-25T23:39:09.881157+0300 | INFO | [180,  1300] loss: 1.485
2025-02-25T23:39:20.533557+0300 | INFO | [180,  1400] loss: 1.503
2025-02-25T23:39:30.820944+0300 | INFO | [180,  1500] loss: 1.480
2025-02-25T23:39:47.183124+0300 | INFO | [180,  1600] loss: 1.482
2025-02-25T23:39:57.301830+0300 | INFO | [180,  1700] loss: 1.488
2025-02-25T23:40:08.074325+0300 | INFO | [180,  1800] loss: 1.484
2025-02-25T23:40:18.057015+0300 | INFO | [180,  1900] loss: 1.493
2025-02-25T23:40:29.367849+0300 | INFO | [180,  2000] loss: 1.496
2025-02-25T23:40:40.087748+0300 | INFO | [180,  2100] loss: 1.488
2025-02-25T23:40:50.040084+0300 | INFO | [180,  2200] loss: 1.489
2025-02-25T23:41:00.660348+0300 | INFO | [180,  2300] loss: 1.487
2025-02-25T23:41:11.731400+0300 | INFO | [180,  2400] loss: 1.487
2025-02-25T23:41:21.535798+0300 | INFO | [180,  2500] loss: 1.494
2025-02-25T23:41:32.315380+0300 | INFO | [180,  2600] loss: 1.492
2025-02-25T23:41:43.280471+0300 | INFO | [180,  2700] loss: 1.487
2025-02-25T23:41:55.057251+0300 | INFO | [180,  2800] loss: 1.496
2025-02-25T23:42:06.555994+0300 | INFO | [180,  2900] loss: 1.489
2025-02-25T23:42:18.238528+0300 | INFO | [180,  3000] loss: 1.484
2025-02-25T23:42:29.329755+0300 | INFO | [180,  3100] loss: 1.484
2025-02-25T23:42:39.100883+0300 | INFO | [180,  3200] loss: 1.488
2025-02-25T23:42:49.681869+0300 | INFO | [180,  3300] loss: 1.491
2025-02-25T23:43:00.121664+0300 | INFO | [180,  3400] loss: 1.488
2025-02-25T23:43:10.535979+0300 | INFO | [180,  3500] loss: 1.496
2025-02-25T23:43:20.909169+0300 | INFO | [180,  3600] loss: 1.486
2025-02-25T23:43:33.898819+0300 | INFO | [180,  3700] loss: 1.488
2025-02-25T23:43:44.261604+0300 | INFO | [180,  3800] loss: 1.485
2025-02-25T23:43:54.382547+0300 | INFO | [180,  3900] loss: 1.494
2025-02-25T23:44:06.202809+0300 | INFO | [180,  4000] loss: 1.493
2025-02-25T23:44:16.810109+0300 | INFO | [180,  4100] loss: 1.486
2025-02-25T23:44:27.088469+0300 | INFO | [180,  4200] loss: 1.490
2025-02-25T23:44:37.465178+0300 | INFO | [180,  4300] loss: 1.485
2025-02-25T23:44:47.191672+0300 | INFO | [180,  4400] loss: 1.488
2025-02-25T23:44:57.610180+0300 | INFO | [180,  4500] loss: 1.490
2025-02-25T23:45:08.283674+0300 | INFO | [180,  4600] loss: 1.485
2025-02-25T23:45:18.248028+0300 | INFO | [180,  4700] loss: 1.497
2025-02-25T23:45:28.649661+0300 | INFO | [180,  4800] loss: 1.488
2025-02-25T23:45:38.521505+0300 | INFO | [180,  4900] loss: 1.491
2025-02-25T23:45:49.040616+0300 | DEBUG | Saving model to flat file storage. Save #180
2025-02-25T23:45:49.063758+0300 | INFO | Averaging client parameters
2025-02-25T23:45:49.069247+0300 | INFO | Updating parameters on client #0
2025-02-25T23:46:04.730485+0300 | DEBUG | Test set: Accuracy: 7887/10000 (79%)
2025-02-25T23:46:04.732401+0300 | DEBUG | Test set: Loss: 1.6714102029800415
2025-02-25T23:46:04.825100+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.64      0.61      0.63      1200
           4       0.78      0.81      0.79      1000
           5       0.51      0.59      0.55       800
           6       0.85      0.87      0.86      1000
           7       0.87      0.80      0.83      1000
           8       0.90      0.88      0.89      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T23:46:04.828096+0300 | DEBUG | Confusion Matrix:
[[829  14  49  18  12  11   4   8  33  22]
 [  6 914   0   5   2   1   8   1  13  50]
 [ 51   4 682  46  60  73  52  16   7   9]
 [ 27   6  46 738  46 248  43  21   8  17]
 [ 13   2  30  55 807  32  25  29   6   1]
 [ 11   1  31 202  27 475  14  34   4   1]
 [  9   1  28  43  21  20 871   2   3   2]
 [ 18   0  11  38  51  66   6 803   3   4]
 [ 49  14  11   8   4   5   4   1 881  23]
 [ 18  45   5   8   3   6   1  10  17 887]]
2025-02-25T23:46:04.831086+0300 | DEBUG | Class precision: [0.80407371 0.91308691 0.76371781 0.63565891 0.78121975 0.50693703
 0.84727626 0.86810811 0.90358974 0.8730315 ]
2025-02-25T23:46:04.833160+0300 | DEBUG | Class recall: [0.829   0.914   0.682   0.615   0.807   0.59375 0.871   0.803   0.881
 0.887  ]
2025-02-25T23:46:04.884301+0300 | INFO | Training epoch #181 on client #0
2025-02-25T23:46:04.885304+0300 | DEBUG | Saving model to flat file storage. Save #181
2025-02-25T23:46:05.023663+0300 | INFO | [181,     0] loss: 0.015
2025-02-25T23:46:15.583065+0300 | INFO | [181,   100] loss: 1.489
2025-02-25T23:46:25.401116+0300 | INFO | [181,   200] loss: 1.487
2025-02-25T23:46:37.511880+0300 | INFO | [181,   300] loss: 1.485
2025-02-25T23:46:49.211896+0300 | INFO | [181,   400] loss: 1.495
2025-02-25T23:46:59.937044+0300 | INFO | [181,   500] loss: 1.490
2025-02-25T23:47:11.870779+0300 | INFO | [181,   600] loss: 1.504
2025-02-25T23:47:23.550841+0300 | INFO | [181,   700] loss: 1.480
2025-02-25T23:47:35.338764+0300 | INFO | [181,   800] loss: 1.496
2025-02-25T23:47:46.630289+0300 | INFO | [181,   900] loss: 1.499
2025-02-25T23:47:57.831464+0300 | INFO | [181,  1000] loss: 1.482
2025-02-25T23:48:14.740067+0300 | INFO | [181,  1100] loss: 1.479
2025-02-25T23:48:28.992155+0300 | INFO | [181,  1200] loss: 1.496
2025-02-25T23:48:40.701799+0300 | INFO | [181,  1300] loss: 1.490
2025-02-25T23:48:51.920426+0300 | INFO | [181,  1400] loss: 1.495
2025-02-25T23:49:02.513071+0300 | INFO | [181,  1500] loss: 1.490
2025-02-25T23:49:13.693064+0300 | INFO | [181,  1600] loss: 1.486
2025-02-25T23:49:25.588044+0300 | INFO | [181,  1700] loss: 1.482
2025-02-25T23:49:37.872261+0300 | INFO | [181,  1800] loss: 1.491
2025-02-25T23:49:51.074670+0300 | INFO | [181,  1900] loss: 1.497
2025-02-25T23:50:02.867256+0300 | INFO | [181,  2000] loss: 1.483
2025-02-25T23:50:14.473931+0300 | INFO | [181,  2100] loss: 1.482
2025-02-25T23:50:24.935347+0300 | INFO | [181,  2200] loss: 1.491
2025-02-25T23:50:35.793465+0300 | INFO | [181,  2300] loss: 1.496
2025-02-25T23:50:46.981021+0300 | INFO | [181,  2400] loss: 1.481
2025-02-25T23:50:57.329121+0300 | INFO | [181,  2500] loss: 1.492
2025-02-25T23:51:08.492560+0300 | INFO | [181,  2600] loss: 1.486
2025-02-25T23:51:19.526282+0300 | INFO | [181,  2700] loss: 1.493
2025-02-25T23:51:29.714687+0300 | INFO | [181,  2800] loss: 1.490
2025-02-25T23:51:40.040905+0300 | INFO | [181,  2900] loss: 1.480
2025-02-25T23:51:50.664048+0300 | INFO | [181,  3000] loss: 1.484
2025-02-25T23:52:00.293798+0300 | INFO | [181,  3100] loss: 1.480
2025-02-25T23:52:10.943579+0300 | INFO | [181,  3200] loss: 1.484
2025-02-25T23:52:21.399282+0300 | INFO | [181,  3300] loss: 1.489
2025-02-25T23:52:31.292127+0300 | INFO | [181,  3400] loss: 1.478
2025-02-25T23:52:41.579791+0300 | INFO | [181,  3500] loss: 1.488
2025-02-25T23:52:52.839221+0300 | INFO | [181,  3600] loss: 1.491
2025-02-25T23:53:02.540869+0300 | INFO | [181,  3700] loss: 1.489
2025-02-25T23:53:15.894737+0300 | INFO | [181,  3800] loss: 1.496
2025-02-25T23:53:26.071488+0300 | INFO | [181,  3900] loss: 1.492
2025-02-25T23:53:35.943397+0300 | INFO | [181,  4000] loss: 1.493
2025-02-25T23:53:46.648024+0300 | INFO | [181,  4100] loss: 1.482
2025-02-25T23:53:57.327842+0300 | INFO | [181,  4200] loss: 1.488
2025-02-25T23:54:07.700095+0300 | INFO | [181,  4300] loss: 1.501
2025-02-25T23:54:18.526079+0300 | INFO | [181,  4400] loss: 1.488
2025-02-25T23:54:29.437558+0300 | INFO | [181,  4500] loss: 1.497
2025-02-25T23:54:40.867380+0300 | INFO | [181,  4600] loss: 1.491
2025-02-25T23:54:50.953362+0300 | INFO | [181,  4700] loss: 1.484
2025-02-25T23:55:01.712273+0300 | INFO | [181,  4800] loss: 1.492
2025-02-25T23:55:12.063367+0300 | INFO | [181,  4900] loss: 1.487
2025-02-25T23:55:22.580707+0300 | DEBUG | Saving model to flat file storage. Save #181
2025-02-25T23:55:22.606829+0300 | INFO | Averaging client parameters
2025-02-25T23:55:22.616843+0300 | INFO | Updating parameters on client #0
2025-02-25T23:55:39.000056+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-25T23:55:39.001062+0300 | DEBUG | Test set: Loss: 1.6723304986953735
2025-02-25T23:55:39.110727+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.65      0.57      0.61      1200
           4       0.78      0.81      0.80      1000
           5       0.52      0.60      0.56       800
           6       0.80      0.89      0.84      1000
           7       0.87      0.81      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-25T23:55:39.113610+0300 | DEBUG | Confusion Matrix:
[[839  13  37  15  14  13   6   8  34  21]
 [  8 913   0   5   1   1   8   1  15  48]
 [ 55   5 679  39  60  64  69  15   5   9]
 [ 30   5  51 690  52 260  58  24  13  17]
 [ 11   2  31  40 811  29  43  27   5   1]
 [ 12   1  35 180  30 484  20  32   5   1]
 [ 10   1  26  34  14  16 891   2   4   2]
 [ 18   1  10  38  50  58   8 809   4   4]
 [ 46  15   7   7   4   6   5   4 886  20]
 [ 23  43   5   8   2   7   6  11  14 881]]
2025-02-25T23:55:39.116732+0300 | DEBUG | Class precision: [0.79752852 0.91391391 0.7707151  0.65340909 0.78131021 0.51599147
 0.79982047 0.86709539 0.89949239 0.87749004]
2025-02-25T23:55:39.117717+0300 | DEBUG | Class recall: [0.839 0.913 0.679 0.575 0.811 0.605 0.891 0.809 0.886 0.881]
2025-02-25T23:55:39.174996+0300 | INFO | Training epoch #182 on client #0
2025-02-25T23:55:39.175995+0300 | DEBUG | Saving model to flat file storage. Save #182
2025-02-25T23:55:39.322643+0300 | INFO | [182,     0] loss: 0.015
2025-02-25T23:55:50.076952+0300 | INFO | [182,   100] loss: 1.504
2025-02-25T23:56:01.144864+0300 | INFO | [182,   200] loss: 1.488
2025-02-25T23:56:12.070546+0300 | INFO | [182,   300] loss: 1.475
2025-02-25T23:56:22.622040+0300 | INFO | [182,   400] loss: 1.488
2025-02-25T23:56:32.703511+0300 | INFO | [182,   500] loss: 1.483
2025-02-25T23:56:43.171549+0300 | INFO | [182,   600] loss: 1.489
2025-02-25T23:56:57.022580+0300 | INFO | [182,   700] loss: 1.490
2025-02-25T23:57:10.760094+0300 | INFO | [182,   800] loss: 1.479
2025-02-25T23:57:20.658440+0300 | INFO | [182,   900] loss: 1.491
2025-02-25T23:57:31.089505+0300 | INFO | [182,  1000] loss: 1.485
2025-02-25T23:57:41.735771+0300 | INFO | [182,  1100] loss: 1.489
2025-02-25T23:57:51.670553+0300 | INFO | [182,  1200] loss: 1.486
2025-02-25T23:58:03.307995+0300 | INFO | [182,  1300] loss: 1.483
2025-02-25T23:58:13.821895+0300 | INFO | [182,  1400] loss: 1.487
2025-02-25T23:58:25.819321+0300 | INFO | [182,  1500] loss: 1.490
2025-02-25T23:58:36.043338+0300 | INFO | [182,  1600] loss: 1.477
2025-02-25T23:58:46.635572+0300 | INFO | [182,  1700] loss: 1.494
2025-02-25T23:58:57.301532+0300 | INFO | [182,  1800] loss: 1.496
2025-02-25T23:59:07.851442+0300 | INFO | [182,  1900] loss: 1.488
2025-02-25T23:59:18.318182+0300 | INFO | [182,  2000] loss: 1.488
2025-02-25T23:59:28.098013+0300 | INFO | [182,  2100] loss: 1.490
2025-02-25T23:59:38.513086+0300 | INFO | [182,  2200] loss: 1.491
2025-02-25T23:59:49.836092+0300 | INFO | [182,  2300] loss: 1.491
2025-02-25T23:59:59.948804+0300 | INFO | [182,  2400] loss: 1.488
2025-02-26T00:00:12.121409+0300 | INFO | [182,  2500] loss: 1.490
2025-02-26T00:00:23.588937+0300 | INFO | [182,  2600] loss: 1.480
2025-02-26T00:00:34.780816+0300 | INFO | [182,  2700] loss: 1.482
2025-02-26T00:00:45.969620+0300 | INFO | [182,  2800] loss: 1.497
2025-02-26T00:00:57.550406+0300 | INFO | [182,  2900] loss: 1.487
2025-02-26T00:01:09.596217+0300 | INFO | [182,  3000] loss: 1.493
2025-02-26T00:01:20.590286+0300 | INFO | [182,  3100] loss: 1.502
2025-02-26T00:01:32.716424+0300 | INFO | [182,  3200] loss: 1.491
2025-02-26T00:01:45.148035+0300 | INFO | [182,  3300] loss: 1.490
2025-02-26T00:01:55.903594+0300 | INFO | [182,  3400] loss: 1.490
2025-02-26T00:02:06.611821+0300 | INFO | [182,  3500] loss: 1.486
2025-02-26T00:02:16.970000+0300 | INFO | [182,  3600] loss: 1.490
2025-02-26T00:02:27.176751+0300 | INFO | [182,  3700] loss: 1.491
2025-02-26T00:02:37.239665+0300 | INFO | [182,  3800] loss: 1.487
2025-02-26T00:02:47.722152+0300 | INFO | [182,  3900] loss: 1.486
2025-02-26T00:02:57.360193+0300 | INFO | [182,  4000] loss: 1.487
2025-02-26T00:03:08.093268+0300 | INFO | [182,  4100] loss: 1.487
2025-02-26T00:03:18.733984+0300 | INFO | [182,  4200] loss: 1.487
2025-02-26T00:03:28.436326+0300 | INFO | [182,  4300] loss: 1.492
2025-02-26T00:03:39.051193+0300 | INFO | [182,  4400] loss: 1.492
2025-02-26T00:03:49.702021+0300 | INFO | [182,  4500] loss: 1.489
2025-02-26T00:03:59.372196+0300 | INFO | [182,  4600] loss: 1.490
2025-02-26T00:04:10.180511+0300 | INFO | [182,  4700] loss: 1.488
2025-02-26T00:04:21.945059+0300 | INFO | [182,  4800] loss: 1.490
2025-02-26T00:04:33.100942+0300 | INFO | [182,  4900] loss: 1.495
2025-02-26T00:04:44.704774+0300 | DEBUG | Saving model to flat file storage. Save #182
2025-02-26T00:04:44.722774+0300 | INFO | Averaging client parameters
2025-02-26T00:04:44.731885+0300 | INFO | Updating parameters on client #0
2025-02-26T00:05:01.769582+0300 | DEBUG | Test set: Accuracy: 7899/10000 (79%)
2025-02-26T00:05:01.771604+0300 | DEBUG | Test set: Loss: 1.6708883047103882
2025-02-26T00:05:01.871211+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.66      0.58      0.62      1200
           4       0.76      0.83      0.79      1000
           5       0.53      0.59      0.56       800
           6       0.83      0.88      0.85      1000
           7       0.87      0.80      0.84      1000
           8       0.88      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T00:05:01.874193+0300 | DEBUG | Confusion Matrix:
[[841  13  41  14  13  10   3   8  36  21]
 [  9 902   1   4   2   0   7   1  20  54]
 [ 52   4 700  39  63  52  60  14   9   7]
 [ 27   7  60 698  61 246  53  22  11  15]
 [  8   0  37  37 833  24  29  24   7   1]
 [ 13   1  42 184  35 469  17  31   7   1]
 [ 10   1  28  36  23  16 876   2   6   2]
 [ 16   1  13  37  60  55   7 804   4   3]
 [ 45  12   6   5   5   6   4   3 892  22]
 [ 20  41   5   8   3   7   3  11  18 884]]
2025-02-26T00:05:01.876216+0300 | DEBUG | Class precision: [0.80787704 0.9185336  0.75026795 0.65725047 0.75865209 0.5299435
 0.82719547 0.87391304 0.88316832 0.87524752]
2025-02-26T00:05:01.877221+0300 | DEBUG | Class recall: [0.841      0.902      0.7        0.58166667 0.833      0.58625
 0.876      0.804      0.892      0.884     ]
2025-02-26T00:05:01.934050+0300 | INFO | Training epoch #183 on client #0
2025-02-26T00:05:01.936058+0300 | DEBUG | Saving model to flat file storage. Save #183
2025-02-26T00:05:02.059849+0300 | INFO | [183,     0] loss: 0.015
2025-02-26T00:05:14.862337+0300 | INFO | [183,   100] loss: 1.492
2025-02-26T00:05:28.778282+0300 | INFO | [183,   200] loss: 1.489
2025-02-26T00:05:42.071578+0300 | INFO | [183,   300] loss: 1.483
2025-02-26T00:05:52.834319+0300 | INFO | [183,   400] loss: 1.492
2025-02-26T00:06:04.153724+0300 | INFO | [183,   500] loss: 1.478
2025-02-26T00:06:15.654613+0300 | INFO | [183,   600] loss: 1.485
2025-02-26T00:06:26.808712+0300 | INFO | [183,   700] loss: 1.489
2025-02-26T00:06:38.808426+0300 | INFO | [183,   800] loss: 1.483
2025-02-26T00:06:50.446825+0300 | INFO | [183,   900] loss: 1.496
2025-02-26T00:07:01.642885+0300 | INFO | [183,  1000] loss: 1.493
2025-02-26T00:07:12.893817+0300 | INFO | [183,  1100] loss: 1.487
2025-02-26T00:07:24.410044+0300 | INFO | [183,  1200] loss: 1.489
2025-02-26T00:07:35.896052+0300 | INFO | [183,  1300] loss: 1.483
2025-02-26T00:07:47.072528+0300 | INFO | [183,  1400] loss: 1.487
2025-02-26T00:07:58.153943+0300 | INFO | [183,  1500] loss: 1.487
2025-02-26T00:08:12.307548+0300 | INFO | [183,  1600] loss: 1.491
2025-02-26T00:08:24.049035+0300 | INFO | [183,  1700] loss: 1.485
2025-02-26T00:08:36.535578+0300 | INFO | [183,  1800] loss: 1.483
2025-02-26T00:08:46.899907+0300 | INFO | [183,  1900] loss: 1.484
2025-02-26T00:08:58.381293+0300 | INFO | [183,  2000] loss: 1.487
2025-02-26T00:09:10.929736+0300 | INFO | [183,  2100] loss: 1.500
2025-02-26T00:09:22.518356+0300 | INFO | [183,  2200] loss: 1.496
2025-02-26T00:09:34.339432+0300 | INFO | [183,  2300] loss: 1.498
2025-02-26T00:09:45.894231+0300 | INFO | [183,  2400] loss: 1.488
2025-02-26T00:09:56.933477+0300 | INFO | [183,  2500] loss: 1.492
2025-02-26T00:10:06.861013+0300 | INFO | [183,  2600] loss: 1.487
2025-02-26T00:10:17.333547+0300 | INFO | [183,  2700] loss: 1.493
2025-02-26T00:10:27.833445+0300 | INFO | [183,  2800] loss: 1.491
2025-02-26T00:10:37.782990+0300 | INFO | [183,  2900] loss: 1.493
2025-02-26T00:10:48.589192+0300 | INFO | [183,  3000] loss: 1.493
2025-02-26T00:10:58.897626+0300 | INFO | [183,  3100] loss: 1.486
2025-02-26T00:11:09.595475+0300 | INFO | [183,  3200] loss: 1.485
2025-02-26T00:11:20.035154+0300 | INFO | [183,  3300] loss: 1.488
2025-02-26T00:11:30.187509+0300 | INFO | [183,  3400] loss: 1.488
2025-02-26T00:11:41.560116+0300 | INFO | [183,  3500] loss: 1.489
2025-02-26T00:11:52.081994+0300 | INFO | [183,  3600] loss: 1.487
2025-02-26T00:12:01.815623+0300 | INFO | [183,  3700] loss: 1.483
2025-02-26T00:12:12.384255+0300 | INFO | [183,  3800] loss: 1.481
2025-02-26T00:12:22.881632+0300 | INFO | [183,  3900] loss: 1.485
2025-02-26T00:12:32.733237+0300 | INFO | [183,  4000] loss: 1.494
2025-02-26T00:12:43.669691+0300 | INFO | [183,  4100] loss: 1.489
2025-02-26T00:12:55.883538+0300 | INFO | [183,  4200] loss: 1.487
2025-02-26T00:13:05.604352+0300 | INFO | [183,  4300] loss: 1.492
2025-02-26T00:13:16.635073+0300 | INFO | [183,  4400] loss: 1.489
2025-02-26T00:13:29.356620+0300 | INFO | [183,  4500] loss: 1.493
2025-02-26T00:13:41.336131+0300 | INFO | [183,  4600] loss: 1.488
2025-02-26T00:13:52.068111+0300 | INFO | [183,  4700] loss: 1.492
2025-02-26T00:14:06.421228+0300 | INFO | [183,  4800] loss: 1.491
2025-02-26T00:14:20.441678+0300 | INFO | [183,  4900] loss: 1.489
2025-02-26T00:14:31.472803+0300 | DEBUG | Saving model to flat file storage. Save #183
2025-02-26T00:14:31.495805+0300 | INFO | Averaging client parameters
2025-02-26T00:14:31.501804+0300 | INFO | Updating parameters on client #0
2025-02-26T00:14:48.170796+0300 | DEBUG | Test set: Accuracy: 7905/10000 (79%)
2025-02-26T00:14:48.170796+0300 | DEBUG | Test set: Loss: 1.6701171398162842
2025-02-26T00:14:48.284660+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.91      0.92      0.91      1000
           2       0.76      0.70      0.73      1000
           3       0.65      0.60      0.62      1200
           4       0.74      0.84      0.79      1000
           5       0.54      0.59      0.56       800
           6       0.85      0.86      0.86      1000
           7       0.87      0.80      0.83      1000
           8       0.88      0.89      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T00:14:48.286642+0300 | DEBUG | Confusion Matrix:
[[846  14  38  15  11  10   4   8  36  18]
 [  6 922   0   5   2   1   6   1  14  43]
 [ 49   5 696  45  76  48  50  14  11   6]
 [ 25   7  57 716  64 237  45  23  12  14]
 [  9   1  31  38 840  27  26  22   5   1]
 [ 12   1  41 188  36 470  14  31   6   1]
 [ 12   2  26  39  28  18 865   2   6   2]
 [ 17   1  17  42  67  46   5 798   5   2]
 [ 45  13   8   8   5   4   5   4 889  19]
 [ 27  50   4   9   5   5   3  13  21 863]]
2025-02-26T00:14:48.289635+0300 | DEBUG | Class precision: [0.80725191 0.90748031 0.75816993 0.6479638  0.74074074 0.54272517
 0.8455523  0.87117904 0.88457711 0.89060888]
2025-02-26T00:14:48.291528+0300 | DEBUG | Class recall: [0.846      0.922      0.696      0.59666667 0.84       0.5875
 0.865      0.798      0.889      0.863     ]
2025-02-26T00:14:48.348083+0300 | INFO | Training epoch #184 on client #0
2025-02-26T00:14:48.350270+0300 | DEBUG | Saving model to flat file storage. Save #184
2025-02-26T00:14:48.480489+0300 | INFO | [184,     0] loss: 0.015
2025-02-26T00:15:01.070951+0300 | INFO | [184,   100] loss: 1.482
2025-02-26T00:15:11.660750+0300 | INFO | [184,   200] loss: 1.489
2025-02-26T00:15:22.619734+0300 | INFO | [184,   300] loss: 1.485
2025-02-26T00:15:33.062020+0300 | INFO | [184,   400] loss: 1.488
2025-02-26T00:15:42.851277+0300 | INFO | [184,   500] loss: 1.483
2025-02-26T00:15:53.942342+0300 | INFO | [184,   600] loss: 1.491
2025-02-26T00:16:06.289010+0300 | INFO | [184,   700] loss: 1.497
2025-02-26T00:16:16.245803+0300 | INFO | [184,   800] loss: 1.496
2025-02-26T00:16:27.316425+0300 | INFO | [184,   900] loss: 1.484
2025-02-26T00:16:38.684306+0300 | INFO | [184,  1000] loss: 1.496
2025-02-26T00:16:48.709975+0300 | INFO | [184,  1100] loss: 1.477
2025-02-26T00:17:00.145482+0300 | INFO | [184,  1200] loss: 1.481
2025-02-26T00:17:11.016920+0300 | INFO | [184,  1300] loss: 1.497
2025-02-26T00:17:22.544563+0300 | INFO | [184,  1400] loss: 1.485
2025-02-26T00:17:33.135490+0300 | INFO | [184,  1500] loss: 1.495
2025-02-26T00:17:44.096121+0300 | INFO | [184,  1600] loss: 1.493
2025-02-26T00:17:56.117272+0300 | INFO | [184,  1700] loss: 1.481
2025-02-26T00:18:06.027214+0300 | INFO | [184,  1800] loss: 1.491
2025-02-26T00:18:16.697710+0300 | INFO | [184,  1900] loss: 1.488
2025-02-26T00:18:27.039632+0300 | INFO | [184,  2000] loss: 1.495
2025-02-26T00:18:37.223859+0300 | INFO | [184,  2100] loss: 1.490
2025-02-26T00:18:48.318247+0300 | INFO | [184,  2200] loss: 1.486
2025-02-26T00:18:59.279646+0300 | INFO | [184,  2300] loss: 1.486
2025-02-26T00:19:10.865793+0300 | INFO | [184,  2400] loss: 1.487
2025-02-26T00:19:22.211550+0300 | INFO | [184,  2500] loss: 1.491
2025-02-26T00:19:33.817353+0300 | INFO | [184,  2600] loss: 1.481
2025-02-26T00:19:44.388664+0300 | INFO | [184,  2700] loss: 1.489
2025-02-26T00:19:55.848943+0300 | INFO | [184,  2800] loss: 1.489
2025-02-26T00:20:07.552081+0300 | INFO | [184,  2900] loss: 1.488
2025-02-26T00:20:18.892852+0300 | INFO | [184,  3000] loss: 1.489
2025-02-26T00:20:29.757650+0300 | INFO | [184,  3100] loss: 1.498
2025-02-26T00:20:40.854636+0300 | INFO | [184,  3200] loss: 1.488
2025-02-26T00:20:52.747901+0300 | INFO | [184,  3300] loss: 1.487
2025-02-26T00:21:04.049226+0300 | INFO | [184,  3400] loss: 1.499
2025-02-26T00:21:17.904844+0300 | INFO | [184,  3500] loss: 1.487
2025-02-26T00:21:28.754684+0300 | INFO | [184,  3600] loss: 1.489
2025-02-26T00:21:39.888078+0300 | INFO | [184,  3700] loss: 1.487
2025-02-26T00:21:50.713296+0300 | INFO | [184,  3800] loss: 1.483
2025-02-26T00:22:01.811207+0300 | INFO | [184,  3900] loss: 1.487
2025-02-26T00:22:12.536180+0300 | INFO | [184,  4000] loss: 1.485
2025-02-26T00:22:22.207022+0300 | INFO | [184,  4100] loss: 1.494
2025-02-26T00:22:33.581543+0300 | INFO | [184,  4200] loss: 1.491
2025-02-26T00:22:44.073283+0300 | INFO | [184,  4300] loss: 1.479
2025-02-26T00:22:57.653764+0300 | INFO | [184,  4400] loss: 1.499
2025-02-26T00:23:11.125161+0300 | INFO | [184,  4500] loss: 1.485
2025-02-26T00:23:21.865447+0300 | INFO | [184,  4600] loss: 1.489
2025-02-26T00:23:32.788587+0300 | INFO | [184,  4700] loss: 1.483
2025-02-26T00:23:42.631275+0300 | INFO | [184,  4800] loss: 1.487
2025-02-26T00:23:53.294086+0300 | INFO | [184,  4900] loss: 1.498
2025-02-26T00:24:04.130251+0300 | DEBUG | Saving model to flat file storage. Save #184
2025-02-26T00:24:04.155236+0300 | INFO | Averaging client parameters
2025-02-26T00:24:04.162246+0300 | INFO | Updating parameters on client #0
2025-02-26T00:24:20.338455+0300 | DEBUG | Test set: Accuracy: 7904/10000 (79%)
2025-02-26T00:24:20.341444+0300 | DEBUG | Test set: Loss: 1.6690136194229126
2025-02-26T00:24:20.436961+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.77      0.69      0.73      1000
           3       0.64      0.58      0.61      1200
           4       0.79      0.81      0.80      1000
           5       0.52      0.61      0.56       800
           6       0.82      0.87      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T00:24:20.440944+0300 | DEBUG | Confusion Matrix:
[[838  13  34  21   9  12   5   8  37  23]
 [  5 919   0   5   1   1   6   1  15  47]
 [ 54   5 692  45  54  56  62  18   8   6]
 [ 26   7  52 702  52 265  49  21   9  17]
 [ 13   1  33  45 809  33  32  28   5   1]
 [ 12   1  35 180  25 491  19  29   7   1]
 [ 12   2  28  34  23  20 872   2   5   2]
 [ 14   1  13  42  50  59   7 806   4   4]
 [ 44  14   6   8   4   7   5   3 887  22]
 [ 18  43   4   8   2   4   4  11  18 888]]
2025-02-26T00:24:20.442962+0300 | DEBUG | Class precision: [0.80888031 0.91351889 0.77146042 0.6440367  0.78620019 0.51793249
 0.82186616 0.86947141 0.89145729 0.87833828]
2025-02-26T00:24:20.446950+0300 | DEBUG | Class recall: [0.838   0.919   0.692   0.585   0.809   0.61375 0.872   0.806   0.887
 0.888  ]
2025-02-26T00:24:20.496513+0300 | INFO | Training epoch #185 on client #0
2025-02-26T00:24:20.498555+0300 | DEBUG | Saving model to flat file storage. Save #185
2025-02-26T00:24:20.752743+0300 | INFO | [185,     0] loss: 0.016
2025-02-26T00:24:30.690982+0300 | INFO | [185,   100] loss: 1.485
2025-02-26T00:24:41.349714+0300 | INFO | [185,   200] loss: 1.487
2025-02-26T00:24:52.250879+0300 | INFO | [185,   300] loss: 1.489
2025-02-26T00:25:04.059832+0300 | INFO | [185,   400] loss: 1.489
2025-02-26T00:25:14.660703+0300 | INFO | [185,   500] loss: 1.488
2025-02-26T00:25:24.983284+0300 | INFO | [185,   600] loss: 1.489
2025-02-26T00:25:34.929909+0300 | INFO | [185,   700] loss: 1.488
2025-02-26T00:25:47.789071+0300 | INFO | [185,   800] loss: 1.499
2025-02-26T00:25:57.802294+0300 | INFO | [185,   900] loss: 1.487
2025-02-26T00:26:08.119825+0300 | INFO | [185,  1000] loss: 1.480
2025-02-26T00:26:18.603071+0300 | INFO | [185,  1100] loss: 1.486
2025-02-26T00:26:29.236732+0300 | INFO | [185,  1200] loss: 1.486
2025-02-26T00:26:38.891676+0300 | INFO | [185,  1300] loss: 1.479
2025-02-26T00:26:49.561670+0300 | INFO | [185,  1400] loss: 1.480
2025-02-26T00:27:00.032996+0300 | INFO | [185,  1500] loss: 1.485
2025-02-26T00:27:10.085803+0300 | INFO | [185,  1600] loss: 1.482
2025-02-26T00:27:22.190277+0300 | INFO | [185,  1700] loss: 1.485
2025-02-26T00:27:35.217839+0300 | INFO | [185,  1800] loss: 1.494
2025-02-26T00:27:44.930171+0300 | INFO | [185,  1900] loss: 1.490
2025-02-26T00:27:55.781884+0300 | INFO | [185,  2000] loss: 1.499
2025-02-26T00:28:06.885087+0300 | INFO | [185,  2100] loss: 1.493
2025-02-26T00:28:16.659864+0300 | INFO | [185,  2200] loss: 1.483
2025-02-26T00:28:27.097136+0300 | INFO | [185,  2300] loss: 1.487
2025-02-26T00:28:37.942923+0300 | INFO | [185,  2400] loss: 1.486
2025-02-26T00:28:47.857170+0300 | INFO | [185,  2500] loss: 1.480
2025-02-26T00:28:58.423006+0300 | INFO | [185,  2600] loss: 1.493
2025-02-26T00:29:09.142664+0300 | INFO | [185,  2700] loss: 1.493
2025-02-26T00:29:18.879559+0300 | INFO | [185,  2800] loss: 1.485
2025-02-26T00:29:29.448312+0300 | INFO | [185,  2900] loss: 1.483
2025-02-26T00:29:40.880551+0300 | INFO | [185,  3000] loss: 1.491
2025-02-26T00:29:51.095688+0300 | INFO | [185,  3100] loss: 1.492
2025-02-26T00:30:01.818267+0300 | INFO | [185,  3200] loss: 1.488
2025-02-26T00:30:12.637654+0300 | INFO | [185,  3300] loss: 1.491
2025-02-26T00:30:23.330630+0300 | INFO | [185,  3400] loss: 1.493
2025-02-26T00:30:34.181658+0300 | INFO | [185,  3500] loss: 1.482
2025-02-26T00:30:45.766104+0300 | INFO | [185,  3600] loss: 1.492
2025-02-26T00:30:55.671071+0300 | INFO | [185,  3700] loss: 1.498
2025-02-26T00:31:06.216737+0300 | INFO | [185,  3800] loss: 1.486
2025-02-26T00:31:21.340558+0300 | INFO | [185,  3900] loss: 1.486
2025-02-26T00:31:33.458338+0300 | INFO | [185,  4000] loss: 1.488
2025-02-26T00:31:45.142000+0300 | INFO | [185,  4100] loss: 1.492
2025-02-26T00:31:55.528837+0300 | INFO | [185,  4200] loss: 1.489
2025-02-26T00:32:06.031742+0300 | INFO | [185,  4300] loss: 1.495
2025-02-26T00:32:16.050741+0300 | INFO | [185,  4400] loss: 1.493
2025-02-26T00:32:26.553781+0300 | INFO | [185,  4500] loss: 1.506
2025-02-26T00:32:37.176192+0300 | INFO | [185,  4600] loss: 1.483
2025-02-26T00:32:47.208558+0300 | INFO | [185,  4700] loss: 1.492
2025-02-26T00:32:57.616992+0300 | INFO | [185,  4800] loss: 1.488
2025-02-26T00:33:08.171214+0300 | INFO | [185,  4900] loss: 1.487
2025-02-26T00:33:18.158561+0300 | DEBUG | Saving model to flat file storage. Save #185
2025-02-26T00:33:18.179581+0300 | INFO | Averaging client parameters
2025-02-26T00:33:18.189167+0300 | INFO | Updating parameters on client #0
2025-02-26T00:33:34.018590+0300 | DEBUG | Test set: Accuracy: 7897/10000 (79%)
2025-02-26T00:33:34.020588+0300 | DEBUG | Test set: Loss: 1.6700773239135742
2025-02-26T00:33:34.115158+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.67      0.56      0.61      1200
           4       0.79      0.80      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.85      0.86      0.85      1000
           7       0.85      0.84      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.86      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T00:33:34.117190+0300 | DEBUG | Confusion Matrix:
[[856  12  36  10   7  11   3   8  36  21]
 [  8 909   0   2   1   1   5   1  17  56]
 [ 64   5 683  43  52  68  48  16  10  11]
 [ 34   7  51 671  57 275  45  27  15  18]
 [ 15   2  37  39 797  34  28  38   8   2]
 [ 13   1  35 156  27 503  18  39   7   1]
 [ 13   2  28  35  25  25 858   3   9   2]
 [ 20   1  11  29  42  48   4 836   4   5]
 [ 44  12   5   4   2   5   4   3 896  25]
 [ 24  43   3   6   2   5   2  10  17 888]]
2025-02-26T00:33:34.120157+0300 | DEBUG | Class precision: [0.78460128 0.91448692 0.76827897 0.67437186 0.78754941 0.51589744
 0.8453202  0.85219164 0.87929342 0.86297376]
2025-02-26T00:33:34.121160+0300 | DEBUG | Class recall: [0.856      0.909      0.683      0.55916667 0.797      0.62875
 0.858      0.836      0.896      0.888     ]
2025-02-26T00:33:34.170176+0300 | INFO | Training epoch #186 on client #0
2025-02-26T00:33:34.172173+0300 | DEBUG | Saving model to flat file storage. Save #186
2025-02-26T00:33:34.324881+0300 | INFO | [186,     0] loss: 0.016
2025-02-26T00:33:45.088296+0300 | INFO | [186,   100] loss: 1.489
2025-02-26T00:33:56.306805+0300 | INFO | [186,   200] loss: 1.493
2025-02-26T00:34:08.153707+0300 | INFO | [186,   300] loss: 1.494
2025-02-26T00:34:18.588533+0300 | INFO | [186,   400] loss: 1.485
2025-02-26T00:34:29.189731+0300 | INFO | [186,   500] loss: 1.494
2025-02-26T00:34:39.286343+0300 | INFO | [186,   600] loss: 1.480
2025-02-26T00:34:49.968548+0300 | INFO | [186,   700] loss: 1.482
2025-02-26T00:35:00.488349+0300 | INFO | [186,   800] loss: 1.497
2025-02-26T00:35:10.441237+0300 | INFO | [186,   900] loss: 1.485
2025-02-26T00:35:21.240184+0300 | INFO | [186,  1000] loss: 1.486
2025-02-26T00:35:33.551165+0300 | INFO | [186,  1100] loss: 1.481
2025-02-26T00:35:43.260349+0300 | INFO | [186,  1200] loss: 1.492
2025-02-26T00:35:55.252475+0300 | INFO | [186,  1300] loss: 1.481
2025-02-26T00:36:05.917130+0300 | INFO | [186,  1400] loss: 1.496
2025-02-26T00:36:15.874667+0300 | INFO | [186,  1500] loss: 1.491
2025-02-26T00:36:27.184357+0300 | INFO | [186,  1600] loss: 1.484
2025-02-26T00:36:38.864989+0300 | INFO | [186,  1700] loss: 1.495
2025-02-26T00:36:49.375341+0300 | INFO | [186,  1800] loss: 1.486
2025-02-26T00:37:00.484570+0300 | INFO | [186,  1900] loss: 1.488
2025-02-26T00:37:11.534118+0300 | INFO | [186,  2000] loss: 1.478
2025-02-26T00:37:21.860515+0300 | INFO | [186,  2100] loss: 1.483
2025-02-26T00:37:32.327654+0300 | INFO | [186,  2200] loss: 1.497
2025-02-26T00:37:42.719737+0300 | INFO | [186,  2300] loss: 1.488
2025-02-26T00:37:53.189062+0300 | INFO | [186,  2400] loss: 1.487
2025-02-26T00:38:04.166517+0300 | INFO | [186,  2500] loss: 1.483
2025-02-26T00:38:15.864878+0300 | INFO | [186,  2600] loss: 1.480
2025-02-26T00:38:25.833587+0300 | INFO | [186,  2700] loss: 1.488
2025-02-26T00:38:36.500661+0300 | INFO | [186,  2800] loss: 1.490
2025-02-26T00:38:47.030360+0300 | INFO | [186,  2900] loss: 1.481
2025-02-26T00:38:57.267200+0300 | INFO | [186,  3000] loss: 1.487
2025-02-26T00:39:07.919366+0300 | INFO | [186,  3100] loss: 1.492
2025-02-26T00:39:18.438389+0300 | INFO | [186,  3200] loss: 1.488
2025-02-26T00:39:28.978591+0300 | INFO | [186,  3300] loss: 1.489
2025-02-26T00:39:39.606070+0300 | INFO | [186,  3400] loss: 1.484
2025-02-26T00:39:54.865691+0300 | INFO | [186,  3500] loss: 1.490
2025-02-26T00:40:06.126756+0300 | INFO | [186,  3600] loss: 1.487
2025-02-26T00:40:16.087213+0300 | INFO | [186,  3700] loss: 1.494
2025-02-26T00:40:26.641170+0300 | INFO | [186,  3800] loss: 1.488
2025-02-26T00:40:37.282792+0300 | INFO | [186,  3900] loss: 1.496
2025-02-26T00:40:47.353854+0300 | INFO | [186,  4000] loss: 1.485
2025-02-26T00:40:58.117776+0300 | INFO | [186,  4100] loss: 1.494
2025-02-26T00:41:09.488338+0300 | INFO | [186,  4200] loss: 1.486
2025-02-26T00:41:19.517182+0300 | INFO | [186,  4300] loss: 1.494
2025-02-26T00:41:30.284102+0300 | INFO | [186,  4400] loss: 1.489
2025-02-26T00:41:41.270873+0300 | INFO | [186,  4500] loss: 1.492
2025-02-26T00:41:51.178559+0300 | INFO | [186,  4600] loss: 1.491
2025-02-26T00:42:02.145410+0300 | INFO | [186,  4700] loss: 1.494
2025-02-26T00:42:12.874649+0300 | INFO | [186,  4800] loss: 1.492
2025-02-26T00:42:22.622599+0300 | INFO | [186,  4900] loss: 1.487
2025-02-26T00:42:34.012795+0300 | DEBUG | Saving model to flat file storage. Save #186
2025-02-26T00:42:34.037808+0300 | INFO | Averaging client parameters
2025-02-26T00:42:34.045794+0300 | INFO | Updating parameters on client #0
2025-02-26T00:42:49.747817+0300 | DEBUG | Test set: Accuracy: 7907/10000 (79%)
2025-02-26T00:42:49.748934+0300 | DEBUG | Test set: Loss: 1.669248104095459
2025-02-26T00:42:49.848575+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.76      0.70      0.73      1000
           3       0.65      0.58      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.51      0.62      0.56       800
           6       0.84      0.85      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T00:42:49.850599+0300 | DEBUG | Confusion Matrix:
[[845  13  40  15   8  11   3   8  37  20]
 [  8 918   1   4   1   0   6   1  15  46]
 [ 53   4 702  37  54  68  52  17   7   6]
 [ 26   6  50 699  59 266  46  21  12  15]
 [ 15   2  34  42 815  33  25  27   5   2]
 [ 10   2  42 172  30 496  12  30   4   2]
 [ 10   2  30  43  27  23 854   3   7   1]
 [ 19   1  14  40  54  55   5 807   2   3]
 [ 43  13   7   8   3   7   4   2 893  20]
 [ 23  44   6   8   2   5   4  11  19 878]]
2025-02-26T00:42:49.851602+0300 | DEBUG | Class precision: [0.80323194 0.91343284 0.75809935 0.65449438 0.77397911 0.51452282
 0.84470821 0.87055016 0.89210789 0.88418933]
2025-02-26T00:42:49.852593+0300 | DEBUG | Class recall: [0.845  0.918  0.702  0.5825 0.815  0.62   0.854  0.807  0.893  0.878 ]
2025-02-26T00:42:49.911730+0300 | INFO | Training epoch #187 on client #0
2025-02-26T00:42:49.913711+0300 | DEBUG | Saving model to flat file storage. Save #187
2025-02-26T00:42:50.039344+0300 | INFO | [187,     0] loss: 0.016
2025-02-26T00:43:00.698603+0300 | INFO | [187,   100] loss: 1.493
2025-02-26T00:43:10.800144+0300 | INFO | [187,   200] loss: 1.486
2025-02-26T00:43:21.551164+0300 | INFO | [187,   300] loss: 1.489
2025-02-26T00:43:32.552216+0300 | INFO | [187,   400] loss: 1.490
2025-02-26T00:43:42.276543+0300 | INFO | [187,   500] loss: 1.492
2025-02-26T00:43:52.931760+0300 | INFO | [187,   600] loss: 1.497
2025-02-26T00:44:03.244208+0300 | INFO | [187,   700] loss: 1.484
2025-02-26T00:44:15.020376+0300 | INFO | [187,   800] loss: 1.488
2025-02-26T00:44:25.881103+0300 | INFO | [187,   900] loss: 1.486
2025-02-26T00:44:36.407199+0300 | INFO | [187,  1000] loss: 1.484
2025-02-26T00:44:46.123458+0300 | INFO | [187,  1100] loss: 1.483
2025-02-26T00:44:56.434731+0300 | INFO | [187,  1200] loss: 1.492
2025-02-26T00:45:06.696669+0300 | INFO | [187,  1300] loss: 1.485
2025-02-26T00:45:17.017917+0300 | INFO | [187,  1400] loss: 1.489
2025-02-26T00:45:27.744361+0300 | INFO | [187,  1500] loss: 1.493
2025-02-26T00:45:38.425861+0300 | INFO | [187,  1600] loss: 1.493
2025-02-26T00:45:49.339332+0300 | INFO | [187,  1700] loss: 1.492
2025-02-26T00:45:59.725814+0300 | INFO | [187,  1800] loss: 1.484
2025-02-26T00:46:09.701403+0300 | INFO | [187,  1900] loss: 1.475
2025-02-26T00:46:20.090617+0300 | INFO | [187,  2000] loss: 1.493
2025-02-26T00:46:30.983044+0300 | INFO | [187,  2100] loss: 1.493
2025-02-26T00:46:41.670296+0300 | INFO | [187,  2200] loss: 1.487
2025-02-26T00:46:52.709795+0300 | INFO | [187,  2300] loss: 1.487
2025-02-26T00:47:03.358404+0300 | INFO | [187,  2400] loss: 1.491
2025-02-26T00:47:13.289506+0300 | INFO | [187,  2500] loss: 1.486
2025-02-26T00:47:24.083269+0300 | INFO | [187,  2600] loss: 1.488
2025-02-26T00:47:35.180232+0300 | INFO | [187,  2700] loss: 1.493
2025-02-26T00:47:45.868344+0300 | INFO | [187,  2800] loss: 1.488
2025-02-26T00:48:00.030800+0300 | INFO | [187,  2900] loss: 1.484
2025-02-26T00:48:14.875437+0300 | INFO | [187,  3000] loss: 1.494
2025-02-26T00:48:25.507457+0300 | INFO | [187,  3100] loss: 1.490
2025-02-26T00:48:36.057874+0300 | INFO | [187,  3200] loss: 1.490
2025-02-26T00:48:46.892960+0300 | INFO | [187,  3300] loss: 1.493
2025-02-26T00:48:57.573450+0300 | INFO | [187,  3400] loss: 1.495
2025-02-26T00:49:08.134530+0300 | INFO | [187,  3500] loss: 1.486
2025-02-26T00:49:18.269224+0300 | INFO | [187,  3600] loss: 1.487
2025-02-26T00:49:29.637895+0300 | INFO | [187,  3700] loss: 1.483
2025-02-26T00:49:40.638937+0300 | INFO | [187,  3800] loss: 1.492
2025-02-26T00:49:52.161737+0300 | INFO | [187,  3900] loss: 1.493
2025-02-26T00:50:02.395319+0300 | INFO | [187,  4000] loss: 1.486
2025-02-26T00:50:13.461903+0300 | INFO | [187,  4100] loss: 1.490
2025-02-26T00:50:25.008476+0300 | INFO | [187,  4200] loss: 1.495
2025-02-26T00:50:35.369221+0300 | INFO | [187,  4300] loss: 1.477
2025-02-26T00:50:46.195414+0300 | INFO | [187,  4400] loss: 1.488
2025-02-26T00:50:56.244521+0300 | INFO | [187,  4500] loss: 1.500
2025-02-26T00:51:06.934214+0300 | INFO | [187,  4600] loss: 1.485
2025-02-26T00:51:17.447052+0300 | INFO | [187,  4700] loss: 1.482
2025-02-26T00:51:29.394742+0300 | INFO | [187,  4800] loss: 1.487
2025-02-26T00:51:40.547203+0300 | INFO | [187,  4900] loss: 1.491
2025-02-26T00:51:51.106763+0300 | DEBUG | Saving model to flat file storage. Save #187
2025-02-26T00:51:51.128700+0300 | INFO | Averaging client parameters
2025-02-26T00:51:51.133713+0300 | INFO | Updating parameters on client #0
2025-02-26T00:52:07.070683+0300 | DEBUG | Test set: Accuracy: 7892/10000 (79%)
2025-02-26T00:52:07.072684+0300 | DEBUG | Test set: Loss: 1.6706459522247314
2025-02-26T00:52:07.170238+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.92      0.92      1000
           2       0.76      0.70      0.73      1000
           3       0.64      0.59      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.60      0.56       800
           6       0.82      0.88      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.91      0.88      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T00:52:07.173239+0300 | DEBUG | Confusion Matrix:
[[845  11  42  17  13  10   5   8  32  17]
 [ 11 919   1   5   2   0   8   1  11  42]
 [ 49   4 702  42  54  61  62  16   5   5]
 [ 26   5  52 710  64 250  50  20   9  14]
 [ 11   0  38  50 814  27  29  26   4   1]
 [ 12   2  38 183  28 479  21  33   3   1]
 [  8   2  28  38  23  17 875   3   5   1]
 [ 18   0  16  37  53  58   8 805   2   3]
 [ 51  14   8  10   4   7   4   3 878  21]
 [ 27  47   4   9   5   6   8  11  18 865]]
2025-02-26T00:52:07.174238+0300 | DEBUG | Class precision: [0.79867675 0.91533865 0.75565124 0.6448683  0.76792453 0.52349727
 0.81775701 0.86933045 0.90796277 0.89175258]
2025-02-26T00:52:07.176246+0300 | DEBUG | Class recall: [0.845      0.919      0.702      0.59166667 0.814      0.59875
 0.875      0.805      0.878      0.865     ]
2025-02-26T00:52:07.229248+0300 | INFO | Training epoch #188 on client #0
2025-02-26T00:52:07.231246+0300 | DEBUG | Saving model to flat file storage. Save #188
2025-02-26T00:52:07.376691+0300 | INFO | [188,     0] loss: 0.015
2025-02-26T00:52:17.473752+0300 | INFO | [188,   100] loss: 1.492
2025-02-26T00:52:28.205922+0300 | INFO | [188,   200] loss: 1.484
2025-02-26T00:52:38.927942+0300 | INFO | [188,   300] loss: 1.486
2025-02-26T00:52:48.599230+0300 | INFO | [188,   400] loss: 1.480
2025-02-26T00:53:00.719765+0300 | INFO | [188,   500] loss: 1.496
2025-02-26T00:53:11.979602+0300 | INFO | [188,   600] loss: 1.486
2025-02-26T00:53:21.883420+0300 | INFO | [188,   700] loss: 1.485
2025-02-26T00:53:32.520770+0300 | INFO | [188,   800] loss: 1.488
2025-02-26T00:53:43.052458+0300 | INFO | [188,   900] loss: 1.479
2025-02-26T00:53:52.985871+0300 | INFO | [188,  1000] loss: 1.499
2025-02-26T00:54:04.177475+0300 | INFO | [188,  1100] loss: 1.486
2025-02-26T00:54:14.849435+0300 | INFO | [188,  1200] loss: 1.484
2025-02-26T00:54:24.863689+0300 | INFO | [188,  1300] loss: 1.484
2025-02-26T00:54:35.452158+0300 | INFO | [188,  1400] loss: 1.497
2025-02-26T00:54:46.715944+0300 | INFO | [188,  1500] loss: 1.492
2025-02-26T00:54:56.544967+0300 | INFO | [188,  1600] loss: 1.492
2025-02-26T00:55:07.537320+0300 | INFO | [188,  1700] loss: 1.493
2025-02-26T00:55:18.226541+0300 | INFO | [188,  1800] loss: 1.483
2025-02-26T00:55:28.290764+0300 | INFO | [188,  1900] loss: 1.490
2025-02-26T00:55:38.867543+0300 | INFO | [188,  2000] loss: 1.490
2025-02-26T00:55:49.769501+0300 | INFO | [188,  2100] loss: 1.486
2025-02-26T00:55:59.814914+0300 | INFO | [188,  2200] loss: 1.481
2025-02-26T00:56:11.184633+0300 | INFO | [188,  2300] loss: 1.493
2025-02-26T00:56:22.007209+0300 | INFO | [188,  2400] loss: 1.481
2025-02-26T00:56:34.372569+0300 | INFO | [188,  2500] loss: 1.497
2025-02-26T00:56:48.651513+0300 | INFO | [188,  2600] loss: 1.492
2025-02-26T00:56:59.271784+0300 | INFO | [188,  2700] loss: 1.488
2025-02-26T00:57:10.161841+0300 | INFO | [188,  2800] loss: 1.488
2025-02-26T00:57:20.168549+0300 | INFO | [188,  2900] loss: 1.485
2025-02-26T00:57:30.805290+0300 | INFO | [188,  3000] loss: 1.496
2025-02-26T00:57:41.391604+0300 | INFO | [188,  3100] loss: 1.488
2025-02-26T00:57:52.150783+0300 | INFO | [188,  3200] loss: 1.490
2025-02-26T00:58:03.731189+0300 | INFO | [188,  3300] loss: 1.485
2025-02-26T00:58:14.435175+0300 | INFO | [188,  3400] loss: 1.495
2025-02-26T00:58:24.432985+0300 | INFO | [188,  3500] loss: 1.496
2025-02-26T00:58:34.802770+0300 | INFO | [188,  3600] loss: 1.487
2025-02-26T00:58:45.830113+0300 | INFO | [188,  3700] loss: 1.479
2025-02-26T00:58:55.919963+0300 | INFO | [188,  3800] loss: 1.484
2025-02-26T00:59:06.497299+0300 | INFO | [188,  3900] loss: 1.493
2025-02-26T00:59:17.337720+0300 | INFO | [188,  4000] loss: 1.485
2025-02-26T00:59:27.266964+0300 | INFO | [188,  4100] loss: 1.492
2025-02-26T00:59:37.728931+0300 | INFO | [188,  4200] loss: 1.501
2025-02-26T00:59:48.706107+0300 | INFO | [188,  4300] loss: 1.483
2025-02-26T00:59:58.744036+0300 | INFO | [188,  4400] loss: 1.484
2025-02-26T01:00:09.923918+0300 | INFO | [188,  4500] loss: 1.494
2025-02-26T01:00:20.756814+0300 | INFO | [188,  4600] loss: 1.492
2025-02-26T01:00:30.467869+0300 | INFO | [188,  4700] loss: 1.483
2025-02-26T01:00:41.867810+0300 | INFO | [188,  4800] loss: 1.491
2025-02-26T01:00:53.478435+0300 | INFO | [188,  4900] loss: 1.485
2025-02-26T01:01:03.090861+0300 | DEBUG | Saving model to flat file storage. Save #188
2025-02-26T01:01:03.108848+0300 | INFO | Averaging client parameters
2025-02-26T01:01:03.115847+0300 | INFO | Updating parameters on client #0
2025-02-26T01:01:19.038622+0300 | DEBUG | Test set: Accuracy: 7899/10000 (79%)
2025-02-26T01:01:19.039622+0300 | DEBUG | Test set: Loss: 1.670766830444336
2025-02-26T01:01:19.129923+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.67      0.57      0.62      1200
           4       0.75      0.84      0.79      1000
           5       0.52      0.62      0.57       800
           6       0.82      0.87      0.84      1000
           7       0.86      0.81      0.83      1000
           8       0.90      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:01:19.131910+0300 | DEBUG | Confusion Matrix:
[[843  12  41  16  12   8   4   8  36  20]
 [  9 912   0   4   1   0   8   1  16  49]
 [ 54   4 676  38  67  69  59  19   6   8]
 [ 25   7  47 690  71 259  51  24  10  16]
 [  9   2  28  33 838  28  28  27   5   2]
 [ 11   0  33 168  30 494  22  36   4   2]
 [  8   2  29  36  25  20 870   3   5   2]
 [ 16   0  12  32  60  57   8 810   2   3]
 [ 49  12   5   6   4   7   5   3 888  21]
 [ 24  43   2   6   5   6   6  10  20 878]]
2025-02-26T01:01:19.134909+0300 | DEBUG | Class precision: [0.80438931 0.91750503 0.77434135 0.67055394 0.75292004 0.52109705
 0.81998115 0.8607864  0.89516129 0.87712288]
2025-02-26T01:01:19.135910+0300 | DEBUG | Class recall: [0.843  0.912  0.676  0.575  0.838  0.6175 0.87   0.81   0.888  0.878 ]
2025-02-26T01:01:19.184674+0300 | INFO | Training epoch #189 on client #0
2025-02-26T01:01:19.185673+0300 | DEBUG | Saving model to flat file storage. Save #189
2025-02-26T01:01:19.328461+0300 | INFO | [189,     0] loss: 0.015
2025-02-26T01:01:30.233995+0300 | INFO | [189,   100] loss: 1.494
2025-02-26T01:01:40.801476+0300 | INFO | [189,   200] loss: 1.481
2025-02-26T01:01:50.580977+0300 | INFO | [189,   300] loss: 1.487
2025-02-26T01:02:01.343615+0300 | INFO | [189,   400] loss: 1.486
2025-02-26T01:02:12.225171+0300 | INFO | [189,   500] loss: 1.479
2025-02-26T01:02:22.010036+0300 | INFO | [189,   600] loss: 1.491
2025-02-26T01:02:32.865194+0300 | INFO | [189,   700] loss: 1.485
2025-02-26T01:02:43.751607+0300 | INFO | [189,   800] loss: 1.490
2025-02-26T01:02:53.717959+0300 | INFO | [189,   900] loss: 1.491
2025-02-26T01:03:04.647941+0300 | INFO | [189,  1000] loss: 1.477
2025-02-26T01:03:14.879893+0300 | INFO | [189,  1100] loss: 1.486
2025-02-26T01:03:26.204679+0300 | INFO | [189,  1200] loss: 1.496
2025-02-26T01:03:36.537393+0300 | INFO | [189,  1300] loss: 1.491
2025-02-26T01:03:46.970100+0300 | INFO | [189,  1400] loss: 1.484
2025-02-26T01:03:58.325720+0300 | INFO | [189,  1500] loss: 1.487
2025-02-26T01:04:08.832887+0300 | INFO | [189,  1600] loss: 1.485
2025-02-26T01:04:19.472832+0300 | INFO | [189,  1700] loss: 1.500
2025-02-26T01:04:29.652189+0300 | INFO | [189,  1800] loss: 1.484
2025-02-26T01:04:40.101368+0300 | INFO | [189,  1900] loss: 1.485
2025-02-26T01:04:52.266174+0300 | INFO | [189,  2000] loss: 1.490
2025-02-26T01:05:05.469751+0300 | INFO | [189,  2100] loss: 1.498
2025-02-26T01:05:16.126183+0300 | INFO | [189,  2200] loss: 1.483
2025-02-26T01:05:27.107653+0300 | INFO | [189,  2300] loss: 1.500
2025-02-26T01:05:36.914546+0300 | INFO | [189,  2400] loss: 1.487
2025-02-26T01:05:48.140149+0300 | INFO | [189,  2500] loss: 1.486
2025-02-26T01:05:59.420826+0300 | INFO | [189,  2600] loss: 1.486
2025-02-26T01:06:09.470649+0300 | INFO | [189,  2700] loss: 1.480
2025-02-26T01:06:20.156168+0300 | INFO | [189,  2800] loss: 1.489
2025-02-26T01:06:31.368364+0300 | INFO | [189,  2900] loss: 1.490
2025-02-26T01:06:42.154882+0300 | INFO | [189,  3000] loss: 1.502
2025-02-26T01:06:53.327348+0300 | INFO | [189,  3100] loss: 1.491
2025-02-26T01:07:06.911118+0300 | INFO | [189,  3200] loss: 1.491
2025-02-26T01:07:17.802264+0300 | INFO | [189,  3300] loss: 1.489
2025-02-26T01:07:27.981043+0300 | INFO | [189,  3400] loss: 1.484
2025-02-26T01:07:38.907087+0300 | INFO | [189,  3500] loss: 1.485
2025-02-26T01:07:49.761525+0300 | INFO | [189,  3600] loss: 1.493
2025-02-26T01:08:00.096596+0300 | INFO | [189,  3700] loss: 1.487
2025-02-26T01:08:12.427892+0300 | INFO | [189,  3800] loss: 1.492
2025-02-26T01:08:23.257714+0300 | INFO | [189,  3900] loss: 1.485
2025-02-26T01:08:33.436016+0300 | INFO | [189,  4000] loss: 1.494
2025-02-26T01:08:44.276717+0300 | INFO | [189,  4100] loss: 1.493
2025-02-26T01:08:55.148749+0300 | INFO | [189,  4200] loss: 1.485
2025-02-26T01:09:05.571522+0300 | INFO | [189,  4300] loss: 1.490
2025-02-26T01:09:16.428996+0300 | INFO | [189,  4400] loss: 1.484
2025-02-26T01:09:27.072083+0300 | INFO | [189,  4500] loss: 1.497
2025-02-26T01:09:36.700159+0300 | INFO | [189,  4600] loss: 1.484
2025-02-26T01:09:47.039107+0300 | INFO | [189,  4700] loss: 1.486
2025-02-26T01:09:58.004799+0300 | INFO | [189,  4800] loss: 1.491
2025-02-26T01:10:08.769873+0300 | INFO | [189,  4900] loss: 1.483
2025-02-26T01:10:19.590326+0300 | DEBUG | Saving model to flat file storage. Save #189
2025-02-26T01:10:19.619197+0300 | INFO | Averaging client parameters
2025-02-26T01:10:19.629654+0300 | INFO | Updating parameters on client #0
2025-02-26T01:10:35.133879+0300 | DEBUG | Test set: Accuracy: 7915/10000 (79%)
2025-02-26T01:10:35.135881+0300 | DEBUG | Test set: Loss: 1.6684640645980835
2025-02-26T01:10:35.241394+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1000
           1       0.92      0.92      0.92      1000
           2       0.77      0.69      0.73      1000
           3       0.67      0.58      0.62      1200
           4       0.76      0.82      0.79      1000
           5       0.53      0.61      0.57       800
           6       0.83      0.87      0.85      1000
           7       0.87      0.81      0.83      1000
           8       0.90      0.89      0.90      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:10:35.243396+0300 | DEBUG | Confusion Matrix:
[[864  11  33  13   9  11   3   7  30  19]
 [ 10 918   1   5   1   0   6   1  15  43]
 [ 57   4 691  36  60  59  60  18   7   8]
 [ 31   5  51 700  64 251  48  25  10  15]
 [ 18   2  32  41 820  27  29  26   4   1]
 [ 11   0  39 170  31 491  21  33   2   2]
 [ 10   2  32  39  25  14 868   2   6   2]
 [ 22   0  12  35  57  57   7 805   2   3]
 [ 55  12   4   5   3   6   5   2 887  21]
 [ 32  46   3   7   3   5   4  10  19 871]]
2025-02-26T01:10:35.246299+0300 | DEBUG | Class precision: [0.77837838 0.918      0.76948775 0.66603235 0.76421249 0.53311618
 0.82588011 0.86652314 0.90325866 0.88426396]
2025-02-26T01:10:35.248310+0300 | DEBUG | Class recall: [0.864      0.918      0.691      0.58333333 0.82       0.61375
 0.868      0.805      0.887      0.871     ]
2025-02-26T01:10:35.297319+0300 | INFO | Training epoch #190 on client #0
2025-02-26T01:10:35.298321+0300 | DEBUG | Saving model to flat file storage. Save #190
2025-02-26T01:10:35.437992+0300 | INFO | [190,     0] loss: 0.015
2025-02-26T01:10:46.253212+0300 | INFO | [190,   100] loss: 1.480
2025-02-26T01:10:56.169021+0300 | INFO | [190,   200] loss: 1.484
2025-02-26T01:11:06.812121+0300 | INFO | [190,   300] loss: 1.489
2025-02-26T01:11:17.716872+0300 | INFO | [190,   400] loss: 1.495
2025-02-26T01:11:27.577829+0300 | INFO | [190,   500] loss: 1.495
2025-02-26T01:11:38.097797+0300 | INFO | [190,   600] loss: 1.495
2025-02-26T01:11:48.663639+0300 | INFO | [190,   700] loss: 1.490
2025-02-26T01:11:58.652198+0300 | INFO | [190,   800] loss: 1.492
2025-02-26T01:12:09.424596+0300 | INFO | [190,   900] loss: 1.487
2025-02-26T01:12:20.194239+0300 | INFO | [190,  1000] loss: 1.489
2025-02-26T01:12:30.150931+0300 | INFO | [190,  1100] loss: 1.487
2025-02-26T01:12:42.614572+0300 | INFO | [190,  1200] loss: 1.494
2025-02-26T01:12:53.124837+0300 | INFO | [190,  1300] loss: 1.486
2025-02-26T01:13:03.604143+0300 | INFO | [190,  1400] loss: 1.494
2025-02-26T01:13:16.583696+0300 | INFO | [190,  1500] loss: 1.494
2025-02-26T01:13:28.403926+0300 | INFO | [190,  1600] loss: 1.488
2025-02-26T01:13:36.608030+0300 | INFO | [190,  1700] loss: 1.491
2025-02-26T01:13:47.529419+0300 | INFO | [190,  1800] loss: 1.493
2025-02-26T01:13:58.078820+0300 | INFO | [190,  1900] loss: 1.488
2025-02-26T01:14:08.022142+0300 | INFO | [190,  2000] loss: 1.484
2025-02-26T01:14:18.852937+0300 | INFO | [190,  2100] loss: 1.484
2025-02-26T01:14:29.320972+0300 | INFO | [190,  2200] loss: 1.481
2025-02-26T01:14:38.954801+0300 | INFO | [190,  2300] loss: 1.493
2025-02-26T01:14:49.740541+0300 | INFO | [190,  2400] loss: 1.484
2025-02-26T01:15:00.272053+0300 | INFO | [190,  2500] loss: 1.481
2025-02-26T01:15:10.117724+0300 | INFO | [190,  2600] loss: 1.488
2025-02-26T01:15:20.836848+0300 | INFO | [190,  2700] loss: 1.490
2025-02-26T01:15:30.958151+0300 | INFO | [190,  2800] loss: 1.493
2025-02-26T01:15:40.799591+0300 | INFO | [190,  2900] loss: 1.493
2025-02-26T01:15:51.695665+0300 | INFO | [190,  3000] loss: 1.494
2025-02-26T01:16:02.391150+0300 | INFO | [190,  3100] loss: 1.484
2025-02-26T01:16:13.135426+0300 | INFO | [190,  3200] loss: 1.486
2025-02-26T01:16:23.511400+0300 | INFO | [190,  3300] loss: 1.482
2025-02-26T01:16:33.619358+0300 | INFO | [190,  3400] loss: 1.480
2025-02-26T01:16:44.251463+0300 | INFO | [190,  3500] loss: 1.507
2025-02-26T01:16:54.658630+0300 | INFO | [190,  3600] loss: 1.487
2025-02-26T01:17:04.759199+0300 | INFO | [190,  3700] loss: 1.485
2025-02-26T01:17:15.402710+0300 | INFO | [190,  3800] loss: 1.490
2025-02-26T01:17:25.771248+0300 | INFO | [190,  3900] loss: 1.484
2025-02-26T01:17:35.500973+0300 | INFO | [190,  4000] loss: 1.487
2025-02-26T01:17:46.674560+0300 | INFO | [190,  4100] loss: 1.489
2025-02-26T01:17:57.530983+0300 | INFO | [190,  4200] loss: 1.488
2025-02-26T01:18:07.382206+0300 | INFO | [190,  4300] loss: 1.489
2025-02-26T01:18:17.985747+0300 | INFO | [190,  4400] loss: 1.488
2025-02-26T01:18:28.513710+0300 | INFO | [190,  4500] loss: 1.480
2025-02-26T01:18:38.060655+0300 | INFO | [190,  4600] loss: 1.491
2025-02-26T01:18:48.657888+0300 | INFO | [190,  4700] loss: 1.488
2025-02-26T01:19:00.199974+0300 | INFO | [190,  4800] loss: 1.492
2025-02-26T01:19:09.927842+0300 | INFO | [190,  4900] loss: 1.495
2025-02-26T01:19:20.414963+0300 | DEBUG | Saving model to flat file storage. Save #190
2025-02-26T01:19:20.441499+0300 | INFO | Averaging client parameters
2025-02-26T01:19:20.447504+0300 | INFO | Updating parameters on client #0
2025-02-26T01:19:36.999821+0300 | DEBUG | Test set: Accuracy: 7903/10000 (79%)
2025-02-26T01:19:36.999821+0300 | DEBUG | Test set: Loss: 1.6698060035705566
2025-02-26T01:19:37.108078+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.90      0.93      0.92      1000
           2       0.76      0.69      0.73      1000
           3       0.66      0.58      0.62      1200
           4       0.76      0.82      0.79      1000
           5       0.53      0.61      0.57       800
           6       0.82      0.86      0.84      1000
           7       0.86      0.81      0.83      1000
           8       0.91      0.88      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:19:37.113099+0300 | DEBUG | Confusion Matrix:
[[853  13  42  16  10   7   2   8  30  19]
 [  9 928   0   5   1   0   6   1  11  39]
 [ 58   4 694  34  61  57  57  22   6   7]
 [ 29   7  52 694  60 257  53  24   9  15]
 [ 13   2  29  42 819  28  33  28   4   2]
 [ 10   1  41 172  30 488  19  35   2   2]
 [ 12   2  32  38  27  17 864   2   4   2]
 [ 18   2  12  35  56  52   6 811   2   6]
 [ 52  18   6   6   4   5   5   3 880  21]
 [ 27  51   4   7   3   3   6   9  18 872]]
2025-02-26T01:19:37.115102+0300 | DEBUG | Class precision: [0.78908418 0.90272374 0.76096491 0.66158246 0.76470588 0.53391685
 0.82207422 0.86002121 0.91097308 0.88527919]
2025-02-26T01:19:37.115102+0300 | DEBUG | Class recall: [0.853      0.928      0.694      0.57833333 0.819      0.61
 0.864      0.811      0.88       0.872     ]
2025-02-26T01:19:37.158855+0300 | INFO | Training epoch #191 on client #0
2025-02-26T01:19:37.160860+0300 | DEBUG | Saving model to flat file storage. Save #191
2025-02-26T01:19:37.305919+0300 | INFO | [191,     0] loss: 0.015
2025-02-26T01:19:47.416779+0300 | INFO | [191,   100] loss: 1.480
2025-02-26T01:19:57.481562+0300 | INFO | [191,   200] loss: 1.497
2025-02-26T01:20:08.122154+0300 | INFO | [191,   300] loss: 1.488
2025-02-26T01:20:17.774130+0300 | INFO | [191,   400] loss: 1.486
2025-02-26T01:20:28.285859+0300 | INFO | [191,   500] loss: 1.484
2025-02-26T01:20:43.848979+0300 | INFO | [191,   600] loss: 1.491
2025-02-26T01:20:55.532340+0300 | INFO | [191,   700] loss: 1.493
2025-02-26T01:21:05.423680+0300 | INFO | [191,   800] loss: 1.500
2025-02-26T01:21:15.846135+0300 | INFO | [191,   900] loss: 1.484
2025-02-26T01:21:26.546851+0300 | INFO | [191,  1000] loss: 1.490
2025-02-26T01:21:36.641200+0300 | INFO | [191,  1100] loss: 1.489
2025-02-26T01:21:47.168319+0300 | INFO | [191,  1200] loss: 1.493
2025-02-26T01:21:58.006405+0300 | INFO | [191,  1300] loss: 1.488
2025-02-26T01:22:08.521294+0300 | INFO | [191,  1400] loss: 1.496
2025-02-26T01:22:19.878278+0300 | INFO | [191,  1500] loss: 1.482
2025-02-26T01:22:31.373109+0300 | INFO | [191,  1600] loss: 1.492
2025-02-26T01:22:42.256882+0300 | INFO | [191,  1700] loss: 1.485
2025-02-26T01:22:53.166325+0300 | INFO | [191,  1800] loss: 1.490
2025-02-26T01:23:04.791070+0300 | INFO | [191,  1900] loss: 1.494
2025-02-26T01:23:16.717851+0300 | INFO | [191,  2000] loss: 1.498
2025-02-26T01:23:27.690499+0300 | INFO | [191,  2100] loss: 1.489
2025-02-26T01:23:38.901613+0300 | INFO | [191,  2200] loss: 1.480
2025-02-26T01:23:50.064721+0300 | INFO | [191,  2300] loss: 1.497
2025-02-26T01:24:01.030276+0300 | INFO | [191,  2400] loss: 1.492
2025-02-26T01:24:12.140056+0300 | INFO | [191,  2500] loss: 1.486
2025-02-26T01:24:23.384256+0300 | INFO | [191,  2600] loss: 1.484
2025-02-26T01:24:34.022123+0300 | INFO | [191,  2700] loss: 1.478
2025-02-26T01:24:45.162558+0300 | INFO | [191,  2800] loss: 1.490
2025-02-26T01:24:56.307958+0300 | INFO | [191,  2900] loss: 1.487
2025-02-26T01:25:08.032243+0300 | INFO | [191,  3000] loss: 1.485
2025-02-26T01:25:19.689374+0300 | INFO | [191,  3100] loss: 1.485
2025-02-26T01:25:30.483949+0300 | INFO | [191,  3200] loss: 1.493
2025-02-26T01:25:41.458338+0300 | INFO | [191,  3300] loss: 1.494
2025-02-26T01:25:51.158794+0300 | INFO | [191,  3400] loss: 1.491
2025-02-26T01:26:01.629892+0300 | INFO | [191,  3500] loss: 1.483
2025-02-26T01:26:12.344996+0300 | INFO | [191,  3600] loss: 1.495
2025-02-26T01:26:22.489633+0300 | INFO | [191,  3700] loss: 1.488
2025-02-26T01:26:33.222461+0300 | INFO | [191,  3800] loss: 1.480
2025-02-26T01:26:43.533403+0300 | INFO | [191,  3900] loss: 1.494
2025-02-26T01:26:53.234981+0300 | INFO | [191,  4000] loss: 1.492
2025-02-26T01:27:03.974472+0300 | INFO | [191,  4100] loss: 1.489
2025-02-26T01:27:13.997605+0300 | INFO | [191,  4200] loss: 1.483
2025-02-26T01:27:24.576664+0300 | INFO | [191,  4300] loss: 1.490
2025-02-26T01:27:35.224685+0300 | INFO | [191,  4400] loss: 1.492
2025-02-26T01:27:44.996811+0300 | INFO | [191,  4500] loss: 1.483
2025-02-26T01:27:56.842254+0300 | INFO | [191,  4600] loss: 1.487
2025-02-26T01:28:11.298728+0300 | INFO | [191,  4700] loss: 1.491
2025-02-26T01:28:23.007442+0300 | INFO | [191,  4800] loss: 1.492
2025-02-26T01:28:32.803138+0300 | INFO | [191,  4900] loss: 1.481
2025-02-26T01:28:43.198419+0300 | DEBUG | Saving model to flat file storage. Save #191
2025-02-26T01:28:43.219509+0300 | INFO | Averaging client parameters
2025-02-26T01:28:43.229235+0300 | INFO | Updating parameters on client #0
2025-02-26T01:28:58.313130+0300 | DEBUG | Test set: Accuracy: 7908/10000 (79%)
2025-02-26T01:28:58.314130+0300 | DEBUG | Test set: Loss: 1.6694984436035156
2025-02-26T01:28:58.404338+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.91      0.93      0.92      1000
           2       0.77      0.68      0.72      1000
           3       0.67      0.58      0.62      1200
           4       0.77      0.82      0.79      1000
           5       0.52      0.64      0.58       800
           6       0.83      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.88      0.89      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:28:58.407338+0300 | DEBUG | Confusion Matrix:
[[842  10  39  16  13  10   4   9  38  19]
 [  9 927   0   3   0   0   7   1  18  35]
 [ 58   4 676  37  65  65  60  22   7   6]
 [ 29   4  49 693  58 269  46  27  12  13]
 [ 12   1  31  42 817  36  28  27   4   2]
 [ 11   1  35 152  29 515  16  33   5   3]
 [ 10   2  28  38  25  23 865   3   4   2]
 [ 16   2  10  32  51  54   4 824   4   3]
 [ 48  15   5   7   4   5   4   3 891  18]
 [ 27  55   4   7   5   6   3  11  24 858]]
2025-02-26T01:28:58.408340+0300 | DEBUG | Class precision: [0.79284369 0.9079334  0.77080958 0.67478092 0.76569822 0.52390641
 0.83413693 0.85833333 0.88480636 0.89468196]
2025-02-26T01:28:58.410338+0300 | DEBUG | Class recall: [0.842   0.927   0.676   0.5775  0.817   0.64375 0.865   0.824   0.891
 0.858  ]
2025-02-26T01:28:58.455075+0300 | INFO | Training epoch #192 on client #0
2025-02-26T01:28:58.458076+0300 | DEBUG | Saving model to flat file storage. Save #192
2025-02-26T01:28:58.574444+0300 | INFO | [192,     0] loss: 0.017
2025-02-26T01:29:09.339827+0300 | INFO | [192,   100] loss: 1.489
2025-02-26T01:29:19.240270+0300 | INFO | [192,   200] loss: 1.489
2025-02-26T01:29:29.792856+0300 | INFO | [192,   300] loss: 1.485
2025-02-26T01:29:40.111197+0300 | INFO | [192,   400] loss: 1.487
2025-02-26T01:29:50.215511+0300 | INFO | [192,   500] loss: 1.484
2025-02-26T01:30:00.826003+0300 | INFO | [192,   600] loss: 1.493
2025-02-26T01:30:11.456499+0300 | INFO | [192,   700] loss: 1.489
2025-02-26T01:30:21.676924+0300 | INFO | [192,   800] loss: 1.490
2025-02-26T01:30:32.774389+0300 | INFO | [192,   900] loss: 1.496
2025-02-26T01:30:43.332843+0300 | INFO | [192,  1000] loss: 1.489
2025-02-26T01:30:53.359237+0300 | INFO | [192,  1100] loss: 1.490
2025-02-26T01:31:04.150762+0300 | INFO | [192,  1200] loss: 1.486
2025-02-26T01:31:14.214867+0300 | INFO | [192,  1300] loss: 1.486
2025-02-26T01:31:25.402059+0300 | INFO | [192,  1400] loss: 1.500
2025-02-26T01:31:36.152476+0300 | INFO | [192,  1500] loss: 1.491
2025-02-26T01:31:46.315491+0300 | INFO | [192,  1600] loss: 1.486
2025-02-26T01:31:56.619840+0300 | INFO | [192,  1700] loss: 1.496
2025-02-26T01:32:07.191013+0300 | INFO | [192,  1800] loss: 1.479
2025-02-26T01:32:17.142864+0300 | INFO | [192,  1900] loss: 1.487
2025-02-26T01:32:27.712922+0300 | INFO | [192,  2000] loss: 1.497
2025-02-26T01:32:38.152807+0300 | INFO | [192,  2100] loss: 1.484
2025-02-26T01:32:48.236070+0300 | INFO | [192,  2200] loss: 1.494
2025-02-26T01:32:58.399380+0300 | INFO | [192,  2300] loss: 1.484
2025-02-26T01:33:08.868462+0300 | INFO | [192,  2400] loss: 1.483
2025-02-26T01:33:18.851098+0300 | INFO | [192,  2500] loss: 1.489
2025-02-26T01:33:29.316639+0300 | INFO | [192,  2600] loss: 1.488
2025-02-26T01:33:40.006941+0300 | INFO | [192,  2700] loss: 1.487
2025-02-26T01:33:50.650201+0300 | INFO | [192,  2800] loss: 1.486
2025-02-26T01:34:01.396691+0300 | INFO | [192,  2900] loss: 1.485
2025-02-26T01:34:12.051695+0300 | INFO | [192,  3000] loss: 1.502
2025-02-26T01:34:22.753629+0300 | INFO | [192,  3100] loss: 1.498
2025-02-26T01:34:33.131919+0300 | INFO | [192,  3200] loss: 1.483
2025-02-26T01:34:43.083644+0300 | INFO | [192,  3300] loss: 1.484
2025-02-26T01:34:52.956109+0300 | INFO | [192,  3400] loss: 1.482
2025-02-26T01:35:03.371191+0300 | INFO | [192,  3500] loss: 1.484
2025-02-26T01:35:18.325322+0300 | INFO | [192,  3600] loss: 1.487
2025-02-26T01:35:29.129444+0300 | INFO | [192,  3700] loss: 1.488
2025-02-26T01:35:39.486378+0300 | INFO | [192,  3800] loss: 1.487
2025-02-26T01:35:50.404619+0300 | INFO | [192,  3900] loss: 1.486
2025-02-26T01:36:00.475918+0300 | INFO | [192,  4000] loss: 1.485
2025-02-26T01:36:11.216720+0300 | INFO | [192,  4100] loss: 1.489
2025-02-26T01:36:21.916139+0300 | INFO | [192,  4200] loss: 1.484
2025-02-26T01:36:31.996667+0300 | INFO | [192,  4300] loss: 1.490
2025-02-26T01:36:43.580291+0300 | INFO | [192,  4400] loss: 1.487
2025-02-26T01:36:54.779611+0300 | INFO | [192,  4500] loss: 1.486
2025-02-26T01:37:05.365978+0300 | INFO | [192,  4600] loss: 1.500
2025-02-26T01:37:17.594097+0300 | INFO | [192,  4700] loss: 1.492
2025-02-26T01:37:29.453470+0300 | INFO | [192,  4800] loss: 1.488
2025-02-26T01:37:40.045131+0300 | INFO | [192,  4900] loss: 1.492
2025-02-26T01:37:50.422606+0300 | DEBUG | Saving model to flat file storage. Save #192
2025-02-26T01:37:50.444620+0300 | INFO | Averaging client parameters
2025-02-26T01:37:50.450914+0300 | INFO | Updating parameters on client #0
2025-02-26T01:38:06.507263+0300 | DEBUG | Test set: Accuracy: 7892/10000 (79%)
2025-02-26T01:38:06.509720+0300 | DEBUG | Test set: Loss: 1.670634150505066
2025-02-26T01:38:06.635670+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.92      0.91      0.92      1000
           2       0.76      0.68      0.72      1000
           3       0.65      0.59      0.62      1200
           4       0.76      0.82      0.79      1000
           5       0.51      0.60      0.55       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.90      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:38:06.640663+0300 | DEBUG | Confusion Matrix:
[[837  10  42  18  15   9   3   9  38  19]
 [ 10 911   0   4   2   1   9   1  18  44]
 [ 50   3 677  45  60  75  56  22   5   7]
 [ 32   4  48 707  61 253  46  24  10  15]
 [ 10   1  35  40 823  33  23  29   4   2]
 [ 11   0  34 185  35 483  14  31   4   3]
 [  8   1  30  45  24  19 863   3   5   2]
 [ 15   1  13  37  52  57   3 816   3   3]
 [ 42  13   5   5   5   6   4   5 896  19]
 [ 23  43   4   8   4   6   3  10  20 879]]
2025-02-26T01:38:06.643666+0300 | DEBUG | Class precision: [0.80635838 0.92299899 0.76238739 0.64625229 0.7613321  0.51273885
 0.84277344 0.85894737 0.89332004 0.88519637]
2025-02-26T01:38:06.645667+0300 | DEBUG | Class recall: [0.837      0.911      0.677      0.58916667 0.823      0.60375
 0.863      0.816      0.896      0.879     ]
2025-02-26T01:38:06.716791+0300 | INFO | Training epoch #193 on client #0
2025-02-26T01:38:06.718795+0300 | DEBUG | Saving model to flat file storage. Save #193
2025-02-26T01:38:06.921943+0300 | INFO | [193,     0] loss: 0.015
2025-02-26T01:38:18.023860+0300 | INFO | [193,   100] loss: 1.491
2025-02-26T01:38:28.623203+0300 | INFO | [193,   200] loss: 1.496
2025-02-26T01:38:38.355695+0300 | INFO | [193,   300] loss: 1.481
2025-02-26T01:38:48.987536+0300 | INFO | [193,   400] loss: 1.483
2025-02-26T01:38:59.430541+0300 | INFO | [193,   500] loss: 1.490
2025-02-26T01:39:09.663584+0300 | INFO | [193,   600] loss: 1.491
2025-02-26T01:39:20.379847+0300 | INFO | [193,   700] loss: 1.490
2025-02-26T01:39:30.151018+0300 | INFO | [193,   800] loss: 1.482
2025-02-26T01:39:41.046274+0300 | INFO | [193,   900] loss: 1.483
2025-02-26T01:39:51.526522+0300 | INFO | [193,  1000] loss: 1.495
2025-02-26T01:40:01.490316+0300 | INFO | [193,  1100] loss: 1.492
2025-02-26T01:40:12.378349+0300 | INFO | [193,  1200] loss: 1.486
2025-02-26T01:40:22.848171+0300 | INFO | [193,  1300] loss: 1.482
2025-02-26T01:40:33.217757+0300 | INFO | [193,  1400] loss: 1.498
2025-02-26T01:40:44.046317+0300 | INFO | [193,  1500] loss: 1.482
2025-02-26T01:40:54.769770+0300 | INFO | [193,  1600] loss: 1.490
2025-02-26T01:41:04.568341+0300 | INFO | [193,  1700] loss: 1.489
2025-02-26T01:41:15.219640+0300 | INFO | [193,  1800] loss: 1.488
2025-02-26T01:41:25.611131+0300 | INFO | [193,  1900] loss: 1.491
2025-02-26T01:41:36.265900+0300 | INFO | [193,  2000] loss: 1.482
2025-02-26T01:41:46.630783+0300 | INFO | [193,  2100] loss: 1.486
2025-02-26T01:41:57.292656+0300 | INFO | [193,  2200] loss: 1.479
2025-02-26T01:42:07.255109+0300 | INFO | [193,  2300] loss: 1.496
2025-02-26T01:42:17.979329+0300 | INFO | [193,  2400] loss: 1.480
2025-02-26T01:42:29.917441+0300 | INFO | [193,  2500] loss: 1.486
2025-02-26T01:42:44.189637+0300 | INFO | [193,  2600] loss: 1.487
2025-02-26T01:42:53.972296+0300 | INFO | [193,  2700] loss: 1.496
2025-02-26T01:43:04.767908+0300 | INFO | [193,  2800] loss: 1.490
2025-02-26T01:43:14.806169+0300 | INFO | [193,  2900] loss: 1.492
2025-02-26T01:43:25.250280+0300 | INFO | [193,  3000] loss: 1.476
2025-02-26T01:43:37.206597+0300 | INFO | [193,  3100] loss: 1.496
2025-02-26T01:43:48.262786+0300 | INFO | [193,  3200] loss: 1.487
2025-02-26T01:43:57.882601+0300 | INFO | [193,  3300] loss: 1.481
2025-02-26T01:44:10.430049+0300 | INFO | [193,  3400] loss: 1.495
2025-02-26T01:44:21.238409+0300 | INFO | [193,  3500] loss: 1.493
2025-02-26T01:44:31.497982+0300 | INFO | [193,  3600] loss: 1.494
2025-02-26T01:44:42.144920+0300 | INFO | [193,  3700] loss: 1.492
2025-02-26T01:44:52.829640+0300 | INFO | [193,  3800] loss: 1.487
2025-02-26T01:45:02.650786+0300 | INFO | [193,  3900] loss: 1.491
2025-02-26T01:45:13.158059+0300 | INFO | [193,  4000] loss: 1.485
2025-02-26T01:45:23.844148+0300 | INFO | [193,  4100] loss: 1.490
2025-02-26T01:45:33.550910+0300 | INFO | [193,  4200] loss: 1.485
2025-02-26T01:45:44.276829+0300 | INFO | [193,  4300] loss: 1.485
2025-02-26T01:45:54.187992+0300 | INFO | [193,  4400] loss: 1.484
2025-02-26T01:46:04.526411+0300 | INFO | [193,  4500] loss: 1.488
2025-02-26T01:46:15.081875+0300 | INFO | [193,  4600] loss: 1.494
2025-02-26T01:46:25.140729+0300 | INFO | [193,  4700] loss: 1.492
2025-02-26T01:46:36.994290+0300 | INFO | [193,  4800] loss: 1.494
2025-02-26T01:46:47.838436+0300 | INFO | [193,  4900] loss: 1.495
2025-02-26T01:46:57.477566+0300 | DEBUG | Saving model to flat file storage. Save #193
2025-02-26T01:46:57.496565+0300 | INFO | Averaging client parameters
2025-02-26T01:46:57.505996+0300 | INFO | Updating parameters on client #0
2025-02-26T01:47:13.258925+0300 | DEBUG | Test set: Accuracy: 7869/10000 (79%)
2025-02-26T01:47:13.260233+0300 | DEBUG | Test set: Loss: 1.6730574369430542
2025-02-26T01:47:13.354239+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.86      0.82      1000
           1       0.90      0.93      0.92      1000
           2       0.78      0.67      0.72      1000
           3       0.62      0.61      0.61      1200
           4       0.78      0.80      0.79      1000
           5       0.51      0.58      0.54       800
           6       0.84      0.86      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.91      0.88      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:47:13.358333+0300 | DEBUG | Confusion Matrix:
[[863   9  36  13   9  10   4   7  29  20]
 [  8 933   1   3   1   1   7   1  11  34]
 [ 58   3 670  54  59  72  53  21   4   6]
 [ 34   6  44 730  51 244  44  22   9  16]
 [ 12   2  32  52 804  33  30  29   4   2]
 [ 11   1  33 218  31 461  11  27   4   3]
 [ 12   2  29  49  23  20 856   3   3   3]
 [ 20   1  10  46  47  57   4 809   3   3]
 [ 53  18   5   8   5   3   3   3 879  23]
 [ 24  59   3   7   4   6   4  10  19 864]]
2025-02-26T01:47:13.361610+0300 | DEBUG | Class precision: [0.78812785 0.90232108 0.77636153 0.61864407 0.77756286 0.50826902
 0.84251969 0.86802575 0.91088083 0.88706366]
2025-02-26T01:47:13.363145+0300 | DEBUG | Class recall: [0.863      0.933      0.67       0.60833333 0.804      0.57625
 0.856      0.809      0.879      0.864     ]
2025-02-26T01:47:13.413337+0300 | INFO | Training epoch #194 on client #0
2025-02-26T01:47:13.414646+0300 | DEBUG | Saving model to flat file storage. Save #194
2025-02-26T01:47:13.539210+0300 | INFO | [194,     0] loss: 0.015
2025-02-26T01:47:24.437762+0300 | INFO | [194,   100] loss: 1.492
2025-02-26T01:47:35.612482+0300 | INFO | [194,   200] loss: 1.501
2025-02-26T01:47:45.684876+0300 | INFO | [194,   300] loss: 1.490
2025-02-26T01:47:56.561855+0300 | INFO | [194,   400] loss: 1.486
2025-02-26T01:48:07.339332+0300 | INFO | [194,   500] loss: 1.492
2025-02-26T01:48:17.355685+0300 | INFO | [194,   600] loss: 1.479
2025-02-26T01:48:27.677631+0300 | INFO | [194,   700] loss: 1.485
2025-02-26T01:48:38.009935+0300 | INFO | [194,   800] loss: 1.485
2025-02-26T01:48:48.023284+0300 | INFO | [194,   900] loss: 1.486
2025-02-26T01:48:58.986321+0300 | INFO | [194,  1000] loss: 1.489
2025-02-26T01:49:09.384166+0300 | INFO | [194,  1100] loss: 1.503
2025-02-26T01:49:19.447205+0300 | INFO | [194,  1200] loss: 1.489
2025-02-26T01:49:30.128861+0300 | INFO | [194,  1300] loss: 1.491
2025-02-26T01:49:41.955284+0300 | INFO | [194,  1400] loss: 1.492
2025-02-26T01:49:56.137338+0300 | INFO | [194,  1500] loss: 1.488
2025-02-26T01:50:07.554954+0300 | INFO | [194,  1600] loss: 1.486
2025-02-26T01:50:18.489974+0300 | INFO | [194,  1700] loss: 1.487
2025-02-26T01:50:29.072616+0300 | INFO | [194,  1800] loss: 1.492
2025-02-26T01:50:38.865101+0300 | INFO | [194,  1900] loss: 1.482
2025-02-26T01:50:49.514976+0300 | INFO | [194,  2000] loss: 1.486
2025-02-26T01:51:00.852795+0300 | INFO | [194,  2100] loss: 1.493
2025-02-26T01:51:10.535853+0300 | INFO | [194,  2200] loss: 1.483
2025-02-26T01:51:20.961936+0300 | INFO | [194,  2300] loss: 1.476
2025-02-26T01:51:31.945507+0300 | INFO | [194,  2400] loss: 1.484
2025-02-26T01:51:41.676863+0300 | INFO | [194,  2500] loss: 1.500
2025-02-26T01:51:52.035533+0300 | INFO | [194,  2600] loss: 1.477
2025-02-26T01:52:02.445969+0300 | INFO | [194,  2700] loss: 1.490
2025-02-26T01:52:12.805377+0300 | INFO | [194,  2800] loss: 1.493
2025-02-26T01:52:23.476248+0300 | INFO | [194,  2900] loss: 1.495
2025-02-26T01:52:33.262387+0300 | INFO | [194,  3000] loss: 1.497
2025-02-26T01:52:44.819728+0300 | INFO | [194,  3100] loss: 1.494
2025-02-26T01:52:55.060979+0300 | INFO | [194,  3200] loss: 1.482
2025-02-26T01:53:04.862948+0300 | INFO | [194,  3300] loss: 1.496
2025-02-26T01:53:15.719176+0300 | INFO | [194,  3400] loss: 1.485
2025-02-26T01:53:26.168633+0300 | INFO | [194,  3500] loss: 1.502
2025-02-26T01:53:35.832304+0300 | INFO | [194,  3600] loss: 1.486
2025-02-26T01:53:46.429611+0300 | INFO | [194,  3700] loss: 1.488
2025-02-26T01:53:56.938818+0300 | INFO | [194,  3800] loss: 1.495
2025-02-26T01:54:06.988107+0300 | INFO | [194,  3900] loss: 1.479
2025-02-26T01:54:17.777442+0300 | INFO | [194,  4000] loss: 1.492
2025-02-26T01:54:28.393223+0300 | INFO | [194,  4100] loss: 1.493
2025-02-26T01:54:38.083752+0300 | INFO | [194,  4200] loss: 1.487
2025-02-26T01:54:48.934860+0300 | INFO | [194,  4300] loss: 1.489
2025-02-26T01:54:59.393092+0300 | INFO | [194,  4400] loss: 1.490
2025-02-26T01:55:10.050180+0300 | INFO | [194,  4500] loss: 1.488
2025-02-26T01:55:20.497313+0300 | INFO | [194,  4600] loss: 1.485
2025-02-26T01:55:31.210868+0300 | INFO | [194,  4700] loss: 1.475
2025-02-26T01:55:42.184826+0300 | INFO | [194,  4800] loss: 1.493
2025-02-26T01:55:52.869390+0300 | INFO | [194,  4900] loss: 1.490
2025-02-26T01:56:03.113527+0300 | DEBUG | Saving model to flat file storage. Save #194
2025-02-26T01:56:03.148099+0300 | INFO | Averaging client parameters
2025-02-26T01:56:03.153959+0300 | INFO | Updating parameters on client #0
2025-02-26T01:56:19.009669+0300 | DEBUG | Test set: Accuracy: 7911/10000 (79%)
2025-02-26T01:56:19.013177+0300 | DEBUG | Test set: Loss: 1.6699867248535156
2025-02-26T01:56:19.146554+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.92      0.92      0.92      1000
           2       0.74      0.71      0.73      1000
           3       0.67      0.57      0.62      1200
           4       0.79      0.80      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.85      0.86      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T01:56:19.148553+0300 | DEBUG | Confusion Matrix:
[[844   9  47  14  10   7   3   7  39  20]
 [  8 915   0   1   1   1   8   1  21  44]
 [ 52   3 710  37  50  68  50  16   7   7]
 [ 33   7  56 687  49 272  44  23  12  17]
 [ 14   2  39  47 796  37  29  30   5   1]
 [ 13   0  42 151  28 512  12  32   7   3]
 [ 13   2  39  34  22  22 858   2   5   3]
 [ 22   1  12  37  43  61   3 813   5   3]
 [ 44  13   5   5   3   5   4   3 899  19]
 [ 24  46   5   5   2   6   3   9  23 877]]
2025-02-26T01:56:19.150551+0300 | DEBUG | Class precision: [0.79100281 0.91683367 0.7434555  0.67485265 0.79282869 0.51664985
 0.84615385 0.86858974 0.87878788 0.88229376]
2025-02-26T01:56:19.151563+0300 | DEBUG | Class recall: [0.844  0.915  0.71   0.5725 0.796  0.64   0.858  0.813  0.899  0.877 ]
2025-02-26T01:56:19.154541+0300 | INFO | Training epoch #195 on client #0
2025-02-26T01:56:19.154541+0300 | DEBUG | Saving model to flat file storage. Save #195
2025-02-26T01:56:19.383473+0300 | INFO | [195,     0] loss: 0.015
2025-02-26T01:56:29.936053+0300 | INFO | [195,   100] loss: 1.482
2025-02-26T01:56:40.461102+0300 | INFO | [195,   200] loss: 1.496
2025-02-26T01:56:50.223406+0300 | INFO | [195,   300] loss: 1.500
2025-02-26T01:57:00.833724+0300 | INFO | [195,   400] loss: 1.491
2025-02-26T01:57:16.189483+0300 | INFO | [195,   500] loss: 1.487
2025-02-26T01:57:26.932459+0300 | INFO | [195,   600] loss: 1.491
2025-02-26T01:57:36.942742+0300 | INFO | [195,   700] loss: 1.490
2025-02-26T01:57:47.486720+0300 | INFO | [195,   800] loss: 1.493
2025-02-26T01:57:58.137657+0300 | INFO | [195,   900] loss: 1.491
2025-02-26T01:58:08.015967+0300 | INFO | [195,  1000] loss: 1.488
2025-02-26T01:58:18.651559+0300 | INFO | [195,  1100] loss: 1.489
2025-02-26T01:58:29.497918+0300 | INFO | [195,  1200] loss: 1.490
2025-02-26T01:58:39.261743+0300 | INFO | [195,  1300] loss: 1.486
2025-02-26T01:58:51.229126+0300 | INFO | [195,  1400] loss: 1.488
2025-02-26T01:59:01.661197+0300 | INFO | [195,  1500] loss: 1.484
2025-02-26T01:59:11.461101+0300 | INFO | [195,  1600] loss: 1.493
2025-02-26T01:59:22.270931+0300 | INFO | [195,  1700] loss: 1.483
2025-02-26T01:59:33.070625+0300 | INFO | [195,  1800] loss: 1.477
2025-02-26T01:59:42.902134+0300 | INFO | [195,  1900] loss: 1.493
2025-02-26T01:59:53.185974+0300 | INFO | [195,  2000] loss: 1.489
2025-02-26T02:00:03.388825+0300 | INFO | [195,  2100] loss: 1.485
2025-02-26T02:00:13.202355+0300 | INFO | [195,  2200] loss: 1.501
2025-02-26T02:00:23.742509+0300 | INFO | [195,  2300] loss: 1.489
2025-02-26T02:00:33.486306+0300 | INFO | [195,  2400] loss: 1.492
2025-02-26T02:00:44.716596+0300 | INFO | [195,  2500] loss: 1.480
2025-02-26T02:00:55.148458+0300 | INFO | [195,  2600] loss: 1.489
2025-02-26T02:01:04.823713+0300 | INFO | [195,  2700] loss: 1.486
2025-02-26T02:01:15.673990+0300 | INFO | [195,  2800] loss: 1.492
2025-02-26T02:01:26.641350+0300 | INFO | [195,  2900] loss: 1.479
2025-02-26T02:01:37.110998+0300 | INFO | [195,  3000] loss: 1.491
2025-02-26T02:01:48.747605+0300 | INFO | [195,  3100] loss: 1.489
2025-02-26T02:01:59.149329+0300 | INFO | [195,  3200] loss: 1.487
2025-02-26T02:02:08.904587+0300 | INFO | [195,  3300] loss: 1.483
2025-02-26T02:02:19.635778+0300 | INFO | [195,  3400] loss: 1.488
2025-02-26T02:02:30.205410+0300 | INFO | [195,  3500] loss: 1.486
2025-02-26T02:02:39.972637+0300 | INFO | [195,  3600] loss: 1.486
2025-02-26T02:02:51.336683+0300 | INFO | [195,  3700] loss: 1.493
2025-02-26T02:03:01.663022+0300 | INFO | [195,  3800] loss: 1.498
2025-02-26T02:03:11.369137+0300 | INFO | [195,  3900] loss: 1.481
2025-02-26T02:03:22.077707+0300 | INFO | [195,  4000] loss: 1.485
2025-02-26T02:03:32.996373+0300 | INFO | [195,  4100] loss: 1.488
2025-02-26T02:03:42.672424+0300 | INFO | [195,  4200] loss: 1.493
2025-02-26T02:03:54.749400+0300 | INFO | [195,  4300] loss: 1.480
2025-02-26T02:04:05.354600+0300 | INFO | [195,  4400] loss: 1.486
2025-02-26T02:04:18.520465+0300 | INFO | [195,  4500] loss: 1.491
2025-02-26T02:04:31.443941+0300 | INFO | [195,  4600] loss: 1.500
2025-02-26T02:04:41.744339+0300 | INFO | [195,  4700] loss: 1.488
2025-02-26T02:04:52.890513+0300 | INFO | [195,  4800] loss: 1.483
2025-02-26T02:05:02.497621+0300 | INFO | [195,  4900] loss: 1.493
2025-02-26T02:05:13.097170+0300 | DEBUG | Saving model to flat file storage. Save #195
2025-02-26T02:05:13.123567+0300 | INFO | Averaging client parameters
2025-02-26T02:05:13.137929+0300 | INFO | Updating parameters on client #0
2025-02-26T02:05:29.211008+0300 | DEBUG | Test set: Accuracy: 7879/10000 (79%)
2025-02-26T02:05:29.214005+0300 | DEBUG | Test set: Loss: 1.6726888418197632
2025-02-26T02:05:29.335222+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.86      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.75      0.69      0.72      1000
           3       0.64      0.58      0.61      1200
           4       0.76      0.82      0.79      1000
           5       0.54      0.57      0.56       800
           6       0.82      0.87      0.84      1000
           7       0.88      0.81      0.84      1000
           8       0.90      0.88      0.89      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T02:05:29.338352+0300 | DEBUG | Confusion Matrix:
[[865   9  37  14  10   7   3   7  29  19]
 [ 10 913   1   3   2   1   9   1  15  45]
 [ 61   3 690  38  68  56  58  16   5   5]
 [ 39   4  62 695  63 234  53  24  10  16]
 [ 16   2  33  43 821  27  30  24   3   1]
 [ 12   0  39 198  34 459  21  29   6   2]
 [ 14   2  35  36  24  12 872   1   3   1]
 [ 23   1  12  41  57  48   7 806   2   3]
 [ 62  12   3   6   3   4   5   2 882  21]
 [ 30  43   5   6   2   4   6   8  20 876]]
2025-02-26T02:05:29.341564+0300 | DEBUG | Class precision: [0.76413428 0.9231547  0.75245365 0.64351852 0.75738007 0.53873239
 0.81954887 0.87799564 0.90461538 0.88574317]
2025-02-26T02:05:29.342565+0300 | DEBUG | Class recall: [0.865      0.913      0.69       0.57916667 0.821      0.57375
 0.872      0.806      0.882      0.876     ]
2025-02-26T02:05:29.399030+0300 | INFO | Training epoch #196 on client #0
2025-02-26T02:05:29.400023+0300 | DEBUG | Saving model to flat file storage. Save #196
2025-02-26T02:05:29.554028+0300 | INFO | [196,     0] loss: 0.015
2025-02-26T02:05:40.127525+0300 | INFO | [196,   100] loss: 1.490
2025-02-26T02:05:50.467917+0300 | INFO | [196,   200] loss: 1.489
2025-02-26T02:06:01.122510+0300 | INFO | [196,   300] loss: 1.488
2025-02-26T02:06:11.806014+0300 | INFO | [196,   400] loss: 1.484
2025-02-26T02:06:21.999850+0300 | INFO | [196,   500] loss: 1.485
2025-02-26T02:06:33.364963+0300 | INFO | [196,   600] loss: 1.492
2025-02-26T02:06:44.548990+0300 | INFO | [196,   700] loss: 1.486
2025-02-26T02:06:54.770073+0300 | INFO | [196,   800] loss: 1.489
2025-02-26T02:07:06.024074+0300 | INFO | [196,   900] loss: 1.495
2025-02-26T02:07:16.970712+0300 | INFO | [196,  1000] loss: 1.490
2025-02-26T02:07:26.830543+0300 | INFO | [196,  1100] loss: 1.486
2025-02-26T02:07:37.312557+0300 | INFO | [196,  1200] loss: 1.483
2025-02-26T02:07:48.089796+0300 | INFO | [196,  1300] loss: 1.490
2025-02-26T02:07:58.853223+0300 | INFO | [196,  1400] loss: 1.483
2025-02-26T02:08:10.724227+0300 | INFO | [196,  1500] loss: 1.490
2025-02-26T02:08:21.322508+0300 | INFO | [196,  1600] loss: 1.493
2025-02-26T02:08:31.058077+0300 | INFO | [196,  1700] loss: 1.489
2025-02-26T02:08:41.358801+0300 | INFO | [196,  1800] loss: 1.490
2025-02-26T02:08:52.003573+0300 | INFO | [196,  1900] loss: 1.497
2025-02-26T02:09:02.241800+0300 | INFO | [196,  2000] loss: 1.487
2025-02-26T02:09:12.799449+0300 | INFO | [196,  2100] loss: 1.483
2025-02-26T02:09:23.140028+0300 | INFO | [196,  2200] loss: 1.487
2025-02-26T02:09:33.209334+0300 | INFO | [196,  2300] loss: 1.484
2025-02-26T02:09:43.521761+0300 | INFO | [196,  2400] loss: 1.486
2025-02-26T02:09:53.099621+0300 | INFO | [196,  2500] loss: 1.482
2025-02-26T02:10:04.467404+0300 | INFO | [196,  2600] loss: 1.495
2025-02-26T02:10:14.844081+0300 | INFO | [196,  2700] loss: 1.490
2025-02-26T02:10:25.058610+0300 | INFO | [196,  2800] loss: 1.493
2025-02-26T02:10:35.658914+0300 | INFO | [196,  2900] loss: 1.489
2025-02-26T02:10:46.207351+0300 | INFO | [196,  3000] loss: 1.485
2025-02-26T02:10:56.454209+0300 | INFO | [196,  3100] loss: 1.487
2025-02-26T02:11:07.296818+0300 | INFO | [196,  3200] loss: 1.486
2025-02-26T02:11:18.065371+0300 | INFO | [196,  3300] loss: 1.493
2025-02-26T02:11:27.693854+0300 | INFO | [196,  3400] loss: 1.492
2025-02-26T02:11:43.414252+0300 | INFO | [196,  3500] loss: 1.487
2025-02-26T02:11:53.823549+0300 | INFO | [196,  3600] loss: 1.489
2025-02-26T02:12:04.365561+0300 | INFO | [196,  3700] loss: 1.483
2025-02-26T02:12:13.967007+0300 | INFO | [196,  3800] loss: 1.480
2025-02-26T02:12:24.661972+0300 | INFO | [196,  3900] loss: 1.491
2025-02-26T02:12:34.433612+0300 | INFO | [196,  4000] loss: 1.491
2025-02-26T02:12:44.873599+0300 | INFO | [196,  4100] loss: 1.485
2025-02-26T02:12:55.161922+0300 | INFO | [196,  4200] loss: 1.492
2025-02-26T02:13:04.877697+0300 | INFO | [196,  4300] loss: 1.484
2025-02-26T02:13:15.130168+0300 | INFO | [196,  4400] loss: 1.491
2025-02-26T02:13:25.816890+0300 | INFO | [196,  4500] loss: 1.489
2025-02-26T02:13:35.669603+0300 | INFO | [196,  4600] loss: 1.476
2025-02-26T02:13:46.307751+0300 | INFO | [196,  4700] loss: 1.485
2025-02-26T02:13:57.230224+0300 | INFO | [196,  4800] loss: 1.500
2025-02-26T02:14:07.354180+0300 | INFO | [196,  4900] loss: 1.499
2025-02-26T02:14:18.149094+0300 | DEBUG | Saving model to flat file storage. Save #196
2025-02-26T02:14:18.172429+0300 | INFO | Averaging client parameters
2025-02-26T02:14:18.182486+0300 | INFO | Updating parameters on client #0
2025-02-26T02:14:33.581646+0300 | DEBUG | Test set: Accuracy: 7891/10000 (79%)
2025-02-26T02:14:33.582639+0300 | DEBUG | Test set: Loss: 1.6699867248535156
2025-02-26T02:14:33.680019+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.76      0.67      0.71      1000
           3       0.66      0.58      0.62      1200
           4       0.77      0.82      0.80      1000
           5       0.53      0.59      0.56       800
           6       0.84      0.86      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T02:14:33.682245+0300 | DEBUG | Confusion Matrix:
[[854  10  41  13   8   9   3   9  35  18]
 [  8 913   0   2   2   1   6   1  15  52]
 [ 61   2 672  39  67  66  57  22   8   6]
 [ 32   5  57 699  56 246  46  32  13  14]
 [ 14   2  27  42 819  31  27  32   4   2]
 [ 12   0  38 180  31 473  14  41   8   3]
 [ 14   2  34  38  30  15 857   2   5   3]
 [ 21   1   8  32  42  49   5 836   3   3]
 [ 55  11   3   6   2   3   4   4 887  25]
 [ 27  43   5   6   1   4   3  12  18 881]]
2025-02-26T02:14:33.683553+0300 | DEBUG | Class precision: [0.77777778 0.9231547  0.75932203 0.66130558 0.77410208 0.52731327
 0.83855186 0.84359233 0.89056225 0.87487587]
2025-02-26T02:14:33.683553+0300 | DEBUG | Class recall: [0.854   0.913   0.672   0.5825  0.819   0.59125 0.857   0.836   0.887
 0.881  ]
2025-02-26T02:14:33.729422+0300 | INFO | Training epoch #197 on client #0
2025-02-26T02:14:33.730569+0300 | DEBUG | Saving model to flat file storage. Save #197
2025-02-26T02:14:33.881209+0300 | INFO | [197,     0] loss: 0.016
2025-02-26T02:14:44.361861+0300 | INFO | [197,   100] loss: 1.485
2025-02-26T02:14:53.980229+0300 | INFO | [197,   200] loss: 1.486
2025-02-26T02:15:04.367417+0300 | INFO | [197,   300] loss: 1.481
2025-02-26T02:15:14.089365+0300 | INFO | [197,   400] loss: 1.487
2025-02-26T02:15:24.515400+0300 | INFO | [197,   500] loss: 1.489
2025-02-26T02:15:35.149617+0300 | INFO | [197,   600] loss: 1.485
2025-02-26T02:15:44.888006+0300 | INFO | [197,   700] loss: 1.491
2025-02-26T02:15:55.523732+0300 | INFO | [197,   800] loss: 1.478
2025-02-26T02:16:06.357464+0300 | INFO | [197,   900] loss: 1.485
2025-02-26T02:16:16.128373+0300 | INFO | [197,  1000] loss: 1.487
2025-02-26T02:16:27.037750+0300 | INFO | [197,  1100] loss: 1.494
2025-02-26T02:16:37.847542+0300 | INFO | [197,  1200] loss: 1.486
2025-02-26T02:16:47.914742+0300 | INFO | [197,  1300] loss: 1.499
2025-02-26T02:16:59.107480+0300 | INFO | [197,  1400] loss: 1.489
2025-02-26T02:17:10.151248+0300 | INFO | [197,  1500] loss: 1.489
2025-02-26T02:17:20.273691+0300 | INFO | [197,  1600] loss: 1.496
2025-02-26T02:17:30.571810+0300 | INFO | [197,  1700] loss: 1.490
2025-02-26T02:17:41.066902+0300 | INFO | [197,  1800] loss: 1.490
2025-02-26T02:17:51.133082+0300 | INFO | [197,  1900] loss: 1.486
2025-02-26T02:18:01.503740+0300 | INFO | [197,  2000] loss: 1.496
2025-02-26T02:18:12.165051+0300 | INFO | [197,  2100] loss: 1.497
2025-02-26T02:18:22.022370+0300 | INFO | [197,  2200] loss: 1.483
2025-02-26T02:18:32.816040+0300 | INFO | [197,  2300] loss: 1.507
2025-02-26T02:18:43.998387+0300 | INFO | [197,  2400] loss: 1.492
2025-02-26T02:18:59.438180+0300 | INFO | [197,  2500] loss: 1.480
2025-02-26T02:19:09.538650+0300 | INFO | [197,  2600] loss: 1.494
2025-02-26T02:19:20.239101+0300 | INFO | [197,  2700] loss: 1.496
2025-02-26T02:19:29.834060+0300 | INFO | [197,  2800] loss: 1.487
2025-02-26T02:19:40.452050+0300 | INFO | [197,  2900] loss: 1.491
2025-02-26T02:19:51.331789+0300 | INFO | [197,  3000] loss: 1.487
2025-02-26T02:20:01.783280+0300 | INFO | [197,  3100] loss: 1.488
2025-02-26T02:20:12.659628+0300 | INFO | [197,  3200] loss: 1.480
2025-02-26T02:20:23.189982+0300 | INFO | [197,  3300] loss: 1.490
2025-02-26T02:20:33.076206+0300 | INFO | [197,  3400] loss: 1.490
2025-02-26T02:20:43.575093+0300 | INFO | [197,  3500] loss: 1.486
2025-02-26T02:20:54.391938+0300 | INFO | [197,  3600] loss: 1.486
2025-02-26T02:21:04.336110+0300 | INFO | [197,  3700] loss: 1.479
2025-02-26T02:21:14.558961+0300 | INFO | [197,  3800] loss: 1.482
2025-02-26T02:21:25.136077+0300 | INFO | [197,  3900] loss: 1.495
2025-02-26T02:21:35.060037+0300 | INFO | [197,  4000] loss: 1.480
2025-02-26T02:21:45.520810+0300 | INFO | [197,  4100] loss: 1.495
2025-02-26T02:21:56.167626+0300 | INFO | [197,  4200] loss: 1.492
2025-02-26T02:22:06.010387+0300 | INFO | [197,  4300] loss: 1.484
2025-02-26T02:22:16.295177+0300 | INFO | [197,  4400] loss: 1.489
2025-02-26T02:22:26.673988+0300 | INFO | [197,  4500] loss: 1.486
2025-02-26T02:22:37.883054+0300 | INFO | [197,  4600] loss: 1.491
2025-02-26T02:22:48.368119+0300 | INFO | [197,  4700] loss: 1.487
2025-02-26T02:22:59.295539+0300 | INFO | [197,  4800] loss: 1.490
2025-02-26T02:23:09.963320+0300 | INFO | [197,  4900] loss: 1.487
2025-02-26T02:23:20.274285+0300 | DEBUG | Saving model to flat file storage. Save #197
2025-02-26T02:23:20.297436+0300 | INFO | Averaging client parameters
2025-02-26T02:23:20.309439+0300 | INFO | Updating parameters on client #0
2025-02-26T02:23:35.656727+0300 | DEBUG | Test set: Accuracy: 7902/10000 (79%)
2025-02-26T02:23:35.657723+0300 | DEBUG | Test set: Loss: 1.6698940992355347
2025-02-26T02:23:35.756567+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.93      0.90      0.92      1000
           2       0.75      0.69      0.72      1000
           3       0.67      0.58      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.83      0.87      0.85      1000
           7       0.87      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T02:23:35.759574+0300 | DEBUG | Confusion Matrix:
[[837  10  44  16  13  11   5   8  38  18]
 [ 10 900   2   3   2   2   9   1  19  52]
 [ 53   2 689  41  59  70  58  18   4   6]
 [ 30   5  58 692  51 266  47  26  10  15]
 [ 12   1  36  46 809  34  29  28   4   1]
 [ 10   0  37 159  32 507  16  32   5   2]
 [ 10   1  33  37  22  18 871   2   4   2]
 [ 20   1  13  30  49  56   7 820   2   2]
 [ 49  11   5   6   5   5   5   2 894  18]
 [ 31  35   6   7   2   4   4   8  20 883]]
2025-02-26T02:23:35.761571+0300 | DEBUG | Class precision: [0.78813559 0.93167702 0.74647887 0.66730955 0.77490421 0.52106886
 0.82873454 0.86772487 0.894      0.88388388]
2025-02-26T02:23:35.762566+0300 | DEBUG | Class recall: [0.837      0.9        0.689      0.57666667 0.809      0.63375
 0.871      0.82       0.894      0.883     ]
2025-02-26T02:23:35.806218+0300 | INFO | Training epoch #198 on client #0
2025-02-26T02:23:35.808216+0300 | DEBUG | Saving model to flat file storage. Save #198
2025-02-26T02:23:35.932484+0300 | INFO | [198,     0] loss: 0.015
2025-02-26T02:23:45.870969+0300 | INFO | [198,   100] loss: 1.503
2025-02-26T02:23:56.441114+0300 | INFO | [198,   200] loss: 1.485
2025-02-26T02:24:07.466071+0300 | INFO | [198,   300] loss: 1.486
2025-02-26T02:24:16.919830+0300 | INFO | [198,   400] loss: 1.489
2025-02-26T02:24:27.456057+0300 | INFO | [198,   500] loss: 1.490
2025-02-26T02:24:38.035144+0300 | INFO | [198,   600] loss: 1.483
2025-02-26T02:24:47.602474+0300 | INFO | [198,   700] loss: 1.482
2025-02-26T02:24:57.876486+0300 | INFO | [198,   800] loss: 1.492
2025-02-26T02:25:08.732854+0300 | INFO | [198,   900] loss: 1.488
2025-02-26T02:25:18.738069+0300 | INFO | [198,  1000] loss: 1.495
2025-02-26T02:25:29.296754+0300 | INFO | [198,  1100] loss: 1.480
2025-02-26T02:25:40.651314+0300 | INFO | [198,  1200] loss: 1.499
2025-02-26T02:25:51.767914+0300 | INFO | [198,  1300] loss: 1.494
2025-02-26T02:26:04.506321+0300 | INFO | [198,  1400] loss: 1.492
2025-02-26T02:26:20.279022+0300 | INFO | [198,  1500] loss: 1.487
2025-02-26T02:26:31.692025+0300 | INFO | [198,  1600] loss: 1.489
2025-02-26T02:26:42.081880+0300 | INFO | [198,  1700] loss: 1.487
2025-02-26T02:26:53.277861+0300 | INFO | [198,  1800] loss: 1.490
2025-02-26T02:27:04.460323+0300 | INFO | [198,  1900] loss: 1.486
2025-02-26T02:27:15.985698+0300 | INFO | [198,  2000] loss: 1.488
2025-02-26T02:27:26.760235+0300 | INFO | [198,  2100] loss: 1.488
2025-02-26T02:27:38.335231+0300 | INFO | [198,  2200] loss: 1.488
2025-02-26T02:27:49.706231+0300 | INFO | [198,  2300] loss: 1.485
2025-02-26T02:28:00.326793+0300 | INFO | [198,  2400] loss: 1.488
2025-02-26T02:28:11.774160+0300 | INFO | [198,  2500] loss: 1.499
2025-02-26T02:28:23.808282+0300 | INFO | [198,  2600] loss: 1.488
2025-02-26T02:28:34.908800+0300 | INFO | [198,  2700] loss: 1.492
2025-02-26T02:28:45.745173+0300 | INFO | [198,  2800] loss: 1.490
2025-02-26T02:28:56.203921+0300 | INFO | [198,  2900] loss: 1.486
2025-02-26T02:29:05.827331+0300 | INFO | [198,  3000] loss: 1.481
2025-02-26T02:29:17.115611+0300 | INFO | [198,  3100] loss: 1.493
2025-02-26T02:29:28.047463+0300 | INFO | [198,  3200] loss: 1.491
2025-02-26T02:29:37.884897+0300 | INFO | [198,  3300] loss: 1.486
2025-02-26T02:29:48.213866+0300 | INFO | [198,  3400] loss: 1.489
2025-02-26T02:29:58.910464+0300 | INFO | [198,  3500] loss: 1.487
2025-02-26T02:30:08.668039+0300 | INFO | [198,  3600] loss: 1.485
2025-02-26T02:30:19.476640+0300 | INFO | [198,  3700] loss: 1.487
2025-02-26T02:30:29.979019+0300 | INFO | [198,  3800] loss: 1.489
2025-02-26T02:30:39.809113+0300 | INFO | [198,  3900] loss: 1.485
2025-02-26T02:30:50.717042+0300 | INFO | [198,  4000] loss: 1.487
2025-02-26T02:31:01.277522+0300 | INFO | [198,  4100] loss: 1.486
2025-02-26T02:31:11.282615+0300 | INFO | [198,  4200] loss: 1.490
2025-02-26T02:31:22.183098+0300 | INFO | [198,  4300] loss: 1.486
2025-02-26T02:31:33.205515+0300 | INFO | [198,  4400] loss: 1.481
2025-02-26T02:31:43.081205+0300 | INFO | [198,  4500] loss: 1.489
2025-02-26T02:31:54.205757+0300 | INFO | [198,  4600] loss: 1.485
2025-02-26T02:32:04.688251+0300 | INFO | [198,  4700] loss: 1.493
2025-02-26T02:32:15.484671+0300 | INFO | [198,  4800] loss: 1.488
2025-02-26T02:32:26.185963+0300 | INFO | [198,  4900] loss: 1.491
2025-02-26T02:32:36.928612+0300 | DEBUG | Saving model to flat file storage. Save #198
2025-02-26T02:32:36.954257+0300 | INFO | Averaging client parameters
2025-02-26T02:32:36.959392+0300 | INFO | Updating parameters on client #0
2025-02-26T02:32:52.668329+0300 | DEBUG | Test set: Accuracy: 7896/10000 (79%)
2025-02-26T02:32:52.671606+0300 | DEBUG | Test set: Loss: 1.6703510284423828
2025-02-26T02:32:52.783985+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.92      0.91      0.92      1000
           2       0.75      0.69      0.72      1000
           3       0.64      0.59      0.62      1200
           4       0.78      0.81      0.79      1000
           5       0.53      0.58      0.56       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.83      0.84      1000
           8       0.91      0.88      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T02:32:52.784997+0300 | DEBUG | Confusion Matrix:
[[852   9  40  17  12   9   5   8  30  18]
 [ 11 909   1   4   2   0   8   1  15  49]
 [ 63   2 689  47  55  61  52  18   4   9]
 [ 35   5  53 714  52 244  47  26   8  16]
 [ 13   2  36  49 811  27  26  32   3   1]
 [ 13   0  38 190  33 466  14  39   5   2]
 [ 10   2  36  40  24  15 864   3   3   3]
 [ 25   1  10  36  45  48   4 826   2   3]
 [ 58  14   6   6   6   5   4   2 879  20]
 [ 25  39   5   7   3   4   3   9  19 886]]
2025-02-26T02:32:52.787003+0300 | DEBUG | Class precision: [0.77104072 0.92472024 0.75382932 0.64324324 0.77756472 0.5301479
 0.8412853  0.85684647 0.90805785 0.87984111]
2025-02-26T02:32:52.791999+0300 | DEBUG | Class recall: [0.852  0.909  0.689  0.595  0.811  0.5825 0.864  0.826  0.879  0.886 ]
2025-02-26T02:32:52.845624+0300 | INFO | Training epoch #199 on client #0
2025-02-26T02:32:52.846632+0300 | DEBUG | Saving model to flat file storage. Save #199
2025-02-26T02:32:52.979383+0300 | INFO | [199,     0] loss: 0.015
2025-02-26T02:33:02.861589+0300 | INFO | [199,   100] loss: 1.485
2025-02-26T02:33:13.202144+0300 | INFO | [199,   200] loss: 1.496
2025-02-26T02:33:23.892789+0300 | INFO | [199,   300] loss: 1.486
2025-02-26T02:33:35.106859+0300 | INFO | [199,   400] loss: 1.483
2025-02-26T02:33:49.505548+0300 | INFO | [199,   500] loss: 1.488
2025-02-26T02:34:00.121980+0300 | INFO | [199,   600] loss: 1.483
2025-02-26T02:34:09.852871+0300 | INFO | [199,   700] loss: 1.492
2025-02-26T02:34:20.772434+0300 | INFO | [199,   800] loss: 1.478
2025-02-26T02:34:31.195987+0300 | INFO | [199,   900] loss: 1.491
2025-02-26T02:34:41.060657+0300 | INFO | [199,  1000] loss: 1.482
2025-02-26T02:34:51.461172+0300 | INFO | [199,  1100] loss: 1.491
2025-02-26T02:35:01.855242+0300 | INFO | [199,  1200] loss: 1.487
2025-02-26T02:35:11.610628+0300 | INFO | [199,  1300] loss: 1.490
2025-02-26T02:35:23.002297+0300 | INFO | [199,  1400] loss: 1.488
2025-02-26T02:35:33.387214+0300 | INFO | [199,  1500] loss: 1.491
2025-02-26T02:35:43.137239+0300 | INFO | [199,  1600] loss: 1.497
2025-02-26T02:35:53.663976+0300 | INFO | [199,  1700] loss: 1.483
2025-02-26T02:36:04.144279+0300 | INFO | [199,  1800] loss: 1.496
2025-02-26T02:36:13.829155+0300 | INFO | [199,  1900] loss: 1.486
2025-02-26T02:36:24.734587+0300 | INFO | [199,  2000] loss: 1.490
2025-02-26T02:36:35.843593+0300 | INFO | [199,  2100] loss: 1.484
2025-02-26T02:36:46.337980+0300 | INFO | [199,  2200] loss: 1.493
2025-02-26T02:36:57.514676+0300 | INFO | [199,  2300] loss: 1.494
2025-02-26T02:37:08.409846+0300 | INFO | [199,  2400] loss: 1.493
2025-02-26T02:37:18.358082+0300 | INFO | [199,  2500] loss: 1.489
2025-02-26T02:37:29.081552+0300 | INFO | [199,  2600] loss: 1.499
2025-02-26T02:37:39.335909+0300 | INFO | [199,  2700] loss: 1.489
2025-02-26T02:37:49.446428+0300 | INFO | [199,  2800] loss: 1.495
2025-02-26T02:38:00.128167+0300 | INFO | [199,  2900] loss: 1.476
2025-02-26T02:38:11.240243+0300 | INFO | [199,  3000] loss: 1.486
2025-02-26T02:38:22.155636+0300 | INFO | [199,  3100] loss: 1.482
2025-02-26T02:38:32.977651+0300 | INFO | [199,  3200] loss: 1.487
2025-02-26T02:38:43.293011+0300 | INFO | [199,  3300] loss: 1.481
2025-02-26T02:38:53.383196+0300 | INFO | [199,  3400] loss: 1.491
2025-02-26T02:39:05.618917+0300 | INFO | [199,  3500] loss: 1.490
2025-02-26T02:39:16.542333+0300 | INFO | [199,  3600] loss: 1.489
2025-02-26T02:39:26.405370+0300 | INFO | [199,  3700] loss: 1.491
2025-02-26T02:39:37.032807+0300 | INFO | [199,  3800] loss: 1.488
2025-02-26T02:39:47.380557+0300 | INFO | [199,  3900] loss: 1.487
2025-02-26T02:39:57.274368+0300 | INFO | [199,  4000] loss: 1.497
2025-02-26T02:40:08.005189+0300 | INFO | [199,  4100] loss: 1.483
2025-02-26T02:40:17.727184+0300 | INFO | [199,  4200] loss: 1.493
2025-02-26T02:40:28.477607+0300 | INFO | [199,  4300] loss: 1.488
2025-02-26T02:40:39.066213+0300 | INFO | [199,  4400] loss: 1.495
2025-02-26T02:40:48.872608+0300 | INFO | [199,  4500] loss: 1.478
2025-02-26T02:41:04.615848+0300 | INFO | [199,  4600] loss: 1.499
2025-02-26T02:41:15.373397+0300 | INFO | [199,  4700] loss: 1.492
2025-02-26T02:41:27.033174+0300 | INFO | [199,  4800] loss: 1.488
2025-02-26T02:41:37.324755+0300 | INFO | [199,  4900] loss: 1.488
2025-02-26T02:41:47.930341+0300 | DEBUG | Saving model to flat file storage. Save #199
2025-02-26T02:41:47.950856+0300 | INFO | Averaging client parameters
2025-02-26T02:41:47.958482+0300 | INFO | Updating parameters on client #0
2025-02-26T02:42:03.758668+0300 | DEBUG | Test set: Accuracy: 7890/10000 (79%)
2025-02-26T02:42:03.759670+0300 | DEBUG | Test set: Loss: 1.6721007823944092
2025-02-26T02:42:03.865101+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.79      0.66      0.72      1000
           3       0.67      0.57      0.62      1200
           4       0.79      0.80      0.79      1000
           5       0.51      0.65      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.87      0.82      0.84      1000
           8       0.88      0.89      0.89      1000
           9       0.85      0.90      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T02:42:03.870103+0300 | DEBUG | Confusion Matrix:
[[855  11  29  14   9  12   2   7  40  21]
 [  7 904   0   2   1   0   6   0  20  60]
 [ 64   2 663  48  55  78  54  17   8  11]
 [ 34   7  45 687  44 274  49  26  12  22]
 [ 16   2  31  47 796  42  28  31   5   2]
 [ 13   0  30 158  28 516  13  31   7   4]
 [ 12   2  32  35  24  25 856   2   8   4]
 [ 23   1   7  29  43  59   5 821   4   8]
 [ 50  12   4   5   4   3   3   2 894  23]
 [ 21  37   2   5   2   5   3   7  20 898]]
2025-02-26T02:42:03.873107+0300 | DEBUG | Class precision: [0.78082192 0.92433538 0.78647687 0.66699029 0.79125249 0.50887574
 0.84003925 0.86970339 0.87819253 0.85280152]
2025-02-26T02:42:03.875105+0300 | DEBUG | Class recall: [0.855  0.904  0.663  0.5725 0.796  0.645  0.856  0.821  0.894  0.898 ]
2025-02-26T02:42:03.877640+0300 | INFO | Training epoch #200 on client #0
2025-02-26T02:42:03.878666+0300 | DEBUG | Saving model to flat file storage. Save #200
2025-02-26T02:42:04.000738+0300 | INFO | [200,     0] loss: 0.015
2025-02-26T02:42:14.430463+0300 | INFO | [200,   100] loss: 1.491
2025-02-26T02:42:24.194134+0300 | INFO | [200,   200] loss: 1.493
2025-02-26T02:42:34.709433+0300 | INFO | [200,   300] loss: 1.493
2025-02-26T02:42:45.280808+0300 | INFO | [200,   400] loss: 1.492
2025-02-26T02:42:54.835047+0300 | INFO | [200,   500] loss: 1.502
2025-02-26T02:43:05.400283+0300 | INFO | [200,   600] loss: 1.476
2025-02-26T02:43:15.703395+0300 | INFO | [200,   700] loss: 1.487
2025-02-26T02:43:25.827697+0300 | INFO | [200,   800] loss: 1.484
2025-02-26T02:43:36.932126+0300 | INFO | [200,   900] loss: 1.484
2025-02-26T02:43:47.205452+0300 | INFO | [200,  1000] loss: 1.490
2025-02-26T02:43:57.109671+0300 | INFO | [200,  1100] loss: 1.487
2025-02-26T02:44:08.027482+0300 | INFO | [200,  1200] loss: 1.493
2025-02-26T02:44:17.662270+0300 | INFO | [200,  1300] loss: 1.491
2025-02-26T02:44:29.279239+0300 | INFO | [200,  1400] loss: 1.490
2025-02-26T02:44:39.746601+0300 | INFO | [200,  1500] loss: 1.487
2025-02-26T02:44:49.452037+0300 | INFO | [200,  1600] loss: 1.484
2025-02-26T02:44:59.825290+0300 | INFO | [200,  1700] loss: 1.492
2025-02-26T02:45:10.686688+0300 | INFO | [200,  1800] loss: 1.496
2025-02-26T02:45:20.605108+0300 | INFO | [200,  1900] loss: 1.490
2025-02-26T02:45:31.022097+0300 | INFO | [200,  2000] loss: 1.486
2025-02-26T02:45:41.698583+0300 | INFO | [200,  2100] loss: 1.482
2025-02-26T02:45:51.946487+0300 | INFO | [200,  2200] loss: 1.487
2025-02-26T02:46:02.221510+0300 | INFO | [200,  2300] loss: 1.486
2025-02-26T02:46:12.347998+0300 | INFO | [200,  2400] loss: 1.485
2025-02-26T02:46:22.487735+0300 | INFO | [200,  2500] loss: 1.502
2025-02-26T02:46:33.177689+0300 | INFO | [200,  2600] loss: 1.489
2025-02-26T02:46:43.860170+0300 | INFO | [200,  2700] loss: 1.482
2025-02-26T02:46:53.872203+0300 | INFO | [200,  2800] loss: 1.480
2025-02-26T02:47:04.499932+0300 | INFO | [200,  2900] loss: 1.495
2025-02-26T02:47:14.061969+0300 | INFO | [200,  3000] loss: 1.481
2025-02-26T02:47:24.686316+0300 | INFO | [200,  3100] loss: 1.494
2025-02-26T02:47:34.513999+0300 | INFO | [200,  3200] loss: 1.489
2025-02-26T02:47:44.481620+0300 | INFO | [200,  3300] loss: 1.481
2025-02-26T02:47:55.332221+0300 | INFO | [200,  3400] loss: 1.484
2025-02-26T02:48:06.140831+0300 | INFO | [200,  3500] loss: 1.485
2025-02-26T02:48:17.801554+0300 | INFO | [200,  3600] loss: 1.485
2025-02-26T02:48:31.614051+0300 | INFO | [200,  3700] loss: 1.487
2025-02-26T02:48:42.061042+0300 | INFO | [200,  3800] loss: 1.484
2025-02-26T02:48:52.748954+0300 | INFO | [200,  3900] loss: 1.490
2025-02-26T02:49:02.580784+0300 | INFO | [200,  4000] loss: 1.489
2025-02-26T02:49:13.317875+0300 | INFO | [200,  4100] loss: 1.492
2025-02-26T02:49:23.714412+0300 | INFO | [200,  4200] loss: 1.485
2025-02-26T02:49:34.021230+0300 | INFO | [200,  4300] loss: 1.492
2025-02-26T02:49:44.866280+0300 | INFO | [200,  4400] loss: 1.490
2025-02-26T02:49:55.792470+0300 | INFO | [200,  4500] loss: 1.485
2025-02-26T02:50:06.083772+0300 | INFO | [200,  4600] loss: 1.495
2025-02-26T02:50:16.949554+0300 | INFO | [200,  4700] loss: 1.480
2025-02-26T02:50:28.191567+0300 | INFO | [200,  4800] loss: 1.496
2025-02-26T02:50:38.362448+0300 | INFO | [200,  4900] loss: 1.485
2025-02-26T02:50:48.948078+0300 | DEBUG | Updating LR for optimizer
2025-02-26T02:50:48.951076+0300 | DEBUG | New LR: 6.25e-06
2025-02-26T02:50:48.952076+0300 | DEBUG | Saving model to flat file storage. Save #200
2025-02-26T02:50:48.978073+0300 | INFO | Averaging client parameters
2025-02-26T02:50:48.989908+0300 | INFO | Updating parameters on client #0
2025-02-26T02:51:04.876792+0300 | DEBUG | Test set: Accuracy: 7880/10000 (79%)
2025-02-26T02:51:04.877792+0300 | DEBUG | Test set: Loss: 1.6718499660491943
2025-02-26T02:51:05.006848+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.63      0.61      0.62      1200
           4       0.80      0.79      0.80      1000
           5       0.54      0.56      0.55       800
           6       0.81      0.88      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T02:51:05.009232+0300 | DEBUG | Confusion Matrix:
[[839  11  46  17  10   9   4   8  37  19]
 [  8 908   0   3   0   0  11   2  17  51]
 [ 55   3 694  45  52  57  65  17   5   7]
 [ 31   5  55 727  46 225  59  24  12  16]
 [ 17   2  40  51 794  27  34  30   4   1]
 [ 10   0  36 218  29 446  21  32   6   2]
 [ 11   0  35  38  17  13 880   1   3   2]
 [ 23   1  12  37  42  51   9 816   5   4]
 [ 49  15   5   7   4   1   6   3 890  20]
 [ 24  40   3   8   3   4   4   9  19 886]]
2025-02-26T02:51:05.013980+0300 | DEBUG | Class precision: [0.78631678 0.92182741 0.74946004 0.63162467 0.79638917 0.53541417
 0.80512351 0.86624204 0.89178357 0.87896825]
2025-02-26T02:51:05.018001+0300 | DEBUG | Class recall: [0.839      0.908      0.694      0.60583333 0.794      0.5575
 0.88       0.816      0.89       0.886     ]
2025-02-26T02:51:05.303567+0300 | DEBUG | Arguments: 
Batch Size: 10
Test Batch Size: 10000
Epochs: 200
Learning Rate: 0.0001
Momentum: 0.5
Beta1: 0.9
Beta2: 0.999
EPS: 1e-08
CUDA Enabled: True
Shuffle Enabled: False
Log Interval: 100
Scheduler Step Size: 50
Scheduler Gamma: 0.5
Scheduler Minimum Learning Rate: 1e-10
Client Selection Strategy: <federated_learning.worker_selection.random.RandomSelectionStrategy object at 0x0000025CA27BA0F0>
Client Selection Strategy Arguments: {
    "NUM_WORKERS_PER_ROUND": 1,
    "current_epoch_number": 200
}
Model Saving Enabled: True
Model Saving Interval: 1
Model Saving Path (Relative): 3001_models
Epoch Save Start Prefix: start
Epoch Save End Suffix: end
Number of Clients: 1
Number of Poisoned Clients: 1
NN: <class 'federated_learning.nets.cifar_10_cnn.Cifar10CNN'>
Train Data Loader Path: data_loaders/cifar10/train_data_loader.pickle
Test Data Loader Path: data_loaders/cifar10/test_data_loader.pickle
Loss Function: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
Default Model Folder Path: default_models
Data Path: data

2025-02-26T02:51:05.305572+0300 | INFO | Loading data loader from file: data_loaders/cifar10/train_data_loader.pickle
2025-02-26T02:51:07.026697+0300 | INFO | Loading data loader from file: data_loaders/cifar10/test_data_loader.pickle
2025-02-26T02:51:15.935038+0300 | INFO | Poisoning data for workers: [0]
2025-02-26T02:51:15.967185+0300 | INFO | Client #0 has data distribution: [5000, 5000, 5000, 6000, 5000, 4000, 5000, 5000, 5000, 5000]
2025-02-26T02:51:16.025194+0300 | INFO | Training epoch #1 on client #0
2025-02-26T02:51:16.027198+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-02-26T02:51:16.170353+0300 | INFO | [1,     0] loss: 0.023
2025-02-26T02:51:25.698908+0300 | INFO | [1,   100] loss: 2.247
2025-02-26T02:51:36.224049+0300 | INFO | [1,   200] loss: 2.186
2025-02-26T02:51:45.690989+0300 | INFO | [1,   300] loss: 2.149
2025-02-26T02:51:55.734134+0300 | INFO | [1,   400] loss: 2.131
2025-02-26T02:52:06.126074+0300 | INFO | [1,   500] loss: 2.128
2025-02-26T02:52:15.661415+0300 | INFO | [1,   600] loss: 2.115
2025-02-26T02:52:25.591056+0300 | INFO | [1,   700] loss: 2.117
2025-02-26T02:52:35.306573+0300 | INFO | [1,   800] loss: 2.099
2025-02-26T02:52:45.017970+0300 | INFO | [1,   900] loss: 2.080
2025-02-26T02:52:54.979521+0300 | INFO | [1,  1000] loss: 2.087
2025-02-26T02:53:04.626306+0300 | INFO | [1,  1100] loss: 2.088
2025-02-26T02:53:15.257443+0300 | INFO | [1,  1200] loss: 2.054
2025-02-26T02:53:25.877288+0300 | INFO | [1,  1300] loss: 2.046
2025-02-26T02:53:35.218158+0300 | INFO | [1,  1400] loss: 2.053
2025-02-26T02:53:45.227623+0300 | INFO | [1,  1500] loss: 2.038
2025-02-26T02:53:54.691820+0300 | INFO | [1,  1600] loss: 2.043
2025-02-26T02:54:04.518511+0300 | INFO | [1,  1700] loss: 2.010
2025-02-26T02:54:14.360758+0300 | INFO | [1,  1800] loss: 2.028
2025-02-26T02:54:23.886910+0300 | INFO | [1,  1900] loss: 2.026
2025-02-26T02:54:33.780814+0300 | INFO | [1,  2000] loss: 2.029
2025-02-26T02:54:43.817682+0300 | INFO | [1,  2100] loss: 2.026
2025-02-26T02:54:53.008926+0300 | INFO | [1,  2200] loss: 2.016
2025-02-26T02:55:03.093893+0300 | INFO | [1,  2300] loss: 2.032
2025-02-26T02:55:12.483879+0300 | INFO | [1,  2400] loss: 2.020
2025-02-26T02:55:22.641992+0300 | INFO | [1,  2500] loss: 2.029
2025-02-26T02:55:32.607202+0300 | INFO | [1,  2600] loss: 2.003
2025-02-26T02:55:45.140743+0300 | INFO | [1,  2700] loss: 2.025
2025-02-26T02:55:57.936805+0300 | INFO | [1,  2800] loss: 2.009
2025-02-26T02:56:08.617628+0300 | INFO | [1,  2900] loss: 1.992
2025-02-26T02:56:19.644796+0300 | INFO | [1,  3000] loss: 2.005
2025-02-26T02:56:30.275100+0300 | INFO | [1,  3100] loss: 2.000
2025-02-26T02:56:41.233708+0300 | INFO | [1,  3200] loss: 1.970
2025-02-26T02:56:51.469793+0300 | INFO | [1,  3300] loss: 1.979
2025-02-26T02:57:01.311899+0300 | INFO | [1,  3400] loss: 2.005
2025-02-26T02:57:11.583220+0300 | INFO | [1,  3500] loss: 1.965
2025-02-26T02:57:20.962714+0300 | INFO | [1,  3600] loss: 1.977
2025-02-26T02:57:31.197349+0300 | INFO | [1,  3700] loss: 1.967
2025-02-26T02:57:41.442266+0300 | INFO | [1,  3800] loss: 1.956
2025-02-26T02:57:50.750554+0300 | INFO | [1,  3900] loss: 1.982
2025-02-26T02:58:00.660893+0300 | INFO | [1,  4000] loss: 1.989
2025-02-26T02:58:09.978002+0300 | INFO | [1,  4100] loss: 1.976
2025-02-26T02:58:19.844541+0300 | INFO | [1,  4200] loss: 1.983
2025-02-26T02:58:29.885862+0300 | INFO | [1,  4300] loss: 1.944
2025-02-26T02:58:39.322343+0300 | INFO | [1,  4400] loss: 1.963
2025-02-26T02:58:49.712183+0300 | INFO | [1,  4500] loss: 1.950
2025-02-26T02:58:59.328747+0300 | INFO | [1,  4600] loss: 1.944
2025-02-26T02:59:08.697853+0300 | INFO | [1,  4700] loss: 1.983
2025-02-26T02:59:19.173676+0300 | INFO | [1,  4800] loss: 1.962
2025-02-26T02:59:28.568848+0300 | INFO | [1,  4900] loss: 1.964
2025-02-26T02:59:38.502197+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-02-26T02:59:38.527273+0300 | INFO | Averaging client parameters
2025-02-26T02:59:38.539273+0300 | INFO | Updating parameters on client #0
2025-02-26T02:59:53.663866+0300 | DEBUG | Test set: Accuracy: 5508/10000 (55%)
2025-02-26T02:59:53.664876+0300 | DEBUG | Test set: Loss: 1.9076460599899292
2025-02-26T02:59:53.769409+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.57      0.67      0.62      1000
           1       0.67      0.71      0.69      1000
           2       0.50      0.29      0.37      1000
           3       0.33      0.72      0.45      1200
           4       0.53      0.43      0.47      1000
           5       0.00      0.00      0.00       800
           6       0.58      0.72      0.64      1000
           7       0.74      0.50      0.60      1000
           8       0.71      0.68      0.70      1000
           9       0.71      0.65      0.68      1000

    accuracy                           0.55     10000
   macro avg       0.53      0.54      0.52     10000
weighted avg       0.54      0.55      0.53     10000

2025-02-26T02:59:53.772408+0300 | DEBUG | Confusion Matrix:
[[667  33  61  48  10   0  17   8 100  56]
 [ 73 712   3  34   5   0  12   6  51 104]
 [116  20 287 252 145   0 130  23  11  16]
 [ 34  19  66 862  49   0 113  26  18  13]
 [ 40  15  53 197 427   0 171  75  16   6]
 [ 14  13  40 610  43   0  27  30  15   8]
 [ 15  11  19 165  41   0 721   4  16   8]
 [ 29  12  14 301  80   0  31 502   4  27]
 [132  72  22  44   9   0  10   3 683  25]
 [ 43 150   5  81   3   0  20   4  47 647]]
2025-02-26T02:59:53.774406+0300 | DEBUG | Class precision: [0.57351677 0.67360454 0.50350877 0.33230532 0.52586207        nan
 0.57587859 0.73715125 0.710718   0.71098901]
2025-02-26T02:59:53.775407+0300 | DEBUG | Class recall: [0.667      0.712      0.287      0.71833333 0.427      0.
 0.721      0.502      0.683      0.647     ]
2025-02-26T02:59:53.821645+0300 | INFO | Training epoch #2 on client #0
2025-02-26T02:59:53.822948+0300 | DEBUG | Saving model to flat file storage. Save #2
2025-02-26T02:59:54.022360+0300 | INFO | [2,     0] loss: 0.022
2025-02-26T03:00:04.274857+0300 | INFO | [2,   100] loss: 1.924
2025-02-26T03:00:13.451906+0300 | INFO | [2,   200] loss: 1.951
2025-02-26T03:00:23.557557+0300 | INFO | [2,   300] loss: 1.941
2025-02-26T03:00:32.761820+0300 | INFO | [2,   400] loss: 1.924
2025-02-26T03:00:43.037361+0300 | INFO | [2,   500] loss: 1.946
2025-02-26T03:00:53.321044+0300 | INFO | [2,   600] loss: 1.948
2025-02-26T03:01:02.631993+0300 | INFO | [2,   700] loss: 1.914
2025-02-26T03:01:12.556016+0300 | INFO | [2,   800] loss: 1.906
2025-02-26T03:01:22.352393+0300 | INFO | [2,   900] loss: 1.914
2025-02-26T03:01:32.681570+0300 | INFO | [2,  1000] loss: 1.925
2025-02-26T03:01:42.655786+0300 | INFO | [2,  1100] loss: 1.923
2025-02-26T03:01:52.306255+0300 | INFO | [2,  1200] loss: 1.934
2025-02-26T03:02:02.116637+0300 | INFO | [2,  1300] loss: 1.907
2025-02-26T03:02:12.466515+0300 | INFO | [2,  1400] loss: 1.901
2025-02-26T03:02:22.603008+0300 | INFO | [2,  1500] loss: 1.943
2025-02-26T03:02:32.668688+0300 | INFO | [2,  1600] loss: 1.930
2025-02-26T03:02:41.878700+0300 | INFO | [2,  1700] loss: 1.906
2025-02-26T03:02:51.721739+0300 | INFO | [2,  1800] loss: 1.903
2025-02-26T03:03:01.906440+0300 | INFO | [2,  1900] loss: 1.929
2025-02-26T03:03:13.089938+0300 | INFO | [2,  2000] loss: 1.924
2025-02-26T03:03:26.704513+0300 | INFO | [2,  2100] loss: 1.902
2025-02-26T03:03:37.119307+0300 | INFO | [2,  2200] loss: 1.896
2025-02-26T03:03:46.477839+0300 | INFO | [2,  2300] loss: 1.912
2025-02-26T03:03:56.585285+0300 | INFO | [2,  2400] loss: 1.900
2025-02-26T03:04:06.586456+0300 | INFO | [2,  2500] loss: 1.902
2025-02-26T03:04:15.785776+0300 | INFO | [2,  2600] loss: 1.919
2025-02-26T03:04:26.350329+0300 | INFO | [2,  2700] loss: 1.931
2025-02-26T03:04:36.414303+0300 | INFO | [2,  2800] loss: 1.912
2025-02-26T03:04:45.724276+0300 | INFO | [2,  2900] loss: 1.896
2025-02-26T03:04:55.784500+0300 | INFO | [2,  3000] loss: 1.915
2025-02-26T03:05:05.071871+0300 | INFO | [2,  3100] loss: 1.901
2025-02-26T03:05:15.654221+0300 | INFO | [2,  3200] loss: 1.925
2025-02-26T03:05:25.940535+0300 | INFO | [2,  3300] loss: 1.910
2025-02-26T03:05:35.201533+0300 | INFO | [2,  3400] loss: 1.909
2025-02-26T03:05:45.160255+0300 | INFO | [2,  3500] loss: 1.910
2025-02-26T03:05:55.177451+0300 | INFO | [2,  3600] loss: 1.898
2025-02-26T03:06:05.042031+0300 | INFO | [2,  3700] loss: 1.890
2025-02-26T03:06:14.856174+0300 | INFO | [2,  3800] loss: 1.892
2025-02-26T03:06:24.380481+0300 | INFO | [2,  3900] loss: 1.869
2025-02-26T03:06:35.207675+0300 | INFO | [2,  4000] loss: 1.900
2025-02-26T03:06:45.916441+0300 | INFO | [2,  4100] loss: 1.897
2025-02-26T03:06:55.724192+0300 | INFO | [2,  4200] loss: 1.901
2025-02-26T03:07:06.403109+0300 | INFO | [2,  4300] loss: 1.902
2025-02-26T03:07:16.170745+0300 | INFO | [2,  4400] loss: 1.853
2025-02-26T03:07:25.887674+0300 | INFO | [2,  4500] loss: 1.892
2025-02-26T03:07:36.255119+0300 | INFO | [2,  4600] loss: 1.874
2025-02-26T03:07:45.632589+0300 | INFO | [2,  4700] loss: 1.878
2025-02-26T03:07:55.473022+0300 | INFO | [2,  4800] loss: 1.868
2025-02-26T03:08:07.766061+0300 | INFO | [2,  4900] loss: 1.900
2025-02-26T03:08:16.688225+0300 | DEBUG | Saving model to flat file storage. Save #2
2025-02-26T03:08:16.709791+0300 | INFO | Averaging client parameters
2025-02-26T03:08:16.721141+0300 | INFO | Updating parameters on client #0
2025-02-26T03:08:32.395746+0300 | DEBUG | Test set: Accuracy: 6003/10000 (60%)
2025-02-26T03:08:32.396752+0300 | DEBUG | Test set: Loss: 1.8596255779266357
2025-02-26T03:08:32.497835+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.62      0.62      0.62      1000
           1       0.67      0.88      0.76      1000
           2       0.46      0.44      0.45      1000
           3       0.47      0.50      0.48      1200
           4       0.52      0.58      0.55      1000
           5       0.00      0.00      0.00       800
           6       0.55      0.84      0.67      1000
           7       0.75      0.58      0.65      1000
           8       0.65      0.86      0.74      1000
           9       0.84      0.60      0.70      1000

    accuracy                           0.60     10000
   macro avg       0.55      0.59      0.56     10000
weighted avg       0.56      0.60      0.57     10000

2025-02-26T03:08:32.502840+0300 | DEBUG | Confusion Matrix:
[[623  34  47  10  31   0  21   7 199  28]
 [ 15 879   2   2   6   0  19   6  39  32]
 [124  16 441  77 135   0 147  18  36   6]
 [ 67  36 124 596  74   0 188  50  50  15]
 [ 47  13  68  49 577   0 169  52  22   3]
 [ 25  24 132 401  74   0  58  48  36   2]
 [  9   8  52  41  31   0 843   1  14   1]
 [ 36  16  87  76 140   0  46 581   9   9]
 [ 30  48   2   9  24   0   8   1 864  14]
 [ 32 231   7  19  12   0  30  14  56 599]]
2025-02-26T03:08:32.505834+0300 | DEBUG | Class precision: [0.61805556 0.67356322 0.45841996 0.465625   0.52264493        nan
 0.55134075 0.74678663 0.65207547 0.8448519 ]
2025-02-26T03:08:32.506844+0300 | DEBUG | Class recall: [0.623      0.879      0.441      0.49666667 0.577      0.
 0.843      0.581      0.864      0.599     ]
2025-02-26T03:08:32.560015+0300 | INFO | Training epoch #3 on client #0
2025-02-26T03:08:32.561027+0300 | DEBUG | Saving model to flat file storage. Save #3
2025-02-26T03:08:32.763133+0300 | INFO | [3,     0] loss: 0.020
2025-02-26T03:08:42.879898+0300 | INFO | [3,   100] loss: 1.877
2025-02-26T03:08:52.919585+0300 | INFO | [3,   200] loss: 1.868
2025-02-26T03:09:02.101494+0300 | INFO | [3,   300] loss: 1.860
2025-02-26T03:09:12.249275+0300 | INFO | [3,   400] loss: 1.875
2025-02-26T03:09:21.585108+0300 | INFO | [3,   500] loss: 1.844
2025-02-26T03:09:31.883473+0300 | INFO | [3,   600] loss: 1.858
2025-02-26T03:09:42.266943+0300 | INFO | [3,   700] loss: 1.886
2025-02-26T03:09:51.567312+0300 | INFO | [3,   800] loss: 1.875
2025-02-26T03:10:02.299336+0300 | INFO | [3,   900] loss: 1.841
2025-02-26T03:10:14.749646+0300 | INFO | [3,  1000] loss: 1.854
2025-02-26T03:10:24.511445+0300 | INFO | [3,  1100] loss: 1.891
2025-02-26T03:10:34.490077+0300 | INFO | [3,  1200] loss: 1.874
2025-02-26T03:10:46.207412+0300 | INFO | [3,  1300] loss: 1.857
2025-02-26T03:11:00.153328+0300 | INFO | [3,  1400] loss: 1.846
2025-02-26T03:11:10.196060+0300 | INFO | [3,  1500] loss: 1.907
2025-02-26T03:11:20.828609+0300 | INFO | [3,  1600] loss: 1.865
2025-02-26T03:11:30.824662+0300 | INFO | [3,  1700] loss: 1.878
2025-02-26T03:11:40.674245+0300 | INFO | [3,  1800] loss: 1.876
2025-02-26T03:11:50.653620+0300 | INFO | [3,  1900] loss: 1.884
2025-02-26T03:12:00.123315+0300 | INFO | [3,  2000] loss: 1.837
2025-02-26T03:12:10.448797+0300 | INFO | [3,  2100] loss: 1.855
2025-02-26T03:12:20.379566+0300 | INFO | [3,  2200] loss: 1.840
2025-02-26T03:12:29.767855+0300 | INFO | [3,  2300] loss: 1.862
2025-02-26T03:12:40.051956+0300 | INFO | [3,  2400] loss: 1.868
2025-02-26T03:12:49.244508+0300 | INFO | [3,  2500] loss: 1.864
2025-02-26T03:12:59.249378+0300 | INFO | [3,  2600] loss: 1.847
2025-02-26T03:13:09.655724+0300 | INFO | [3,  2700] loss: 1.880
2025-02-26T03:13:18.758016+0300 | INFO | [3,  2800] loss: 1.832
2025-02-26T03:13:29.069021+0300 | INFO | [3,  2900] loss: 1.861
2025-02-26T03:13:38.677617+0300 | INFO | [3,  3000] loss: 1.842
2025-02-26T03:13:48.413553+0300 | INFO | [3,  3100] loss: 1.854
2025-02-26T03:13:58.427341+0300 | INFO | [3,  3200] loss: 1.855
2025-02-26T03:14:08.258816+0300 | INFO | [3,  3300] loss: 1.854
2025-02-26T03:14:18.289616+0300 | INFO | [3,  3400] loss: 1.835
2025-02-26T03:14:28.475346+0300 | INFO | [3,  3500] loss: 1.848
2025-02-26T03:14:37.824940+0300 | INFO | [3,  3600] loss: 1.839
2025-02-26T03:14:47.884855+0300 | INFO | [3,  3700] loss: 1.836
2025-02-26T03:14:57.336640+0300 | INFO | [3,  3800] loss: 1.832
2025-02-26T03:15:07.320997+0300 | INFO | [3,  3900] loss: 1.854
2025-02-26T03:15:17.170681+0300 | INFO | [3,  4000] loss: 1.847
2025-02-26T03:15:26.635657+0300 | INFO | [3,  4100] loss: 1.828
2025-02-26T03:15:36.511432+0300 | INFO | [3,  4200] loss: 1.825
2025-02-26T03:15:46.238788+0300 | INFO | [3,  4300] loss: 1.856
2025-02-26T03:15:56.451082+0300 | INFO | [3,  4400] loss: 1.867
2025-02-26T03:16:06.364525+0300 | INFO | [3,  4500] loss: 1.829
2025-02-26T03:16:15.781667+0300 | INFO | [3,  4600] loss: 1.813
2025-02-26T03:16:26.265322+0300 | INFO | [3,  4700] loss: 1.852
2025-02-26T03:16:36.352963+0300 | INFO | [3,  4800] loss: 1.839
2025-02-26T03:16:45.852853+0300 | INFO | [3,  4900] loss: 1.839
2025-02-26T03:16:55.750597+0300 | DEBUG | Saving model to flat file storage. Save #3
2025-02-26T03:16:55.776206+0300 | INFO | Averaging client parameters
2025-02-26T03:16:55.789156+0300 | INFO | Updating parameters on client #0
2025-02-26T03:17:11.826964+0300 | DEBUG | Test set: Accuracy: 6525/10000 (65%)
2025-02-26T03:17:11.827980+0300 | DEBUG | Test set: Loss: 1.8057523965835571
2025-02-26T03:17:11.937411+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.79      0.71      1000
           1       0.78      0.86      0.82      1000
           2       0.51      0.56      0.53      1000
           3       0.45      0.59      0.51      1200
           4       0.62      0.60      0.61      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.70      0.72      1000
           7       0.66      0.76      0.70      1000
           8       0.77      0.84      0.80      1000
           9       0.83      0.71      0.76      1000

    accuracy                           0.65     10000
   macro avg       0.60      0.64      0.62     10000
weighted avg       0.61      0.65      0.63     10000

2025-02-26T03:17:11.941415+0300 | DEBUG | Confusion Matrix:
[[794  26  41  13  16   0   4  12  62  32]
 [ 25 862   7   6   1   0   7  10  44  38]
 [118   8 559  75 108   0  55  47  20  10]
 [ 50  14 142 710  65   0  85  77  37  20]
 [ 41   7  88  79 599   0  48 120  13   5]
 [ 28   8  98 502  46   0  14  84  16   4]
 [ 15   7  89  85  64   0 701  21  14   4]
 [ 42   4  48  69  51   0  11 757   3  15]
 [ 82  28  13  10   6   0   2   3 836  20]
 [ 53 135  11  16   9   0   8  19  42 707]]
2025-02-26T03:17:11.942417+0300 | DEBUG | Class precision: [0.63621795 0.78434941 0.5100365  0.45367412 0.62072539        nan
 0.74973262 0.65826087 0.76908924 0.82690058]
2025-02-26T03:17:11.943414+0300 | DEBUG | Class recall: [0.794      0.862      0.559      0.59166667 0.599      0.
 0.701      0.757      0.836      0.707     ]
2025-02-26T03:17:11.992454+0300 | INFO | Training epoch #4 on client #0
2025-02-26T03:17:11.995454+0300 | DEBUG | Saving model to flat file storage. Save #4
2025-02-26T03:17:12.204431+0300 | INFO | [4,     0] loss: 0.022
2025-02-26T03:17:21.470296+0300 | INFO | [4,   100] loss: 1.827
2025-02-26T03:17:31.473500+0300 | INFO | [4,   200] loss: 1.845
2025-02-26T03:17:41.897780+0300 | INFO | [4,   300] loss: 1.847
2025-02-26T03:17:51.251400+0300 | INFO | [4,   400] loss: 1.819
2025-02-26T03:18:01.285016+0300 | INFO | [4,   500] loss: 1.773
2025-02-26T03:18:11.356683+0300 | INFO | [4,   600] loss: 1.800
2025-02-26T03:18:23.358029+0300 | INFO | [4,   700] loss: 1.817
2025-02-26T03:18:36.138719+0300 | INFO | [4,   800] loss: 1.834
2025-02-26T03:18:46.599962+0300 | INFO | [4,   900] loss: 1.833
2025-02-26T03:18:55.753709+0300 | INFO | [4,  1000] loss: 1.805
2025-02-26T03:19:06.012547+0300 | INFO | [4,  1100] loss: 1.800
2025-02-26T03:19:16.174395+0300 | INFO | [4,  1200] loss: 1.818
2025-02-26T03:19:25.651867+0300 | INFO | [4,  1300] loss: 1.808
2025-02-26T03:19:35.481237+0300 | INFO | [4,  1400] loss: 1.833
2025-02-26T03:19:44.816895+0300 | INFO | [4,  1500] loss: 1.834
2025-02-26T03:19:54.778590+0300 | INFO | [4,  1600] loss: 1.840
2025-02-26T03:20:05.814977+0300 | INFO | [4,  1700] loss: 1.819
2025-02-26T03:20:15.114490+0300 | INFO | [4,  1800] loss: 1.794
2025-02-26T03:20:25.436720+0300 | INFO | [4,  1900] loss: 1.826
2025-02-26T03:20:34.921025+0300 | INFO | [4,  2000] loss: 1.846
2025-02-26T03:20:44.613268+0300 | INFO | [4,  2100] loss: 1.829
2025-02-26T03:20:54.752522+0300 | INFO | [4,  2200] loss: 1.807
2025-02-26T03:21:04.023413+0300 | INFO | [4,  2300] loss: 1.812
2025-02-26T03:21:14.105093+0300 | INFO | [4,  2400] loss: 1.817
2025-02-26T03:21:24.174194+0300 | INFO | [4,  2500] loss: 1.812
2025-02-26T03:21:34.105606+0300 | INFO | [4,  2600] loss: 1.819
2025-02-26T03:21:44.502765+0300 | INFO | [4,  2700] loss: 1.833
2025-02-26T03:21:53.539760+0300 | INFO | [4,  2800] loss: 1.809
2025-02-26T03:22:04.290205+0300 | INFO | [4,  2900] loss: 1.813
2025-02-26T03:22:14.312486+0300 | INFO | [4,  3000] loss: 1.825
2025-02-26T03:22:23.344796+0300 | INFO | [4,  3100] loss: 1.833
2025-02-26T03:22:33.540410+0300 | INFO | [4,  3200] loss: 1.805
2025-02-26T03:22:43.438054+0300 | INFO | [4,  3300] loss: 1.855
2025-02-26T03:22:52.709430+0300 | INFO | [4,  3400] loss: 1.833
2025-02-26T03:23:03.524908+0300 | INFO | [4,  3500] loss: 1.829
2025-02-26T03:23:13.586091+0300 | INFO | [4,  3600] loss: 1.821
2025-02-26T03:23:23.335330+0300 | INFO | [4,  3700] loss: 1.831
2025-02-26T03:23:33.205522+0300 | INFO | [4,  3800] loss: 1.813
2025-02-26T03:23:42.502690+0300 | INFO | [4,  3900] loss: 1.825
2025-02-26T03:23:52.609152+0300 | INFO | [4,  4000] loss: 1.829
2025-02-26T03:24:04.007797+0300 | INFO | [4,  4100] loss: 1.813
2025-02-26T03:24:13.622835+0300 | INFO | [4,  4200] loss: 1.817
2025-02-26T03:24:24.273032+0300 | INFO | [4,  4300] loss: 1.820
2025-02-26T03:24:33.716825+0300 | INFO | [4,  4400] loss: 1.795
2025-02-26T03:24:44.016703+0300 | INFO | [4,  4500] loss: 1.808
2025-02-26T03:24:53.610874+0300 | INFO | [4,  4600] loss: 1.806
2025-02-26T03:25:03.542953+0300 | INFO | [4,  4700] loss: 1.806
2025-02-26T03:25:13.488740+0300 | INFO | [4,  4800] loss: 1.821
2025-02-26T03:25:22.943725+0300 | INFO | [4,  4900] loss: 1.819
2025-02-26T03:25:32.710682+0300 | DEBUG | Saving model to flat file storage. Save #4
2025-02-26T03:25:32.738695+0300 | INFO | Averaging client parameters
2025-02-26T03:25:32.748231+0300 | INFO | Updating parameters on client #0
2025-02-26T03:25:48.825084+0300 | DEBUG | Test set: Accuracy: 6680/10000 (67%)
2025-02-26T03:25:48.825084+0300 | DEBUG | Test set: Loss: 1.7903839349746704
2025-02-26T03:25:48.932687+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.70      0.73      1000
           1       0.73      0.90      0.81      1000
           2       0.65      0.46      0.54      1000
           3       0.48      0.61      0.54      1200
           4       0.58      0.67      0.62      1000
           5       0.00      0.00      0.00       800
           6       0.67      0.84      0.75      1000
           7       0.65      0.76      0.70      1000
           8       0.80      0.84      0.82      1000
           9       0.77      0.79      0.78      1000

    accuracy                           0.67     10000
   macro avg       0.61      0.66      0.63     10000
weighted avg       0.62      0.67      0.64     10000

2025-02-26T03:25:48.936013+0300 | DEBUG | Confusion Matrix:
[[705  54  50  12  26   0   7  17  82  47]
 [  8 898   3   4   2   0   8   5  24  48]
 [ 79   9 457  97 155   0 114  57  13  19]
 [ 20  28  61 735 103   0 125  74  32  22]
 [ 20   7  23  52 666   0  89 117  12  14]
 [  9  15  45 495  65   0  39 110   9  13]
 [  7  10  26  41  41   0 838  13  13  11]
 [ 14  16  27  67  75   0  14 755   5  27]
 [ 44  50   7  13  10   0   1   5 841  29]
 [ 28 135   3  12   2   0   9   7  19 785]]
2025-02-26T03:25:48.939435+0300 | DEBUG | Class precision: [0.75481799 0.73486088 0.65099715 0.48102094 0.58165939        nan
 0.67363344 0.65086207 0.80095238 0.77339901]
2025-02-26T03:25:48.940449+0300 | DEBUG | Class recall: [0.705  0.898  0.457  0.6125 0.666  0.     0.838  0.755  0.841  0.785 ]
2025-02-26T03:25:48.986620+0300 | INFO | Training epoch #5 on client #0
2025-02-26T03:25:48.989619+0300 | DEBUG | Saving model to flat file storage. Save #5
2025-02-26T03:25:49.223123+0300 | INFO | [5,     0] loss: 0.019
2025-02-26T03:26:05.700159+0300 | INFO | [5,   100] loss: 1.796
2025-02-26T03:26:16.110408+0300 | INFO | [5,   200] loss: 1.792
2025-02-26T03:26:25.452448+0300 | INFO | [5,   300] loss: 1.779
2025-02-26T03:26:35.630388+0300 | INFO | [5,   400] loss: 1.814
2025-02-26T03:26:45.963850+0300 | INFO | [5,   500] loss: 1.805
2025-02-26T03:26:55.203060+0300 | INFO | [5,   600] loss: 1.807
2025-02-26T03:27:05.669606+0300 | INFO | [5,   700] loss: 1.790
2025-02-26T03:27:15.929024+0300 | INFO | [5,   800] loss: 1.826
2025-02-26T03:27:25.156342+0300 | INFO | [5,   900] loss: 1.793
2025-02-26T03:27:35.244679+0300 | INFO | [5,  1000] loss: 1.774
2025-02-26T03:27:45.289668+0300 | INFO | [5,  1100] loss: 1.801
2025-02-26T03:27:55.163923+0300 | INFO | [5,  1200] loss: 1.834
2025-02-26T03:28:05.268094+0300 | INFO | [5,  1300] loss: 1.805
2025-02-26T03:28:14.633084+0300 | INFO | [5,  1400] loss: 1.822
2025-02-26T03:28:24.956042+0300 | INFO | [5,  1500] loss: 1.795
2025-02-26T03:28:34.418806+0300 | INFO | [5,  1600] loss: 1.793
2025-02-26T03:28:45.057770+0300 | INFO | [5,  1700] loss: 1.788
2025-02-26T03:28:55.610692+0300 | INFO | [5,  1800] loss: 1.803
2025-02-26T03:29:05.992673+0300 | INFO | [5,  1900] loss: 1.813
2025-02-26T03:29:16.672428+0300 | INFO | [5,  2000] loss: 1.806
2025-02-26T03:29:27.855760+0300 | INFO | [5,  2100] loss: 1.777
2025-02-26T03:29:37.628161+0300 | INFO | [5,  2200] loss: 1.835
2025-02-26T03:29:48.310198+0300 | INFO | [5,  2300] loss: 1.765
2025-02-26T03:29:59.037385+0300 | INFO | [5,  2400] loss: 1.787
2025-02-26T03:30:09.303809+0300 | INFO | [5,  2500] loss: 1.777
2025-02-26T03:30:19.861841+0300 | INFO | [5,  2600] loss: 1.789
2025-02-26T03:30:31.325767+0300 | INFO | [5,  2700] loss: 1.797
2025-02-26T03:30:42.131715+0300 | INFO | [5,  2800] loss: 1.805
2025-02-26T03:30:53.028128+0300 | INFO | [5,  2900] loss: 1.788
2025-02-26T03:31:03.676692+0300 | INFO | [5,  3000] loss: 1.800
2025-02-26T03:31:13.648566+0300 | INFO | [5,  3100] loss: 1.795
2025-02-26T03:31:24.638378+0300 | INFO | [5,  3200] loss: 1.759
2025-02-26T03:31:35.799507+0300 | INFO | [5,  3300] loss: 1.806
2025-02-26T03:31:45.874758+0300 | INFO | [5,  3400] loss: 1.766
2025-02-26T03:31:56.959093+0300 | INFO | [5,  3500] loss: 1.797
2025-02-26T03:32:08.479835+0300 | INFO | [5,  3600] loss: 1.777
2025-02-26T03:32:17.851347+0300 | INFO | [5,  3700] loss: 1.778
2025-02-26T03:32:29.534822+0300 | INFO | [5,  3800] loss: 1.811
2025-02-26T03:32:39.496288+0300 | INFO | [5,  3900] loss: 1.793
2025-02-26T03:32:49.136492+0300 | INFO | [5,  4000] loss: 1.766
2025-02-26T03:32:59.249341+0300 | INFO | [5,  4100] loss: 1.793
2025-02-26T03:33:09.433639+0300 | INFO | [5,  4200] loss: 1.810
2025-02-26T03:33:18.522257+0300 | INFO | [5,  4300] loss: 1.824
2025-02-26T03:33:29.140817+0300 | INFO | [5,  4400] loss: 1.801
2025-02-26T03:33:40.059214+0300 | INFO | [5,  4500] loss: 1.792
2025-02-26T03:33:53.734628+0300 | INFO | [5,  4600] loss: 1.796
2025-02-26T03:34:04.372080+0300 | INFO | [5,  4700] loss: 1.791
2025-02-26T03:34:14.298319+0300 | INFO | [5,  4800] loss: 1.788
2025-02-26T03:34:23.877071+0300 | INFO | [5,  4900] loss: 1.821
2025-02-26T03:34:33.800798+0300 | DEBUG | Saving model to flat file storage. Save #5
2025-02-26T03:34:33.826865+0300 | INFO | Averaging client parameters
2025-02-26T03:34:33.832490+0300 | INFO | Updating parameters on client #0
2025-02-26T03:34:48.991250+0300 | DEBUG | Test set: Accuracy: 6771/10000 (68%)
2025-02-26T03:34:48.993255+0300 | DEBUG | Test set: Loss: 1.7830543518066406
2025-02-26T03:34:49.085496+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.72      0.74      1000
           1       0.86      0.85      0.86      1000
           2       0.68      0.38      0.49      1000
           3       0.45      0.72      0.55      1200
           4       0.55      0.74      0.63      1000
           5       0.00      0.00      0.00       800
           6       0.66      0.86      0.75      1000
           7       0.78      0.66      0.72      1000
           8       0.79      0.88      0.83      1000
           9       0.83      0.82      0.82      1000

    accuracy                           0.68     10000
   macro avg       0.64      0.66      0.64     10000
weighted avg       0.65      0.68      0.65     10000

2025-02-26T03:34:49.087492+0300 | DEBUG | Confusion Matrix:
[[720  27  24  25  46   0  12  10  92  44]
 [ 15 852   3   8   3   0   9   5  29  76]
 [ 88   3 378 140 216   0 117  26  21  11]
 [ 13   7  51 859  85   0 110  41  25   9]
 [ 11   3   8  96 739   0  97  27  16   3]
 [  6   5  43 551  79   0  53  52   8   3]
 [  6   7  13  69  27   0 863   3  12   0]
 [ 18   4  27 101 140   0  30 662   6  12]
 [ 45  22   3  22  12   0   2   4 876  14]
 [ 21  55   6  31   8   0  12  17  28 822]]
2025-02-26T03:34:49.088493+0300 | DEBUG | Class precision: [0.76352068 0.86497462 0.67985612 0.45162986 0.54538745        nan
 0.66130268 0.78158205 0.78706199 0.82696177]
2025-02-26T03:34:49.088493+0300 | DEBUG | Class recall: [0.72       0.852      0.378      0.71583333 0.739      0.
 0.863      0.662      0.876      0.822     ]
2025-02-26T03:34:49.138491+0300 | INFO | Training epoch #6 on client #0
2025-02-26T03:34:49.139492+0300 | DEBUG | Saving model to flat file storage. Save #6
2025-02-26T03:34:49.330844+0300 | INFO | [6,     0] loss: 0.016
2025-02-26T03:34:59.193798+0300 | INFO | [6,   100] loss: 1.795
2025-02-26T03:35:09.603075+0300 | INFO | [6,   200] loss: 1.771
2025-02-26T03:35:19.377576+0300 | INFO | [6,   300] loss: 1.752
2025-02-26T03:35:28.869841+0300 | INFO | [6,   400] loss: 1.784
2025-02-26T03:35:38.756193+0300 | INFO | [6,   500] loss: 1.774
2025-02-26T03:35:49.200024+0300 | INFO | [6,   600] loss: 1.768
2025-02-26T03:35:58.817939+0300 | INFO | [6,   700] loss: 1.789
2025-02-26T03:36:08.822780+0300 | INFO | [6,   800] loss: 1.752
2025-02-26T03:36:18.033921+0300 | INFO | [6,   900] loss: 1.770
2025-02-26T03:36:28.418582+0300 | INFO | [6,  1000] loss: 1.782
2025-02-26T03:36:39.114707+0300 | INFO | [6,  1100] loss: 1.791
2025-02-26T03:36:48.819485+0300 | INFO | [6,  1200] loss: 1.775
2025-02-26T03:36:59.650146+0300 | INFO | [6,  1300] loss: 1.783
2025-02-26T03:37:10.106976+0300 | INFO | [6,  1400] loss: 1.781
2025-02-26T03:37:19.642730+0300 | INFO | [6,  1500] loss: 1.773
2025-02-26T03:37:30.375900+0300 | INFO | [6,  1600] loss: 1.755
2025-02-26T03:37:40.252805+0300 | INFO | [6,  1700] loss: 1.765
2025-02-26T03:37:50.359325+0300 | INFO | [6,  1800] loss: 1.765
2025-02-26T03:38:01.068975+0300 | INFO | [6,  1900] loss: 1.774
2025-02-26T03:38:12.772030+0300 | INFO | [6,  2000] loss: 1.776
2025-02-26T03:38:22.018674+0300 | INFO | [6,  2100] loss: 1.777
2025-02-26T03:38:32.193508+0300 | INFO | [6,  2200] loss: 1.790
2025-02-26T03:38:41.340976+0300 | INFO | [6,  2300] loss: 1.767
2025-02-26T03:38:51.234513+0300 | INFO | [6,  2400] loss: 1.761
2025-02-26T03:39:01.267112+0300 | INFO | [6,  2500] loss: 1.768
2025-02-26T03:39:10.708913+0300 | INFO | [6,  2600] loss: 1.734
2025-02-26T03:39:20.591877+0300 | INFO | [6,  2700] loss: 1.751
2025-02-26T03:39:30.891636+0300 | INFO | [6,  2800] loss: 1.777
2025-02-26T03:39:40.215300+0300 | INFO | [6,  2900] loss: 1.781
2025-02-26T03:39:50.140658+0300 | INFO | [6,  3000] loss: 1.792
2025-02-26T03:39:59.251239+0300 | INFO | [6,  3100] loss: 1.784
2025-02-26T03:40:09.530481+0300 | INFO | [6,  3200] loss: 1.781
2025-02-26T03:40:19.020466+0300 | INFO | [6,  3300] loss: 1.766
2025-02-26T03:40:28.543152+0300 | INFO | [6,  3400] loss: 1.782
2025-02-26T03:40:38.437016+0300 | INFO | [6,  3500] loss: 1.800
2025-02-26T03:40:48.089744+0300 | INFO | [6,  3600] loss: 1.763
2025-02-26T03:40:58.777166+0300 | INFO | [6,  3700] loss: 1.756
2025-02-26T03:41:08.944216+0300 | INFO | [6,  3800] loss: 1.779
2025-02-26T03:41:18.350775+0300 | INFO | [6,  3900] loss: 1.778
2025-02-26T03:41:34.000697+0300 | INFO | [6,  4000] loss: 1.773
2025-02-26T03:41:44.713256+0300 | INFO | [6,  4100] loss: 1.766
2025-02-26T03:41:54.075145+0300 | INFO | [6,  4200] loss: 1.773
2025-02-26T03:42:04.208313+0300 | INFO | [6,  4300] loss: 1.782
2025-02-26T03:42:13.982271+0300 | INFO | [6,  4400] loss: 1.772
2025-02-26T03:42:23.245495+0300 | INFO | [6,  4500] loss: 1.796
2025-02-26T03:42:33.352378+0300 | INFO | [6,  4600] loss: 1.796
2025-02-26T03:42:43.157315+0300 | INFO | [6,  4700] loss: 1.744
2025-02-26T03:42:52.936436+0300 | INFO | [6,  4800] loss: 1.780
2025-02-26T03:43:03.056450+0300 | INFO | [6,  4900] loss: 1.775
2025-02-26T03:43:12.325722+0300 | DEBUG | Saving model to flat file storage. Save #6
2025-02-26T03:43:12.364912+0300 | INFO | Averaging client parameters
2025-02-26T03:43:12.370115+0300 | INFO | Updating parameters on client #0
2025-02-26T03:43:27.549828+0300 | DEBUG | Test set: Accuracy: 6999/10000 (70%)
2025-02-26T03:43:27.550827+0300 | DEBUG | Test set: Loss: 1.7581655979156494
2025-02-26T03:43:27.643841+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      1000
           1       0.87      0.86      0.87      1000
           2       0.59      0.63      0.61      1000
           3       0.49      0.66      0.56      1200
           4       0.67      0.68      0.68      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.78      0.76      1000
           7       0.73      0.78      0.75      1000
           8       0.80      0.87      0.83      1000
           9       0.81      0.84      0.83      1000

    accuracy                           0.70     10000
   macro avg       0.64      0.69      0.66     10000
weighted avg       0.65      0.70      0.67     10000

2025-02-26T03:43:27.644850+0300 | DEBUG | Confusion Matrix:
[[767  13  44   7  23   0   3  19  86  38]
 [ 14 864   2   2   4   0   8   7  23  76]
 [ 90   7 629  88  76   0  49  37   7  17]
 [ 49   8  98 795  74   0  83  52  26  15]
 [ 32   2  91  58 684   0  49  70  12   2]
 [ 14   3  80 510  57   0  40  65  23   8]
 [ 19   0  73  59  40   0 776   8  16   9]
 [ 25   4  45  72  53   0  13 775   4   9]
 [ 43  30   5  10   9   0   3  11 871  18]
 [ 31  63   5  15   4   0   6  18  20 838]]
2025-02-26T03:43:27.645846+0300 | DEBUG | Class precision: [0.70756458 0.86921529 0.58675373 0.49195545 0.66796875        nan
 0.75339806 0.72975518 0.80055147 0.81359223]
2025-02-26T03:43:27.648223+0300 | DEBUG | Class recall: [0.767  0.864  0.629  0.6625 0.684  0.     0.776  0.775  0.871  0.838 ]
2025-02-26T03:43:27.700878+0300 | INFO | Training epoch #7 on client #0
2025-02-26T03:43:27.703053+0300 | DEBUG | Saving model to flat file storage. Save #7
2025-02-26T03:43:27.911695+0300 | INFO | [7,     0] loss: 0.017
2025-02-26T03:43:38.613650+0300 | INFO | [7,   100] loss: 1.746
2025-02-26T03:43:48.990654+0300 | INFO | [7,   200] loss: 1.744
2025-02-26T03:43:58.403007+0300 | INFO | [7,   300] loss: 1.739
2025-02-26T03:44:11.084519+0300 | INFO | [7,   400] loss: 1.753
2025-02-26T03:44:21.494383+0300 | INFO | [7,   500] loss: 1.786
2025-02-26T03:44:31.083854+0300 | INFO | [7,   600] loss: 1.749
2025-02-26T03:44:41.109955+0300 | INFO | [7,   700] loss: 1.738
2025-02-26T03:44:50.746901+0300 | INFO | [7,   800] loss: 1.749
2025-02-26T03:45:00.350254+0300 | INFO | [7,   900] loss: 1.758
2025-02-26T03:45:10.776075+0300 | INFO | [7,  1000] loss: 1.745
2025-02-26T03:45:20.091577+0300 | INFO | [7,  1100] loss: 1.746
2025-02-26T03:45:30.215879+0300 | INFO | [7,  1200] loss: 1.780
2025-02-26T03:45:40.250980+0300 | INFO | [7,  1300] loss: 1.790
2025-02-26T03:45:49.914478+0300 | INFO | [7,  1400] loss: 1.750
2025-02-26T03:46:00.402812+0300 | INFO | [7,  1500] loss: 1.784
2025-02-26T03:46:09.825386+0300 | INFO | [7,  1600] loss: 1.778
2025-02-26T03:46:19.998962+0300 | INFO | [7,  1700] loss: 1.764
2025-02-26T03:46:30.542565+0300 | INFO | [7,  1800] loss: 1.776
2025-02-26T03:46:40.578918+0300 | INFO | [7,  1900] loss: 1.756
2025-02-26T03:46:52.398971+0300 | INFO | [7,  2000] loss: 1.774
2025-02-26T03:47:04.374368+0300 | INFO | [7,  2100] loss: 1.750
2025-02-26T03:47:13.962614+0300 | INFO | [7,  2200] loss: 1.768
2025-02-26T03:47:24.856217+0300 | INFO | [7,  2300] loss: 1.752
2025-02-26T03:47:36.128442+0300 | INFO | [7,  2400] loss: 1.781
2025-02-26T03:47:45.994167+0300 | INFO | [7,  2500] loss: 1.757
2025-02-26T03:47:56.751611+0300 | INFO | [7,  2600] loss: 1.760
2025-02-26T03:48:07.258997+0300 | INFO | [7,  2700] loss: 1.756
2025-02-26T03:48:17.103787+0300 | INFO | [7,  2800] loss: 1.744
2025-02-26T03:48:27.771162+0300 | INFO | [7,  2900] loss: 1.755
2025-02-26T03:48:38.169418+0300 | INFO | [7,  3000] loss: 1.761
2025-02-26T03:48:48.062133+0300 | INFO | [7,  3100] loss: 1.733
2025-02-26T03:48:58.813737+0300 | INFO | [7,  3200] loss: 1.781
2025-02-26T03:49:10.440730+0300 | INFO | [7,  3300] loss: 1.761
2025-02-26T03:49:25.657584+0300 | INFO | [7,  3400] loss: 1.761
2025-02-26T03:49:35.852932+0300 | INFO | [7,  3500] loss: 1.773
2025-02-26T03:49:46.716272+0300 | INFO | [7,  3600] loss: 1.761
2025-02-26T03:49:57.921129+0300 | INFO | [7,  3700] loss: 1.742
2025-02-26T03:50:09.014611+0300 | INFO | [7,  3800] loss: 1.785
2025-02-26T03:50:20.042896+0300 | INFO | [7,  3900] loss: 1.739
2025-02-26T03:50:31.183349+0300 | INFO | [7,  4000] loss: 1.770
2025-02-26T03:50:41.122551+0300 | INFO | [7,  4100] loss: 1.765
2025-02-26T03:50:51.882762+0300 | INFO | [7,  4200] loss: 1.741
2025-02-26T03:51:01.788774+0300 | INFO | [7,  4300] loss: 1.766
2025-02-26T03:51:11.064219+0300 | INFO | [7,  4400] loss: 1.759
2025-02-26T03:51:21.098004+0300 | INFO | [7,  4500] loss: 1.748
2025-02-26T03:51:31.346443+0300 | INFO | [7,  4600] loss: 1.745
2025-02-26T03:51:40.974131+0300 | INFO | [7,  4700] loss: 1.743
2025-02-26T03:51:51.112249+0300 | INFO | [7,  4800] loss: 1.737
2025-02-26T03:52:00.500033+0300 | INFO | [7,  4900] loss: 1.773
2025-02-26T03:52:10.194389+0300 | DEBUG | Saving model to flat file storage. Save #7
2025-02-26T03:52:10.217683+0300 | INFO | Averaging client parameters
2025-02-26T03:52:10.224681+0300 | INFO | Updating parameters on client #0
2025-02-26T03:52:25.788889+0300 | DEBUG | Test set: Accuracy: 7001/10000 (70%)
2025-02-26T03:52:25.790884+0300 | DEBUG | Test set: Loss: 1.7589869499206543
2025-02-26T03:52:25.896314+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.80      0.74      1000
           1       0.79      0.91      0.84      1000
           2       0.63      0.54      0.58      1000
           3       0.48      0.74      0.58      1200
           4       0.67      0.72      0.69      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.79      0.80      1000
           7       0.69      0.81      0.75      1000
           8       0.88      0.80      0.84      1000
           9       0.90      0.74      0.81      1000

    accuracy                           0.70     10000
   macro avg       0.65      0.69      0.66     10000
weighted avg       0.66      0.70      0.68     10000

2025-02-26T03:52:25.899306+0300 | DEBUG | Confusion Matrix:
[[798  27  30  21  31   0   9  13  52  19]
 [ 22 913   0   3   3   0   9   5  10  35]
 [113   5 536 116 117   0  64  44   4   1]
 [ 20  12  84 890  67   0  42  69   9   7]
 [ 15   4  31  91 718   0  37  96   8   0]
 [ 15   6  83 534  45   0  15  95   5   2]
 [  9   4  40 104  33   0 794  12   4   0]
 [ 28   9  28  71  42   0   6 811   2   3]
 [ 80  53  10  21  12   0   2   3 802  17]
 [ 49 130   7  19  10   0   9  25  12 739]]
2025-02-26T03:52:25.901310+0300 | DEBUG | Class precision: [0.69451697 0.78503869 0.63133098 0.47593583 0.66604824        nan
 0.80445795 0.6913896  0.88325991 0.89793439]
2025-02-26T03:52:25.903313+0300 | DEBUG | Class recall: [0.798      0.913      0.536      0.74166667 0.718      0.
 0.794      0.811      0.802      0.739     ]
2025-02-26T03:52:25.946874+0300 | INFO | Training epoch #8 on client #0
2025-02-26T03:52:25.948148+0300 | DEBUG | Saving model to flat file storage. Save #8
2025-02-26T03:52:26.148485+0300 | INFO | [8,     0] loss: 0.018
2025-02-26T03:52:36.523620+0300 | INFO | [8,   100] loss: 1.739
2025-02-26T03:52:45.609554+0300 | INFO | [8,   200] loss: 1.748
2025-02-26T03:52:55.489340+0300 | INFO | [8,   300] loss: 1.734
2025-02-26T03:53:04.738312+0300 | INFO | [8,   400] loss: 1.754
2025-02-26T03:53:16.156539+0300 | INFO | [8,   500] loss: 1.757
2025-02-26T03:53:26.094780+0300 | INFO | [8,   600] loss: 1.733
2025-02-26T03:53:35.486817+0300 | INFO | [8,   700] loss: 1.740
2025-02-26T03:53:45.557722+0300 | INFO | [8,   800] loss: 1.735
2025-02-26T03:53:54.790632+0300 | INFO | [8,   900] loss: 1.749
2025-02-26T03:54:04.542566+0300 | INFO | [8,  1000] loss: 1.705
2025-02-26T03:54:14.666981+0300 | INFO | [8,  1100] loss: 1.712
2025-02-26T03:54:24.200679+0300 | INFO | [8,  1200] loss: 1.761
2025-02-26T03:54:34.437280+0300 | INFO | [8,  1300] loss: 1.754
2025-02-26T03:54:44.647784+0300 | INFO | [8,  1400] loss: 1.740
2025-02-26T03:54:53.825387+0300 | INFO | [8,  1500] loss: 1.722
2025-02-26T03:55:03.745322+0300 | INFO | [8,  1600] loss: 1.737
2025-02-26T03:55:12.836980+0300 | INFO | [8,  1700] loss: 1.752
2025-02-26T03:55:22.463584+0300 | INFO | [8,  1800] loss: 1.768
2025-02-26T03:55:32.482653+0300 | INFO | [8,  1900] loss: 1.753
2025-02-26T03:55:42.042245+0300 | INFO | [8,  2000] loss: 1.725
2025-02-26T03:55:52.013788+0300 | INFO | [8,  2100] loss: 1.747
2025-02-26T03:56:01.809693+0300 | INFO | [8,  2200] loss: 1.729
2025-02-26T03:56:12.093602+0300 | INFO | [8,  2300] loss: 1.764
2025-02-26T03:56:22.187227+0300 | INFO | [8,  2400] loss: 1.736
2025-02-26T03:56:31.912776+0300 | INFO | [8,  2500] loss: 1.761
2025-02-26T03:56:42.009486+0300 | INFO | [8,  2600] loss: 1.741
2025-02-26T03:56:52.028661+0300 | INFO | [8,  2700] loss: 1.747
2025-02-26T03:57:07.283637+0300 | INFO | [8,  2800] loss: 1.731
2025-02-26T03:57:16.983105+0300 | INFO | [8,  2900] loss: 1.750
2025-02-26T03:57:27.069979+0300 | INFO | [8,  3000] loss: 1.749
2025-02-26T03:57:36.469262+0300 | INFO | [8,  3100] loss: 1.780
2025-02-26T03:57:46.728522+0300 | INFO | [8,  3200] loss: 1.743
2025-02-26T03:57:56.675652+0300 | INFO | [8,  3300] loss: 1.752
2025-02-26T03:58:05.883700+0300 | INFO | [8,  3400] loss: 1.723
2025-02-26T03:58:15.929672+0300 | INFO | [8,  3500] loss: 1.724
2025-02-26T03:58:24.922056+0300 | INFO | [8,  3600] loss: 1.728
2025-02-26T03:58:34.973732+0300 | INFO | [8,  3700] loss: 1.739
2025-02-26T03:58:44.767894+0300 | INFO | [8,  3800] loss: 1.738
2025-02-26T03:58:54.000575+0300 | INFO | [8,  3900] loss: 1.740
2025-02-26T03:59:04.877623+0300 | INFO | [8,  4000] loss: 1.766
2025-02-26T03:59:13.972505+0300 | INFO | [8,  4100] loss: 1.761
2025-02-26T03:59:24.202770+0300 | INFO | [8,  4200] loss: 1.760
2025-02-26T03:59:34.554850+0300 | INFO | [8,  4300] loss: 1.722
2025-02-26T03:59:43.966339+0300 | INFO | [8,  4400] loss: 1.752
2025-02-26T03:59:54.341703+0300 | INFO | [8,  4500] loss: 1.763
2025-02-26T04:00:04.359740+0300 | INFO | [8,  4600] loss: 1.750
2025-02-26T04:00:13.727753+0300 | INFO | [8,  4700] loss: 1.747
2025-02-26T04:00:23.640910+0300 | INFO | [8,  4800] loss: 1.759
2025-02-26T04:00:32.841183+0300 | INFO | [8,  4900] loss: 1.753
2025-02-26T04:00:43.196080+0300 | DEBUG | Saving model to flat file storage. Save #8
2025-02-26T04:00:43.222088+0300 | INFO | Averaging client parameters
2025-02-26T04:00:43.228954+0300 | INFO | Updating parameters on client #0
2025-02-26T04:00:57.988109+0300 | DEBUG | Test set: Accuracy: 7026/10000 (70%)
2025-02-26T04:00:57.988109+0300 | DEBUG | Test set: Loss: 1.7551624774932861
2025-02-26T04:00:58.086414+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.86      0.75      1000
           1       0.91      0.80      0.85      1000
           2       0.74      0.51      0.60      1000
           3       0.51      0.66      0.57      1200
           4       0.62      0.79      0.69      1000
           5       0.00      0.00      0.00       800
           6       0.70      0.85      0.77      1000
           7       0.75      0.76      0.75      1000
           8       0.87      0.81      0.84      1000
           9       0.77      0.86      0.81      1000

    accuracy                           0.70     10000
   macro avg       0.65      0.69      0.66     10000
weighted avg       0.66      0.70      0.67     10000

2025-02-26T04:00:58.088419+0300 | DEBUG | Confusion Matrix:
[[862  12  24   9  13   0   5   7  34  34]
 [ 25 800   0   0   4   0  11   6  18 136]
 [115   2 506  84 142   0  91  39  10  11]
 [ 39   5  48 792 115   0 110  51  21  19]
 [ 39   1  18  38 785   0  64  49   4   2]
 [ 24   3  43 496  75   0  47  92  12   8]
 [ 17   1  31  52  31   0 855   5   7   1]
 [ 40   0  12  64  85   0  25 756   2  16]
 [108  23   2  12   6   0   3   2 814  30]
 [ 45  31   4  18   6   0  16   5  19 856]]
2025-02-26T04:00:58.092828+0300 | DEBUG | Class precision: [0.65601218 0.91116173 0.73546512 0.50607029 0.62202853        nan
 0.69682152 0.74703557 0.86503719 0.76909254]
2025-02-26T04:00:58.095832+0300 | DEBUG | Class recall: [0.862 0.8   0.506 0.66  0.785 0.    0.855 0.756 0.814 0.856]
2025-02-26T04:00:58.143364+0300 | INFO | Training epoch #9 on client #0
2025-02-26T04:00:58.145367+0300 | DEBUG | Saving model to flat file storage. Save #9
2025-02-26T04:00:58.353945+0300 | INFO | [9,     0] loss: 0.017
2025-02-26T04:01:08.486651+0300 | INFO | [9,   100] loss: 1.729
2025-02-26T04:01:18.063855+0300 | INFO | [9,   200] loss: 1.723
2025-02-26T04:01:28.182393+0300 | INFO | [9,   300] loss: 1.756
2025-02-26T04:01:37.759379+0300 | INFO | [9,   400] loss: 1.747
2025-02-26T04:01:48.175316+0300 | INFO | [9,   500] loss: 1.722
2025-02-26T04:01:58.597551+0300 | INFO | [9,   600] loss: 1.724
2025-02-26T04:02:08.148386+0300 | INFO | [9,   700] loss: 1.739
2025-02-26T04:02:18.140442+0300 | INFO | [9,   800] loss: 1.732
2025-02-26T04:02:28.497437+0300 | INFO | [9,   900] loss: 1.714
2025-02-26T04:02:37.727288+0300 | INFO | [9,  1000] loss: 1.739
2025-02-26T04:02:47.845681+0300 | INFO | [9,  1100] loss: 1.723
2025-02-26T04:02:57.056989+0300 | INFO | [9,  1200] loss: 1.724
2025-02-26T04:03:07.324791+0300 | INFO | [9,  1300] loss: 1.745
2025-02-26T04:03:17.607756+0300 | INFO | [9,  1400] loss: 1.724
2025-02-26T04:03:27.085059+0300 | INFO | [9,  1500] loss: 1.726
2025-02-26T04:03:37.116039+0300 | INFO | [9,  1600] loss: 1.711
2025-02-26T04:03:47.544059+0300 | INFO | [9,  1700] loss: 1.736
2025-02-26T04:03:56.910649+0300 | INFO | [9,  1800] loss: 1.737
2025-02-26T04:04:06.342414+0300 | INFO | [9,  1900] loss: 1.732
2025-02-26T04:04:16.046433+0300 | INFO | [9,  2000] loss: 1.738
2025-02-26T04:04:25.749394+0300 | INFO | [9,  2100] loss: 1.717
2025-02-26T04:04:37.506012+0300 | INFO | [9,  2200] loss: 1.737
2025-02-26T04:04:50.486223+0300 | INFO | [9,  2300] loss: 1.736
2025-02-26T04:05:01.684377+0300 | INFO | [9,  2400] loss: 1.731
2025-02-26T04:05:11.927002+0300 | INFO | [9,  2500] loss: 1.757
2025-02-26T04:05:21.205123+0300 | INFO | [9,  2600] loss: 1.752
2025-02-26T04:05:31.305799+0300 | INFO | [9,  2700] loss: 1.756
2025-02-26T04:05:41.591075+0300 | INFO | [9,  2800] loss: 1.742
2025-02-26T04:05:51.389906+0300 | INFO | [9,  2900] loss: 1.714
2025-02-26T04:06:01.510806+0300 | INFO | [9,  3000] loss: 1.724
2025-02-26T04:06:11.730001+0300 | INFO | [9,  3100] loss: 1.728
2025-02-26T04:06:20.953982+0300 | INFO | [9,  3200] loss: 1.770
2025-02-26T04:06:31.610149+0300 | INFO | [9,  3300] loss: 1.713
2025-02-26T04:06:41.565897+0300 | INFO | [9,  3400] loss: 1.747
2025-02-26T04:06:51.932825+0300 | INFO | [9,  3500] loss: 1.739
2025-02-26T04:07:02.293740+0300 | INFO | [9,  3600] loss: 1.734
2025-02-26T04:07:11.864446+0300 | INFO | [9,  3700] loss: 1.737
2025-02-26T04:07:22.062877+0300 | INFO | [9,  3800] loss: 1.747
2025-02-26T04:07:32.143007+0300 | INFO | [9,  3900] loss: 1.722
2025-02-26T04:07:41.276025+0300 | INFO | [9,  4000] loss: 1.714
2025-02-26T04:07:51.756929+0300 | INFO | [9,  4100] loss: 1.718
2025-02-26T04:08:01.063358+0300 | INFO | [9,  4200] loss: 1.744
2025-02-26T04:08:12.443963+0300 | INFO | [9,  4300] loss: 1.718
2025-02-26T04:08:22.432129+0300 | INFO | [9,  4400] loss: 1.758
2025-02-26T04:08:31.509803+0300 | INFO | [9,  4500] loss: 1.733
2025-02-26T04:08:41.006788+0300 | INFO | [9,  4600] loss: 1.725
2025-02-26T04:08:51.363999+0300 | INFO | [9,  4700] loss: 1.748
2025-02-26T04:09:00.844052+0300 | INFO | [9,  4800] loss: 1.727
2025-02-26T04:09:11.762127+0300 | INFO | [9,  4900] loss: 1.731
2025-02-26T04:09:20.894853+0300 | DEBUG | Saving model to flat file storage. Save #9
2025-02-26T04:09:20.919889+0300 | INFO | Averaging client parameters
2025-02-26T04:09:20.927954+0300 | INFO | Updating parameters on client #0
2025-02-26T04:09:36.453289+0300 | DEBUG | Test set: Accuracy: 7174/10000 (72%)
2025-02-26T04:09:36.454797+0300 | DEBUG | Test set: Loss: 1.7423869371414185
2025-02-26T04:09:36.559769+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.80      0.76      1000
           1       0.88      0.84      0.86      1000
           2       0.65      0.60      0.62      1000
           3       0.49      0.76      0.60      1200
           4       0.68      0.76      0.72      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.82      0.79      1000
           7       0.75      0.80      0.78      1000
           8       0.86      0.84      0.85      1000
           9       0.87      0.81      0.84      1000

    accuracy                           0.72     10000
   macro avg       0.67      0.70      0.68     10000
weighted avg       0.68      0.72      0.69     10000

2025-02-26T04:09:36.561845+0300 | DEBUG | Confusion Matrix:
[[803  18  43  18  14   0  13  10  60  21]
 [ 24 837   8  12   2   0  35   4  19  59]
 [ 76   0 600  91 112   0  70  41   4   6]
 [ 23   2  81 909  64   0  47  53  10  11]
 [ 28   2  41  56 763   0  34  69   6   1]
 [ 11   2  67 560  55   0  25  71   7   2]
 [ 11   2  35  79  46   0 817  10   0   0]
 [ 27   2  22  77  46   0  13 803   2   8]
 [ 70  28  16  15  11   0   9   2 837  12]
 [ 42  59   8  32   4   0   9   9  32 805]]
2025-02-26T04:09:36.563880+0300 | DEBUG | Class precision: [0.72017937 0.87920168 0.6514658  0.49161709 0.68307968        nan
 0.76212687 0.74906716 0.8567042  0.87027027]
2025-02-26T04:09:36.565875+0300 | DEBUG | Class recall: [0.803  0.837  0.6    0.7575 0.763  0.     0.817  0.803  0.837  0.805 ]
2025-02-26T04:09:36.618003+0300 | INFO | Training epoch #10 on client #0
2025-02-26T04:09:36.619011+0300 | DEBUG | Saving model to flat file storage. Save #10
2025-02-26T04:09:36.829886+0300 | INFO | [10,     0] loss: 0.017
2025-02-26T04:09:47.025686+0300 | INFO | [10,   100] loss: 1.714
2025-02-26T04:09:57.061542+0300 | INFO | [10,   200] loss: 1.702
2025-02-26T04:10:06.307762+0300 | INFO | [10,   300] loss: 1.721
2025-02-26T04:10:16.449442+0300 | INFO | [10,   400] loss: 1.715
2025-02-26T04:10:25.455987+0300 | INFO | [10,   500] loss: 1.715
2025-02-26T04:10:35.473425+0300 | INFO | [10,   600] loss: 1.724
2025-02-26T04:10:46.309087+0300 | INFO | [10,   700] loss: 1.725
2025-02-26T04:10:55.739852+0300 | INFO | [10,   800] loss: 1.724
2025-02-26T04:11:05.939269+0300 | INFO | [10,   900] loss: 1.719
2025-02-26T04:11:16.007892+0300 | INFO | [10,  1000] loss: 1.707
2025-02-26T04:11:25.247843+0300 | INFO | [10,  1100] loss: 1.736
2025-02-26T04:11:35.552697+0300 | INFO | [10,  1200] loss: 1.730
2025-02-26T04:11:45.015032+0300 | INFO | [10,  1300] loss: 1.726
2025-02-26T04:11:54.862530+0300 | INFO | [10,  1400] loss: 1.721
2025-02-26T04:12:04.668131+0300 | INFO | [10,  1500] loss: 1.696
2025-02-26T04:12:13.957584+0300 | INFO | [10,  1600] loss: 1.728
2025-02-26T04:12:29.227510+0300 | INFO | [10,  1700] loss: 1.730
2025-02-26T04:12:39.569762+0300 | INFO | [10,  1800] loss: 1.745
2025-02-26T04:12:49.049292+0300 | INFO | [10,  1900] loss: 1.710
2025-02-26T04:12:58.609785+0300 | INFO | [10,  2000] loss: 1.721
2025-02-26T04:13:08.639473+0300 | INFO | [10,  2100] loss: 1.736
2025-02-26T04:13:18.160807+0300 | INFO | [10,  2200] loss: 1.733
2025-02-26T04:13:27.983500+0300 | INFO | [10,  2300] loss: 1.747
2025-02-26T04:13:37.452405+0300 | INFO | [10,  2400] loss: 1.712
2025-02-26T04:13:48.383822+0300 | INFO | [10,  2500] loss: 1.723
2025-02-26T04:13:58.312084+0300 | INFO | [10,  2600] loss: 1.734
2025-02-26T04:14:07.528050+0300 | INFO | [10,  2700] loss: 1.728
2025-02-26T04:14:17.677945+0300 | INFO | [10,  2800] loss: 1.725
2025-02-26T04:14:27.280360+0300 | INFO | [10,  2900] loss: 1.716
2025-02-26T04:14:36.569522+0300 | INFO | [10,  3000] loss: 1.737
2025-02-26T04:14:46.166392+0300 | INFO | [10,  3100] loss: 1.725
2025-02-26T04:14:55.292003+0300 | INFO | [10,  3200] loss: 1.704
2025-02-26T04:15:05.291768+0300 | INFO | [10,  3300] loss: 1.734
2025-02-26T04:15:15.772751+0300 | INFO | [10,  3400] loss: 1.731
2025-02-26T04:15:24.797533+0300 | INFO | [10,  3500] loss: 1.700
2025-02-26T04:15:35.260744+0300 | INFO | [10,  3600] loss: 1.763
2025-02-26T04:15:44.818278+0300 | INFO | [10,  3700] loss: 1.745
2025-02-26T04:15:55.243200+0300 | INFO | [10,  3800] loss: 1.735
2025-02-26T04:16:05.186775+0300 | INFO | [10,  3900] loss: 1.736
2025-02-26T04:16:14.741491+0300 | INFO | [10,  4000] loss: 1.718
2025-02-26T04:16:24.883545+0300 | INFO | [10,  4100] loss: 1.718
2025-02-26T04:16:35.909058+0300 | INFO | [10,  4200] loss: 1.723
2025-02-26T04:16:45.446837+0300 | INFO | [10,  4300] loss: 1.717
2025-02-26T04:16:55.385639+0300 | INFO | [10,  4400] loss: 1.720
2025-02-26T04:17:04.898095+0300 | INFO | [10,  4500] loss: 1.722
2025-02-26T04:17:15.392011+0300 | INFO | [10,  4600] loss: 1.732
2025-02-26T04:17:25.447661+0300 | INFO | [10,  4700] loss: 1.718
2025-02-26T04:17:34.811587+0300 | INFO | [10,  4800] loss: 1.732
2025-02-26T04:17:44.768541+0300 | INFO | [10,  4900] loss: 1.721
2025-02-26T04:17:54.025058+0300 | DEBUG | Saving model to flat file storage. Save #10
2025-02-26T04:17:54.051508+0300 | INFO | Averaging client parameters
2025-02-26T04:17:54.056696+0300 | INFO | Updating parameters on client #0
2025-02-26T04:18:09.182036+0300 | DEBUG | Test set: Accuracy: 7307/10000 (73%)
2025-02-26T04:18:09.183498+0300 | DEBUG | Test set: Loss: 1.7298693656921387
2025-02-26T04:18:09.281458+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.87      0.76      1000
           1       0.86      0.91      0.88      1000
           2       0.63      0.65      0.64      1000
           3       0.51      0.72      0.60      1200
           4       0.73      0.76      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.84      0.81      1000
           7       0.80      0.78      0.79      1000
           8       0.89      0.79      0.84      1000
           9       0.86      0.84      0.85      1000

    accuracy                           0.73     10000
   macro avg       0.68      0.72      0.69     10000
weighted avg       0.69      0.73      0.70     10000

2025-02-26T04:18:09.284458+0300 | DEBUG | Confusion Matrix:
[[867  15  29  12   3   0   7   7  33  27]
 [ 30 909   1   1   1   0   7   2  12  37]
 [ 94   4 650  68  88   0  59  20   7  10]
 [ 38  10  94 869  51   0  69  33  11  25]
 [ 31   1  60  57 758   0  49  40   3   1]
 [ 17   5  87 526  48   0  26  75   7   9]
 [ 11   8  52  50  29   0 843   4   3   0]
 [ 26   2  38  74  49   0  15 782   5   9]
 [110  48  11  17   3   0   4   2 787  18]
 [ 45  61   3  17   2   0   7   7  16 842]]
2025-02-26T04:18:09.286455+0300 | DEBUG | Class precision: [0.68321513 0.855127   0.63414634 0.5138971  0.73449612        nan
 0.77624309 0.80452675 0.89027149 0.8609407 ]
2025-02-26T04:18:09.287449+0300 | DEBUG | Class recall: [0.867      0.909      0.65       0.72416667 0.758      0.
 0.843      0.782      0.787      0.842     ]
2025-02-26T04:18:09.343217+0300 | INFO | Training epoch #11 on client #0
2025-02-26T04:18:09.345219+0300 | DEBUG | Saving model to flat file storage. Save #11
2025-02-26T04:18:09.544517+0300 | INFO | [11,     0] loss: 0.018
2025-02-26T04:18:20.043977+0300 | INFO | [11,   100] loss: 1.713
2025-02-26T04:18:30.000463+0300 | INFO | [11,   200] loss: 1.722
2025-02-26T04:18:38.891748+0300 | INFO | [11,   300] loss: 1.709
2025-02-26T04:18:49.107727+0300 | INFO | [11,   400] loss: 1.731
2025-02-26T04:18:59.265226+0300 | INFO | [11,   500] loss: 1.697
2025-02-26T04:19:08.993451+0300 | INFO | [11,   600] loss: 1.697
2025-02-26T04:19:19.105453+0300 | INFO | [11,   700] loss: 1.698
2025-02-26T04:19:28.224017+0300 | INFO | [11,   800] loss: 1.719
2025-02-26T04:19:38.976236+0300 | INFO | [11,   900] loss: 1.729
2025-02-26T04:19:49.415620+0300 | INFO | [11,  1000] loss: 1.682
2025-02-26T04:20:00.545444+0300 | INFO | [11,  1100] loss: 1.715
2025-02-26T04:20:14.213899+0300 | INFO | [11,  1200] loss: 1.724
2025-02-26T04:20:24.062850+0300 | INFO | [11,  1300] loss: 1.708
2025-02-26T04:20:33.396267+0300 | INFO | [11,  1400] loss: 1.725
2025-02-26T04:20:43.218644+0300 | INFO | [11,  1500] loss: 1.690
2025-02-26T04:20:54.258428+0300 | INFO | [11,  1600] loss: 1.733
2025-02-26T04:21:05.228999+0300 | INFO | [11,  1700] loss: 1.726
2025-02-26T04:21:15.715895+0300 | INFO | [11,  1800] loss: 1.720
2025-02-26T04:21:25.821864+0300 | INFO | [11,  1900] loss: 1.702
2025-02-26T04:21:35.621296+0300 | INFO | [11,  2000] loss: 1.728
2025-02-26T04:21:47.626924+0300 | INFO | [11,  2100] loss: 1.719
2025-02-26T04:21:58.083016+0300 | INFO | [11,  2200] loss: 1.734
2025-02-26T04:22:07.336775+0300 | INFO | [11,  2300] loss: 1.702
2025-02-26T04:22:17.811117+0300 | INFO | [11,  2400] loss: 1.693
2025-02-26T04:22:27.761762+0300 | INFO | [11,  2500] loss: 1.704
2025-02-26T04:22:37.912318+0300 | INFO | [11,  2600] loss: 1.721
2025-02-26T04:22:48.892727+0300 | INFO | [11,  2700] loss: 1.707
2025-02-26T04:22:58.567567+0300 | INFO | [11,  2800] loss: 1.727
2025-02-26T04:23:09.344975+0300 | INFO | [11,  2900] loss: 1.717
2025-02-26T04:23:19.631263+0300 | INFO | [11,  3000] loss: 1.723
2025-02-26T04:23:28.707157+0300 | INFO | [11,  3100] loss: 1.725
2025-02-26T04:23:38.659676+0300 | INFO | [11,  3200] loss: 1.716
2025-02-26T04:23:48.858121+0300 | INFO | [11,  3300] loss: 1.713
2025-02-26T04:23:58.099352+0300 | INFO | [11,  3400] loss: 1.718
2025-02-26T04:24:08.240935+0300 | INFO | [11,  3500] loss: 1.726
2025-02-26T04:24:17.333211+0300 | INFO | [11,  3600] loss: 1.714
2025-02-26T04:24:27.133282+0300 | INFO | [11,  3700] loss: 1.717
2025-02-26T04:24:37.546372+0300 | INFO | [11,  3800] loss: 1.713
2025-02-26T04:24:46.872090+0300 | INFO | [11,  3900] loss: 1.712
2025-02-26T04:24:56.735302+0300 | INFO | [11,  4000] loss: 1.714
2025-02-26T04:25:06.239378+0300 | INFO | [11,  4100] loss: 1.734
2025-02-26T04:25:16.408576+0300 | INFO | [11,  4200] loss: 1.709
2025-02-26T04:25:26.046354+0300 | INFO | [11,  4300] loss: 1.727
2025-02-26T04:25:36.501319+0300 | INFO | [11,  4400] loss: 1.705
2025-02-26T04:25:46.873393+0300 | INFO | [11,  4500] loss: 1.714
2025-02-26T04:25:56.893651+0300 | INFO | [11,  4600] loss: 1.723
2025-02-26T04:26:06.249801+0300 | INFO | [11,  4700] loss: 1.715
2025-02-26T04:26:16.718704+0300 | INFO | [11,  4800] loss: 1.734
2025-02-26T04:26:26.076135+0300 | INFO | [11,  4900] loss: 1.742
2025-02-26T04:26:36.494694+0300 | DEBUG | Saving model to flat file storage. Save #11
2025-02-26T04:26:36.514589+0300 | INFO | Averaging client parameters
2025-02-26T04:26:36.521817+0300 | INFO | Updating parameters on client #0
2025-02-26T04:26:52.355302+0300 | DEBUG | Test set: Accuracy: 7278/10000 (73%)
2025-02-26T04:26:52.357614+0300 | DEBUG | Test set: Loss: 1.7321531772613525
2025-02-26T04:26:52.457774+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.82      0.77      1000
           1       0.91      0.87      0.89      1000
           2       0.59      0.69      0.64      1000
           3       0.53      0.68      0.59      1200
           4       0.73      0.70      0.71      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.81      0.81      1000
           7       0.70      0.84      0.76      1000
           8       0.83      0.90      0.86      1000
           9       0.86      0.84      0.85      1000

    accuracy                           0.73     10000
   macro avg       0.67      0.71      0.69     10000
weighted avg       0.68      0.73      0.70     10000

2025-02-26T04:26:52.462213+0300 | DEBUG | Confusion Matrix:
[[817  17  51   8  10   0   2   9  66  20]
 [ 13 869   6   2   2   0  10   6  24  68]
 [ 83   3 686  62  65   0  44  39   9   9]
 [ 42   4 114 819  66   0  45  67  26  17]
 [ 24   2  69  45 701   0  54  96   8   1]
 [ 15   3 117 473  49   0  19 107  12   5]
 [  8   3  56  69  26   0 812  18   7   1]
 [ 27   0  31  52  35   0   6 836   7   6]
 [ 51  10  12  12   5   0   2   3 896   9]
 [ 43  44  11  14   4   0   4   9  29 842]]
2025-02-26T04:26:52.464080+0300 | DEBUG | Class precision: [0.72751558 0.90994764 0.59496964 0.52634961 0.72793354        nan
 0.81362725 0.70252101 0.82656827 0.8609407 ]
2025-02-26T04:26:52.465213+0300 | DEBUG | Class recall: [0.817  0.869  0.686  0.6825 0.701  0.     0.812  0.836  0.896  0.842 ]
2025-02-26T04:26:52.515549+0300 | INFO | Training epoch #12 on client #0
2025-02-26T04:26:52.517913+0300 | DEBUG | Saving model to flat file storage. Save #12
2025-02-26T04:26:52.720629+0300 | INFO | [12,     0] loss: 0.016
2025-02-26T04:27:02.734541+0300 | INFO | [12,   100] loss: 1.712
2025-02-26T04:27:12.616886+0300 | INFO | [12,   200] loss: 1.717
2025-02-26T04:27:22.837123+0300 | INFO | [12,   300] loss: 1.700
2025-02-26T04:27:32.894105+0300 | INFO | [12,   400] loss: 1.698
2025-02-26T04:27:42.235429+0300 | INFO | [12,   500] loss: 1.692
2025-02-26T04:27:56.122560+0300 | INFO | [12,   600] loss: 1.685
2025-02-26T04:28:08.015289+0300 | INFO | [12,   700] loss: 1.693
2025-02-26T04:28:17.653610+0300 | INFO | [12,   800] loss: 1.727
2025-02-26T04:28:27.249103+0300 | INFO | [12,   900] loss: 1.697
2025-02-26T04:28:38.022322+0300 | INFO | [12,  1000] loss: 1.691
2025-02-26T04:28:47.440736+0300 | INFO | [12,  1100] loss: 1.708
2025-02-26T04:28:57.408485+0300 | INFO | [12,  1200] loss: 1.685
2025-02-26T04:29:07.400285+0300 | INFO | [12,  1300] loss: 1.691
2025-02-26T04:29:16.985283+0300 | INFO | [12,  1400] loss: 1.709
2025-02-26T04:29:27.071899+0300 | INFO | [12,  1500] loss: 1.699
2025-02-26T04:29:36.509397+0300 | INFO | [12,  1600] loss: 1.709
2025-02-26T04:29:46.360723+0300 | INFO | [12,  1700] loss: 1.691
2025-02-26T04:29:56.437140+0300 | INFO | [12,  1800] loss: 1.707
2025-02-26T04:30:05.715747+0300 | INFO | [12,  1900] loss: 1.732
2025-02-26T04:30:15.739551+0300 | INFO | [12,  2000] loss: 1.712
2025-02-26T04:30:24.681014+0300 | INFO | [12,  2100] loss: 1.711
2025-02-26T04:30:34.693426+0300 | INFO | [12,  2200] loss: 1.730
2025-02-26T04:30:45.108319+0300 | INFO | [12,  2300] loss: 1.717
2025-02-26T04:30:54.292671+0300 | INFO | [12,  2400] loss: 1.716
2025-02-26T04:31:04.480716+0300 | INFO | [12,  2500] loss: 1.696
2025-02-26T04:31:13.837663+0300 | INFO | [12,  2600] loss: 1.742
2025-02-26T04:31:23.944551+0300 | INFO | [12,  2700] loss: 1.694
2025-02-26T04:31:34.748610+0300 | INFO | [12,  2800] loss: 1.703
2025-02-26T04:31:43.872513+0300 | INFO | [12,  2900] loss: 1.712
2025-02-26T04:31:53.854308+0300 | INFO | [12,  3000] loss: 1.706
2025-02-26T04:32:03.110278+0300 | INFO | [12,  3100] loss: 1.710
2025-02-26T04:32:12.855820+0300 | INFO | [12,  3200] loss: 1.717
2025-02-26T04:32:23.397362+0300 | INFO | [12,  3300] loss: 1.737
2025-02-26T04:32:34.572249+0300 | INFO | [12,  3400] loss: 1.704
2025-02-26T04:32:45.351991+0300 | INFO | [12,  3500] loss: 1.704
2025-02-26T04:32:56.210029+0300 | INFO | [12,  3600] loss: 1.719
2025-02-26T04:33:06.693119+0300 | INFO | [12,  3700] loss: 1.723
2025-02-26T04:33:17.304453+0300 | INFO | [12,  3800] loss: 1.720
2025-02-26T04:33:28.111094+0300 | INFO | [12,  3900] loss: 1.702
2025-02-26T04:33:38.413719+0300 | INFO | [12,  4000] loss: 1.711
2025-02-26T04:33:49.280162+0300 | INFO | [12,  4100] loss: 1.705
2025-02-26T04:34:00.191761+0300 | INFO | [12,  4200] loss: 1.688
2025-02-26T04:34:10.503422+0300 | INFO | [12,  4300] loss: 1.686
2025-02-26T04:34:21.706659+0300 | INFO | [12,  4400] loss: 1.703
2025-02-26T04:34:33.408441+0300 | INFO | [12,  4500] loss: 1.694
2025-02-26T04:34:44.087687+0300 | INFO | [12,  4600] loss: 1.708
2025-02-26T04:34:54.111347+0300 | INFO | [12,  4700] loss: 1.716
2025-02-26T04:35:05.135877+0300 | INFO | [12,  4800] loss: 1.715
2025-02-26T04:35:15.859998+0300 | INFO | [12,  4900] loss: 1.722
2025-02-26T04:35:25.892084+0300 | DEBUG | Saving model to flat file storage. Save #12
2025-02-26T04:35:25.916206+0300 | INFO | Averaging client parameters
2025-02-26T04:35:25.922357+0300 | INFO | Updating parameters on client #0
2025-02-26T04:35:41.883030+0300 | DEBUG | Test set: Accuracy: 7325/10000 (73%)
2025-02-26T04:35:41.885028+0300 | DEBUG | Test set: Loss: 1.7265563011169434
2025-02-26T04:35:41.945834+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.76      0.77      1000
           1       0.89      0.91      0.90      1000
           2       0.61      0.68      0.64      1000
           3       0.53      0.68      0.59      1200
           4       0.65      0.80      0.72      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.86      0.81      1000
           7       0.80      0.76      0.78      1000
           8       0.86      0.89      0.87      1000
           9       0.85      0.85      0.85      1000

    accuracy                           0.73     10000
   macro avg       0.67      0.72      0.69     10000
weighted avg       0.68      0.73      0.71     10000

2025-02-26T04:35:41.947826+0300 | DEBUG | Confusion Matrix:
[[764  20  67  15  27   0   8   8  59  32]
 [ 12 906   6   4   1   0   6   3  17  45]
 [ 64   1 680  57 107   0  54  21   8   8]
 [ 27   6 105 813  97   0  80  39  13  20]
 [ 12   3  52  37 797   0  44  44   7   4]
 [  6   5 100 485  73   0  48  65   9   9]
 [  5   1  46  42  36   0 863   4   3   0]
 [ 23   4  40  63  72   0  15 761   3  19]
 [ 38  17  12  17   4   0   6   2 888  16]
 [ 34  56  10  11   3   0   6   4  23 853]]
2025-02-26T04:35:41.948826+0300 | DEBUG | Class precision: [0.77563452 0.88910697 0.60822898 0.5265544  0.65488907        nan
 0.76371681 0.8002103  0.86213592 0.84791252]
2025-02-26T04:35:41.949829+0300 | DEBUG | Class recall: [0.764  0.906  0.68   0.6775 0.797  0.     0.863  0.761  0.888  0.853 ]
2025-02-26T04:35:42.068832+0300 | INFO | Training epoch #13 on client #0
2025-02-26T04:35:42.070824+0300 | DEBUG | Saving model to flat file storage. Save #13
2025-02-26T04:35:42.360246+0300 | INFO | [13,     0] loss: 0.017
2025-02-26T04:35:58.230564+0300 | INFO | [13,   100] loss: 1.704
2025-02-26T04:36:08.605247+0300 | INFO | [13,   200] loss: 1.694
2025-02-26T04:36:17.960740+0300 | INFO | [13,   300] loss: 1.694
2025-02-26T04:36:28.068726+0300 | INFO | [13,   400] loss: 1.675
2025-02-26T04:36:39.008194+0300 | INFO | [13,   500] loss: 1.688
2025-02-26T04:36:48.953806+0300 | INFO | [13,   600] loss: 1.678
2025-02-26T04:36:59.374348+0300 | INFO | [13,   700] loss: 1.678
2025-02-26T04:37:09.707548+0300 | INFO | [13,   800] loss: 1.685
2025-02-26T04:37:19.466197+0300 | INFO | [13,   900] loss: 1.686
2025-02-26T04:37:29.531136+0300 | INFO | [13,  1000] loss: 1.703
2025-02-26T04:37:40.409449+0300 | INFO | [13,  1100] loss: 1.703
2025-02-26T04:37:50.050683+0300 | INFO | [13,  1200] loss: 1.682
2025-02-26T04:38:00.471154+0300 | INFO | [13,  1300] loss: 1.695
2025-02-26T04:38:10.738780+0300 | INFO | [13,  1400] loss: 1.682
2025-02-26T04:38:20.798500+0300 | INFO | [13,  1500] loss: 1.700
2025-02-26T04:38:30.691700+0300 | INFO | [13,  1600] loss: 1.699
2025-02-26T04:38:40.154367+0300 | INFO | [13,  1700] loss: 1.703
2025-02-26T04:38:50.213844+0300 | INFO | [13,  1800] loss: 1.720
2025-02-26T04:39:00.041553+0300 | INFO | [13,  1900] loss: 1.703
2025-02-26T04:39:09.339726+0300 | INFO | [13,  2000] loss: 1.707
2025-02-26T04:39:19.371585+0300 | INFO | [13,  2100] loss: 1.715
2025-02-26T04:39:28.186809+0300 | INFO | [13,  2200] loss: 1.691
2025-02-26T04:39:38.642736+0300 | INFO | [13,  2300] loss: 1.679
2025-02-26T04:39:48.164576+0300 | INFO | [13,  2400] loss: 1.722
2025-02-26T04:39:57.840306+0300 | INFO | [13,  2500] loss: 1.716
2025-02-26T04:40:07.888324+0300 | INFO | [13,  2600] loss: 1.673
2025-02-26T04:40:17.062922+0300 | INFO | [13,  2700] loss: 1.688
2025-02-26T04:40:27.008733+0300 | INFO | [13,  2800] loss: 1.684
2025-02-26T04:40:38.034587+0300 | INFO | [13,  2900] loss: 1.716
2025-02-26T04:40:47.505878+0300 | INFO | [13,  3000] loss: 1.706
2025-02-26T04:40:57.756861+0300 | INFO | [13,  3100] loss: 1.721
2025-02-26T04:41:07.701667+0300 | INFO | [13,  3200] loss: 1.710
2025-02-26T04:41:17.108329+0300 | INFO | [13,  3300] loss: 1.724
2025-02-26T04:41:27.041406+0300 | INFO | [13,  3400] loss: 1.703
2025-02-26T04:41:37.265325+0300 | INFO | [13,  3500] loss: 1.722
2025-02-26T04:41:47.352473+0300 | INFO | [13,  3600] loss: 1.709
2025-02-26T04:41:57.140509+0300 | INFO | [13,  3700] loss: 1.709
2025-02-26T04:42:06.434612+0300 | INFO | [13,  3800] loss: 1.712
2025-02-26T04:42:16.455743+0300 | INFO | [13,  3900] loss: 1.692
2025-02-26T04:42:25.605894+0300 | INFO | [13,  4000] loss: 1.716
2025-02-26T04:42:35.717404+0300 | INFO | [13,  4100] loss: 1.700
2025-02-26T04:42:46.311179+0300 | INFO | [13,  4200] loss: 1.684
2025-02-26T04:42:55.557312+0300 | INFO | [13,  4300] loss: 1.685
2025-02-26T04:43:05.692736+0300 | INFO | [13,  4400] loss: 1.708
2025-02-26T04:43:15.839796+0300 | INFO | [13,  4500] loss: 1.684
2025-02-26T04:43:28.091745+0300 | INFO | [13,  4600] loss: 1.709
2025-02-26T04:43:41.893705+0300 | INFO | [13,  4700] loss: 1.702
2025-02-26T04:43:51.966481+0300 | INFO | [13,  4800] loss: 1.672
2025-02-26T04:44:01.267449+0300 | INFO | [13,  4900] loss: 1.695
2025-02-26T04:44:12.407953+0300 | DEBUG | Saving model to flat file storage. Save #13
2025-02-26T04:44:12.436962+0300 | INFO | Averaging client parameters
2025-02-26T04:44:12.447288+0300 | INFO | Updating parameters on client #0
2025-02-26T04:44:28.540233+0300 | DEBUG | Test set: Accuracy: 7345/10000 (73%)
2025-02-26T04:44:28.541488+0300 | DEBUG | Test set: Loss: 1.7250304222106934
2025-02-26T04:44:28.644341+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.78      0.79      1000
           1       0.86      0.93      0.89      1000
           2       0.61      0.71      0.65      1000
           3       0.56      0.62      0.59      1200
           4       0.75      0.74      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.70      0.88      0.78      1000
           7       0.78      0.80      0.79      1000
           8       0.77      0.92      0.84      1000
           9       0.88      0.82      0.85      1000

    accuracy                           0.73     10000
   macro avg       0.67      0.72      0.69     10000
weighted avg       0.68      0.73      0.70     10000

2025-02-26T04:44:28.645350+0300 | DEBUG | Confusion Matrix:
[[781  22  44   8   7   0  13   8  93  24]
 [  8 932   0   1   1   0   4   1  26  27]
 [ 56   4 711  36  62   0  80  26  21   4]
 [ 28   7 133 749  57   0 113  63  34  16]
 [ 18   4  57  40 743   0  76  39  19   4]
 [ 11   4 132 435  51   0  61  79  19   8]
 [  3   5  44  24  13   0 883   6  20   2]
 [ 21   9  34  32  52   0  22 803  11  16]
 [ 25  20   8   8   1   0   4   5 919  10]
 [ 30  81  10  10   3   0  11   5  26 824]]
2025-02-26T04:44:28.649355+0300 | DEBUG | Class precision: [0.7961264  0.85661765 0.60613811 0.55770663 0.75050505        nan
 0.69692186 0.77584541 0.77356902 0.88128342]
2025-02-26T04:44:28.650349+0300 | DEBUG | Class recall: [0.781      0.932      0.711      0.62416667 0.743      0.
 0.883      0.803      0.919      0.824     ]
2025-02-26T04:44:28.696728+0300 | INFO | Training epoch #14 on client #0
2025-02-26T04:44:28.696728+0300 | DEBUG | Saving model to flat file storage. Save #14
2025-02-26T04:44:28.900282+0300 | INFO | [14,     0] loss: 0.017
2025-02-26T04:44:39.583446+0300 | INFO | [14,   100] loss: 1.662
2025-02-26T04:44:48.939727+0300 | INFO | [14,   200] loss: 1.673
2025-02-26T04:44:58.812642+0300 | INFO | [14,   300] loss: 1.663
2025-02-26T04:45:08.874484+0300 | INFO | [14,   400] loss: 1.684
2025-02-26T04:45:18.409110+0300 | INFO | [14,   500] loss: 1.689
2025-02-26T04:45:28.403541+0300 | INFO | [14,   600] loss: 1.681
2025-02-26T04:45:37.851666+0300 | INFO | [14,   700] loss: 1.684
2025-02-26T04:45:48.341916+0300 | INFO | [14,   800] loss: 1.679
2025-02-26T04:45:58.366879+0300 | INFO | [14,   900] loss: 1.721
2025-02-26T04:46:08.007114+0300 | INFO | [14,  1000] loss: 1.675
2025-02-26T04:46:17.992123+0300 | INFO | [14,  1100] loss: 1.677
2025-02-26T04:46:28.150422+0300 | INFO | [14,  1200] loss: 1.680
2025-02-26T04:46:38.842480+0300 | INFO | [14,  1300] loss: 1.666
2025-02-26T04:46:48.978127+0300 | INFO | [14,  1400] loss: 1.694
2025-02-26T04:46:58.000648+0300 | INFO | [14,  1500] loss: 1.685
2025-02-26T04:47:07.842873+0300 | INFO | [14,  1600] loss: 1.689
2025-02-26T04:47:17.915554+0300 | INFO | [14,  1700] loss: 1.695
2025-02-26T04:47:27.165679+0300 | INFO | [14,  1800] loss: 1.681
2025-02-26T04:47:37.660314+0300 | INFO | [14,  1900] loss: 1.735
2025-02-26T04:47:47.661175+0300 | INFO | [14,  2000] loss: 1.672
2025-02-26T04:47:57.011564+0300 | INFO | [14,  2100] loss: 1.703
2025-02-26T04:48:06.985640+0300 | INFO | [14,  2200] loss: 1.686
2025-02-26T04:48:16.262399+0300 | INFO | [14,  2300] loss: 1.681
2025-02-26T04:48:27.470627+0300 | INFO | [14,  2400] loss: 1.660
2025-02-26T04:48:37.552853+0300 | INFO | [14,  2500] loss: 1.696
2025-02-26T04:48:47.095354+0300 | INFO | [14,  2600] loss: 1.715
2025-02-26T04:48:57.252948+0300 | INFO | [14,  2700] loss: 1.689
2025-02-26T04:49:06.572777+0300 | INFO | [14,  2800] loss: 1.669
2025-02-26T04:49:16.463209+0300 | INFO | [14,  2900] loss: 1.686
2025-02-26T04:49:27.334593+0300 | INFO | [14,  3000] loss: 1.694
2025-02-26T04:49:36.664067+0300 | INFO | [14,  3100] loss: 1.686
2025-02-26T04:49:46.929274+0300 | INFO | [14,  3200] loss: 1.711
2025-02-26T04:49:56.821435+0300 | INFO | [14,  3300] loss: 1.687
2025-02-26T04:50:06.870770+0300 | INFO | [14,  3400] loss: 1.698
2025-02-26T04:50:16.986881+0300 | INFO | [14,  3500] loss: 1.712
2025-02-26T04:50:26.256378+0300 | INFO | [14,  3600] loss: 1.691
2025-02-26T04:50:36.440497+0300 | INFO | [14,  3700] loss: 1.698
2025-02-26T04:50:47.059312+0300 | INFO | [14,  3800] loss: 1.688
2025-02-26T04:50:56.728257+0300 | INFO | [14,  3900] loss: 1.703
2025-02-26T04:51:06.777293+0300 | INFO | [14,  4000] loss: 1.685
2025-02-26T04:51:21.193911+0300 | INFO | [14,  4100] loss: 1.680
2025-02-26T04:51:32.342532+0300 | INFO | [14,  4200] loss: 1.698
2025-02-26T04:51:41.776302+0300 | INFO | [14,  4300] loss: 1.692
2025-02-26T04:51:51.925785+0300 | INFO | [14,  4400] loss: 1.681
2025-02-26T04:52:01.290411+0300 | INFO | [14,  4500] loss: 1.692
2025-02-26T04:52:10.962402+0300 | INFO | [14,  4600] loss: 1.722
2025-02-26T04:52:20.648199+0300 | INFO | [14,  4700] loss: 1.703
2025-02-26T04:52:30.568954+0300 | INFO | [14,  4800] loss: 1.689
2025-02-26T04:52:40.963318+0300 | INFO | [14,  4900] loss: 1.697
2025-02-26T04:52:50.499712+0300 | DEBUG | Saving model to flat file storage. Save #14
2025-02-26T04:52:50.526203+0300 | INFO | Averaging client parameters
2025-02-26T04:52:50.538728+0300 | INFO | Updating parameters on client #0
2025-02-26T04:53:05.681298+0300 | DEBUG | Test set: Accuracy: 7353/10000 (74%)
2025-02-26T04:53:05.684297+0300 | DEBUG | Test set: Loss: 1.7241153717041016
2025-02-26T04:53:05.820751+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.85      0.78      1000
           1       0.85      0.92      0.88      1000
           2       0.66      0.64      0.65      1000
           3       0.50      0.75      0.60      1200
           4       0.77      0.73      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.82      0.81      1000
           7       0.83      0.75      0.79      1000
           8       0.85      0.88      0.86      1000
           9       0.85      0.86      0.85      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.72      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-26T04:53:05.825053+0300 | DEBUG | Confusion Matrix:
[[852  27  13  15   5   0   5   5  49  29]
 [ 11 919   1   3   1   0   7   0  14  44]
 [118   5 640  80  56   0  64  16  11  10]
 [ 38  12  75 904  50   0  53  29  19  20]
 [ 26   4  57  85 727   0  46  45  10   0]
 [ 13   7  96 550  33   0  25  51  16   9]
 [ 14   7  38  74  22   0 820   6  16   3]
 [ 45   5  44  70  53   0   8 753   5  17]
 [ 47  30   8  10   0   0   4   3 882  16]
 [ 34  63   5  15   3   0   3   3  18 856]]
2025-02-26T04:53:05.829572+0300 | DEBUG | Class precision: [0.71118531 0.85171455 0.65506653 0.50055371 0.76526316        nan
 0.79227053 0.82656422 0.84807692 0.85258964]
2025-02-26T04:53:05.832980+0300 | DEBUG | Class recall: [0.852      0.919      0.64       0.75333333 0.727      0.
 0.82       0.753      0.882      0.856     ]
2025-02-26T04:53:05.885361+0300 | INFO | Training epoch #15 on client #0
2025-02-26T04:53:05.889353+0300 | DEBUG | Saving model to flat file storage. Save #15
2025-02-26T04:53:06.172225+0300 | INFO | [15,     0] loss: 0.016
2025-02-26T04:53:16.676903+0300 | INFO | [15,   100] loss: 1.706
2025-02-26T04:53:26.659170+0300 | INFO | [15,   200] loss: 1.702
2025-02-26T04:53:35.943805+0300 | INFO | [15,   300] loss: 1.697
2025-02-26T04:53:45.716377+0300 | INFO | [15,   400] loss: 1.689
2025-02-26T04:53:55.515158+0300 | INFO | [15,   500] loss: 1.662
2025-02-26T04:54:05.225918+0300 | INFO | [15,   600] loss: 1.675
2025-02-26T04:54:15.234833+0300 | INFO | [15,   700] loss: 1.668
2025-02-26T04:54:24.489947+0300 | INFO | [15,   800] loss: 1.699
2025-02-26T04:54:34.633999+0300 | INFO | [15,   900] loss: 1.703
2025-02-26T04:54:44.685587+0300 | INFO | [15,  1000] loss: 1.678
2025-02-26T04:54:53.933937+0300 | INFO | [15,  1100] loss: 1.666
2025-02-26T04:55:03.985896+0300 | INFO | [15,  1200] loss: 1.688
2025-02-26T04:55:13.442973+0300 | INFO | [15,  1300] loss: 1.676
2025-02-26T04:55:24.495860+0300 | INFO | [15,  1400] loss: 1.673
2025-02-26T04:55:34.580849+0300 | INFO | [15,  1500] loss: 1.686
2025-02-26T04:55:44.038665+0300 | INFO | [15,  1600] loss: 1.703
2025-02-26T04:55:54.235918+0300 | INFO | [15,  1700] loss: 1.669
2025-02-26T04:56:04.673576+0300 | INFO | [15,  1800] loss: 1.676
2025-02-26T04:56:14.123618+0300 | INFO | [15,  1900] loss: 1.675
2025-02-26T04:56:24.032603+0300 | INFO | [15,  2000] loss: 1.661
2025-02-26T04:56:33.687996+0300 | INFO | [15,  2100] loss: 1.685
2025-02-26T04:56:43.799835+0300 | INFO | [15,  2200] loss: 1.658
2025-02-26T04:56:54.026259+0300 | INFO | [15,  2300] loss: 1.692
2025-02-26T04:57:03.259819+0300 | INFO | [15,  2400] loss: 1.672
2025-02-26T04:57:13.480258+0300 | INFO | [15,  2500] loss: 1.664
2025-02-26T04:57:23.425760+0300 | INFO | [15,  2600] loss: 1.687
2025-02-26T04:57:32.978995+0300 | INFO | [15,  2700] loss: 1.689
2025-02-26T04:57:43.202513+0300 | INFO | [15,  2800] loss: 1.706
2025-02-26T04:57:52.564162+0300 | INFO | [15,  2900] loss: 1.691
2025-02-26T04:58:02.675190+0300 | INFO | [15,  3000] loss: 1.684
2025-02-26T04:58:12.775498+0300 | INFO | [15,  3100] loss: 1.688
2025-02-26T04:58:23.083263+0300 | INFO | [15,  3200] loss: 1.697
2025-02-26T04:58:33.100918+0300 | INFO | [15,  3300] loss: 1.688
2025-02-26T04:58:42.944490+0300 | INFO | [15,  3400] loss: 1.682
2025-02-26T04:58:53.093034+0300 | INFO | [15,  3500] loss: 1.670
2025-02-26T04:59:07.676194+0300 | INFO | [15,  3600] loss: 1.704
2025-02-26T04:59:17.830050+0300 | INFO | [15,  3700] loss: 1.698
2025-02-26T04:59:27.267340+0300 | INFO | [15,  3800] loss: 1.691
2025-02-26T04:59:37.352918+0300 | INFO | [15,  3900] loss: 1.698
2025-02-26T04:59:46.645785+0300 | INFO | [15,  4000] loss: 1.704
2025-02-26T04:59:56.343867+0300 | INFO | [15,  4100] loss: 1.704
2025-02-26T05:00:06.461959+0300 | INFO | [15,  4200] loss: 1.685
2025-02-26T05:00:15.950185+0300 | INFO | [15,  4300] loss: 1.685
2025-02-26T05:00:26.045853+0300 | INFO | [15,  4400] loss: 1.680
2025-02-26T05:00:36.246707+0300 | INFO | [15,  4500] loss: 1.679
2025-02-26T05:00:45.865826+0300 | INFO | [15,  4600] loss: 1.685
2025-02-26T05:00:56.014753+0300 | INFO | [15,  4700] loss: 1.698
2025-02-26T05:01:05.445948+0300 | INFO | [15,  4800] loss: 1.704
2025-02-26T05:01:16.561693+0300 | INFO | [15,  4900] loss: 1.694
2025-02-26T05:01:26.225048+0300 | DEBUG | Saving model to flat file storage. Save #15
2025-02-26T05:01:26.250589+0300 | INFO | Averaging client parameters
2025-02-26T05:01:26.259581+0300 | INFO | Updating parameters on client #0
2025-02-26T05:01:41.714161+0300 | DEBUG | Test set: Accuracy: 7413/10000 (74%)
2025-02-26T05:01:41.715160+0300 | DEBUG | Test set: Loss: 1.7179017066955566
2025-02-26T05:01:41.820573+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.81      0.78      1000
           1       0.83      0.94      0.88      1000
           2       0.65      0.69      0.67      1000
           3       0.51      0.74      0.60      1200
           4       0.79      0.73      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.82      0.84      0.83      1000
           7       0.79      0.82      0.81      1000
           8       0.85      0.88      0.86      1000
           9       0.85      0.83      0.84      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-26T05:01:41.823569+0300 | DEBUG | Confusion Matrix:
[[812  33  22  10   7   0   8  11  62  35]
 [ 10 936   1   3   0   0   7   0  16  27]
 [ 83   4 690  76  55   0  39  26  15  12]
 [ 27   8  89 884  39   0  60  45  19  29]
 [ 24   3  70  76 727   0  36  52   9   3]
 [ 12   6  82 559  37   0  24  62   9   9]
 [  8   1  60  49  20   0 838   6  14   4]
 [ 23   3  33  68  34   0   7 820   3   9]
 [ 47  29   8   9   2   0   1   5 878  21]
 [ 25 108   6   5   3   0   5   7  13 828]]
2025-02-26T05:01:41.825579+0300 | DEBUG | Class precision: [0.75816993 0.82758621 0.65032988 0.50833813 0.78679654        nan
 0.81756098 0.79303675 0.84585742 0.84749232]
2025-02-26T05:01:41.826970+0300 | DEBUG | Class recall: [0.812      0.936      0.69       0.73666667 0.727      0.
 0.838      0.82       0.878      0.828     ]
2025-02-26T05:01:41.874115+0300 | INFO | Training epoch #16 on client #0
2025-02-26T05:01:41.876725+0300 | DEBUG | Saving model to flat file storage. Save #16
2025-02-26T05:01:42.077440+0300 | INFO | [16,     0] loss: 0.018
2025-02-26T05:01:51.851660+0300 | INFO | [16,   100] loss: 1.664
2025-02-26T05:02:01.710496+0300 | INFO | [16,   200] loss: 1.661
2025-02-26T05:02:11.417803+0300 | INFO | [16,   300] loss: 1.656
2025-02-26T05:02:21.091126+0300 | INFO | [16,   400] loss: 1.670
2025-02-26T05:02:30.691866+0300 | INFO | [16,   500] loss: 1.668
2025-02-26T05:02:39.956061+0300 | INFO | [16,   600] loss: 1.662
2025-02-26T05:02:50.321966+0300 | INFO | [16,   700] loss: 1.654
2025-02-26T05:03:00.473059+0300 | INFO | [16,   800] loss: 1.680
2025-02-26T05:03:09.721591+0300 | INFO | [16,   900] loss: 1.682
2025-02-26T05:03:19.961276+0300 | INFO | [16,  1000] loss: 1.670
2025-02-26T05:03:29.134899+0300 | INFO | [16,  1100] loss: 1.690
2025-02-26T05:03:39.435242+0300 | INFO | [16,  1200] loss: 1.686
2025-02-26T05:03:49.921178+0300 | INFO | [16,  1300] loss: 1.679
2025-02-26T05:03:59.397674+0300 | INFO | [16,  1400] loss: 1.681
2025-02-26T05:04:09.609058+0300 | INFO | [16,  1500] loss: 1.684
2025-02-26T05:04:20.174218+0300 | INFO | [16,  1600] loss: 1.687
2025-02-26T05:04:29.271348+0300 | INFO | [16,  1700] loss: 1.673
2025-02-26T05:04:39.059026+0300 | INFO | [16,  1800] loss: 1.693
2025-02-26T05:04:48.147221+0300 | INFO | [16,  1900] loss: 1.671
2025-02-26T05:04:57.767132+0300 | INFO | [16,  2000] loss: 1.691
2025-02-26T05:05:07.613139+0300 | INFO | [16,  2100] loss: 1.668
2025-02-26T05:05:16.934597+0300 | INFO | [16,  2200] loss: 1.687
2025-02-26T05:05:26.680387+0300 | INFO | [16,  2300] loss: 1.668
2025-02-26T05:05:35.837015+0300 | INFO | [16,  2400] loss: 1.669
2025-02-26T05:05:46.176995+0300 | INFO | [16,  2500] loss: 1.705
2025-02-26T05:05:56.421099+0300 | INFO | [16,  2600] loss: 1.690
2025-02-26T05:06:06.312987+0300 | INFO | [16,  2700] loss: 1.710
2025-02-26T05:06:16.275101+0300 | INFO | [16,  2800] loss: 1.653
2025-02-26T05:06:25.540325+0300 | INFO | [16,  2900] loss: 1.688
2025-02-26T05:06:37.836125+0300 | INFO | [16,  3000] loss: 1.672
2025-02-26T05:06:51.874263+0300 | INFO | [16,  3100] loss: 1.670
2025-02-26T05:07:02.664465+0300 | INFO | [16,  3200] loss: 1.664
2025-02-26T05:07:13.071031+0300 | INFO | [16,  3300] loss: 1.680
2025-02-26T05:07:23.220974+0300 | INFO | [16,  3400] loss: 1.662
2025-02-26T05:07:33.589485+0300 | INFO | [16,  3500] loss: 1.699
2025-02-26T05:07:43.100577+0300 | INFO | [16,  3600] loss: 1.681
2025-02-26T05:07:53.097214+0300 | INFO | [16,  3700] loss: 1.666
2025-02-26T05:08:03.758141+0300 | INFO | [16,  3800] loss: 1.691
2025-02-26T05:08:14.166046+0300 | INFO | [16,  3900] loss: 1.686
2025-02-26T05:08:24.290759+0300 | INFO | [16,  4000] loss: 1.706
2025-02-26T05:08:33.474318+0300 | INFO | [16,  4100] loss: 1.675
2025-02-26T05:08:43.755246+0300 | INFO | [16,  4200] loss: 1.672
2025-02-26T05:08:53.805650+0300 | INFO | [16,  4300] loss: 1.675
2025-02-26T05:09:03.126965+0300 | INFO | [16,  4400] loss: 1.684
2025-02-26T05:09:12.751862+0300 | INFO | [16,  4500] loss: 1.684
2025-02-26T05:09:22.713867+0300 | INFO | [16,  4600] loss: 1.695
2025-02-26T05:09:32.475011+0300 | INFO | [16,  4700] loss: 1.666
2025-02-26T05:09:42.249659+0300 | INFO | [16,  4800] loss: 1.668
2025-02-26T05:09:51.698162+0300 | INFO | [16,  4900] loss: 1.685
2025-02-26T05:10:02.609520+0300 | DEBUG | Saving model to flat file storage. Save #16
2025-02-26T05:10:02.626560+0300 | INFO | Averaging client parameters
2025-02-26T05:10:02.635561+0300 | INFO | Updating parameters on client #0
2025-02-26T05:10:17.401759+0300 | DEBUG | Test set: Accuracy: 7402/10000 (74%)
2025-02-26T05:10:17.402773+0300 | DEBUG | Test set: Loss: 1.7197507619857788
2025-02-26T05:10:17.513839+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.82      0.79      1000
           1       0.87      0.91      0.89      1000
           2       0.57      0.74      0.64      1000
           3       0.55      0.67      0.60      1200
           4       0.72      0.76      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.86      0.81      1000
           7       0.83      0.77      0.80      1000
           8       0.89      0.87      0.88      1000
           9       0.86      0.86      0.86      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-26T05:10:17.515854+0300 | DEBUG | Confusion Matrix:
[[822  24  45  10  10   0   9   7  49  24]
 [  9 909   3   1   1   0   9   1  12  55]
 [ 67   5 741  45  56   0  54  16   8   8]
 [ 29   4 145 798  76   0  79  40  11  18]
 [ 19   4  79  44 760   0  56  32   6   0]
 [ 13   3 150 462  59   0  41  58   7   7]
 [ 10   4  64  35  18   0 862   2   4   1]
 [ 27   7  49  48  66   0  16 773   4  10]
 [ 48  25  16  12   2   0   5   4 872  16]
 [ 30  60  11   7   5   0   7   3  12 865]]
2025-02-26T05:10:17.519351+0300 | DEBUG | Class precision: [0.76536313 0.86985646 0.56868764 0.54582763 0.72174739        nan
 0.75746924 0.8258547  0.88527919 0.86155378]
2025-02-26T05:10:17.522596+0300 | DEBUG | Class recall: [0.822 0.909 0.741 0.665 0.76  0.    0.862 0.773 0.872 0.865]
2025-02-26T05:10:17.577551+0300 | INFO | Training epoch #17 on client #0
2025-02-26T05:10:17.579375+0300 | DEBUG | Saving model to flat file storage. Save #17
2025-02-26T05:10:17.817321+0300 | INFO | [17,     0] loss: 0.018
2025-02-26T05:10:27.570005+0300 | INFO | [17,   100] loss: 1.678
2025-02-26T05:10:37.111105+0300 | INFO | [17,   200] loss: 1.677
2025-02-26T05:10:46.911382+0300 | INFO | [17,   300] loss: 1.682
2025-02-26T05:10:56.193109+0300 | INFO | [17,   400] loss: 1.700
2025-02-26T05:11:06.424829+0300 | INFO | [17,   500] loss: 1.677
2025-02-26T05:11:16.493212+0300 | INFO | [17,   600] loss: 1.654
2025-02-26T05:11:25.827134+0300 | INFO | [17,   700] loss: 1.679
2025-02-26T05:11:35.944499+0300 | INFO | [17,   800] loss: 1.681
2025-02-26T05:11:45.150839+0300 | INFO | [17,   900] loss: 1.663
2025-02-26T05:11:55.057392+0300 | INFO | [17,  1000] loss: 1.652
2025-02-26T05:12:05.431160+0300 | INFO | [17,  1100] loss: 1.660
2025-02-26T05:12:14.414325+0300 | INFO | [17,  1200] loss: 1.662
2025-02-26T05:12:24.785962+0300 | INFO | [17,  1300] loss: 1.668
2025-02-26T05:12:33.497500+0300 | INFO | [17,  1400] loss: 1.674
2025-02-26T05:12:43.713365+0300 | INFO | [17,  1500] loss: 1.670
2025-02-26T05:12:53.717331+0300 | INFO | [17,  1600] loss: 1.665
2025-02-26T05:13:03.903179+0300 | INFO | [17,  1700] loss: 1.694
2025-02-26T05:13:13.785964+0300 | INFO | [17,  1800] loss: 1.683
2025-02-26T05:13:23.090390+0300 | INFO | [17,  1900] loss: 1.672
2025-02-26T05:13:32.807708+0300 | INFO | [17,  2000] loss: 1.660
2025-02-26T05:13:42.924603+0300 | INFO | [17,  2100] loss: 1.660
2025-02-26T05:13:52.448499+0300 | INFO | [17,  2200] loss: 1.666
2025-02-26T05:14:02.315358+0300 | INFO | [17,  2300] loss: 1.689
2025-02-26T05:14:11.487754+0300 | INFO | [17,  2400] loss: 1.650
2025-02-26T05:14:23.646957+0300 | INFO | [17,  2500] loss: 1.652
2025-02-26T05:14:35.786760+0300 | INFO | [17,  2600] loss: 1.658
2025-02-26T05:14:46.111009+0300 | INFO | [17,  2700] loss: 1.674
2025-02-26T05:14:55.613403+0300 | INFO | [17,  2800] loss: 1.662
2025-02-26T05:15:05.753020+0300 | INFO | [17,  2900] loss: 1.691
2025-02-26T05:15:15.780947+0300 | INFO | [17,  3000] loss: 1.693
2025-02-26T05:15:24.886577+0300 | INFO | [17,  3100] loss: 1.683
2025-02-26T05:15:34.364015+0300 | INFO | [17,  3200] loss: 1.672
2025-02-26T05:15:44.208119+0300 | INFO | [17,  3300] loss: 1.666
2025-02-26T05:15:55.149621+0300 | INFO | [17,  3400] loss: 1.674
2025-02-26T05:16:05.565210+0300 | INFO | [17,  3500] loss: 1.666
2025-02-26T05:16:14.647311+0300 | INFO | [17,  3600] loss: 1.669
2025-02-26T05:16:24.480288+0300 | INFO | [17,  3700] loss: 1.675
2025-02-26T05:16:33.711186+0300 | INFO | [17,  3800] loss: 1.666
2025-02-26T05:16:44.245728+0300 | INFO | [17,  3900] loss: 1.667
2025-02-26T05:16:54.174396+0300 | INFO | [17,  4000] loss: 1.685
2025-02-26T05:17:03.784422+0300 | INFO | [17,  4100] loss: 1.665
2025-02-26T05:17:13.525398+0300 | INFO | [17,  4200] loss: 1.665
2025-02-26T05:17:23.674241+0300 | INFO | [17,  4300] loss: 1.696
2025-02-26T05:17:32.809085+0300 | INFO | [17,  4400] loss: 1.676
2025-02-26T05:17:43.530501+0300 | INFO | [17,  4500] loss: 1.687
2025-02-26T05:17:53.026765+0300 | INFO | [17,  4600] loss: 1.661
2025-02-26T05:18:02.928550+0300 | INFO | [17,  4700] loss: 1.672
2025-02-26T05:18:12.914734+0300 | INFO | [17,  4800] loss: 1.690
2025-02-26T05:18:22.379716+0300 | INFO | [17,  4900] loss: 1.684
2025-02-26T05:18:31.883834+0300 | DEBUG | Saving model to flat file storage. Save #17
2025-02-26T05:18:31.908830+0300 | INFO | Averaging client parameters
2025-02-26T05:18:31.915642+0300 | INFO | Updating parameters on client #0
2025-02-26T05:18:47.517652+0300 | DEBUG | Test set: Accuracy: 7363/10000 (74%)
2025-02-26T05:18:47.520135+0300 | DEBUG | Test set: Loss: 1.7237058877944946
2025-02-26T05:18:47.610199+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.85      0.74      1000
           1       0.89      0.90      0.89      1000
           2       0.73      0.57      0.64      1000
           3       0.50      0.75      0.60      1200
           4       0.74      0.78      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.85      0.82      1000
           7       0.85      0.77      0.81      1000
           8       0.88      0.84      0.86      1000
           9       0.83      0.89      0.86      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.72      0.70     10000
weighted avg       0.69      0.74      0.71     10000

2025-02-26T05:18:47.614400+0300 | DEBUG | Confusion Matrix:
[[854  24  12  15   7   0   2   5  37  44]
 [ 14 899   0   1   1   0   6   2  13  64]
 [131   5 573 110  75   0  66  18   9  13]
 [ 60   7  46 900  59   0  69  29  16  14]
 [ 39   2  39  61 784   0  41  25   7   2]
 [ 29   3  51 570  48   0  42  43   9   5]
 [ 20   4  35  45  24   0 855   4  11   2]
 [ 46   2  18  84  59   0  13 769   1   8]
 [ 76  22   8  13   3   0   1   3 841  33]
 [ 32  47   4   8   3   0   2   6  10 888]]
2025-02-26T05:18:47.615396+0300 | DEBUG | Class precision: [0.65641814 0.88571429 0.72900763 0.49806309 0.73753528        nan
 0.77939836 0.85066372 0.88155136 0.82758621]
2025-02-26T05:18:47.616391+0300 | DEBUG | Class recall: [0.854 0.899 0.573 0.75  0.784 0.    0.855 0.769 0.841 0.888]
2025-02-26T05:18:47.664097+0300 | INFO | Training epoch #18 on client #0
2025-02-26T05:18:47.665550+0300 | DEBUG | Saving model to flat file storage. Save #18
2025-02-26T05:18:47.858879+0300 | INFO | [18,     0] loss: 0.016
2025-02-26T05:18:58.570865+0300 | INFO | [18,   100] loss: 1.663
2025-02-26T05:19:08.944378+0300 | INFO | [18,   200] loss: 1.668
2025-02-26T05:19:19.132477+0300 | INFO | [18,   300] loss: 1.654
2025-02-26T05:19:28.163434+0300 | INFO | [18,   400] loss: 1.666
2025-02-26T05:19:37.987356+0300 | INFO | [18,   500] loss: 1.654
2025-02-26T05:19:47.747505+0300 | INFO | [18,   600] loss: 1.646
2025-02-26T05:19:56.987844+0300 | INFO | [18,   700] loss: 1.665
2025-02-26T05:20:06.861343+0300 | INFO | [18,   800] loss: 1.677
2025-02-26T05:20:16.071756+0300 | INFO | [18,   900] loss: 1.676
2025-02-26T05:20:26.215004+0300 | INFO | [18,  1000] loss: 1.674
2025-02-26T05:20:37.367325+0300 | INFO | [18,  1100] loss: 1.666
2025-02-26T05:20:46.612458+0300 | INFO | [18,  1200] loss: 1.660
2025-02-26T05:20:56.521408+0300 | INFO | [18,  1300] loss: 1.654
2025-02-26T05:21:05.933550+0300 | INFO | [18,  1400] loss: 1.654
2025-02-26T05:21:15.930873+0300 | INFO | [18,  1500] loss: 1.658
2025-02-26T05:21:26.076614+0300 | INFO | [18,  1600] loss: 1.652
2025-02-26T05:21:35.604512+0300 | INFO | [18,  1700] loss: 1.657
2025-02-26T05:21:46.342810+0300 | INFO | [18,  1800] loss: 1.646
2025-02-26T05:21:56.504576+0300 | INFO | [18,  1900] loss: 1.683
2025-02-26T05:22:09.843785+0300 | INFO | [18,  2000] loss: 1.668
2025-02-26T05:22:21.160667+0300 | INFO | [18,  2100] loss: 1.687
2025-02-26T05:22:30.845161+0300 | INFO | [18,  2200] loss: 1.651
2025-02-26T05:22:40.241824+0300 | INFO | [18,  2300] loss: 1.658
2025-02-26T05:22:49.960337+0300 | INFO | [18,  2400] loss: 1.673
2025-02-26T05:22:59.646435+0300 | INFO | [18,  2500] loss: 1.657
2025-02-26T05:23:09.875775+0300 | INFO | [18,  2600] loss: 1.679
2025-02-26T05:23:20.389563+0300 | INFO | [18,  2700] loss: 1.686
2025-02-26T05:23:29.584712+0300 | INFO | [18,  2800] loss: 1.668
2025-02-26T05:23:39.889721+0300 | INFO | [18,  2900] loss: 1.689
2025-02-26T05:23:50.110903+0300 | INFO | [18,  3000] loss: 1.663
2025-02-26T05:23:59.430311+0300 | INFO | [18,  3100] loss: 1.683
2025-02-26T05:24:09.255575+0300 | INFO | [18,  3200] loss: 1.683
2025-02-26T05:24:18.235958+0300 | INFO | [18,  3300] loss: 1.664
2025-02-26T05:24:28.140456+0300 | INFO | [18,  3400] loss: 1.674
2025-02-26T05:24:38.843678+0300 | INFO | [18,  3500] loss: 1.667
2025-02-26T05:24:48.396422+0300 | INFO | [18,  3600] loss: 1.691
2025-02-26T05:24:58.185309+0300 | INFO | [18,  3700] loss: 1.666
2025-02-26T05:25:08.554952+0300 | INFO | [18,  3800] loss: 1.677
2025-02-26T05:25:17.623725+0300 | INFO | [18,  3900] loss: 1.679
2025-02-26T05:25:27.789720+0300 | INFO | [18,  4000] loss: 1.664
2025-02-26T05:25:37.205436+0300 | INFO | [18,  4100] loss: 1.698
2025-02-26T05:25:47.594655+0300 | INFO | [18,  4200] loss: 1.651
2025-02-26T05:25:57.757568+0300 | INFO | [18,  4300] loss: 1.685
2025-02-26T05:26:07.532244+0300 | INFO | [18,  4400] loss: 1.675
2025-02-26T05:26:17.442164+0300 | INFO | [18,  4500] loss: 1.670
2025-02-26T05:26:27.510307+0300 | INFO | [18,  4600] loss: 1.667
2025-02-26T05:26:37.668025+0300 | INFO | [18,  4700] loss: 1.698
2025-02-26T05:26:47.371624+0300 | INFO | [18,  4800] loss: 1.678
2025-02-26T05:26:56.888152+0300 | INFO | [18,  4900] loss: 1.663
2025-02-26T05:27:07.162937+0300 | DEBUG | Saving model to flat file storage. Save #18
2025-02-26T05:27:07.188932+0300 | INFO | Averaging client parameters
2025-02-26T05:27:07.197384+0300 | INFO | Updating parameters on client #0
2025-02-26T05:27:22.279124+0300 | DEBUG | Test set: Accuracy: 7487/10000 (75%)
2025-02-26T05:27:22.280133+0300 | DEBUG | Test set: Loss: 1.7109347581863403
2025-02-26T05:27:22.375614+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.85      0.79      1000
           1       0.92      0.86      0.89      1000
           2       0.73      0.62      0.67      1000
           3       0.50      0.79      0.61      1200
           4       0.68      0.81      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.82      0.85      0.83      1000
           7       0.83      0.80      0.81      1000
           8       0.89      0.89      0.89      1000
           9       0.88      0.85      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.73      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-26T05:27:22.376615+0300 | DEBUG | Confusion Matrix:
[[847  12  24  21  21   0   6   5  44  20]
 [ 40 859   4  13   2   0   8   3  14  57]
 [ 81   3 624  86 101   0  67  23   9   6]
 [ 20   2  51 953  75   0  46  33  12   8]
 [ 17   2  43  66 815   0  30  21   4   2]
 [  8   0  48 590  62   0  18  65   7   2]
 [  6   1  26  78  32   0 849   3   5   0]
 [ 22   1  22  64  80   0   7 795   1   8]
 [ 54   9   8  17   1   0   2   5 891  13]
 [ 47  40   9  18   3   0   4   8  17 854]]
2025-02-26T05:27:22.378616+0300 | DEBUG | Class precision: [0.74168126 0.92465016 0.72642608 0.5        0.68372483        nan
 0.81870781 0.82726327 0.8874502  0.88041237]
2025-02-26T05:27:22.379617+0300 | DEBUG | Class recall: [0.847      0.859      0.624      0.79416667 0.815      0.
 0.849      0.795      0.891      0.854     ]
2025-02-26T05:27:22.431194+0300 | INFO | Training epoch #19 on client #0
2025-02-26T05:27:22.433192+0300 | DEBUG | Saving model to flat file storage. Save #19
2025-02-26T05:27:22.636444+0300 | INFO | [19,     0] loss: 0.016
2025-02-26T05:27:32.555866+0300 | INFO | [19,   100] loss: 1.666
2025-02-26T05:27:43.098473+0300 | INFO | [19,   200] loss: 1.696
2025-02-26T05:27:52.891249+0300 | INFO | [19,   300] loss: 1.634
2025-02-26T05:28:02.272303+0300 | INFO | [19,   400] loss: 1.651
2025-02-26T05:28:12.258855+0300 | INFO | [19,   500] loss: 1.665
2025-02-26T05:28:21.906332+0300 | INFO | [19,   600] loss: 1.663
2025-02-26T05:28:30.966247+0300 | INFO | [19,   700] loss: 1.650
2025-02-26T05:28:41.124762+0300 | INFO | [19,   800] loss: 1.651
2025-02-26T05:28:50.266674+0300 | INFO | [19,   900] loss: 1.673
2025-02-26T05:28:59.931288+0300 | INFO | [19,  1000] loss: 1.662
2025-02-26T05:29:09.874279+0300 | INFO | [19,  1100] loss: 1.648
2025-02-26T05:29:19.453253+0300 | INFO | [19,  1200] loss: 1.664
2025-02-26T05:29:29.411791+0300 | INFO | [19,  1300] loss: 1.655
2025-02-26T05:29:39.087887+0300 | INFO | [19,  1400] loss: 1.657
2025-02-26T05:29:54.115325+0300 | INFO | [19,  1500] loss: 1.684
2025-02-26T05:30:04.023807+0300 | INFO | [19,  1600] loss: 1.691
2025-02-26T05:30:13.700956+0300 | INFO | [19,  1700] loss: 1.660
2025-02-26T05:30:23.443527+0300 | INFO | [19,  1800] loss: 1.649
2025-02-26T05:30:33.966539+0300 | INFO | [19,  1900] loss: 1.653
2025-02-26T05:30:44.890499+0300 | INFO | [19,  2000] loss: 1.667
2025-02-26T05:30:54.265420+0300 | INFO | [19,  2100] loss: 1.650
2025-02-26T05:31:04.226408+0300 | INFO | [19,  2200] loss: 1.639
2025-02-26T05:31:13.476624+0300 | INFO | [19,  2300] loss: 1.666
2025-02-26T05:31:23.637894+0300 | INFO | [19,  2400] loss: 1.671
2025-02-26T05:31:33.424147+0300 | INFO | [19,  2500] loss: 1.667
2025-02-26T05:31:43.129550+0300 | INFO | [19,  2600] loss: 1.645
2025-02-26T05:31:53.187396+0300 | INFO | [19,  2700] loss: 1.655
2025-02-26T05:32:02.488588+0300 | INFO | [19,  2800] loss: 1.665
2025-02-26T05:32:12.241963+0300 | INFO | [19,  2900] loss: 1.693
2025-02-26T05:32:21.858822+0300 | INFO | [19,  3000] loss: 1.660
2025-02-26T05:32:30.845373+0300 | INFO | [19,  3100] loss: 1.670
2025-02-26T05:32:41.072020+0300 | INFO | [19,  3200] loss: 1.696
2025-02-26T05:32:50.831761+0300 | INFO | [19,  3300] loss: 1.661
2025-02-26T05:33:00.603093+0300 | INFO | [19,  3400] loss: 1.655
2025-02-26T05:33:10.619235+0300 | INFO | [19,  3500] loss: 1.672
2025-02-26T05:33:19.702120+0300 | INFO | [19,  3600] loss: 1.670
2025-02-26T05:33:30.456987+0300 | INFO | [19,  3700] loss: 1.664
2025-02-26T05:33:40.410674+0300 | INFO | [19,  3800] loss: 1.668
2025-02-26T05:33:50.212610+0300 | INFO | [19,  3900] loss: 1.678
2025-02-26T05:34:00.279246+0300 | INFO | [19,  4000] loss: 1.667
2025-02-26T05:34:09.757077+0300 | INFO | [19,  4100] loss: 1.653
2025-02-26T05:34:19.437775+0300 | INFO | [19,  4200] loss: 1.685
2025-02-26T05:34:29.647135+0300 | INFO | [19,  4300] loss: 1.661
2025-02-26T05:34:39.018295+0300 | INFO | [19,  4400] loss: 1.673
2025-02-26T05:34:49.036073+0300 | INFO | [19,  4500] loss: 1.675
2025-02-26T05:34:58.379576+0300 | INFO | [19,  4600] loss: 1.660
2025-02-26T05:35:08.190014+0300 | INFO | [19,  4700] loss: 1.660
2025-02-26T05:35:18.203100+0300 | INFO | [19,  4800] loss: 1.643
2025-02-26T05:35:27.038903+0300 | INFO | [19,  4900] loss: 1.670
2025-02-26T05:35:36.718109+0300 | DEBUG | Saving model to flat file storage. Save #19
2025-02-26T05:35:36.742125+0300 | INFO | Averaging client parameters
2025-02-26T05:35:36.752659+0300 | INFO | Updating parameters on client #0
2025-02-26T05:35:52.591106+0300 | DEBUG | Test set: Accuracy: 7397/10000 (74%)
2025-02-26T05:35:52.593264+0300 | DEBUG | Test set: Loss: 1.7204878330230713
2025-02-26T05:35:52.702408+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.82      0.80      1000
           1       0.92      0.85      0.88      1000
           2       0.58      0.73      0.65      1000
           3       0.53      0.68      0.59      1200
           4       0.71      0.81      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.86      0.82      1000
           7       0.89      0.76      0.82      1000
           8       0.79      0.91      0.85      1000
           9       0.88      0.83      0.86      1000

    accuracy                           0.74     10000
   macro avg       0.68      0.73      0.70     10000
weighted avg       0.70      0.74      0.71     10000

2025-02-26T05:35:52.705897+0300 | DEBUG | Confusion Matrix:
[[824  13  38   7  15   0   8   9  68  18]
 [ 26 849   6   4   1   0  16   1  53  44]
 [ 57   1 735  42  79   0  51   9  17   9]
 [ 27   5 160 810  75   0  67  20  30   6]
 [  5   1  57  47 813   0  49  14  11   3]
 [ 10   1 125 518  61   0  32  34  13   6]
 [  5   0  58  33  22   0 865   2  12   3]
 [ 19   2  54  61  79   0  14 755   3  13]
 [ 45   7  12   4   1   0   3   4 913  11]
 [ 46  40  13  14   2   0  10   3  39 833]]
2025-02-26T05:35:52.707652+0300 | DEBUG | Class precision: [0.77443609 0.92383025 0.58426073 0.52597403 0.70818815        nan
 0.77578475 0.88719154 0.78774806 0.88054968]
2025-02-26T05:35:52.708675+0300 | DEBUG | Class recall: [0.824 0.849 0.735 0.675 0.813 0.    0.865 0.755 0.913 0.833]
2025-02-26T05:35:52.766748+0300 | INFO | Training epoch #20 on client #0
2025-02-26T05:35:52.767743+0300 | DEBUG | Saving model to flat file storage. Save #20
2025-02-26T05:35:53.001403+0300 | INFO | [20,     0] loss: 0.016
2025-02-26T05:36:04.538719+0300 | INFO | [20,   100] loss: 1.646
2025-02-26T05:36:14.487771+0300 | INFO | [20,   200] loss: 1.661
2025-02-26T05:36:26.153956+0300 | INFO | [20,   300] loss: 1.669
2025-02-26T05:36:37.366517+0300 | INFO | [20,   400] loss: 1.622
2025-02-26T05:36:48.253393+0300 | INFO | [20,   500] loss: 1.634
2025-02-26T05:36:59.448919+0300 | INFO | [20,   600] loss: 1.634
2025-02-26T05:37:10.767524+0300 | INFO | [20,   700] loss: 1.675
2025-02-26T05:37:20.790603+0300 | INFO | [20,   800] loss: 1.649
2025-02-26T05:37:31.463081+0300 | INFO | [20,   900] loss: 1.678
2025-02-26T05:37:47.731299+0300 | INFO | [20,  1000] loss: 1.667
2025-02-26T05:37:59.149237+0300 | INFO | [20,  1100] loss: 1.690
2025-02-26T05:38:11.218486+0300 | INFO | [20,  1200] loss: 1.656
2025-02-26T05:38:21.571298+0300 | INFO | [20,  1300] loss: 1.653
2025-02-26T05:38:32.450023+0300 | INFO | [20,  1400] loss: 1.657
2025-02-26T05:38:43.474591+0300 | INFO | [20,  1500] loss: 1.658
2025-02-26T05:38:53.726843+0300 | INFO | [20,  1600] loss: 1.654
2025-02-26T05:39:04.903871+0300 | INFO | [20,  1700] loss: 1.660
2025-02-26T05:39:15.079258+0300 | INFO | [20,  1800] loss: 1.655
2025-02-26T05:39:24.538198+0300 | INFO | [20,  1900] loss: 1.654
2025-02-26T05:39:34.387980+0300 | INFO | [20,  2000] loss: 1.652
2025-02-26T05:39:44.635896+0300 | INFO | [20,  2100] loss: 1.649
2025-02-26T05:39:54.811095+0300 | INFO | [20,  2200] loss: 1.643
2025-02-26T05:40:05.445298+0300 | INFO | [20,  2300] loss: 1.655
2025-02-26T05:40:14.367015+0300 | INFO | [20,  2400] loss: 1.679
2025-02-26T05:40:24.009427+0300 | INFO | [20,  2500] loss: 1.669
2025-02-26T05:40:33.359650+0300 | INFO | [20,  2600] loss: 1.681
2025-02-26T05:40:43.768635+0300 | INFO | [20,  2700] loss: 1.642
2025-02-26T05:40:54.005348+0300 | INFO | [20,  2800] loss: 1.665
2025-02-26T05:41:03.734862+0300 | INFO | [20,  2900] loss: 1.659
2025-02-26T05:41:13.736566+0300 | INFO | [20,  3000] loss: 1.653
2025-02-26T05:41:23.467164+0300 | INFO | [20,  3100] loss: 1.652
2025-02-26T05:41:33.111315+0300 | INFO | [20,  3200] loss: 1.644
2025-02-26T05:41:43.735381+0300 | INFO | [20,  3300] loss: 1.654
2025-02-26T05:41:52.956817+0300 | INFO | [20,  3400] loss: 1.691
2025-02-26T05:42:03.294145+0300 | INFO | [20,  3500] loss: 1.665
2025-02-26T05:42:15.160955+0300 | INFO | [20,  3600] loss: 1.659
2025-02-26T05:42:24.561914+0300 | INFO | [20,  3700] loss: 1.651
2025-02-26T05:42:35.006401+0300 | INFO | [20,  3800] loss: 1.675
2025-02-26T05:42:45.581298+0300 | INFO | [20,  3900] loss: 1.643
2025-02-26T05:42:54.811099+0300 | INFO | [20,  4000] loss: 1.666
2025-02-26T05:43:04.817364+0300 | INFO | [20,  4100] loss: 1.669
2025-02-26T05:43:14.108742+0300 | INFO | [20,  4200] loss: 1.646
2025-02-26T05:43:23.723204+0300 | INFO | [20,  4300] loss: 1.678
2025-02-26T05:43:33.709308+0300 | INFO | [20,  4400] loss: 1.657
2025-02-26T05:43:43.151399+0300 | INFO | [20,  4500] loss: 1.651
2025-02-26T05:43:52.971351+0300 | INFO | [20,  4600] loss: 1.661
2025-02-26T05:44:02.814871+0300 | INFO | [20,  4700] loss: 1.653
2025-02-26T05:44:12.498783+0300 | INFO | [20,  4800] loss: 1.661
2025-02-26T05:44:22.411737+0300 | INFO | [20,  4900] loss: 1.655
2025-02-26T05:44:31.272435+0300 | DEBUG | Saving model to flat file storage. Save #20
2025-02-26T05:44:31.299238+0300 | INFO | Averaging client parameters
2025-02-26T05:44:31.304470+0300 | INFO | Updating parameters on client #0
2025-02-26T05:44:46.195268+0300 | DEBUG | Test set: Accuracy: 7457/10000 (75%)
2025-02-26T05:44:46.197626+0300 | DEBUG | Test set: Loss: 1.7150763273239136
2025-02-26T05:44:46.308005+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.83      0.80      1000
           1       0.89      0.90      0.90      1000
           2       0.79      0.58      0.67      1000
           3       0.50      0.76      0.60      1200
           4       0.67      0.83      0.74      1000
           5       0.00      0.00      0.00       800
           6       0.75      0.90      0.82      1000
           7       0.85      0.77      0.81      1000
           8       0.87      0.88      0.88      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.73      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-26T05:44:46.312009+0300 | DEBUG | Confusion Matrix:
[[831  17  13  23  26   0   6  11  51  22]
 [ 15 899   0   4   2   0   9   4  17  50]
 [ 80   2 576 107 117   0  81  16  12   9]
 [ 28   7  33 910  86   0  88  27  13   8]
 [ 10   2  28  45 827   0  58  19   9   2]
 [  8   3  38 595  59   0  43  42   7   5]
 [  8   8  17  44  12   0 903   5   3   0]
 [ 16   2  17  70  98   0  17 770   3   7]
 [ 52  15   3  15  10   0   2   4 883  16]
 [ 40  51   5  14   3   0   5  10  14 858]]
2025-02-26T05:44:46.315017+0300 | DEBUG | Class precision: [0.76378676 0.89363817 0.7890411  0.49808429 0.66693548        nan
 0.7450495  0.84801762 0.87252964 0.87819857]
2025-02-26T05:44:46.317008+0300 | DEBUG | Class recall: [0.831      0.899      0.576      0.75833333 0.827      0.
 0.903      0.77       0.883      0.858     ]
2025-02-26T05:44:46.368001+0300 | INFO | Training epoch #21 on client #0
2025-02-26T05:44:46.368514+0300 | DEBUG | Saving model to flat file storage. Save #21
2025-02-26T05:44:46.573400+0300 | INFO | [21,     0] loss: 0.018
2025-02-26T05:44:56.639558+0300 | INFO | [21,   100] loss: 1.660
2025-02-26T05:45:05.679831+0300 | INFO | [21,   200] loss: 1.670
2025-02-26T05:45:15.751836+0300 | INFO | [21,   300] loss: 1.639
2025-02-26T05:45:25.893472+0300 | INFO | [21,   400] loss: 1.632
2025-02-26T05:45:42.177483+0300 | INFO | [21,   500] loss: 1.641
2025-02-26T05:45:52.076962+0300 | INFO | [21,   600] loss: 1.656
2025-02-26T05:46:02.852082+0300 | INFO | [21,   700] loss: 1.648
2025-02-26T05:46:12.718796+0300 | INFO | [21,   800] loss: 1.646
2025-02-26T05:46:22.170575+0300 | INFO | [21,   900] loss: 1.663
2025-02-26T05:46:32.349242+0300 | INFO | [21,  1000] loss: 1.665
2025-02-26T05:46:41.749214+0300 | INFO | [21,  1100] loss: 1.652
2025-02-26T05:46:52.398635+0300 | INFO | [21,  1200] loss: 1.645
2025-02-26T05:47:02.352457+0300 | INFO | [21,  1300] loss: 1.652
2025-02-26T05:47:11.806267+0300 | INFO | [21,  1400] loss: 1.640
2025-02-26T05:47:21.820280+0300 | INFO | [21,  1500] loss: 1.629
2025-02-26T05:47:32.288332+0300 | INFO | [21,  1600] loss: 1.663
2025-02-26T05:47:41.970075+0300 | INFO | [21,  1700] loss: 1.650
2025-02-26T05:47:52.604594+0300 | INFO | [21,  1800] loss: 1.646
2025-02-26T05:48:01.833654+0300 | INFO | [21,  1900] loss: 1.628
2025-02-26T05:48:11.660311+0300 | INFO | [21,  2000] loss: 1.674
2025-02-26T05:48:21.989487+0300 | INFO | [21,  2100] loss: 1.667
2025-02-26T05:48:32.014943+0300 | INFO | [21,  2200] loss: 1.657
2025-02-26T05:48:42.093117+0300 | INFO | [21,  2300] loss: 1.632
2025-02-26T05:48:52.626865+0300 | INFO | [21,  2400] loss: 1.648
2025-02-26T05:49:02.277593+0300 | INFO | [21,  2500] loss: 1.644
2025-02-26T05:49:12.281615+0300 | INFO | [21,  2600] loss: 1.666
2025-02-26T05:49:21.770724+0300 | INFO | [21,  2700] loss: 1.651
2025-02-26T05:49:32.203519+0300 | INFO | [21,  2800] loss: 1.679
2025-02-26T05:49:41.744502+0300 | INFO | [21,  2900] loss: 1.668
2025-02-26T05:49:51.225352+0300 | INFO | [21,  3000] loss: 1.649
2025-02-26T05:50:01.328981+0300 | INFO | [21,  3100] loss: 1.657
2025-02-26T05:50:12.236939+0300 | INFO | [21,  3200] loss: 1.648
2025-02-26T05:50:21.748916+0300 | INFO | [21,  3300] loss: 1.676
2025-02-26T05:50:31.835498+0300 | INFO | [21,  3400] loss: 1.650
2025-02-26T05:50:40.767858+0300 | INFO | [21,  3500] loss: 1.649
2025-02-26T05:50:51.540260+0300 | INFO | [21,  3600] loss: 1.686
2025-02-26T05:51:01.791104+0300 | INFO | [21,  3700] loss: 1.671
2025-02-26T05:51:11.210628+0300 | INFO | [21,  3800] loss: 1.656
2025-02-26T05:51:21.449248+0300 | INFO | [21,  3900] loss: 1.675
2025-02-26T05:51:32.158010+0300 | INFO | [21,  4000] loss: 1.679
2025-02-26T05:51:41.596648+0300 | INFO | [21,  4100] loss: 1.663
2025-02-26T05:51:50.964505+0300 | INFO | [21,  4200] loss: 1.666
2025-02-26T05:52:00.438828+0300 | INFO | [21,  4300] loss: 1.650
2025-02-26T05:52:10.441782+0300 | INFO | [21,  4400] loss: 1.672
2025-02-26T05:52:20.204780+0300 | INFO | [21,  4500] loss: 1.650
2025-02-26T05:52:29.507096+0300 | INFO | [21,  4600] loss: 1.657
2025-02-26T05:52:39.508594+0300 | INFO | [21,  4700] loss: 1.657
2025-02-26T05:52:48.595946+0300 | INFO | [21,  4800] loss: 1.644
2025-02-26T05:52:58.742441+0300 | INFO | [21,  4900] loss: 1.663
2025-02-26T05:53:09.089466+0300 | DEBUG | Saving model to flat file storage. Save #21
2025-02-26T05:53:09.102816+0300 | INFO | Averaging client parameters
2025-02-26T05:53:09.111799+0300 | INFO | Updating parameters on client #0
2025-02-26T05:53:28.969510+0300 | DEBUG | Test set: Accuracy: 7453/10000 (75%)
2025-02-26T05:53:28.971816+0300 | DEBUG | Test set: Loss: 1.7148593664169312
2025-02-26T05:53:29.097410+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.89      0.78      1000
           1       0.84      0.95      0.89      1000
           2       0.71      0.64      0.67      1000
           3       0.51      0.74      0.61      1200
           4       0.74      0.79      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.87      0.82      1000
           7       0.84      0.76      0.80      1000
           8       0.91      0.84      0.87      1000
           9       0.88      0.85      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-26T05:53:29.100805+0300 | DEBUG | Confusion Matrix:
[[885  24  13  13   6   0   7   6  26  20]
 [ 13 948   0   1   1   0   5   0   4  28]
 [ 99   4 635  75  84   0  68  16   9  10]
 [ 45  12  73 890  59   0  56  34  13  18]
 [ 35   6  33  65 785   0  36  31   8   1]
 [ 19   4  72 557  47   0  39  52   7   3]
 [ 10   5  28  53  26   0 867   3   4   4]
 [ 54   7  33  60  50   0  18 759   5  14]
 [ 79  39   4  11   1   0   5   3 836  22]
 [ 38  86   5   4   0   0   4   4  11 848]]
2025-02-26T05:53:29.101803+0300 | DEBUG | Class precision: [0.69303054 0.83524229 0.70870536 0.51474841 0.74126534        nan
 0.78461538 0.83590308 0.90574215 0.87603306]
2025-02-26T05:53:29.102803+0300 | DEBUG | Class recall: [0.885      0.948      0.635      0.74166667 0.785      0.
 0.867      0.759      0.836      0.848     ]
2025-02-26T05:53:29.155702+0300 | INFO | Training epoch #22 on client #0
2025-02-26T05:53:29.156723+0300 | DEBUG | Saving model to flat file storage. Save #22
2025-02-26T05:53:29.378005+0300 | INFO | [22,     0] loss: 0.017
2025-02-26T05:53:39.509782+0300 | INFO | [22,   100] loss: 1.635
2025-02-26T05:53:49.345616+0300 | INFO | [22,   200] loss: 1.640
2025-02-26T05:53:58.876185+0300 | INFO | [22,   300] loss: 1.653
2025-02-26T05:54:08.086341+0300 | INFO | [22,   400] loss: 1.631
2025-02-26T05:54:17.421200+0300 | INFO | [22,   500] loss: 1.643
2025-02-26T05:54:27.484288+0300 | INFO | [22,   600] loss: 1.649
2025-02-26T05:54:36.958296+0300 | INFO | [22,   700] loss: 1.620
2025-02-26T05:54:47.110113+0300 | INFO | [22,   800] loss: 1.617
2025-02-26T05:54:55.974225+0300 | INFO | [22,   900] loss: 1.619
2025-02-26T05:55:06.025164+0300 | INFO | [22,  1000] loss: 1.641
2025-02-26T05:55:15.361378+0300 | INFO | [22,  1100] loss: 1.646
2025-02-26T05:55:24.868353+0300 | INFO | [22,  1200] loss: 1.654
2025-02-26T05:55:34.130173+0300 | INFO | [22,  1300] loss: 1.646
2025-02-26T05:55:43.185647+0300 | INFO | [22,  1400] loss: 1.675
2025-02-26T05:55:53.440665+0300 | INFO | [22,  1500] loss: 1.669
2025-02-26T05:56:02.633717+0300 | INFO | [22,  1600] loss: 1.628
2025-02-26T05:56:12.928048+0300 | INFO | [22,  1700] loss: 1.652
2025-02-26T05:56:22.362578+0300 | INFO | [22,  1800] loss: 1.659
2025-02-26T05:56:31.781974+0300 | INFO | [22,  1900] loss: 1.663
2025-02-26T05:56:41.359820+0300 | INFO | [22,  2000] loss: 1.634
2025-02-26T05:56:50.588205+0300 | INFO | [22,  2100] loss: 1.646
2025-02-26T05:57:00.520019+0300 | INFO | [22,  2200] loss: 1.647
2025-02-26T05:57:10.098922+0300 | INFO | [22,  2300] loss: 1.669
2025-02-26T05:57:19.762866+0300 | INFO | [22,  2400] loss: 1.647
2025-02-26T05:57:29.787532+0300 | INFO | [22,  2500] loss: 1.651
2025-02-26T05:57:39.834760+0300 | INFO | [22,  2600] loss: 1.663
2025-02-26T05:57:49.656539+0300 | INFO | [22,  2700] loss: 1.658
2025-02-26T05:57:59.279765+0300 | INFO | [22,  2800] loss: 1.644
2025-02-26T05:58:08.684676+0300 | INFO | [22,  2900] loss: 1.655
2025-02-26T05:58:18.714463+0300 | INFO | [22,  3000] loss: 1.654
2025-02-26T05:58:28.668783+0300 | INFO | [22,  3100] loss: 1.651
2025-02-26T05:58:37.993176+0300 | INFO | [22,  3200] loss: 1.648
2025-02-26T05:58:47.914535+0300 | INFO | [22,  3300] loss: 1.671
2025-02-26T05:58:56.980226+0300 | INFO | [22,  3400] loss: 1.664
2025-02-26T05:59:07.506865+0300 | INFO | [22,  3500] loss: 1.653
2025-02-26T05:59:17.592000+0300 | INFO | [22,  3600] loss: 1.658
2025-02-26T05:59:27.223270+0300 | INFO | [22,  3700] loss: 1.677
2025-02-26T05:59:36.930873+0300 | INFO | [22,  3800] loss: 1.658
2025-02-26T05:59:45.955695+0300 | INFO | [22,  3900] loss: 1.673
2025-02-26T05:59:55.706852+0300 | INFO | [22,  4000] loss: 1.656
2025-02-26T06:00:07.000635+0300 | INFO | [22,  4100] loss: 1.625
2025-02-26T06:00:16.037146+0300 | INFO | [22,  4200] loss: 1.650
2025-02-26T06:00:25.695366+0300 | INFO | [22,  4300] loss: 1.652
2025-02-26T06:00:35.471640+0300 | INFO | [22,  4400] loss: 1.656
2025-02-26T06:00:45.412526+0300 | INFO | [22,  4500] loss: 1.652
2025-02-26T06:01:00.806908+0300 | INFO | [22,  4600] loss: 1.658
2025-02-26T06:01:10.938135+0300 | INFO | [22,  4700] loss: 1.670
2025-02-26T06:01:20.204272+0300 | INFO | [22,  4800] loss: 1.658
2025-02-26T06:01:30.926149+0300 | INFO | [22,  4900] loss: 1.672
2025-02-26T06:01:41.057019+0300 | DEBUG | Saving model to flat file storage. Save #22
2025-02-26T06:01:41.088162+0300 | INFO | Averaging client parameters
2025-02-26T06:01:41.100665+0300 | INFO | Updating parameters on client #0
2025-02-26T06:01:56.503630+0300 | DEBUG | Test set: Accuracy: 7449/10000 (74%)
2025-02-26T06:01:56.506782+0300 | DEBUG | Test set: Loss: 1.714792013168335
2025-02-26T06:01:56.604502+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.83      0.79      1000
           1       0.82      0.94      0.88      1000
           2       0.66      0.72      0.69      1000
           3       0.52      0.70      0.60      1200
           4       0.74      0.78      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.83      0.82      1000
           7       0.84      0.79      0.81      1000
           8       0.86      0.89      0.87      1000
           9       0.87      0.82      0.84      1000

    accuracy                           0.74     10000
   macro avg       0.69      0.73      0.71     10000
weighted avg       0.70      0.74      0.72     10000

2025-02-26T06:01:56.607510+0300 | DEBUG | Confusion Matrix:
[[835  30  28  12   9   0   5   9  41  31]
 [  7 940   1   2   1   0   4   1  17  27]
 [ 74   4 721  49  67   0  40  19  14  12]
 [ 39   9 100 842  77   0  67  31  21  14]
 [ 26   3  68  52 779   0  34  26   9   3]
 [ 12  11  80 549  49   0  27  51   9  12]
 [ 13   9  51  52  25   0 832   5  13   0]
 [ 33   6  35  59  48   0  12 789   3  15]
 [ 59  25   4   9   1   0   1   2 888  11]
 [ 28 106   7   2   1   0   3   8  22 823]]
2025-02-26T06:01:56.608499+0300 | DEBUG | Class precision: [0.74156306 0.8223972  0.65844749 0.51719902 0.73699149        nan
 0.81170732 0.83846971 0.8563163  0.86814346]
2025-02-26T06:01:56.609681+0300 | DEBUG | Class recall: [0.835      0.94       0.721      0.70166667 0.779      0.
 0.832      0.789      0.888      0.823     ]
2025-02-26T06:01:56.663224+0300 | INFO | Training epoch #23 on client #0
2025-02-26T06:01:56.664299+0300 | DEBUG | Saving model to flat file storage. Save #23
2025-02-26T06:01:56.876077+0300 | INFO | [23,     0] loss: 0.016
2025-02-26T06:02:06.544715+0300 | INFO | [23,   100] loss: 1.654
2025-02-26T06:02:16.436842+0300 | INFO | [23,   200] loss: 1.638
2025-02-26T06:02:25.568115+0300 | INFO | [23,   300] loss: 1.646
2025-02-26T06:02:34.710458+0300 | INFO | [23,   400] loss: 1.634
2025-02-26T06:02:44.416668+0300 | INFO | [23,   500] loss: 1.644
2025-02-26T06:02:54.398976+0300 | INFO | [23,   600] loss: 1.641
2025-02-26T06:03:04.200463+0300 | INFO | [23,   700] loss: 1.638
2025-02-26T06:03:14.352684+0300 | INFO | [23,   800] loss: 1.631
2025-02-26T06:03:24.454438+0300 | INFO | [23,   900] loss: 1.673
2025-02-26T06:03:34.224360+0300 | INFO | [23,  1000] loss: 1.650
2025-02-26T06:03:43.127459+0300 | INFO | [23,  1100] loss: 1.658
2025-02-26T06:03:53.396565+0300 | INFO | [23,  1200] loss: 1.640
2025-02-26T06:04:03.143932+0300 | INFO | [23,  1300] loss: 1.654
2025-02-26T06:04:12.647429+0300 | INFO | [23,  1400] loss: 1.663
2025-02-26T06:04:22.607990+0300 | INFO | [23,  1500] loss: 1.650
2025-02-26T06:04:31.495426+0300 | INFO | [23,  1600] loss: 1.650
2025-02-26T06:04:41.118081+0300 | INFO | [23,  1700] loss: 1.652
2025-02-26T06:04:50.141549+0300 | INFO | [23,  1800] loss: 1.648
2025-02-26T06:05:00.012357+0300 | INFO | [23,  1900] loss: 1.652
2025-02-26T06:05:10.332988+0300 | INFO | [23,  2000] loss: 1.633
2025-02-26T06:05:19.370278+0300 | INFO | [23,  2100] loss: 1.638
2025-02-26T06:05:29.312826+0300 | INFO | [23,  2200] loss: 1.649
2025-02-26T06:05:38.156640+0300 | INFO | [23,  2300] loss: 1.639
2025-02-26T06:05:48.457440+0300 | INFO | [23,  2400] loss: 1.634
2025-02-26T06:05:59.324083+0300 | INFO | [23,  2500] loss: 1.664
2025-02-26T06:06:08.457173+0300 | INFO | [23,  2600] loss: 1.649
2025-02-26T06:06:18.532394+0300 | INFO | [23,  2700] loss: 1.634
2025-02-26T06:06:28.711801+0300 | INFO | [23,  2800] loss: 1.665
2025-02-26T06:06:38.745636+0300 | INFO | [23,  2900] loss: 1.657
2025-02-26T06:06:49.631175+0300 | INFO | [23,  3000] loss: 1.638
2025-02-26T06:07:00.453749+0300 | INFO | [23,  3100] loss: 1.640
2025-02-26T06:07:10.033894+0300 | INFO | [23,  3200] loss: 1.643
2025-02-26T06:07:20.566635+0300 | INFO | [23,  3300] loss: 1.680
2025-02-26T06:07:29.601485+0300 | INFO | [23,  3400] loss: 1.665
2025-02-26T06:07:39.082341+0300 | INFO | [23,  3500] loss: 1.651
2025-02-26T06:07:49.155187+0300 | INFO | [23,  3600] loss: 1.672
2025-02-26T06:07:58.109570+0300 | INFO | [23,  3700] loss: 1.674
2025-02-26T06:08:09.692903+0300 | INFO | [23,  3800] loss: 1.640
2025-02-26T06:08:18.772495+0300 | INFO | [23,  3900] loss: 1.647
2025-02-26T06:08:29.381333+0300 | INFO | [23,  4000] loss: 1.650
2025-02-26T06:08:43.689291+0300 | INFO | [23,  4100] loss: 1.635
2025-02-26T06:08:54.810335+0300 | INFO | [23,  4200] loss: 1.655
2025-02-26T06:09:05.511107+0300 | INFO | [23,  4300] loss: 1.666
2025-02-26T06:09:16.325495+0300 | INFO | [23,  4400] loss: 1.643
2025-02-26T06:09:26.658010+0300 | INFO | [23,  4500] loss: 1.655
2025-02-26T06:09:35.792786+0300 | INFO | [23,  4600] loss: 1.644
2025-02-26T06:09:45.750354+0300 | INFO | [23,  4700] loss: 1.662
2025-02-26T06:09:56.082584+0300 | INFO | [23,  4800] loss: 1.638
2025-02-26T06:10:05.073703+0300 | INFO | [23,  4900] loss: 1.654
2025-02-26T06:10:15.007652+0300 | DEBUG | Saving model to flat file storage. Save #23
2025-02-26T06:10:15.036108+0300 | INFO | Averaging client parameters
2025-02-26T06:10:15.042606+0300 | INFO | Updating parameters on client #0
2025-02-26T06:10:29.924029+0300 | DEBUG | Test set: Accuracy: 7498/10000 (75%)
2025-02-26T06:10:29.925037+0300 | DEBUG | Test set: Loss: 1.7106542587280273
2025-02-26T06:10:30.021377+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.86      0.80      1000
           1       0.84      0.95      0.89      1000
           2       0.67      0.70      0.68      1000
           3       0.53      0.72      0.61      1200
           4       0.74      0.78      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.87      0.83      1000
           7       0.79      0.81      0.80      1000
           8       0.90      0.86      0.88      1000
           9       0.89      0.81      0.85      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-26T06:10:30.022379+0300 | DEBUG | Confusion Matrix:
[[862  25  30  11  11   0   5   7  34  15]
 [  6 947   3   2   1   0   5   2   8  26]
 [ 77   4 699  64  66   0  50  26   2  12]
 [ 32  14  80 860  65   0  74  44  14  17]
 [ 20   5  69  42 775   0  41  43   4   1]
 [ 12   7  59 525  60   0  46  76  10   5]
 [  9   4  48  39  16   0 873   8   2   1]
 [ 24   5  35  50  46   0  11 813   3  13]
 [ 65  26  12  17   4   0   4   2 859  11]
 [ 43  96   9   9   3   0   6   6  18 810]]
2025-02-26T06:10:30.023377+0300 | DEBUG | Class precision: [0.74956522 0.83583407 0.66954023 0.53119209 0.74021012        nan
 0.78295964 0.7916261  0.90041929 0.88913282]
2025-02-26T06:10:30.027376+0300 | DEBUG | Class recall: [0.862      0.947      0.699      0.71666667 0.775      0.
 0.873      0.813      0.859      0.81      ]
2025-02-26T06:10:30.073808+0300 | INFO | Training epoch #24 on client #0
2025-02-26T06:10:30.076817+0300 | DEBUG | Saving model to flat file storage. Save #24
2025-02-26T06:10:30.287664+0300 | INFO | [24,     0] loss: 0.017
2025-02-26T06:10:40.178970+0300 | INFO | [24,   100] loss: 1.629
2025-02-26T06:10:50.671539+0300 | INFO | [24,   200] loss: 1.632
2025-02-26T06:11:00.371654+0300 | INFO | [24,   300] loss: 1.647
2025-02-26T06:11:10.360446+0300 | INFO | [24,   400] loss: 1.643
2025-02-26T06:11:20.234135+0300 | INFO | [24,   500] loss: 1.658
2025-02-26T06:11:29.074065+0300 | INFO | [24,   600] loss: 1.635
2025-02-26T06:11:39.128747+0300 | INFO | [24,   700] loss: 1.638
2025-02-26T06:11:49.467237+0300 | INFO | [24,   800] loss: 1.665
2025-02-26T06:11:59.750927+0300 | INFO | [24,   900] loss: 1.656
2025-02-26T06:12:09.827678+0300 | INFO | [24,  1000] loss: 1.657
2025-02-26T06:12:18.650667+0300 | INFO | [24,  1100] loss: 1.667
2025-02-26T06:12:28.343566+0300 | INFO | [24,  1200] loss: 1.663
2025-02-26T06:12:38.246501+0300 | INFO | [24,  1300] loss: 1.657
2025-02-26T06:12:48.231636+0300 | INFO | [24,  1400] loss: 1.625
2025-02-26T06:12:58.212402+0300 | INFO | [24,  1500] loss: 1.631
2025-02-26T06:13:08.063545+0300 | INFO | [24,  1600] loss: 1.640
2025-02-26T06:13:17.509383+0300 | INFO | [24,  1700] loss: 1.661
2025-02-26T06:13:27.209214+0300 | INFO | [24,  1800] loss: 1.616
2025-02-26T06:13:36.345645+0300 | INFO | [24,  1900] loss: 1.646
2025-02-26T06:13:46.454696+0300 | INFO | [24,  2000] loss: 1.623
2025-02-26T06:13:56.766755+0300 | INFO | [24,  2100] loss: 1.647
2025-02-26T06:14:05.687412+0300 | INFO | [24,  2200] loss: 1.635
2025-02-26T06:14:15.749199+0300 | INFO | [24,  2300] loss: 1.649
2025-02-26T06:14:24.898533+0300 | INFO | [24,  2400] loss: 1.653
2025-02-26T06:14:35.262201+0300 | INFO | [24,  2500] loss: 1.641
2025-02-26T06:14:46.035798+0300 | INFO | [24,  2600] loss: 1.638
2025-02-26T06:14:55.852492+0300 | INFO | [24,  2700] loss: 1.626
2025-02-26T06:15:05.688057+0300 | INFO | [24,  2800] loss: 1.627
2025-02-26T06:15:15.360339+0300 | INFO | [24,  2900] loss: 1.660
2025-02-26T06:15:24.775550+0300 | INFO | [24,  3000] loss: 1.648
2025-02-26T06:15:34.821231+0300 | INFO | [24,  3100] loss: 1.651
2025-02-26T06:15:43.728607+0300 | INFO | [24,  3200] loss: 1.662
2025-02-26T06:15:54.297876+0300 | INFO | [24,  3300] loss: 1.636
2025-02-26T06:16:04.462905+0300 | INFO | [24,  3400] loss: 1.654
2025-02-26T06:16:14.222333+0300 | INFO | [24,  3500] loss: 1.654
2025-02-26T06:16:29.269583+0300 | INFO | [24,  3600] loss: 1.625
2025-02-26T06:16:39.789646+0300 | INFO | [24,  3700] loss: 1.648
2025-02-26T06:16:48.864158+0300 | INFO | [24,  3800] loss: 1.636
2025-02-26T06:16:59.217162+0300 | INFO | [24,  3900] loss: 1.649
2025-02-26T06:17:08.854441+0300 | INFO | [24,  4000] loss: 1.662
2025-02-26T06:17:17.819574+0300 | INFO | [24,  4100] loss: 1.661
2025-02-26T06:17:27.579210+0300 | INFO | [24,  4200] loss: 1.633
2025-02-26T06:17:36.624451+0300 | INFO | [24,  4300] loss: 1.661
2025-02-26T06:17:47.199309+0300 | INFO | [24,  4400] loss: 1.648
2025-02-26T06:17:57.298472+0300 | INFO | [24,  4500] loss: 1.639
2025-02-26T06:18:06.072751+0300 | INFO | [24,  4600] loss: 1.632
2025-02-26T06:18:16.341458+0300 | INFO | [24,  4700] loss: 1.635
2025-02-26T06:18:25.899911+0300 | INFO | [24,  4800] loss: 1.656
2025-02-26T06:18:35.691894+0300 | INFO | [24,  4900] loss: 1.632
2025-02-26T06:18:45.954260+0300 | DEBUG | Saving model to flat file storage. Save #24
2025-02-26T06:18:45.976793+0300 | INFO | Averaging client parameters
2025-02-26T06:18:45.986966+0300 | INFO | Updating parameters on client #0
2025-02-26T06:19:00.783184+0300 | DEBUG | Test set: Accuracy: 7530/10000 (75%)
2025-02-26T06:19:00.784646+0300 | DEBUG | Test set: Loss: 1.7070138454437256
2025-02-26T06:19:00.876083+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.82      0.80      1000
           1       0.87      0.91      0.89      1000
           2       0.73      0.65      0.69      1000
           3       0.52      0.77      0.62      1200
           4       0.73      0.79      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.87      0.83      1000
           7       0.82      0.81      0.82      1000
           8       0.83      0.90      0.86      1000
           9       0.87      0.86      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.73     10000

2025-02-26T06:19:00.880095+0300 | DEBUG | Confusion Matrix:
[[816  26  25  17  11   0   8  10  59  28]
 [ 11 912   0   0   2   0   6   1  21  47]
 [ 64   4 651  80  88   0  63  17  24   9]
 [ 24   7  65 922  56   0  60  34  19  13]
 [  8   4  42  69 786   0  37  34  17   3]
 [  6   5  61 562  57   0  34  61   8   6]
 [  9   5  25  45  23   0 872   5  13   3]
 [ 20   4  14  68  54   0  14 814   4   8]
 [ 40  24   3  10   3   0   3   5 900  12]
 [ 35  62   3   7   2   0   7   7  20 857]]
2025-02-26T06:19:00.883105+0300 | DEBUG | Class precision: [0.78993224 0.86609687 0.73228346 0.51797753 0.72643253        nan
 0.78985507 0.82388664 0.82949309 0.86916836]
2025-02-26T06:19:00.884101+0300 | DEBUG | Class recall: [0.816      0.912      0.651      0.76833333 0.786      0.
 0.872      0.814      0.9        0.857     ]
2025-02-26T06:19:00.930062+0300 | INFO | Training epoch #25 on client #0
2025-02-26T06:19:00.931074+0300 | DEBUG | Saving model to flat file storage. Save #25
2025-02-26T06:19:01.135991+0300 | INFO | [25,     0] loss: 0.015
2025-02-26T06:19:10.545142+0300 | INFO | [25,   100] loss: 1.620
2025-02-26T06:19:20.440648+0300 | INFO | [25,   200] loss: 1.639
2025-02-26T06:19:29.082589+0300 | INFO | [25,   300] loss: 1.650
2025-02-26T06:19:38.703048+0300 | INFO | [25,   400] loss: 1.613
2025-02-26T06:19:48.198305+0300 | INFO | [25,   500] loss: 1.660
2025-02-26T06:19:57.859075+0300 | INFO | [25,   600] loss: 1.661
2025-02-26T06:20:07.410519+0300 | INFO | [25,   700] loss: 1.627
2025-02-26T06:20:16.418990+0300 | INFO | [25,   800] loss: 1.638
2025-02-26T06:20:26.197681+0300 | INFO | [25,   900] loss: 1.630
2025-02-26T06:20:35.740950+0300 | INFO | [25,  1000] loss: 1.628
2025-02-26T06:20:45.911037+0300 | INFO | [25,  1100] loss: 1.649
2025-02-26T06:20:56.794489+0300 | INFO | [25,  1200] loss: 1.646
2025-02-26T06:21:06.546095+0300 | INFO | [25,  1300] loss: 1.629
2025-02-26T06:21:16.230433+0300 | INFO | [25,  1400] loss: 1.654
2025-02-26T06:21:26.269211+0300 | INFO | [25,  1500] loss: 1.657
2025-02-26T06:21:35.490820+0300 | INFO | [25,  1600] loss: 1.655
2025-02-26T06:21:45.354520+0300 | INFO | [25,  1700] loss: 1.655
2025-02-26T06:21:54.798432+0300 | INFO | [25,  1800] loss: 1.635
2025-02-26T06:22:05.620633+0300 | INFO | [25,  1900] loss: 1.634
2025-02-26T06:22:15.250966+0300 | INFO | [25,  2000] loss: 1.647
2025-02-26T06:22:24.455353+0300 | INFO | [25,  2100] loss: 1.639
2025-02-26T06:22:33.685995+0300 | INFO | [25,  2200] loss: 1.642
2025-02-26T06:22:43.001590+0300 | INFO | [25,  2300] loss: 1.646
2025-02-26T06:22:53.857726+0300 | INFO | [25,  2400] loss: 1.644
2025-02-26T06:23:03.817921+0300 | INFO | [25,  2500] loss: 1.658
2025-02-26T06:23:13.833441+0300 | INFO | [25,  2600] loss: 1.627
2025-02-26T06:23:23.213853+0300 | INFO | [25,  2700] loss: 1.667
2025-02-26T06:23:34.091145+0300 | INFO | [25,  2800] loss: 1.658
2025-02-26T06:23:43.337969+0300 | INFO | [25,  2900] loss: 1.642
2025-02-26T06:23:53.107677+0300 | INFO | [25,  3000] loss: 1.651
2025-02-26T06:24:07.753483+0300 | INFO | [25,  3100] loss: 1.637
2025-02-26T06:24:17.055719+0300 | INFO | [25,  3200] loss: 1.651
2025-02-26T06:24:26.815838+0300 | INFO | [25,  3300] loss: 1.629
2025-02-26T06:24:36.117389+0300 | INFO | [25,  3400] loss: 1.647
2025-02-26T06:24:45.163298+0300 | INFO | [25,  3500] loss: 1.642
2025-02-26T06:24:54.643234+0300 | INFO | [25,  3600] loss: 1.648
2025-02-26T06:25:03.507848+0300 | INFO | [25,  3700] loss: 1.660
2025-02-26T06:25:13.652839+0300 | INFO | [25,  3800] loss: 1.622
2025-02-26T06:25:22.513664+0300 | INFO | [25,  3900] loss: 1.653
2025-02-26T06:25:31.986789+0300 | INFO | [25,  4000] loss: 1.648
2025-02-26T06:25:42.558442+0300 | INFO | [25,  4100] loss: 1.664
2025-02-26T06:25:51.848201+0300 | INFO | [25,  4200] loss: 1.620
2025-02-26T06:26:01.691848+0300 | INFO | [25,  4300] loss: 1.667
2025-02-26T06:26:11.364841+0300 | INFO | [25,  4400] loss: 1.644
2025-02-26T06:26:21.645159+0300 | INFO | [25,  4500] loss: 1.672
2025-02-26T06:26:32.222252+0300 | INFO | [25,  4600] loss: 1.663
2025-02-26T06:26:41.393972+0300 | INFO | [25,  4700] loss: 1.649
2025-02-26T06:26:51.153412+0300 | INFO | [25,  4800] loss: 1.646
2025-02-26T06:27:00.860830+0300 | INFO | [25,  4900] loss: 1.627
2025-02-26T06:27:09.774283+0300 | DEBUG | Saving model to flat file storage. Save #25
2025-02-26T06:27:09.798043+0300 | INFO | Averaging client parameters
2025-02-26T06:27:09.806268+0300 | INFO | Updating parameters on client #0
2025-02-26T06:27:24.629942+0300 | DEBUG | Test set: Accuracy: 7471/10000 (75%)
2025-02-26T06:27:24.631951+0300 | DEBUG | Test set: Loss: 1.7127574682235718
2025-02-26T06:27:24.728926+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.80      0.79      1000
           1       0.90      0.89      0.90      1000
           2       0.70      0.64      0.67      1000
           3       0.48      0.83      0.61      1200
           4       0.83      0.69      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.85      0.81      0.83      1000
           7       0.77      0.86      0.81      1000
           8       0.89      0.89      0.89      1000
           9       0.82      0.90      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.73      0.71     10000
weighted avg       0.71      0.75      0.72     10000

2025-02-26T06:27:24.729924+0300 | DEBUG | Confusion Matrix:
[[800  17  29  20   9   0   7  17  48  53]
 [  8 890   0   1   1   0   5   3  15  77]
 [ 74   5 637 137  49   0  44  34   7  13]
 [ 20   9  63 991  27   0  28  38   9  15]
 [ 15   3  63 113 688   0  33  77   8   0]
 [ 10   3  43 628  23   0  16  71   3   3]
 [ 11   8  44  96  11   0 812   9   5   4]
 [ 18   1  11  65  22   0   4 864   3  12]
 [ 40  18  10  14   2   0   2   6 885  23]
 [ 21  33   4  10   1   0   3   7  17 904]]
2025-02-26T06:27:24.730927+0300 | DEBUG | Class precision: [0.78662734 0.90172239 0.70464602 0.47759036 0.82593037        nan
 0.85115304 0.76731794 0.885      0.81884058]
2025-02-26T06:27:24.732926+0300 | DEBUG | Class recall: [0.8        0.89       0.637      0.82583333 0.688      0.
 0.812      0.864      0.885      0.904     ]
2025-02-26T06:27:24.793705+0300 | INFO | Training epoch #26 on client #0
2025-02-26T06:27:24.795702+0300 | DEBUG | Saving model to flat file storage. Save #26
2025-02-26T06:27:25.032675+0300 | INFO | [26,     0] loss: 0.015
2025-02-26T06:27:35.210062+0300 | INFO | [26,   100] loss: 1.650
2025-02-26T06:27:45.281884+0300 | INFO | [26,   200] loss: 1.621
2025-02-26T06:27:55.060550+0300 | INFO | [26,   300] loss: 1.631
2025-02-26T06:28:04.289322+0300 | INFO | [26,   400] loss: 1.648
2025-02-26T06:28:13.536152+0300 | INFO | [26,   500] loss: 1.632
2025-02-26T06:28:23.676368+0300 | INFO | [26,   600] loss: 1.653
2025-02-26T06:28:32.731253+0300 | INFO | [26,   700] loss: 1.633
2025-02-26T06:28:41.743492+0300 | INFO | [26,   800] loss: 1.631
2025-02-26T06:28:51.690263+0300 | INFO | [26,   900] loss: 1.639
2025-02-26T06:29:01.179569+0300 | INFO | [26,  1000] loss: 1.648
2025-02-26T06:29:10.859009+0300 | INFO | [26,  1100] loss: 1.633
2025-02-26T06:29:20.992396+0300 | INFO | [26,  1200] loss: 1.632
2025-02-26T06:29:31.229194+0300 | INFO | [26,  1300] loss: 1.632
2025-02-26T06:29:40.990213+0300 | INFO | [26,  1400] loss: 1.626
2025-02-26T06:29:51.043708+0300 | INFO | [26,  1500] loss: 1.637
2025-02-26T06:30:00.858655+0300 | INFO | [26,  1600] loss: 1.625
2025-02-26T06:30:10.012812+0300 | INFO | [26,  1700] loss: 1.650
2025-02-26T06:30:19.546474+0300 | INFO | [26,  1800] loss: 1.629
2025-02-26T06:30:28.959286+0300 | INFO | [26,  1900] loss: 1.633
2025-02-26T06:30:38.071568+0300 | INFO | [26,  2000] loss: 1.640
2025-02-26T06:30:48.345243+0300 | INFO | [26,  2100] loss: 1.636
2025-02-26T06:30:57.976682+0300 | INFO | [26,  2200] loss: 1.655
2025-02-26T06:31:07.888036+0300 | INFO | [26,  2300] loss: 1.640
2025-02-26T06:31:17.582773+0300 | INFO | [26,  2400] loss: 1.653
2025-02-26T06:31:26.835617+0300 | INFO | [26,  2500] loss: 1.659
2025-02-26T06:31:41.816350+0300 | INFO | [26,  2600] loss: 1.651
2025-02-26T06:31:52.453040+0300 | INFO | [26,  2700] loss: 1.656
2025-02-26T06:32:01.402353+0300 | INFO | [26,  2800] loss: 1.650
2025-02-26T06:32:11.782201+0300 | INFO | [26,  2900] loss: 1.636
2025-02-26T06:32:21.535338+0300 | INFO | [26,  3000] loss: 1.623
2025-02-26T06:32:30.492848+0300 | INFO | [26,  3100] loss: 1.648
2025-02-26T06:32:40.028028+0300 | INFO | [26,  3200] loss: 1.626
2025-02-26T06:32:49.187445+0300 | INFO | [26,  3300] loss: 1.643
2025-02-26T06:32:59.674408+0300 | INFO | [26,  3400] loss: 1.642
2025-02-26T06:33:09.138502+0300 | INFO | [26,  3500] loss: 1.661
2025-02-26T06:33:17.997678+0300 | INFO | [26,  3600] loss: 1.650
2025-02-26T06:33:27.935530+0300 | INFO | [26,  3700] loss: 1.651
2025-02-26T06:33:37.468736+0300 | INFO | [26,  3800] loss: 1.647
2025-02-26T06:33:48.517631+0300 | INFO | [26,  3900] loss: 1.649
2025-02-26T06:33:58.602505+0300 | INFO | [26,  4000] loss: 1.641
2025-02-26T06:34:07.730118+0300 | INFO | [26,  4100] loss: 1.626
2025-02-26T06:34:17.479816+0300 | INFO | [26,  4200] loss: 1.646
2025-02-26T06:34:26.202317+0300 | INFO | [26,  4300] loss: 1.635
2025-02-26T06:34:35.318742+0300 | INFO | [26,  4400] loss: 1.637
2025-02-26T06:34:44.798028+0300 | INFO | [26,  4500] loss: 1.662
2025-02-26T06:34:54.136321+0300 | INFO | [26,  4600] loss: 1.666
2025-02-26T06:35:04.600702+0300 | INFO | [26,  4700] loss: 1.636
2025-02-26T06:35:13.724099+0300 | INFO | [26,  4800] loss: 1.644
2025-02-26T06:35:23.455258+0300 | INFO | [26,  4900] loss: 1.640
2025-02-26T06:35:33.769861+0300 | DEBUG | Saving model to flat file storage. Save #26
2025-02-26T06:35:33.796868+0300 | INFO | Averaging client parameters
2025-02-26T06:35:33.801859+0300 | INFO | Updating parameters on client #0
2025-02-26T06:35:48.949488+0300 | DEBUG | Test set: Accuracy: 7543/10000 (75%)
2025-02-26T06:35:48.952848+0300 | DEBUG | Test set: Loss: 1.7052816152572632
2025-02-26T06:35:49.054292+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.81      0.81      1000
           1       0.88      0.90      0.89      1000
           2       0.70      0.69      0.69      1000
           3       0.53      0.73      0.62      1200
           4       0.70      0.82      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.84      0.83      1000
           7       0.76      0.83      0.79      1000
           8       0.86      0.90      0.88      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.73     10000

2025-02-26T06:35:49.055522+0300 | DEBUG | Confusion Matrix:
[[811  20  25  10  22   0   8  22  55  27]
 [  7 902   2   1   2   0   5   2  14  65]
 [ 59   7 685  61  92   0  48  29  11   8]
 [ 20  11  78 879  83   0  55  49  17   8]
 [  7   4  45  42 816   0  33  42  11   0]
 [ 10   3  60 538  58   0  27  93   8   3]
 [  8   8  39  50  34   0 845   6  10   0]
 [ 14   2  27  46  62   0  10 829   2   8]
 [ 35  21   5  10   2   0   5   7 904  11]
 [ 24  51   7  14   1   0   9   7  15 872]]
2025-02-26T06:35:49.059545+0300 | DEBUG | Class precision: [0.81507538 0.8765792  0.70400822 0.5324046  0.69624573        nan
 0.80861244 0.76335175 0.86341929 0.87025948]
2025-02-26T06:35:49.061544+0300 | DEBUG | Class recall: [0.811  0.902  0.685  0.7325 0.816  0.     0.845  0.829  0.904  0.872 ]
2025-02-26T06:35:49.121459+0300 | INFO | Training epoch #27 on client #0
2025-02-26T06:35:49.123969+0300 | DEBUG | Saving model to flat file storage. Save #27
2025-02-26T06:35:49.338092+0300 | INFO | [27,     0] loss: 0.016
2025-02-26T06:35:58.961168+0300 | INFO | [27,   100] loss: 1.637
2025-02-26T06:36:08.883411+0300 | INFO | [27,   200] loss: 1.635
2025-02-26T06:36:17.722988+0300 | INFO | [27,   300] loss: 1.630
2025-02-26T06:36:27.223229+0300 | INFO | [27,   400] loss: 1.647
2025-02-26T06:36:37.355403+0300 | INFO | [27,   500] loss: 1.635
2025-02-26T06:36:47.646293+0300 | INFO | [27,   600] loss: 1.645
2025-02-26T06:36:58.414942+0300 | INFO | [27,   700] loss: 1.629
2025-02-26T06:37:08.668440+0300 | INFO | [27,   800] loss: 1.641
2025-02-26T06:37:18.882726+0300 | INFO | [27,   900] loss: 1.624
2025-02-26T06:37:28.712172+0300 | INFO | [27,  1000] loss: 1.630
2025-02-26T06:37:37.982014+0300 | INFO | [27,  1100] loss: 1.635
2025-02-26T06:37:48.151531+0300 | INFO | [27,  1200] loss: 1.656
2025-02-26T06:37:58.494674+0300 | INFO | [27,  1300] loss: 1.629
2025-02-26T06:38:09.278783+0300 | INFO | [27,  1400] loss: 1.670
2025-02-26T06:38:19.383900+0300 | INFO | [27,  1500] loss: 1.648
2025-02-26T06:38:28.788317+0300 | INFO | [27,  1600] loss: 1.635
2025-02-26T06:38:37.951751+0300 | INFO | [27,  1700] loss: 1.620
2025-02-26T06:38:47.820733+0300 | INFO | [27,  1800] loss: 1.625
2025-02-26T06:38:56.674610+0300 | INFO | [27,  1900] loss: 1.638
2025-02-26T06:39:07.164561+0300 | INFO | [27,  2000] loss: 1.628
2025-02-26T06:39:20.813239+0300 | INFO | [27,  2100] loss: 1.649
2025-02-26T06:39:34.087780+0300 | INFO | [27,  2200] loss: 1.631
2025-02-26T06:39:44.298837+0300 | INFO | [27,  2300] loss: 1.636
2025-02-26T06:39:55.237636+0300 | INFO | [27,  2400] loss: 1.628
2025-02-26T06:40:06.383849+0300 | INFO | [27,  2500] loss: 1.633
2025-02-26T06:40:17.138834+0300 | INFO | [27,  2600] loss: 1.658
2025-02-26T06:40:28.054411+0300 | INFO | [27,  2700] loss: 1.646
2025-02-26T06:40:39.001780+0300 | INFO | [27,  2800] loss: 1.627
2025-02-26T06:40:49.503379+0300 | INFO | [27,  2900] loss: 1.650
2025-02-26T06:41:01.340572+0300 | INFO | [27,  3000] loss: 1.652
2025-02-26T06:41:12.583311+0300 | INFO | [27,  3100] loss: 1.654
2025-02-26T06:41:22.742774+0300 | INFO | [27,  3200] loss: 1.636
2025-02-26T06:41:33.491144+0300 | INFO | [27,  3300] loss: 1.651
2025-02-26T06:41:45.061597+0300 | INFO | [27,  3400] loss: 1.664
2025-02-26T06:41:55.933558+0300 | INFO | [27,  3500] loss: 1.630
2025-02-26T06:42:06.442365+0300 | INFO | [27,  3600] loss: 1.650
2025-02-26T06:42:17.468048+0300 | INFO | [27,  3700] loss: 1.644
2025-02-26T06:42:28.268955+0300 | INFO | [27,  3800] loss: 1.648
2025-02-26T06:42:38.016954+0300 | INFO | [27,  3900] loss: 1.634
2025-02-26T06:42:48.345122+0300 | INFO | [27,  4000] loss: 1.628
2025-02-26T06:42:57.274803+0300 | INFO | [27,  4100] loss: 1.637
2025-02-26T06:43:07.636570+0300 | INFO | [27,  4200] loss: 1.649
2025-02-26T06:43:17.197812+0300 | INFO | [27,  4300] loss: 1.644
2025-02-26T06:43:26.290845+0300 | INFO | [27,  4400] loss: 1.643
2025-02-26T06:43:36.484984+0300 | INFO | [27,  4500] loss: 1.654
2025-02-26T06:43:46.163444+0300 | INFO | [27,  4600] loss: 1.641
2025-02-26T06:43:56.109120+0300 | INFO | [27,  4700] loss: 1.655
2025-02-26T06:44:07.840097+0300 | INFO | [27,  4800] loss: 1.633
2025-02-26T06:44:17.441715+0300 | INFO | [27,  4900] loss: 1.637
2025-02-26T06:44:27.467724+0300 | DEBUG | Saving model to flat file storage. Save #27
2025-02-26T06:44:27.496153+0300 | INFO | Averaging client parameters
2025-02-26T06:44:27.505152+0300 | INFO | Updating parameters on client #0
2025-02-26T06:44:42.067575+0300 | DEBUG | Test set: Accuracy: 7532/10000 (75%)
2025-02-26T06:44:42.069576+0300 | DEBUG | Test set: Loss: 1.7071579694747925
2025-02-26T06:44:42.179974+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.82      0.81      1000
           1       0.90      0.90      0.90      1000
           2       0.67      0.68      0.67      1000
           3       0.51      0.74      0.60      1200
           4       0.73      0.80      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.81      0.86      0.83      1000
           7       0.76      0.83      0.80      1000
           8       0.92      0.85      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.75     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.75      0.73     10000

2025-02-26T06:44:42.183450+0300 | DEBUG | Confusion Matrix:
[[825  14  38  26  14   0   7  17  33  26]
 [ 14 898   7  12   1   0   8   1  12  47]
 [ 63   2 684  68  84   0  57  32   3   7]
 [ 24   3  93 891  67   0  47  61   5   9]
 [  6   2  46  51 803   0  38  49   4   1]
 [  5   3  80 554  54   0  26  75   0   3]
 [ 11   2  31  54  30   0 859  10   3   0]
 [ 15   3  24  58  43   0  11 835   1  10]
 [ 44  25  16  24   3   0   6   3 853  26]
 [ 23  43   8  13   3   0   4  12  10 884]]
2025-02-26T06:44:42.185450+0300 | DEBUG | Class precision: [0.80097087 0.90251256 0.66601753 0.50885208 0.72867514        nan
 0.80809031 0.76255708 0.92316017 0.87265548]
2025-02-26T06:44:42.185450+0300 | DEBUG | Class recall: [0.825  0.898  0.684  0.7425 0.803  0.     0.859  0.835  0.853  0.884 ]
2025-02-26T06:44:42.236074+0300 | INFO | Training epoch #28 on client #0
2025-02-26T06:44:42.238078+0300 | DEBUG | Saving model to flat file storage. Save #28
2025-02-26T06:44:42.443052+0300 | INFO | [28,     0] loss: 0.019
2025-02-26T06:44:52.763160+0300 | INFO | [28,   100] loss: 1.631
2025-02-26T06:45:02.005607+0300 | INFO | [28,   200] loss: 1.628
2025-02-26T06:45:12.201806+0300 | INFO | [28,   300] loss: 1.614
2025-02-26T06:45:21.443889+0300 | INFO | [28,   400] loss: 1.641
2025-02-26T06:45:31.153641+0300 | INFO | [28,   500] loss: 1.630
2025-02-26T06:45:40.250140+0300 | INFO | [28,   600] loss: 1.633
2025-02-26T06:45:50.831220+0300 | INFO | [28,   700] loss: 1.640
2025-02-26T06:46:01.004342+0300 | INFO | [28,   800] loss: 1.658
2025-02-26T06:46:09.947704+0300 | INFO | [28,   900] loss: 1.620
2025-02-26T06:46:19.050736+0300 | INFO | [28,  1000] loss: 1.619
2025-02-26T06:46:28.496542+0300 | INFO | [28,  1100] loss: 1.622
2025-02-26T06:46:38.297330+0300 | INFO | [28,  1200] loss: 1.650
2025-02-26T06:46:48.605625+0300 | INFO | [28,  1300] loss: 1.626
2025-02-26T06:46:58.986969+0300 | INFO | [28,  1400] loss: 1.633
2025-02-26T06:47:09.100041+0300 | INFO | [28,  1500] loss: 1.640
2025-02-26T06:47:23.964907+0300 | INFO | [28,  1600] loss: 1.630
2025-02-26T06:47:35.221143+0300 | INFO | [28,  1700] loss: 1.640
2025-02-26T06:47:44.264021+0300 | INFO | [28,  1800] loss: 1.623
2025-02-26T06:47:53.954308+0300 | INFO | [28,  1900] loss: 1.669
2025-02-26T06:48:02.917094+0300 | INFO | [28,  2000] loss: 1.653
2025-02-26T06:48:12.450796+0300 | INFO | [28,  2100] loss: 1.623
2025-02-26T06:48:22.219878+0300 | INFO | [28,  2200] loss: 1.611
2025-02-26T06:48:31.589630+0300 | INFO | [28,  2300] loss: 1.641
2025-02-26T06:48:40.955445+0300 | INFO | [28,  2400] loss: 1.639
2025-02-26T06:48:50.538154+0300 | INFO | [28,  2500] loss: 1.632
2025-02-26T06:49:00.180766+0300 | INFO | [28,  2600] loss: 1.612
2025-02-26T06:49:10.677706+0300 | INFO | [28,  2700] loss: 1.626
2025-02-26T06:49:19.776453+0300 | INFO | [28,  2800] loss: 1.641
2025-02-26T06:49:29.696822+0300 | INFO | [28,  2900] loss: 1.629
2025-02-26T06:49:38.951327+0300 | INFO | [28,  3000] loss: 1.627
2025-02-26T06:49:47.778172+0300 | INFO | [28,  3100] loss: 1.645
2025-02-26T06:49:58.763631+0300 | INFO | [28,  3200] loss: 1.645
2025-02-26T06:50:08.125288+0300 | INFO | [28,  3300] loss: 1.627
2025-02-26T06:50:18.743227+0300 | INFO | [28,  3400] loss: 1.629
2025-02-26T06:50:29.296516+0300 | INFO | [28,  3500] loss: 1.650
2025-02-26T06:50:38.062623+0300 | INFO | [28,  3600] loss: 1.628
2025-02-26T06:50:48.277958+0300 | INFO | [28,  3700] loss: 1.643
2025-02-26T06:50:58.229313+0300 | INFO | [28,  3800] loss: 1.645
2025-02-26T06:51:08.177071+0300 | INFO | [28,  3900] loss: 1.632
2025-02-26T06:51:18.550365+0300 | INFO | [28,  4000] loss: 1.639
2025-02-26T06:51:27.820272+0300 | INFO | [28,  4100] loss: 1.638
2025-02-26T06:51:37.627504+0300 | INFO | [28,  4200] loss: 1.623
2025-02-26T06:51:47.437167+0300 | INFO | [28,  4300] loss: 1.628
2025-02-26T06:51:56.693385+0300 | INFO | [28,  4400] loss: 1.646
2025-02-26T06:52:07.047130+0300 | INFO | [28,  4500] loss: 1.635
2025-02-26T06:52:15.919947+0300 | INFO | [28,  4600] loss: 1.647
2025-02-26T06:52:25.020131+0300 | INFO | [28,  4700] loss: 1.646
2025-02-26T06:52:34.237080+0300 | INFO | [28,  4800] loss: 1.649
2025-02-26T06:52:44.380703+0300 | INFO | [28,  4900] loss: 1.622
2025-02-26T06:52:54.573546+0300 | DEBUG | Saving model to flat file storage. Save #28
2025-02-26T06:52:54.600367+0300 | INFO | Averaging client parameters
2025-02-26T06:52:54.608756+0300 | INFO | Updating parameters on client #0
2025-02-26T06:53:10.179471+0300 | DEBUG | Test set: Accuracy: 7522/10000 (75%)
2025-02-26T06:53:10.181473+0300 | DEBUG | Test set: Loss: 1.7083412408828735
2025-02-26T06:53:10.277130+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.91      0.89      0.90      1000
           2       0.63      0.72      0.67      1000
           3       0.53      0.69      0.60      1200
           4       0.75      0.79      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.76      0.87      0.82      1000
           7       0.83      0.81      0.82      1000
           8       0.85      0.90      0.87      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-26T06:53:10.279132+0300 | DEBUG | Confusion Matrix:
[[851  17  26   9  11   0  10   8  46  22]
 [ 13 886   4   2   2   0  11   1  28  53]
 [ 66   3 725  47  61   0  53  20  11  14]
 [ 35   4 132 822  60   0  83  33  21  10]
 [ 15   2  62  47 786   0  39  35   9   5]
 [ 15   2 106 516  42   0  44  62  10   3]
 [  8   0  46  38  23   0 874   4   7   0]
 [ 21   2  37  47  54   0  16 807   6  10]
 [ 45  16  15   6   4   0   4   3 896  11]
 [ 28  43   6   9   1   0  10   5  23 875]]
2025-02-26T06:53:10.281135+0300 | DEBUG | Class precision: [0.77575205 0.90871795 0.62553926 0.53272845 0.75287356        nan
 0.76398601 0.82515337 0.84768212 0.87238285]
2025-02-26T06:53:10.283134+0300 | DEBUG | Class recall: [0.851 0.886 0.725 0.685 0.786 0.    0.874 0.807 0.896 0.875]
2025-02-26T06:53:10.331356+0300 | INFO | Training epoch #29 on client #0
2025-02-26T06:53:10.332359+0300 | DEBUG | Saving model to flat file storage. Save #29
2025-02-26T06:53:10.539374+0300 | INFO | [29,     0] loss: 0.016
2025-02-26T06:53:19.842545+0300 | INFO | [29,   100] loss: 1.634
2025-02-26T06:53:29.064348+0300 | INFO | [29,   200] loss: 1.636
2025-02-26T06:53:38.121581+0300 | INFO | [29,   300] loss: 1.619
2025-02-26T06:53:47.230895+0300 | INFO | [29,   400] loss: 1.647
2025-02-26T06:53:56.890723+0300 | INFO | [29,   500] loss: 1.640
2025-02-26T06:54:06.426112+0300 | INFO | [29,   600] loss: 1.643
2025-02-26T06:54:15.740682+0300 | INFO | [29,   700] loss: 1.617
2025-02-26T06:54:24.767043+0300 | INFO | [29,   800] loss: 1.640
2025-02-26T06:54:34.438268+0300 | INFO | [29,   900] loss: 1.613
2025-02-26T06:54:44.454667+0300 | INFO | [29,  1000] loss: 1.636
2025-02-26T06:54:59.288074+0300 | INFO | [29,  1100] loss: 1.646
2025-02-26T06:55:09.595591+0300 | INFO | [29,  1200] loss: 1.622
2025-02-26T06:55:19.448247+0300 | INFO | [29,  1300] loss: 1.626
2025-02-26T06:55:28.520252+0300 | INFO | [29,  1400] loss: 1.620
2025-02-26T06:55:38.739055+0300 | INFO | [29,  1500] loss: 1.647
2025-02-26T06:55:49.190898+0300 | INFO | [29,  1600] loss: 1.627
2025-02-26T06:55:58.343216+0300 | INFO | [29,  1700] loss: 1.635
2025-02-26T06:56:08.466079+0300 | INFO | [29,  1800] loss: 1.612
2025-02-26T06:56:17.760820+0300 | INFO | [29,  1900] loss: 1.645
2025-02-26T06:56:27.894456+0300 | INFO | [29,  2000] loss: 1.638
2025-02-26T06:56:37.337491+0300 | INFO | [29,  2100] loss: 1.637
2025-02-26T06:56:46.583765+0300 | INFO | [29,  2200] loss: 1.647
2025-02-26T06:56:56.260625+0300 | INFO | [29,  2300] loss: 1.629
2025-02-26T06:57:05.432706+0300 | INFO | [29,  2400] loss: 1.635
2025-02-26T06:57:14.849526+0300 | INFO | [29,  2500] loss: 1.631
2025-02-26T06:57:23.758600+0300 | INFO | [29,  2600] loss: 1.614
2025-02-26T06:57:35.078761+0300 | INFO | [29,  2700] loss: 1.623
2025-02-26T06:57:43.848599+0300 | INFO | [29,  2800] loss: 1.647
2025-02-26T06:57:55.343069+0300 | INFO | [29,  2900] loss: 1.645
2025-02-26T06:58:04.665687+0300 | INFO | [29,  3000] loss: 1.624
2025-02-26T06:58:13.871316+0300 | INFO | [29,  3100] loss: 1.652
2025-02-26T06:58:22.826020+0300 | INFO | [29,  3200] loss: 1.631
2025-02-26T06:58:33.130793+0300 | INFO | [29,  3300] loss: 1.659
2025-02-26T06:58:42.022423+0300 | INFO | [29,  3400] loss: 1.634
2025-02-26T06:58:51.429595+0300 | INFO | [29,  3500] loss: 1.615
2025-02-26T06:59:01.801640+0300 | INFO | [29,  3600] loss: 1.640
2025-02-26T06:59:11.034806+0300 | INFO | [29,  3700] loss: 1.637
2025-02-26T06:59:21.065105+0300 | INFO | [29,  3800] loss: 1.639
2025-02-26T06:59:29.962421+0300 | INFO | [29,  3900] loss: 1.634
2025-02-26T06:59:39.139189+0300 | INFO | [29,  4000] loss: 1.631
2025-02-26T06:59:48.660874+0300 | INFO | [29,  4100] loss: 1.629
2025-02-26T06:59:57.818071+0300 | INFO | [29,  4200] loss: 1.622
2025-02-26T07:00:07.218428+0300 | INFO | [29,  4300] loss: 1.625
2025-02-26T07:00:16.176672+0300 | INFO | [29,  4400] loss: 1.629
2025-02-26T07:00:25.199100+0300 | INFO | [29,  4500] loss: 1.645
2025-02-26T07:00:34.150098+0300 | INFO | [29,  4600] loss: 1.654
2025-02-26T07:00:43.431069+0300 | INFO | [29,  4700] loss: 1.629
2025-02-26T07:00:53.815078+0300 | INFO | [29,  4800] loss: 1.646
2025-02-26T07:01:02.834679+0300 | INFO | [29,  4900] loss: 1.643
2025-02-26T07:01:13.220190+0300 | DEBUG | Saving model to flat file storage. Save #29
2025-02-26T07:01:13.245761+0300 | INFO | Averaging client parameters
2025-02-26T07:01:13.254193+0300 | INFO | Updating parameters on client #0
2025-02-26T07:01:27.997483+0300 | DEBUG | Test set: Accuracy: 7509/10000 (75%)
2025-02-26T07:01:27.999485+0300 | DEBUG | Test set: Loss: 1.7101408243179321
2025-02-26T07:01:28.092264+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1000
           1       0.89      0.91      0.90      1000
           2       0.71      0.67      0.69      1000
           3       0.53      0.70      0.61      1200
           4       0.73      0.80      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.68      0.91      0.78      1000
           7       0.83      0.80      0.81      1000
           8       0.87      0.90      0.88      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-26T07:01:28.094262+0300 | DEBUG | Confusion Matrix:
[[805  19  25  11  16   0  15  11  52  46]
 [  7 910   0   1   0   0  11   3  17  51]
 [ 68   1 669  63  63   0 102  14   9  11]
 [ 18   5  74 840  72   0 129  33  19  10]
 [ 12   2  39  48 799   0  67  23  10   0]
 [ 18   5  77 517  53   0  57  60   8   5]
 [  6   3  20  27  18   0 913  11   2   0]
 [ 18   6  24  45  71   0  25 796   3  12]
 [ 29  22  12  11   3   0  13   1 896  13]
 [ 12  51   8  10   3   0  13   4  18 881]]
2025-02-26T07:01:28.095255+0300 | DEBUG | Class precision: [0.81067472 0.88867188 0.7056962  0.53401144 0.7276867         nan
 0.67881041 0.83263598 0.86653772 0.85617104]
2025-02-26T07:01:28.096292+0300 | DEBUG | Class recall: [0.805 0.91  0.669 0.7   0.799 0.    0.913 0.796 0.896 0.881]
2025-02-26T07:01:28.148696+0300 | INFO | Training epoch #30 on client #0
2025-02-26T07:01:28.150702+0300 | DEBUG | Saving model to flat file storage. Save #30
2025-02-26T07:01:28.350049+0300 | INFO | [30,     0] loss: 0.017
2025-02-26T07:01:37.829095+0300 | INFO | [30,   100] loss: 1.635
2025-02-26T07:01:47.497443+0300 | INFO | [30,   200] loss: 1.628
2025-02-26T07:01:57.709159+0300 | INFO | [30,   300] loss: 1.635
2025-02-26T07:02:07.088885+0300 | INFO | [30,   400] loss: 1.618
2025-02-26T07:02:16.828698+0300 | INFO | [30,   500] loss: 1.642
2025-02-26T07:02:27.084326+0300 | INFO | [30,   600] loss: 1.621
2025-02-26T07:02:40.584637+0300 | INFO | [30,   700] loss: 1.625
2025-02-26T07:02:50.759686+0300 | INFO | [30,   800] loss: 1.616
2025-02-26T07:03:00.419452+0300 | INFO | [30,   900] loss: 1.629
2025-02-26T07:03:09.391270+0300 | INFO | [30,  1000] loss: 1.609
2025-02-26T07:03:18.865906+0300 | INFO | [30,  1100] loss: 1.631
2025-02-26T07:03:27.888278+0300 | INFO | [30,  1200] loss: 1.613
2025-02-26T07:03:37.052364+0300 | INFO | [30,  1300] loss: 1.668
2025-02-26T07:03:46.038644+0300 | INFO | [30,  1400] loss: 1.642
2025-02-26T07:03:56.330797+0300 | INFO | [30,  1500] loss: 1.637
2025-02-26T07:04:06.557618+0300 | INFO | [30,  1600] loss: 1.629
2025-02-26T07:04:16.070357+0300 | INFO | [30,  1700] loss: 1.631
2025-02-26T07:04:25.953155+0300 | INFO | [30,  1800] loss: 1.626
2025-02-26T07:04:35.316743+0300 | INFO | [30,  1900] loss: 1.640
2025-02-26T07:04:44.658840+0300 | INFO | [30,  2000] loss: 1.638
2025-02-26T07:04:54.307987+0300 | INFO | [30,  2100] loss: 1.635
2025-02-26T07:05:03.773163+0300 | INFO | [30,  2200] loss: 1.624
2025-02-26T07:05:13.694735+0300 | INFO | [30,  2300] loss: 1.632
2025-02-26T07:05:22.757889+0300 | INFO | [30,  2400] loss: 1.638
2025-02-26T07:05:32.504605+0300 | INFO | [30,  2500] loss: 1.625
2025-02-26T07:05:41.790772+0300 | INFO | [30,  2600] loss: 1.648
2025-02-26T07:05:51.656416+0300 | INFO | [30,  2700] loss: 1.627
2025-02-26T07:06:02.208963+0300 | INFO | [30,  2800] loss: 1.635
2025-02-26T07:06:11.550261+0300 | INFO | [30,  2900] loss: 1.637
2025-02-26T07:06:21.043076+0300 | INFO | [30,  3000] loss: 1.602
2025-02-26T07:06:30.477880+0300 | INFO | [30,  3100] loss: 1.640
2025-02-26T07:06:40.328001+0300 | INFO | [30,  3200] loss: 1.626
2025-02-26T07:06:51.454434+0300 | INFO | [30,  3300] loss: 1.627
2025-02-26T07:07:03.502867+0300 | INFO | [30,  3400] loss: 1.616
2025-02-26T07:07:13.312036+0300 | INFO | [30,  3500] loss: 1.643
2025-02-26T07:07:23.929215+0300 | INFO | [30,  3600] loss: 1.646
2025-02-26T07:07:34.121478+0300 | INFO | [30,  3700] loss: 1.645
2025-02-26T07:07:43.092823+0300 | INFO | [30,  3800] loss: 1.644
2025-02-26T07:07:52.585879+0300 | INFO | [30,  3900] loss: 1.637
2025-02-26T07:08:01.780772+0300 | INFO | [30,  4000] loss: 1.620
2025-02-26T07:08:13.701516+0300 | INFO | [30,  4100] loss: 1.639
2025-02-26T07:08:23.560829+0300 | INFO | [30,  4200] loss: 1.646
2025-02-26T07:08:32.764454+0300 | INFO | [30,  4300] loss: 1.628
2025-02-26T07:08:42.298595+0300 | INFO | [30,  4400] loss: 1.639
2025-02-26T07:08:51.595498+0300 | INFO | [30,  4500] loss: 1.627
2025-02-26T07:09:01.214700+0300 | INFO | [30,  4600] loss: 1.645
2025-02-26T07:09:11.720185+0300 | INFO | [30,  4700] loss: 1.652
2025-02-26T07:09:20.510354+0300 | INFO | [30,  4800] loss: 1.632
2025-02-26T07:09:30.530065+0300 | INFO | [30,  4900] loss: 1.637
2025-02-26T07:09:39.745568+0300 | DEBUG | Saving model to flat file storage. Save #30
2025-02-26T07:09:39.767598+0300 | INFO | Averaging client parameters
2025-02-26T07:09:39.771597+0300 | INFO | Updating parameters on client #0
2025-02-26T07:09:55.551970+0300 | DEBUG | Test set: Accuracy: 7465/10000 (75%)
2025-02-26T07:09:55.551970+0300 | DEBUG | Test set: Loss: 1.7129502296447754
2025-02-26T07:09:55.657105+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.76      0.85      0.80      1000
           1       0.87      0.92      0.89      1000
           2       0.61      0.74      0.67      1000
           3       0.54      0.67      0.60      1200
           4       0.77      0.76      0.76      1000
           5       0.00      0.00      0.00       800
           6       0.80      0.86      0.83      1000
           7       0.79      0.81      0.80      1000
           8       0.84      0.88      0.86      1000
           9       0.86      0.85      0.86      1000

    accuracy                           0.75     10000
   macro avg       0.68      0.73      0.71     10000
weighted avg       0.69      0.75      0.72     10000

2025-02-26T07:09:55.667657+0300 | DEBUG | Confusion Matrix:
[[848  18  37  10  12   0   5   5  40  25]
 [ 13 916   0   3   2   0   5   1  18  42]
 [ 81   3 739  42  46   0  52  18   9  10]
 [ 23   6 134 799  54   0  62  62  35  25]
 [ 20   1  68  43 759   0  44  47  12   6]
 [  9   4 136 485  45   0  27  72  12  10]
 [  9   7  48  44  13   0 857   9  10   3]
 [ 28   4  38  41  52   0  11 813   3  10]
 [ 62  22  10   8   3   0   2   3 883   7]
 [ 25  74  10   8   3   0   1   5  23 851]]
2025-02-26T07:09:55.670634+0300 | DEBUG | Class precision: [0.75849732 0.86824645 0.6057377  0.53877276 0.76744186        nan
 0.80393996 0.78550725 0.84497608 0.86046512]
2025-02-26T07:09:55.671632+0300 | DEBUG | Class recall: [0.848      0.916      0.739      0.66583333 0.759      0.
 0.857      0.813      0.883      0.851     ]
2025-02-26T07:09:55.673631+0300 | INFO | Training epoch #31 on client #0
2025-02-26T07:09:55.678804+0300 | DEBUG | Saving model to flat file storage. Save #31
2025-02-26T07:09:55.918961+0300 | INFO | [31,     0] loss: 0.018
2025-02-26T07:10:08.959370+0300 | INFO | [31,   100] loss: 1.647
2025-02-26T07:10:23.011375+0300 | INFO | [31,   200] loss: 1.624
2025-02-26T07:10:32.993372+0300 | INFO | [31,   300] loss: 1.636
2025-02-26T07:10:41.979645+0300 | INFO | [31,   400] loss: 1.622
2025-02-26T07:10:51.566889+0300 | INFO | [31,   500] loss: 1.625
2025-02-26T07:11:02.040277+0300 | INFO | [31,   600] loss: 1.623
2025-02-26T07:11:11.798174+0300 | INFO | [31,   700] loss: 1.642
2025-02-26T07:11:21.135328+0300 | INFO | [31,   800] loss: 1.632
2025-02-26T07:11:30.122835+0300 | INFO | [31,   900] loss: 1.609
2025-02-26T07:11:40.139017+0300 | INFO | [31,  1000] loss: 1.631
2025-02-26T07:11:49.752953+0300 | INFO | [31,  1100] loss: 1.629
2025-02-26T07:11:58.930923+0300 | INFO | [31,  1200] loss: 1.615
2025-02-26T07:12:08.601980+0300 | INFO | [31,  1300] loss: 1.613
2025-02-26T07:12:17.630134+0300 | INFO | [31,  1400] loss: 1.635
2025-02-26T07:12:26.608105+0300 | INFO | [31,  1500] loss: 1.631
2025-02-26T07:12:36.304069+0300 | INFO | [31,  1600] loss: 1.648
2025-02-26T07:12:45.953771+0300 | INFO | [31,  1700] loss: 1.637
2025-02-26T07:12:56.494425+0300 | INFO | [31,  1800] loss: 1.632
2025-02-26T07:13:05.408456+0300 | INFO | [31,  1900] loss: 1.653
2025-02-26T07:13:14.395800+0300 | INFO | [31,  2000] loss: 1.610
2025-02-26T07:13:23.322687+0300 | INFO | [31,  2100] loss: 1.611
2025-02-26T07:13:32.391135+0300 | INFO | [31,  2200] loss: 1.636
2025-02-26T07:13:41.574797+0300 | INFO | [31,  2300] loss: 1.632
2025-02-26T07:13:50.878528+0300 | INFO | [31,  2400] loss: 1.641
2025-02-26T07:14:01.868236+0300 | INFO | [31,  2500] loss: 1.640
2025-02-26T07:14:13.223163+0300 | INFO | [31,  2600] loss: 1.636
2025-02-26T07:14:22.478416+0300 | INFO | [31,  2700] loss: 1.638
2025-02-26T07:14:31.537489+0300 | INFO | [31,  2800] loss: 1.618
2025-02-26T07:14:40.532053+0300 | INFO | [31,  2900] loss: 1.638
2025-02-26T07:14:49.631149+0300 | INFO | [31,  3000] loss: 1.631
2025-02-26T07:14:58.560916+0300 | INFO | [31,  3100] loss: 1.656
2025-02-26T07:15:08.464081+0300 | INFO | [31,  3200] loss: 1.633
2025-02-26T07:15:17.873056+0300 | INFO | [31,  3300] loss: 1.605
2025-02-26T07:15:26.909735+0300 | INFO | [31,  3400] loss: 1.619
2025-02-26T07:15:36.605607+0300 | INFO | [31,  3500] loss: 1.633
2025-02-26T07:15:45.400187+0300 | INFO | [31,  3600] loss: 1.630
2025-02-26T07:15:55.373706+0300 | INFO | [31,  3700] loss: 1.651
2025-02-26T07:16:04.880606+0300 | INFO | [31,  3800] loss: 1.631
2025-02-26T07:16:14.039269+0300 | INFO | [31,  3900] loss: 1.643
2025-02-26T07:16:23.374830+0300 | INFO | [31,  4000] loss: 1.604
2025-02-26T07:16:32.415609+0300 | INFO | [31,  4100] loss: 1.638
2025-02-26T07:16:41.572561+0300 | INFO | [31,  4200] loss: 1.628
2025-02-26T07:16:51.672275+0300 | INFO | [31,  4300] loss: 1.628
2025-02-26T07:17:00.849446+0300 | INFO | [31,  4400] loss: 1.624
2025-02-26T07:17:10.357954+0300 | INFO | [31,  4500] loss: 1.640
2025-02-26T07:17:19.682298+0300 | INFO | [31,  4600] loss: 1.640
2025-02-26T07:17:31.755320+0300 | INFO | [31,  4700] loss: 1.627
2025-02-26T07:17:44.926470+0300 | INFO | [31,  4800] loss: 1.639
2025-02-26T07:17:54.680212+0300 | INFO | [31,  4900] loss: 1.640
2025-02-26T07:18:04.624472+0300 | DEBUG | Saving model to flat file storage. Save #31
2025-02-26T07:18:04.649016+0300 | INFO | Averaging client parameters
2025-02-26T07:18:04.657199+0300 | INFO | Updating parameters on client #0
2025-02-26T07:18:19.736083+0300 | DEBUG | Test set: Accuracy: 7600/10000 (76%)
2025-02-26T07:18:19.737093+0300 | DEBUG | Test set: Loss: 1.7001888751983643
2025-02-26T07:18:19.833843+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82      1000
           1       0.87      0.92      0.89      1000
           2       0.72      0.69      0.71      1000
           3       0.52      0.76      0.62      1200
           4       0.77      0.76      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.78      0.86      0.82      1000
           7       0.81      0.83      0.82      1000
           8       0.88      0.89      0.88      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.74      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-26T07:18:19.836841+0300 | DEBUG | Confusion Matrix:
[[852  21  33  12   8   0   5  10  36  23]
 [ 12 920   0   3   1   0   7   3  13  41]
 [ 76   2 695  73  50   0  65  19  11   9]
 [ 17   7  70 913  47   0  70  40  19  17]
 [ 15   2  53  65 764   0  44  42  10   5]
 [  5   5  62 570  44   0  37  60   8   9]
 [ 10   8  26  45  24   0 865   9  10   3]
 [ 23   4  22  45  48   0   9 833   5  11]
 [ 52  23   5   6   0   0   2   7 889  16]
 [ 25  65   5  11   1   0   4   6  14 869]]
2025-02-26T07:18:19.838839+0300 | DEBUG | Class precision: [0.78380865 0.87038789 0.71575695 0.52380952 0.77406282        nan
 0.78068592 0.80952381 0.87586207 0.8664008 ]
2025-02-26T07:18:19.840843+0300 | DEBUG | Class recall: [0.852      0.92       0.695      0.76083333 0.764      0.
 0.865      0.833      0.889      0.869     ]
2025-02-26T07:18:19.892101+0300 | INFO | Training epoch #32 on client #0
2025-02-26T07:18:19.894094+0300 | DEBUG | Saving model to flat file storage. Save #32
2025-02-26T07:18:20.084509+0300 | INFO | [32,     0] loss: 0.019
2025-02-26T07:18:31.072455+0300 | INFO | [32,   100] loss: 1.616
2025-02-26T07:18:39.976109+0300 | INFO | [32,   200] loss: 1.631
2025-02-26T07:18:49.724050+0300 | INFO | [32,   300] loss: 1.635
2025-02-26T07:18:58.873734+0300 | INFO | [32,   400] loss: 1.615
2025-02-26T07:19:08.236616+0300 | INFO | [32,   500] loss: 1.638
2025-02-26T07:19:17.622349+0300 | INFO | [32,   600] loss: 1.635
2025-02-26T07:19:26.636332+0300 | INFO | [32,   700] loss: 1.622
2025-02-26T07:19:35.436661+0300 | INFO | [32,   800] loss: 1.638
2025-02-26T07:19:44.474675+0300 | INFO | [32,   900] loss: 1.631
2025-02-26T07:19:54.105920+0300 | INFO | [32,  1000] loss: 1.612
2025-02-26T07:20:04.958469+0300 | INFO | [32,  1100] loss: 1.639
2025-02-26T07:20:14.048562+0300 | INFO | [32,  1200] loss: 1.641
2025-02-26T07:20:23.060214+0300 | INFO | [32,  1300] loss: 1.637
2025-02-26T07:20:32.241749+0300 | INFO | [32,  1400] loss: 1.627
2025-02-26T07:20:41.118169+0300 | INFO | [32,  1500] loss: 1.627
2025-02-26T07:20:50.013278+0300 | INFO | [32,  1600] loss: 1.625
2025-02-26T07:20:59.871198+0300 | INFO | [32,  1700] loss: 1.607
2025-02-26T07:21:10.188907+0300 | INFO | [32,  1800] loss: 1.630
2025-02-26T07:21:20.019989+0300 | INFO | [32,  1900] loss: 1.629
2025-02-26T07:21:29.494907+0300 | INFO | [32,  2000] loss: 1.636
2025-02-26T07:21:38.554961+0300 | INFO | [32,  2100] loss: 1.624
2025-02-26T07:21:47.740834+0300 | INFO | [32,  2200] loss: 1.658
2025-02-26T07:21:57.249653+0300 | INFO | [32,  2300] loss: 1.648
2025-02-26T07:22:07.059986+0300 | INFO | [32,  2400] loss: 1.623
2025-02-26T07:22:16.294797+0300 | INFO | [32,  2500] loss: 1.643
2025-02-26T07:22:25.376693+0300 | INFO | [32,  2600] loss: 1.637
2025-02-26T07:22:34.940232+0300 | INFO | [32,  2700] loss: 1.625
2025-02-26T07:22:43.916554+0300 | INFO | [32,  2800] loss: 1.633
2025-02-26T07:22:53.277052+0300 | INFO | [32,  2900] loss: 1.624
2025-02-26T07:23:03.058522+0300 | INFO | [32,  3000] loss: 1.613
2025-02-26T07:23:13.248300+0300 | INFO | [32,  3100] loss: 1.613
2025-02-26T07:23:22.785908+0300 | INFO | [32,  3200] loss: 1.634
2025-02-26T07:23:32.896864+0300 | INFO | [32,  3300] loss: 1.641
2025-02-26T07:23:42.096183+0300 | INFO | [32,  3400] loss: 1.607
2025-02-26T07:23:51.498914+0300 | INFO | [32,  3500] loss: 1.628
2025-02-26T07:24:01.555769+0300 | INFO | [32,  3600] loss: 1.646
2025-02-26T07:24:11.714541+0300 | INFO | [32,  3700] loss: 1.619
2025-02-26T07:24:21.155413+0300 | INFO | [32,  3800] loss: 1.627
2025-02-26T07:24:30.110988+0300 | INFO | [32,  3900] loss: 1.642
2025-02-26T07:24:39.102186+0300 | INFO | [32,  4000] loss: 1.648
2025-02-26T07:24:47.947142+0300 | INFO | [32,  4100] loss: 1.612
2025-02-26T07:24:59.258082+0300 | INFO | [32,  4200] loss: 1.630
2025-02-26T07:25:13.097931+0300 | INFO | [32,  4300] loss: 1.636
2025-02-26T07:25:22.117582+0300 | INFO | [32,  4400] loss: 1.619
2025-02-26T07:25:31.552706+0300 | INFO | [32,  4500] loss: 1.638
2025-02-26T07:25:41.065661+0300 | INFO | [32,  4600] loss: 1.618
2025-02-26T07:25:50.525742+0300 | INFO | [32,  4700] loss: 1.625
2025-02-26T07:26:00.557842+0300 | INFO | [32,  4800] loss: 1.603
2025-02-26T07:26:10.087224+0300 | INFO | [32,  4900] loss: 1.627
2025-02-26T07:26:20.052473+0300 | DEBUG | Saving model to flat file storage. Save #32
2025-02-26T07:26:20.080476+0300 | INFO | Averaging client parameters
2025-02-26T07:26:20.084471+0300 | INFO | Updating parameters on client #0
2025-02-26T07:26:35.153776+0300 | DEBUG | Test set: Accuracy: 7603/10000 (76%)
2025-02-26T07:26:35.156356+0300 | DEBUG | Test set: Loss: 1.7008546590805054
2025-02-26T07:26:35.280082+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.89      0.91      0.90      1000
           2       0.70      0.72      0.71      1000
           3       0.53      0.73      0.62      1200
           4       0.77      0.78      0.77      1000
           5       0.00      0.00      0.00       800
           6       0.79      0.86      0.82      1000
           7       0.80      0.85      0.82      1000
           8       0.90      0.87      0.89      1000
           9       0.81      0.90      0.86      1000

    accuracy                           0.76     10000
   macro avg       0.70      0.75      0.72     10000
weighted avg       0.71      0.76      0.73     10000

2025-02-26T07:26:35.283087+0300 | DEBUG | Confusion Matrix:
[[835  20  33  11  14   0   4  16  32  35]
 [  8 907   0   1   1   0   2   5  11  65]
 [ 55   5 720  58  63   0  54  23   6  16]
 [ 25   7  77 882  53   0  67  38  16  35]
 [ 11   3  50  60 775   0  40  49   7   5]
 [  7   5  79 550  35   0  43  65   8   8]
 [ 15   9  28  50  18   0 856   8   6  10]
 [ 18   0  18  43  42   0  13 851   1  14]
 [ 55  23  15   6   4   0   2   2 874  19]
 [ 15  43  11   2   1   0   3   8  14 903]]
2025-02-26T07:26:35.285092+0300 | DEBUG | Class precision: [0.79980843 0.88747554 0.69835112 0.53036681 0.77037773        nan
 0.7896679  0.79906103 0.89641026 0.81351351]
2025-02-26T07:26:35.288104+0300 | DEBUG | Class recall: [0.835 0.907 0.72  0.735 0.775 0.    0.856 0.851 0.874 0.903]
2025-02-26T07:26:35.339891+0300 | INFO | Training epoch #33 on client #0
2025-02-26T07:26:35.340891+0300 | DEBUG | Saving model to flat file storage. Save #33
2025-02-26T07:26:35.574267+0300 | INFO | [33,     0] loss: 0.016
2025-02-26T07:26:45.309919+0300 | INFO | [33,   100] loss: 1.614
2025-02-26T07:26:55.180743+0300 | INFO | [33,   200] loss: 1.627
2025-02-26T07:27:05.680922+0300 | INFO | [33,   300] loss: 1.615
2025-02-26T07:27:16.597642+0300 | INFO | [33,   400] loss: 1.610
2025-02-26T07:27:25.730419+0300 | INFO | [33,   500] loss: 1.634
2025-02-26T07:27:35.063292+0300 | INFO | [33,   600] loss: 1.626
2025-02-26T07:27:44.251406+0300 | INFO | [33,   700] loss: 1.634
2025-02-26T07:27:53.897119+0300 | INFO | [33,   800] loss: 1.613
2025-02-26T07:28:04.054354+0300 | INFO | [33,   900] loss: 1.623
2025-02-26T07:28:13.268386+0300 | INFO | [33,  1000] loss: 1.630
2025-02-26T07:28:22.659729+0300 | INFO | [33,  1100] loss: 1.613
2025-02-26T07:28:31.642064+0300 | INFO | [33,  1200] loss: 1.618
2025-02-26T07:28:40.870431+0300 | INFO | [33,  1300] loss: 1.605
2025-02-26T07:28:49.871392+0300 | INFO | [33,  1400] loss: 1.623
2025-02-26T07:28:59.345345+0300 | INFO | [33,  1500] loss: 1.641
2025-02-26T07:29:09.913084+0300 | INFO | [33,  1600] loss: 1.625
2025-02-26T07:29:19.024954+0300 | INFO | [33,  1700] loss: 1.633
2025-02-26T07:29:28.249831+0300 | INFO | [33,  1800] loss: 1.625
2025-02-26T07:29:37.221392+0300 | INFO | [33,  1900] loss: 1.627
2025-02-26T07:29:48.178290+0300 | INFO | [33,  2000] loss: 1.637
2025-02-26T07:29:58.214390+0300 | INFO | [33,  2100] loss: 1.630
2025-02-26T07:30:07.822358+0300 | INFO | [33,  2200] loss: 1.635
2025-02-26T07:30:16.960469+0300 | INFO | [33,  2300] loss: 1.628
2025-02-26T07:30:26.198641+0300 | INFO | [33,  2400] loss: 1.643
2025-02-26T07:30:35.820023+0300 | INFO | [33,  2500] loss: 1.614
2025-02-26T07:30:45.783242+0300 | INFO | [33,  2600] loss: 1.631
2025-02-26T07:30:54.995307+0300 | INFO | [33,  2700] loss: 1.623
2025-02-26T07:31:04.964612+0300 | INFO | [33,  2800] loss: 1.603
2025-02-26T07:31:14.346488+0300 | INFO | [33,  2900] loss: 1.627
2025-02-26T07:31:23.699781+0300 | INFO | [33,  3000] loss: 1.627
2025-02-26T07:31:32.922981+0300 | INFO | [33,  3100] loss: 1.615
2025-02-26T07:31:42.279502+0300 | INFO | [33,  3200] loss: 1.602
2025-02-26T07:31:51.764082+0300 | INFO | [33,  3300] loss: 1.640
2025-02-26T07:32:01.048666+0300 | INFO | [33,  3400] loss: 1.646
2025-02-26T07:32:11.082149+0300 | INFO | [33,  3500] loss: 1.633
2025-02-26T07:32:20.366370+0300 | INFO | [33,  3600] loss: 1.627
2025-02-26T07:32:34.214169+0300 | INFO | [33,  3700] loss: 1.634
2025-02-26T07:32:46.479298+0300 | INFO | [33,  3800] loss: 1.630
2025-02-26T07:32:56.403698+0300 | INFO | [33,  3900] loss: 1.637
2025-02-26T07:33:05.691946+0300 | INFO | [33,  4000] loss: 1.628
2025-02-26T07:33:15.887632+0300 | INFO | [33,  4100] loss: 1.615
2025-02-26T07:33:24.794995+0300 | INFO | [33,  4200] loss: 1.623
2025-02-26T07:33:33.800843+0300 | INFO | [33,  4300] loss: 1.646
2025-02-26T07:33:43.374463+0300 | INFO | [33,  4400] loss: 1.623
2025-02-26T07:33:53.138606+0300 | INFO | [33,  4500] loss: 1.627
2025-02-26T07:34:03.418561+0300 | INFO | [33,  4600] loss: 1.638
2025-02-26T07:34:12.918505+0300 | INFO | [33,  4700] loss: 1.631
2025-02-26T07:34:22.168505+0300 | INFO | [33,  4800] loss: 1.611
2025-02-26T07:34:31.459784+0300 | INFO | [33,  4900] loss: 1.616
2025-02-26T07:34:40.452069+0300 | DEBUG | Saving model to flat file storage. Save #33
2025-02-26T07:34:40.476632+0300 | INFO | Averaging client parameters
2025-02-26T07:34:40.485165+0300 | INFO | Updating parameters on client #0
2025-02-26T07:34:54.687412+0300 | DEBUG | Test set: Accuracy: 7506/10000 (75%)
2025-02-26T07:34:54.688420+0300 | DEBUG | Test set: Loss: 1.7088415622711182
2025-02-26T07:34:54.792666+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.80      0.79      1000
           1       0.86      0.90      0.88      1000
           2       0.72      0.67      0.69      1000
           3       0.53      0.73      0.61      1200
           4       0.75      0.77      0.76      1000
           5       0.50      0.00      0.00       800
           6       0.80      0.85      0.83      1000
           7       0.80      0.83      0.81      1000
           8       0.80      0.93      0.86      1000
           9       0.82      0.89      0.85      1000

    accuracy                           0.75     10000
   macro avg       0.74      0.74      0.71     10000
weighted avg       0.74      0.75      0.72     10000

2025-02-26T07:34:54.794993+0300 | DEBUG | Confusion Matrix:
[[795  26  21   7   6   0   8   7  89  41]
 [  2 904   0   2   1   0   4   1  15  71]
 [ 83   6 669  67  71   0  50  26  14  14]
 [ 29  14  60 876  63   1  63  40  35  19]
 [ 18   3  50  57 771   0  34  47  15   5]
 [ 14  10  66 547  41   1  33  67  14   7]
 [  9  16  32  39  22   0 849   8  17   8]
 [ 28   4  22  45  47   0   9 827   9   9]
 [ 19  17   8   4   3   0   2   1 929  17]
 [ 20  48   7   7   1   0   4   7  21 885]]
2025-02-26T07:34:54.796007+0300 | DEBUG | Class precision: [0.78171091 0.86259542 0.71550802 0.53058752 0.75146199 0.5
 0.80397727 0.80213385 0.80224525 0.82249071]
2025-02-26T07:34:54.797002+0300 | DEBUG | Class recall: [0.795   0.904   0.669   0.73    0.771   0.00125 0.849   0.827   0.929
 0.885  ]
2025-02-26T07:34:54.845084+0300 | INFO | Training epoch #34 on client #0
2025-02-26T07:34:54.847515+0300 | DEBUG | Saving model to flat file storage. Save #34
2025-02-26T07:34:55.051681+0300 | INFO | [34,     0] loss: 0.016
2025-02-26T07:35:05.568557+0300 | INFO | [34,   100] loss: 1.643
2025-02-26T07:35:14.496465+0300 | INFO | [34,   200] loss: 1.636
2025-02-26T07:35:24.574472+0300 | INFO | [34,   300] loss: 1.623
2025-02-26T07:35:34.034986+0300 | INFO | [34,   400] loss: 1.601
2025-02-26T07:35:43.064507+0300 | INFO | [34,   500] loss: 1.625
2025-02-26T07:35:54.773013+0300 | INFO | [34,   600] loss: 1.616
2025-02-26T07:36:04.485951+0300 | INFO | [34,   700] loss: 1.637
2025-02-26T07:36:13.764634+0300 | INFO | [34,   800] loss: 1.623
2025-02-26T07:36:22.921509+0300 | INFO | [34,   900] loss: 1.614
2025-02-26T07:36:31.942130+0300 | INFO | [34,  1000] loss: 1.632
2025-02-26T07:36:43.618248+0300 | INFO | [34,  1100] loss: 1.601
2025-02-26T07:36:54.848165+0300 | INFO | [34,  1200] loss: 1.600
2025-02-26T07:37:05.344878+0300 | INFO | [34,  1300] loss: 1.622
2025-02-26T07:37:15.715849+0300 | INFO | [34,  1400] loss: 1.634
2025-02-26T07:37:25.319150+0300 | INFO | [34,  1500] loss: 1.619
2025-02-26T07:37:34.453305+0300 | INFO | [34,  1600] loss: 1.620
2025-02-26T07:37:46.014201+0300 | INFO | [34,  1700] loss: 1.625
2025-02-26T07:37:55.181934+0300 | INFO | [34,  1800] loss: 1.616
2025-02-26T07:38:04.943873+0300 | INFO | [34,  1900] loss: 1.633
2025-02-26T07:38:17.827192+0300 | INFO | [34,  2000] loss: 1.638
2025-02-26T07:38:27.372928+0300 | INFO | [34,  2100] loss: 1.634
2025-02-26T07:38:36.551149+0300 | INFO | [34,  2200] loss: 1.630
2025-02-26T07:38:45.476221+0300 | INFO | [34,  2300] loss: 1.625
2025-02-26T07:38:54.498179+0300 | INFO | [34,  2400] loss: 1.614
2025-02-26T07:39:04.212555+0300 | INFO | [34,  2500] loss: 1.626
2025-02-26T07:39:13.297264+0300 | INFO | [34,  2600] loss: 1.637
2025-02-26T07:39:22.999130+0300 | INFO | [34,  2700] loss: 1.614
2025-02-26T07:39:32.209590+0300 | INFO | [34,  2800] loss: 1.634
2025-02-26T07:39:41.921175+0300 | INFO | [34,  2900] loss: 1.620
2025-02-26T07:39:53.990662+0300 | INFO | [34,  3000] loss: 1.637
2025-02-26T07:40:03.412458+0300 | INFO | [34,  3100] loss: 1.621
2025-02-26T07:40:13.012131+0300 | INFO | [34,  3200] loss: 1.632
2025-02-26T07:40:24.550175+0300 | INFO | [34,  3300] loss: 1.625
2025-02-26T07:40:37.880352+0300 | INFO | [34,  3400] loss: 1.618
2025-02-26T07:40:49.485398+0300 | INFO | [34,  3500] loss: 1.646
2025-02-26T07:40:58.999860+0300 | INFO | [34,  3600] loss: 1.630
2025-02-26T07:41:09.354270+0300 | INFO | [34,  3700] loss: 1.608
2025-02-26T07:41:19.157235+0300 | INFO | [34,  3800] loss: 1.611
2025-02-26T07:41:28.896666+0300 | INFO | [34,  3900] loss: 1.609
2025-02-26T07:41:38.822832+0300 | INFO | [34,  4000] loss: 1.639
2025-02-26T07:41:48.959190+0300 | INFO | [34,  4100] loss: 1.616
2025-02-26T07:41:58.664313+0300 | INFO | [34,  4200] loss: 1.622
2025-02-26T07:42:07.913880+0300 | INFO | [34,  4300] loss: 1.630
2025-02-26T07:42:17.358925+0300 | INFO | [34,  4400] loss: 1.633
2025-02-26T07:42:28.628207+0300 | INFO | [34,  4500] loss: 1.618
2025-02-26T07:42:37.874226+0300 | INFO | [34,  4600] loss: 1.627
2025-02-26T07:42:48.214131+0300 | INFO | [34,  4700] loss: 1.636
2025-02-26T07:42:59.026953+0300 | INFO | [34,  4800] loss: 1.645
2025-02-26T07:43:09.561704+0300 | INFO | [34,  4900] loss: 1.622
2025-02-26T07:43:20.339834+0300 | DEBUG | Saving model to flat file storage. Save #34
2025-02-26T07:43:20.363339+0300 | INFO | Averaging client parameters
2025-02-26T07:43:20.373334+0300 | INFO | Updating parameters on client #0
2025-02-26T07:43:36.239716+0300 | DEBUG | Test set: Accuracy: 7498/10000 (75%)
2025-02-26T07:43:36.240719+0300 | DEBUG | Test set: Loss: 1.7107515335083008
2025-02-26T07:43:36.340852+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.85      0.80      1000
           1       0.88      0.92      0.90      1000
           2       0.69      0.69      0.69      1000
           3       0.52      0.72      0.61      1200
           4       0.69      0.82      0.75      1000
           5       0.00      0.00      0.00       800
           6       0.87      0.80      0.83      1000
           7       0.75      0.85      0.80      1000
           8       0.88      0.89      0.88      1000
           9       0.88      0.81      0.85      1000

    accuracy                           0.75     10000
   macro avg       0.69      0.74      0.71     10000
weighted avg       0.70      0.75      0.72     10000

2025-02-26T07:43:36.342858+0300 | DEBUG | Confusion Matrix:
[[855  15  25  11  16   0   5  14  43  16]
 [ 12 921   0   3   1   0   4   4  12  43]
 [ 65   2 690  63 101   2  30  28   8  11]
 [ 46   6  83 867  74   0  38  60  12  14]
 [ 12   1  43  59 816   0  11  53   4   1]
 [ 11   2  67 539  61   0  17  93   7   3]
 [ 15   4  52  61  49   0 797  12   7   3]
 [ 20   0  23  41  49   0   6 852   2   7]
 [ 45  27  10  10   6   0   2   5 885  10]
 [ 57  67   7   7   9   0   3  13  22 815]]
2025-02-26T07:43:36.344864+0300 | DEBUG | Class precision: [0.7513181  0.88133971 0.69       0.52197471 0.69035533 0.
 0.87294633 0.75132275 0.88323353 0.88299025]
2025-02-26T07:43:36.345976+0300 | DEBUG | Class recall: [0.855  0.921  0.69   0.7225 0.816  0.     0.797  0.852  0.885  0.815 ]
2025-02-26T07:43:36.403962+0300 | INFO | Training epoch #35 on client #0
2025-02-26T07:43:36.405179+0300 | DEBUG | Saving model to flat file storage. Save #35
2025-02-26T07:43:36.617154+0300 | INFO | [35,     0] loss: 0.017
2025-02-26T07:43:48.253536+0300 | INFO | [35,   100] loss: 1.626
2025-02-26T07:43:58.815251+0300 | INFO | [35,   200] loss: 1.619
2025-02-26T07:44:09.851682+0300 | INFO | [35,   300] loss: 1.615
2025-02-26T07:44:21.852538+0300 | INFO | [35,   400] loss: 1.637
2025-02-26T07:44:31.862771+0300 | INFO | [35,   500] loss: 1.629
2025-02-26T07:44:42.545137+0300 | INFO | [35,   600] loss: 1.616
2025-02-26T07:44:53.850312+0300 | INFO | [35,   700] loss: 1.601
2025-02-26T07:45:04.239757+0300 | INFO | [35,   800] loss: 1.607
2025-02-26T07:45:15.356483+0300 | INFO | [35,   900] loss: 1.633
2025-02-26T07:45:26.290330+0300 | INFO | [35,  1000] loss: 1.622
2025-02-26T07:45:36.453132+0300 | INFO | [35,  1100] loss: 1.625
2025-02-26T07:45:47.534437+0300 | INFO | [35,  1200] loss: 1.609
2025-02-26T07:45:58.599665+0300 | INFO | [35,  1300] loss: 1.591
2025-02-26T07:46:07.755225+0300 | INFO | [35,  1400] loss: 1.613
2025-02-26T07:46:16.709800+0300 | INFO | [35,  1500] loss: 1.613
2025-02-26T07:46:26.014703+0300 | INFO | [35,  1600] loss: 1.624
2025-02-26T07:46:35.428521+0300 | INFO | [35,  1700] loss: 1.620
2025-02-26T07:46:44.844472+0300 | INFO | [35,  1800] loss: 1.625
2025-02-26T07:46:53.932337+0300 | INFO | [35,  1900] loss: 1.624
2025-02-26T07:47:03.374374+0300 | INFO | [35,  2000] loss: 1.647
2025-02-26T07:47:13.137087+0300 | INFO | [35,  2100] loss: 1.637
2025-02-26T07:47:22.912703+0300 | INFO | [35,  2200] loss: 1.627
2025-02-26T07:47:32.069437+0300 | INFO | [35,  2300] loss: 1.622
2025-02-26T07:47:41.476149+0300 | INFO | [35,  2400] loss: 1.614
2025-02-26T07:47:50.890454+0300 | INFO | [35,  2500] loss: 1.637
2025-02-26T07:48:00.102360+0300 | INFO | [35,  2600] loss: 1.630
2025-02-26T07:48:10.119183+0300 | INFO | [35,  2700] loss: 1.626
2025-02-26T07:48:20.518858+0300 | INFO | [35,  2800] loss: 1.619
2025-02-26T07:48:33.694095+0300 | INFO | [35,  2900] loss: 1.630
2025-02-26T07:48:43.482264+0300 | INFO | [35,  3000] loss: 1.621
2025-02-26T07:48:53.721621+0300 | INFO | [35,  3100] loss: 1.605
2025-02-26T07:49:02.939565+0300 | INFO | [35,  3200] loss: 1.629
2025-02-26T07:49:12.607601+0300 | INFO | [35,  3300] loss: 1.622
2025-02-26T07:49:21.617525+0300 | INFO | [35,  3400] loss: 1.626
2025-02-26T07:49:31.435898+0300 | INFO | [35,  3500] loss: 1.638
2025-02-26T07:49:40.522817+0300 | INFO | [35,  3600] loss: 1.632
2025-02-26T07:49:49.830224+0300 | INFO | [35,  3700] loss: 1.611
2025-02-26T07:49:58.912234+0300 | INFO | [35,  3800] loss: 1.620
2025-02-26T07:50:09.098364+0300 | INFO | [35,  3900] loss: 1.617
2025-02-26T07:50:19.333101+0300 | INFO | [35,  4000] loss: 1.625
2025-02-26T07:50:29.308399+0300 | INFO | [35,  4100] loss: 1.643
2025-02-26T07:50:38.764502+0300 | INFO | [35,  4200] loss: 1.630
2025-02-26T07:50:48.427771+0300 | INFO | [35,  4300] loss: 1.633
2025-02-26T07:50:58.939097+0300 | INFO | [35,  4400] loss: 1.615
2025-02-26T07:51:11.151940+0300 | INFO | [35,  4500] loss: 1.636
2025-02-26T07:51:20.377490+0300 | INFO | [35,  4600] loss: 1.630
2025-02-26T07:51:29.590260+0300 | INFO | [35,  4700] loss: 1.613
2025-02-26T07:51:38.648005+0300 | INFO | [35,  4800] loss: 1.607
2025-02-26T07:51:47.657768+0300 | INFO | [35,  4900] loss: 1.636
2025-02-26T07:51:56.760699+0300 | DEBUG | Saving model to flat file storage. Save #35
2025-02-26T07:51:56.785185+0300 | INFO | Averaging client parameters
2025-02-26T07:51:56.793197+0300 | INFO | Updating parameters on client #0
2025-02-26T07:52:12.927518+0300 | DEBUG | Test set: Accuracy: 7581/10000 (76%)
2025-02-26T07:52:12.928987+0300 | DEBUG | Test set: Loss: 1.7026574611663818
2025-02-26T07:52:13.038190+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1000
           1       0.86      0.94      0.90      1000
           2       0.74      0.64      0.69      1000
           3       0.52      0.77      0.62      1200
           4       0.74      0.79      0.77      1000
           5       0.48      0.01      0.03       800
           6       0.81      0.88      0.84      1000
           7       0.76      0.83      0.79      1000
           8       0.89      0.88      0.88      1000
           9       0.92      0.81      0.86      1000

    accuracy                           0.76     10000
   macro avg       0.75      0.74      0.72     10000
weighted avg       0.75      0.76      0.73     10000

2025-02-26T07:52:13.040327+0300 | DEBUG | Confusion Matrix:
[[856  21  23  16   9   0   6  15  41  13]
 [  7 943   0   7   1   0   6   1  12  23]
 [ 81   5 642  80  87   2  62  29   7   5]
 [ 19   8  54 929  64   4  51  51  11   9]
 [ 16   1  27  76 793   0  31  51   5   0]
 [  8   3  73 529  46  12  23  97   6   3]
 [  7   5  21  60  15   0 877   8   4   3]
 [ 19   3  19  50  51   2  11 835   4   6]
 [ 48  25   9  15   4   2   5   5 881   6]
 [ 31  87   5  20   0   3  11   9  21 813]]
2025-02-26T07:52:13.041334+0300 | DEBUG | Class precision: [0.78388278 0.8564941  0.73539519 0.52132435 0.7411215  0.48
 0.80978763 0.75840145 0.88810484 0.92281498]
2025-02-26T07:52:13.042335+0300 | DEBUG | Class recall: [0.856      0.943      0.642      0.77416667 0.793      0.015
 0.877      0.835      0.881      0.813     ]
2025-02-26T07:52:13.091033+0300 | INFO | Training epoch #36 on client #0
2025-02-26T07:52:13.092035+0300 | DEBUG | Saving model to flat file storage. Save #36
2025-02-26T07:52:13.290639+0300 | INFO | [36,     0] loss: 0.017
2025-02-26T07:52:23.483753+0300 | INFO | [36,   100] loss: 1.608
2025-02-26T07:52:32.606742+0300 | INFO | [36,   200] loss: 1.624
2025-02-26T07:52:41.910770+0300 | INFO | [36,   300] loss: 1.608
2025-02-26T07:52:50.610199+0300 | INFO | [36,   400] loss: 1.603
2025-02-26T07:53:01.022457+0300 | INFO | [36,   500] loss: 1.617
2025-02-26T07:53:11.586483+0300 | INFO | [36,   600] loss: 1.605
2025-02-26T07:53:20.721536+0300 | INFO | [36,   700] loss: 1.622
2025-02-26T07:53:29.733771+0300 | INFO | [36,   800] loss: 1.628
2025-02-26T07:53:40.376164+0300 | INFO | [36,   900] loss: 1.605
2025-02-26T07:53:49.326371+0300 | INFO | [36,  1000] loss: 1.628
2025-02-26T07:53:58.558924+0300 | INFO | [36,  1100] loss: 1.617
2025-02-26T07:54:07.733700+0300 | INFO | [36,  1200] loss: 1.613
2025-02-26T07:54:18.895883+0300 | INFO | [36,  1300] loss: 1.613
2025-02-26T07:54:28.058084+0300 | INFO | [36,  1400] loss: 1.618
2025-02-26T07:54:37.265222+0300 | INFO | [36,  1500] loss: 1.622
2025-02-26T07:54:46.706139+0300 | INFO | [36,  1600] loss: 1.631
2025-02-26T07:54:57.178488+0300 | INFO | [36,  1700] loss: 1.600
2025-02-26T07:55:07.087234+0300 | INFO | [36,  1800] loss: 1.625
2025-02-26T07:55:16.569510+0300 | INFO | [36,  1900] loss: 1.618
2025-02-26T07:55:25.846650+0300 | INFO | [36,  2000] loss: 1.613
2025-02-26T07:55:34.742724+0300 | INFO | [36,  2100] loss: 1.614
2025-02-26T07:55:44.694761+0300 | INFO | [36,  2200] loss: 1.626
2025-02-26T07:55:54.649862+0300 | INFO | [36,  2300] loss: 1.605
2025-02-26T07:56:04.357781+0300 | INFO | [36,  2400] loss: 1.610
2025-02-26T07:56:18.908040+0300 | INFO | [36,  2500] loss: 1.623
2025-02-26T07:56:29.120514+0300 | INFO | [36,  2600] loss: 1.602
2025-02-26T07:56:39.776591+0300 | INFO | [36,  2700] loss: 1.618
2025-02-26T07:56:48.688251+0300 | INFO | [36,  2800] loss: 1.630
2025-02-26T07:56:58.395481+0300 | INFO | [36,  2900] loss: 1.610
2025-02-26T07:57:08.280965+0300 | INFO | [36,  3000] loss: 1.615
2025-02-26T07:57:17.501468+0300 | INFO | [36,  3100] loss: 1.600
2025-02-26T07:57:26.840012+0300 | INFO | [36,  3200] loss: 1.618
2025-02-26T07:57:35.963640+0300 | INFO | [36,  3300] loss: 1.633
2025-02-26T07:57:45.501552+0300 | INFO | [36,  3400] loss: 1.611
2025-02-26T07:57:54.722647+0300 | INFO | [36,  3500] loss: 1.622
2025-02-26T07:58:04.402881+0300 | INFO | [36,  3600] loss: 1.596
2025-02-26T07:58:13.977402+0300 | INFO | [36,  3700] loss: 1.626
2025-02-26T07:58:25.311016+0300 | INFO | [36,  3800] loss: 1.625
2025-02-26T07:58:34.814589+0300 | INFO | [36,  3900] loss: 1.601
2025-02-26T07:58:44.983461+0300 | INFO | [36,  4000] loss: 1.621
2025-02-26T07:58:56.461976+0300 | INFO | [36,  4100] loss: 1.610
2025-02-26T07:59:05.870338+0300 | INFO | [36,  4200] loss: 1.631
2025-02-26T07:59:15.007101+0300 | INFO | [36,  4300] loss: 1.632
2025-02-26T07:59:24.019450+0300 | INFO | [36,  4400] loss: 1.617
2025-02-26T07:59:33.022125+0300 | INFO | [36,  4500] loss: 1.610
2025-02-26T07:59:42.116377+0300 | INFO | [36,  4600] loss: 1.646
2025-02-26T07:59:53.762351+0300 | INFO | [36,  4700] loss: 1.621
2025-02-26T08:00:02.769903+0300 | INFO | [36,  4800] loss: 1.618
2025-02-26T08:00:12.900650+0300 | INFO | [36,  4900] loss: 1.614
2025-02-26T08:00:23.509677+0300 | DEBUG | Saving model to flat file storage. Save #36
2025-02-26T08:00:23.528203+0300 | INFO | Averaging client parameters
2025-02-26T08:00:23.533706+0300 | INFO | Updating parameters on client #0
2025-02-26T08:00:37.835852+0300 | DEBUG | Test set: Accuracy: 7715/10000 (77%)
2025-02-26T08:00:37.835852+0300 | DEBUG | Test set: Loss: 1.6881868839263916
2025-02-26T08:00:37.937378+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1000
           1       0.89      0.90      0.89      1000
           2       0.71      0.68      0.69      1000
           3       0.67      0.53      0.59      1200
           4       0.74      0.79      0.77      1000
           5       0.49      0.56      0.52       800
           6       0.83      0.85      0.84      1000
           7       0.80      0.83      0.81      1000
           8       0.90      0.88      0.89      1000
           9       0.84      0.89      0.87      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000

2025-02-26T08:00:37.940386+0300 | DEBUG | Confusion Matrix:
[[814  18  53  12  17   6   8  10  33  29]
 [  6 900   4   3   1   3   6   0  12  65]
 [ 49   2 680  24  93  66  47  24   8   7]
 [ 20   7  71 632  53 282  51  47  13  24]
 [ 12   4  42  37 793  30  25  46   8   3]
 [  7   2  49 167  35 446  23  57   7   7]
 [  7   6  30  41  33  12 852  12   6   1]
 [ 16   5  16  18  40  55   4 828   3  15]
 [ 49  23  12   5   3   5   4   4 880  15]
 [ 19  46   7   3   1   5  10   6  13 890]]
2025-02-26T08:00:37.941388+0300 | DEBUG | Class precision: [0.81481481 0.88845015 0.70539419 0.67091295 0.74181478 0.49010989
 0.82718447 0.80077369 0.89521872 0.84280303]
2025-02-26T08:00:37.941388+0300 | DEBUG | Class recall: [0.814      0.9        0.68       0.52666667 0.793      0.5575
 0.852      0.828      0.88       0.89      ]
2025-02-26T08:00:37.990689+0300 | INFO | Training epoch #37 on client #0
2025-02-26T08:00:37.993678+0300 | DEBUG | Saving model to flat file storage. Save #37
2025-02-26T08:00:38.234014+0300 | INFO | [37,     0] loss: 0.017
2025-02-26T08:00:47.327584+0300 | INFO | [37,   100] loss: 1.625
2025-02-26T08:00:57.293766+0300 | INFO | [37,   200] loss: 1.627
2025-02-26T08:01:06.561054+0300 | INFO | [37,   300] loss: 1.596
2025-02-26T08:01:16.279360+0300 | INFO | [37,   400] loss: 1.624
2025-02-26T08:01:25.383695+0300 | INFO | [37,   500] loss: 1.613
2025-02-26T08:01:35.131010+0300 | INFO | [37,   600] loss: 1.598
2025-02-26T08:01:45.129397+0300 | INFO | [37,   700] loss: 1.613
2025-02-26T08:01:54.735224+0300 | INFO | [37,   800] loss: 1.603
2025-02-26T08:02:04.349545+0300 | INFO | [37,   900] loss: 1.604
2025-02-26T08:02:13.740424+0300 | INFO | [37,  1000] loss: 1.609
2025-02-26T08:02:22.930036+0300 | INFO | [37,  1100] loss: 1.607
2025-02-26T08:02:31.858096+0300 | INFO | [37,  1200] loss: 1.607
2025-02-26T08:02:43.413580+0300 | INFO | [37,  1300] loss: 1.608
2025-02-26T08:02:52.554325+0300 | INFO | [37,  1400] loss: 1.603
2025-02-26T08:03:02.294582+0300 | INFO | [37,  1500] loss: 1.588
2025-02-26T08:03:11.734941+0300 | INFO | [37,  1600] loss: 1.595
2025-02-26T08:03:20.979063+0300 | INFO | [37,  1700] loss: 1.611
2025-02-26T08:03:29.992937+0300 | INFO | [37,  1800] loss: 1.602
2025-02-26T08:03:39.167232+0300 | INFO | [37,  1900] loss: 1.597
2025-02-26T08:03:48.210365+0300 | INFO | [37,  2000] loss: 1.595
2025-02-26T08:03:59.907066+0300 | INFO | [37,  2100] loss: 1.621
2025-02-26T08:04:09.914304+0300 | INFO | [37,  2200] loss: 1.615
2025-02-26T08:04:25.291412+0300 | INFO | [37,  2300] loss: 1.623
2025-02-26T08:04:34.292313+0300 | INFO | [37,  2400] loss: 1.621
2025-02-26T08:04:43.733862+0300 | INFO | [37,  2500] loss: 1.627
2025-02-26T08:04:52.623115+0300 | INFO | [37,  2600] loss: 1.609
2025-02-26T08:05:02.033874+0300 | INFO | [37,  2700] loss: 1.609
2025-02-26T08:05:11.872703+0300 | INFO | [37,  2800] loss: 1.607
2025-02-26T08:05:20.844737+0300 | INFO | [37,  2900] loss: 1.588
2025-02-26T08:05:30.302161+0300 | INFO | [37,  3000] loss: 1.617
2025-02-26T08:05:39.374113+0300 | INFO | [37,  3100] loss: 1.587
2025-02-26T08:05:48.247732+0300 | INFO | [37,  3200] loss: 1.600
2025-02-26T08:05:57.954584+0300 | INFO | [37,  3300] loss: 1.608
2025-02-26T08:06:07.341859+0300 | INFO | [37,  3400] loss: 1.596
2025-02-26T08:06:16.658847+0300 | INFO | [37,  3500] loss: 1.595
2025-02-26T08:06:28.143485+0300 | INFO | [37,  3600] loss: 1.586
2025-02-26T08:06:37.954469+0300 | INFO | [37,  3700] loss: 1.610
2025-02-26T08:06:49.153307+0300 | INFO | [37,  3800] loss: 1.606
2025-02-26T08:07:00.045024+0300 | INFO | [37,  3900] loss: 1.611
2025-02-26T08:07:10.453865+0300 | INFO | [37,  4000] loss: 1.618
2025-02-26T08:07:20.970464+0300 | INFO | [37,  4100] loss: 1.609
2025-02-26T08:07:30.109558+0300 | INFO | [37,  4200] loss: 1.605
2025-02-26T08:07:39.368718+0300 | INFO | [37,  4300] loss: 1.596
2025-02-26T08:07:48.306347+0300 | INFO | [37,  4400] loss: 1.606
2025-02-26T08:07:57.465589+0300 | INFO | [37,  4500] loss: 1.619
2025-02-26T08:08:08.692966+0300 | INFO | [37,  4600] loss: 1.609
2025-02-26T08:08:18.225045+0300 | INFO | [37,  4700] loss: 1.610
2025-02-26T08:08:28.925073+0300 | INFO | [37,  4800] loss: 1.612
2025-02-26T08:08:38.142989+0300 | INFO | [37,  4900] loss: 1.594
2025-02-26T08:08:47.189586+0300 | DEBUG | Saving model to flat file storage. Save #37
2025-02-26T08:08:47.213697+0300 | INFO | Averaging client parameters
2025-02-26T08:08:47.223706+0300 | INFO | Updating parameters on client #0
2025-02-26T08:09:01.847639+0300 | DEBUG | Test set: Accuracy: 7695/10000 (77%)
2025-02-26T08:09:01.850640+0300 | DEBUG | Test set: Loss: 1.6913129091262817
2025-02-26T08:09:01.946762+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.81      0.82      1000
           1       0.93      0.88      0.90      1000
           2       0.68      0.71      0.69      1000
           3       0.65      0.56      0.60      1200
           4       0.76      0.76      0.76      1000
           5       0.49      0.54      0.51       800
           6       0.86      0.80      0.83      1000
           7       0.75      0.86      0.80      1000
           8       0.88      0.88      0.88      1000
           9       0.85      0.89      0.87      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000

2025-02-26T08:09:01.948756+0300 | DEBUG | Confusion Matrix:
[[808  12  37  12  21   3   8  17  48  34]
 [  5 877   2   0   0   2   9   7  18  80]
 [ 50   1 713  29  72  57  36  28   8   6]
 [ 14   4  87 674  53 261  34  50  12  11]
 [  6   2  57  42 758  25  17  88   5   0]
 [  6   3  60 195  26 431  10  58   7   4]
 [  7   3  59  40  26  37 800  22   4   2]
 [  8   0  16  22  26  54   4 862   3   5]
 [ 39  13  18   6  11   3   7   2 880  21]
 [ 19  27   5  10   3   8   9  15  12 892]]
2025-02-26T08:09:01.950758+0300 | DEBUG | Class precision: [0.83991684 0.93099788 0.67647059 0.65436893 0.76104418 0.4892168
 0.85653105 0.75021758 0.88264794 0.84549763]
2025-02-26T08:09:01.952755+0300 | DEBUG | Class recall: [0.808      0.877      0.713      0.56166667 0.758      0.53875
 0.8        0.862      0.88       0.892     ]
2025-02-26T08:09:02.002610+0300 | INFO | Training epoch #38 on client #0
2025-02-26T08:09:02.004610+0300 | DEBUG | Saving model to flat file storage. Save #38
2025-02-26T08:09:02.199842+0300 | INFO | [38,     0] loss: 0.017
2025-02-26T08:09:12.551042+0300 | INFO | [38,   100] loss: 1.597
2025-02-26T08:09:21.754751+0300 | INFO | [38,   200] loss: 1.587
2025-02-26T08:09:30.829170+0300 | INFO | [38,   300] loss: 1.574
2025-02-26T08:09:40.060987+0300 | INFO | [38,   400] loss: 1.589
2025-02-26T08:09:50.684688+0300 | INFO | [38,   500] loss: 1.603
2025-02-26T08:10:01.112472+0300 | INFO | [38,   600] loss: 1.607
2025-02-26T08:10:10.528972+0300 | INFO | [38,   700] loss: 1.592
2025-02-26T08:10:20.031578+0300 | INFO | [38,   800] loss: 1.596
2025-02-26T08:10:29.191470+0300 | INFO | [38,   900] loss: 1.613
2025-02-26T08:10:38.373892+0300 | INFO | [38,  1000] loss: 1.587
2025-02-26T08:10:47.840399+0300 | INFO | [38,  1100] loss: 1.592
2025-02-26T08:10:57.125131+0300 | INFO | [38,  1200] loss: 1.584
2025-02-26T08:11:07.548104+0300 | INFO | [38,  1300] loss: 1.596
2025-02-26T08:11:16.966971+0300 | INFO | [38,  1400] loss: 1.597
2025-02-26T08:11:27.349782+0300 | INFO | [38,  1500] loss: 1.597
2025-02-26T08:11:37.269481+0300 | INFO | [38,  1600] loss: 1.597
2025-02-26T08:11:46.478361+0300 | INFO | [38,  1700] loss: 1.616
2025-02-26T08:11:57.967617+0300 | INFO | [38,  1800] loss: 1.601
2025-02-26T08:12:12.694225+0300 | INFO | [38,  1900] loss: 1.616
2025-02-26T08:12:22.170722+0300 | INFO | [38,  2000] loss: 1.594
2025-02-26T08:12:31.281849+0300 | INFO | [38,  2100] loss: 1.605
2025-02-26T08:12:40.666163+0300 | INFO | [38,  2200] loss: 1.585
2025-02-26T08:12:50.098219+0300 | INFO | [38,  2300] loss: 1.612
2025-02-26T08:13:00.140235+0300 | INFO | [38,  2400] loss: 1.613
2025-02-26T08:13:09.926294+0300 | INFO | [38,  2500] loss: 1.590
2025-02-26T08:13:19.060343+0300 | INFO | [38,  2600] loss: 1.586
2025-02-26T08:13:28.109376+0300 | INFO | [38,  2700] loss: 1.603
2025-02-26T08:13:37.210647+0300 | INFO | [38,  2800] loss: 1.608
2025-02-26T08:13:46.589696+0300 | INFO | [38,  2900] loss: 1.609
2025-02-26T08:13:55.903901+0300 | INFO | [38,  3000] loss: 1.598
2025-02-26T08:14:08.358744+0300 | INFO | [38,  3100] loss: 1.593
2025-02-26T08:14:18.621500+0300 | INFO | [38,  3200] loss: 1.607
2025-02-26T08:14:28.244322+0300 | INFO | [38,  3300] loss: 1.605
2025-02-26T08:14:37.309422+0300 | INFO | [38,  3400] loss: 1.598
2025-02-26T08:14:46.547570+0300 | INFO | [38,  3500] loss: 1.598
2025-02-26T08:14:55.639286+0300 | INFO | [38,  3600] loss: 1.613
2025-02-26T08:15:05.650861+0300 | INFO | [38,  3700] loss: 1.611
2025-02-26T08:15:16.404700+0300 | INFO | [38,  3800] loss: 1.599
2025-02-26T08:15:26.009667+0300 | INFO | [38,  3900] loss: 1.593
2025-02-26T08:15:36.724670+0300 | INFO | [38,  4000] loss: 1.602
2025-02-26T08:15:48.018213+0300 | INFO | [38,  4100] loss: 1.622
2025-02-26T08:15:57.550576+0300 | INFO | [38,  4200] loss: 1.615
2025-02-26T08:16:07.288837+0300 | INFO | [38,  4300] loss: 1.612
2025-02-26T08:16:16.834485+0300 | INFO | [38,  4400] loss: 1.596
2025-02-26T08:16:26.429146+0300 | INFO | [38,  4500] loss: 1.609
2025-02-26T08:16:35.923474+0300 | INFO | [38,  4600] loss: 1.615
2025-02-26T08:16:45.077333+0300 | INFO | [38,  4700] loss: 1.600
2025-02-26T08:16:54.726629+0300 | INFO | [38,  4800] loss: 1.614
2025-02-26T08:17:03.752671+0300 | INFO | [38,  4900] loss: 1.605
2025-02-26T08:17:13.010879+0300 | DEBUG | Saving model to flat file storage. Save #38
2025-02-26T08:17:13.033840+0300 | INFO | Averaging client parameters
2025-02-26T08:17:13.040931+0300 | INFO | Updating parameters on client #0
2025-02-26T08:17:27.731608+0300 | DEBUG | Test set: Accuracy: 7726/10000 (77%)
2025-02-26T08:17:27.732607+0300 | DEBUG | Test set: Loss: 1.6878995895385742
2025-02-26T08:17:27.845459+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.89      0.90      0.89      1000
           2       0.74      0.66      0.70      1000
           3       0.62      0.60      0.61      1200
           4       0.73      0.80      0.76      1000
           5       0.52      0.52      0.52       800
           6       0.81      0.86      0.84      1000
           7       0.85      0.81      0.83      1000
           8       0.91      0.85      0.88      1000
           9       0.83      0.90      0.86      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000

2025-02-26T08:17:27.849455+0300 | DEBUG | Confusion Matrix:
[[821  20  35  13  19   3   8  11  33  37]
 [  7 896   2   5   1   1   3   3  18  64]
 [ 54   2 662  43  95  51  59  19   5  10]
 [ 15   3  56 715  65 232  57  32   7  18]
 [  7   1  32  46 802  27  37  34   7   7]
 [  7   2  39 225  47 417  18  34   5   6]
 [ 14   2  32  48  19  14 862   4   1   4]
 [ 13   4  14  30  44  60   9 809   2  15]
 [ 51  30  16  12   6   3   7   3 846  26]
 [ 24  45   4   7   4   1   3   8   8 896]]
2025-02-26T08:17:27.851458+0300 | DEBUG | Class precision: [0.81046397 0.89154229 0.74215247 0.625      0.7277677  0.51545117
 0.81091251 0.84535005 0.90772532 0.82733149]
2025-02-26T08:17:27.853449+0300 | DEBUG | Class recall: [0.821      0.896      0.662      0.59583333 0.802      0.52125
 0.862      0.809      0.846      0.896     ]
2025-02-26T08:17:27.911586+0300 | INFO | Training epoch #39 on client #0
2025-02-26T08:17:27.913591+0300 | DEBUG | Saving model to flat file storage. Save #39
2025-02-26T08:17:28.152371+0300 | INFO | [39,     0] loss: 0.015
2025-02-26T08:17:37.442315+0300 | INFO | [39,   100] loss: 1.596
2025-02-26T08:17:46.971084+0300 | INFO | [39,   200] loss: 1.588
2025-02-26T08:17:58.303463+0300 | INFO | [39,   300] loss: 1.591
2025-02-26T08:18:07.713073+0300 | INFO | [39,   400] loss: 1.582
2025-02-26T08:18:16.996365+0300 | INFO | [39,   500] loss: 1.600
2025-02-26T08:18:25.873285+0300 | INFO | [39,   600] loss: 1.581
2025-02-26T08:18:36.810072+0300 | INFO | [39,   700] loss: 1.594
2025-02-26T08:18:48.276270+0300 | INFO | [39,   800] loss: 1.569
2025-02-26T08:18:57.027730+0300 | INFO | [39,   900] loss: 1.577
2025-02-26T08:19:06.796525+0300 | INFO | [39,  1000] loss: 1.607
2025-02-26T08:19:15.888470+0300 | INFO | [39,  1100] loss: 1.593
2025-02-26T08:19:26.213985+0300 | INFO | [39,  1200] loss: 1.618
2025-02-26T08:19:36.651141+0300 | INFO | [39,  1300] loss: 1.604
2025-02-26T08:19:45.774603+0300 | INFO | [39,  1400] loss: 1.582
2025-02-26T08:19:54.986862+0300 | INFO | [39,  1500] loss: 1.598
2025-02-26T08:20:09.335440+0300 | INFO | [39,  1600] loss: 1.605
2025-02-26T08:20:18.433676+0300 | INFO | [39,  1700] loss: 1.596
2025-02-26T08:20:27.857204+0300 | INFO | [39,  1800] loss: 1.602
2025-02-26T08:20:36.813693+0300 | INFO | [39,  1900] loss: 1.598
2025-02-26T08:20:45.916822+0300 | INFO | [39,  2000] loss: 1.591
2025-02-26T08:20:55.406116+0300 | INFO | [39,  2100] loss: 1.591
2025-02-26T08:21:05.090123+0300 | INFO | [39,  2200] loss: 1.586
2025-02-26T08:21:15.748964+0300 | INFO | [39,  2300] loss: 1.590
2025-02-26T08:21:26.037896+0300 | INFO | [39,  2400] loss: 1.583
2025-02-26T08:21:37.007723+0300 | INFO | [39,  2500] loss: 1.625
2025-02-26T08:21:46.894886+0300 | INFO | [39,  2600] loss: 1.578
2025-02-26T08:21:56.063699+0300 | INFO | [39,  2700] loss: 1.597
2025-02-26T08:22:05.374764+0300 | INFO | [39,  2800] loss: 1.578
2025-02-26T08:22:14.545174+0300 | INFO | [39,  2900] loss: 1.591
2025-02-26T08:22:24.038194+0300 | INFO | [39,  3000] loss: 1.609
2025-02-26T08:22:33.274759+0300 | INFO | [39,  3100] loss: 1.605
2025-02-26T08:22:42.230027+0300 | INFO | [39,  3200] loss: 1.618
2025-02-26T08:22:51.432205+0300 | INFO | [39,  3300] loss: 1.592
2025-02-26T08:23:02.028923+0300 | INFO | [39,  3400] loss: 1.604
2025-02-26T08:23:12.262711+0300 | INFO | [39,  3500] loss: 1.594
2025-02-26T08:23:21.743889+0300 | INFO | [39,  3600] loss: 1.593
2025-02-26T08:23:30.658690+0300 | INFO | [39,  3700] loss: 1.621
2025-02-26T08:23:40.109220+0300 | INFO | [39,  3800] loss: 1.592
2025-02-26T08:23:49.003505+0300 | INFO | [39,  3900] loss: 1.583
2025-02-26T08:23:58.206036+0300 | INFO | [39,  4000] loss: 1.580
2025-02-26T08:24:07.977509+0300 | INFO | [39,  4100] loss: 1.594
2025-02-26T08:24:17.198542+0300 | INFO | [39,  4200] loss: 1.595
2025-02-26T08:24:26.399466+0300 | INFO | [39,  4300] loss: 1.601
2025-02-26T08:24:39.730733+0300 | INFO | [39,  4400] loss: 1.613
2025-02-26T08:24:48.752515+0300 | INFO | [39,  4500] loss: 1.606
2025-02-26T08:24:57.692248+0300 | INFO | [39,  4600] loss: 1.595
2025-02-26T08:25:06.944852+0300 | INFO | [39,  4700] loss: 1.599
2025-02-26T08:25:16.485354+0300 | INFO | [39,  4800] loss: 1.582
2025-02-26T08:25:25.453923+0300 | INFO | [39,  4900] loss: 1.584
2025-02-26T08:25:34.641709+0300 | DEBUG | Saving model to flat file storage. Save #39
2025-02-26T08:25:34.663710+0300 | INFO | Averaging client parameters
2025-02-26T08:25:34.677152+0300 | INFO | Updating parameters on client #0
2025-02-26T08:25:49.240177+0300 | DEBUG | Test set: Accuracy: 7720/10000 (77%)
2025-02-26T08:25:49.240177+0300 | DEBUG | Test set: Loss: 1.68800687789917
2025-02-26T08:25:49.325840+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.79      0.80      1000
           1       0.92      0.87      0.89      1000
           2       0.75      0.66      0.70      1000
           3       0.65      0.54      0.59      1200
           4       0.75      0.79      0.77      1000
           5       0.50      0.61      0.55       800
           6       0.85      0.85      0.85      1000
           7       0.82      0.83      0.82      1000
           8       0.84      0.90      0.87      1000
           9       0.84      0.89      0.87      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000

2025-02-26T08:25:49.329489+0300 | DEBUG | Confusion Matrix:
[[786  16  44  11  21   5   8  10  67  32]
 [ 13 870   0   2   1   0   8   2  31  73]
 [ 51   2 660  40 101  61  44  20  13   8]
 [ 16   4  52 649  52 314  46  33  16  18]
 [ 10   4  27  47 790  27  23  55  11   6]
 [  7   0  33 167  32 491  12  44  11   3]
 [  8   4  35  43  25  15 853   9   6   2]
 [ 11   4  15  23  33  64   6 829   7   8]
 [ 38   9  10  12   4   3   5   2 902  15]
 [ 27  34   7   8   1   4   2  11  16 890]]
2025-02-26T08:25:49.330501+0300 | DEBUG | Class precision: [0.81282316 0.9186906  0.74745187 0.64770459 0.74528302 0.49898374
 0.84707051 0.81674877 0.83518519 0.8436019 ]
2025-02-26T08:25:49.331510+0300 | DEBUG | Class recall: [0.786      0.87       0.66       0.54083333 0.79       0.61375
 0.853      0.829      0.902      0.89      ]
2025-02-26T08:25:49.383763+0300 | INFO | Training epoch #40 on client #0
2025-02-26T08:25:49.387753+0300 | DEBUG | Saving model to flat file storage. Save #40
2025-02-26T08:25:49.621226+0300 | INFO | [40,     0] loss: 0.017
2025-02-26T08:26:00.364701+0300 | INFO | [40,   100] loss: 1.589
2025-02-26T08:26:10.010084+0300 | INFO | [40,   200] loss: 1.611
2025-02-26T08:26:19.137913+0300 | INFO | [40,   300] loss: 1.589
2025-02-26T08:26:30.775528+0300 | INFO | [40,   400] loss: 1.592
2025-02-26T08:26:39.951005+0300 | INFO | [40,   500] loss: 1.581
2025-02-26T08:26:50.243706+0300 | INFO | [40,   600] loss: 1.583
2025-02-26T08:27:00.801214+0300 | INFO | [40,   700] loss: 1.576
2025-02-26T08:27:10.104003+0300 | INFO | [40,   800] loss: 1.596
2025-02-26T08:27:19.897482+0300 | INFO | [40,   900] loss: 1.569
2025-02-26T08:27:29.019054+0300 | INFO | [40,  1000] loss: 1.577
2025-02-26T08:27:38.371781+0300 | INFO | [40,  1100] loss: 1.595
2025-02-26T08:27:48.362003+0300 | INFO | [40,  1200] loss: 1.589
2025-02-26T08:28:03.569272+0300 | INFO | [40,  1300] loss: 1.588
2025-02-26T08:28:14.265595+0300 | INFO | [40,  1400] loss: 1.607
2025-02-26T08:28:23.232332+0300 | INFO | [40,  1500] loss: 1.595
2025-02-26T08:28:32.369231+0300 | INFO | [40,  1600] loss: 1.596
2025-02-26T08:28:43.682320+0300 | INFO | [40,  1700] loss: 1.594
2025-02-26T08:28:53.689085+0300 | INFO | [40,  1800] loss: 1.573
2025-02-26T08:29:03.049807+0300 | INFO | [40,  1900] loss: 1.577
2025-02-26T08:29:12.955600+0300 | INFO | [40,  2000] loss: 1.598
2025-02-26T08:29:21.989443+0300 | INFO | [40,  2100] loss: 1.591
2025-02-26T08:29:31.742681+0300 | INFO | [40,  2200] loss: 1.583
2025-02-26T08:29:43.360479+0300 | INFO | [40,  2300] loss: 1.573
2025-02-26T08:29:52.960827+0300 | INFO | [40,  2400] loss: 1.588
2025-02-26T08:30:02.433920+0300 | INFO | [40,  2500] loss: 1.589
2025-02-26T08:30:12.249206+0300 | INFO | [40,  2600] loss: 1.584
2025-02-26T08:30:21.598024+0300 | INFO | [40,  2700] loss: 1.595
2025-02-26T08:30:30.958756+0300 | INFO | [40,  2800] loss: 1.589
2025-02-26T08:30:40.104357+0300 | INFO | [40,  2900] loss: 1.607
2025-02-26T08:30:49.529902+0300 | INFO | [40,  3000] loss: 1.595
2025-02-26T08:30:58.831854+0300 | INFO | [40,  3100] loss: 1.577
2025-02-26T08:31:08.392558+0300 | INFO | [40,  3200] loss: 1.587
2025-02-26T08:31:17.321233+0300 | INFO | [40,  3300] loss: 1.602
2025-02-26T08:31:26.421806+0300 | INFO | [40,  3400] loss: 1.617
2025-02-26T08:31:35.987332+0300 | INFO | [40,  3500] loss: 1.599
2025-02-26T08:31:45.005888+0300 | INFO | [40,  3600] loss: 1.588
2025-02-26T08:31:54.963189+0300 | INFO | [40,  3700] loss: 1.593
2025-02-26T08:32:04.319832+0300 | INFO | [40,  3800] loss: 1.571
2025-02-26T08:32:13.858807+0300 | INFO | [40,  3900] loss: 1.575
2025-02-26T08:32:23.275987+0300 | INFO | [40,  4000] loss: 1.594
2025-02-26T08:32:32.441517+0300 | INFO | [40,  4100] loss: 1.599
2025-02-26T08:32:44.653815+0300 | INFO | [40,  4200] loss: 1.596
2025-02-26T08:32:53.748423+0300 | INFO | [40,  4300] loss: 1.584
2025-02-26T08:33:02.858121+0300 | INFO | [40,  4400] loss: 1.579
2025-02-26T08:33:12.117747+0300 | INFO | [40,  4500] loss: 1.611
2025-02-26T08:33:21.315497+0300 | INFO | [40,  4600] loss: 1.576
2025-02-26T08:33:30.563646+0300 | INFO | [40,  4700] loss: 1.595
2025-02-26T08:33:42.007403+0300 | INFO | [40,  4800] loss: 1.590
2025-02-26T08:33:51.099717+0300 | INFO | [40,  4900] loss: 1.590
2025-02-26T08:34:01.189906+0300 | DEBUG | Saving model to flat file storage. Save #40
2025-02-26T08:34:01.214074+0300 | INFO | Averaging client parameters
2025-02-26T08:34:01.226517+0300 | INFO | Updating parameters on client #0
2025-02-26T08:34:16.272569+0300 | DEBUG | Test set: Accuracy: 7712/10000 (77%)
2025-02-26T08:34:16.274581+0300 | DEBUG | Test set: Loss: 1.6890369653701782
2025-02-26T08:34:16.365737+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.88      0.77      1000
           1       0.85      0.94      0.89      1000
           2       0.74      0.64      0.69      1000
           3       0.65      0.60      0.63      1200
           4       0.77      0.75      0.76      1000
           5       0.60      0.49      0.54       800
           6       0.78      0.89      0.83      1000
           7       0.83      0.81      0.82      1000
           8       0.87      0.88      0.87      1000
           9       0.91      0.81      0.86      1000

    accuracy                           0.77     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.77      0.77     10000

2025-02-26T08:34:16.368090+0300 | DEBUG | Confusion Matrix:
[[876  22  24   8   8   4   8   1  40   9]
 [ 14 942   1   1   1   2   4   1  11  23]
 [110   5 641  41  63  39  74  15   6   6]
 [ 44   6  58 726  63 167  65  33  17  21]
 [ 30   3  53  44 749   6  43  58  10   4]
 [ 20   5  38 226  37 394  27  44   8   1]
 [ 17   8  22  36  15   5 885   5   7   0]
 [ 40   7  15  30  35  38  13 810   4   8]
 [ 64  25  10   6   4   4   6   1 875   5]
 [ 55  85   4   3   2   2   7   3  25 814]]
2025-02-26T08:34:16.370089+0300 | DEBUG | Class precision: [0.68976378 0.85018051 0.74018476 0.64763604 0.76663255 0.59606657
 0.78180212 0.83419156 0.87238285 0.91358025]
2025-02-26T08:34:16.372092+0300 | DEBUG | Class recall: [0.876  0.942  0.641  0.605  0.749  0.4925 0.885  0.81   0.875  0.814 ]
2025-02-26T08:34:16.413292+0300 | INFO | Training epoch #41 on client #0
2025-02-26T08:34:16.415481+0300 | DEBUG | Saving model to flat file storage. Save #41
2025-02-26T08:34:16.619001+0300 | INFO | [41,     0] loss: 0.016
2025-02-26T08:34:26.666091+0300 | INFO | [41,   100] loss: 1.579
2025-02-26T08:34:38.605228+0300 | INFO | [41,   200] loss: 1.569
2025-02-26T08:34:48.980577+0300 | INFO | [41,   300] loss: 1.592
2025-02-26T08:34:58.068950+0300 | INFO | [41,   400] loss: 1.599
2025-02-26T08:35:08.310005+0300 | INFO | [41,   500] loss: 1.579
2025-02-26T08:35:19.142509+0300 | INFO | [41,   600] loss: 1.575
2025-02-26T08:35:28.354553+0300 | INFO | [41,   700] loss: 1.598
2025-02-26T08:35:38.390220+0300 | INFO | [41,   800] loss: 1.588
2025-02-26T08:35:50.098516+0300 | INFO | [41,   900] loss: 1.594
2025-02-26T08:35:59.268892+0300 | INFO | [41,  1000] loss: 1.585
2025-02-26T08:36:12.939390+0300 | INFO | [41,  1100] loss: 1.583
2025-02-26T08:36:23.319230+0300 | INFO | [41,  1200] loss: 1.579
2025-02-26T08:36:32.614941+0300 | INFO | [41,  1300] loss: 1.579
2025-02-26T08:36:43.446619+0300 | INFO | [41,  1400] loss: 1.583
2025-02-26T08:36:54.135063+0300 | INFO | [41,  1500] loss: 1.577
2025-02-26T08:37:03.940780+0300 | INFO | [41,  1600] loss: 1.595
2025-02-26T08:37:14.465520+0300 | INFO | [41,  1700] loss: 1.583
2025-02-26T08:37:23.755014+0300 | INFO | [41,  1800] loss: 1.579
2025-02-26T08:37:33.106989+0300 | INFO | [41,  1900] loss: 1.586
2025-02-26T08:37:42.137055+0300 | INFO | [41,  2000] loss: 1.586
2025-02-26T08:37:52.642496+0300 | INFO | [41,  2100] loss: 1.577
2025-02-26T08:38:02.562861+0300 | INFO | [41,  2200] loss: 1.567
2025-02-26T08:38:13.397490+0300 | INFO | [41,  2300] loss: 1.582
2025-02-26T08:38:23.111730+0300 | INFO | [41,  2400] loss: 1.577
2025-02-26T08:38:35.867626+0300 | INFO | [41,  2500] loss: 1.591
2025-02-26T08:38:45.405556+0300 | INFO | [41,  2600] loss: 1.575
2025-02-26T08:38:54.797330+0300 | INFO | [41,  2700] loss: 1.582
2025-02-26T08:39:05.975515+0300 | INFO | [41,  2800] loss: 1.589
2025-02-26T08:39:16.055868+0300 | INFO | [41,  2900] loss: 1.596
2025-02-26T08:39:26.477497+0300 | INFO | [41,  3000] loss: 1.590
2025-02-26T08:39:35.643120+0300 | INFO | [41,  3100] loss: 1.592
2025-02-26T08:39:44.681703+0300 | INFO | [41,  3200] loss: 1.614
2025-02-26T08:39:54.000114+0300 | INFO | [41,  3300] loss: 1.585
2025-02-26T08:40:03.189962+0300 | INFO | [41,  3400] loss: 1.591
2025-02-26T08:40:12.830070+0300 | INFO | [41,  3500] loss: 1.590
2025-02-26T08:40:22.387026+0300 | INFO | [41,  3600] loss: 1.595
2025-02-26T08:40:31.777185+0300 | INFO | [41,  3700] loss: 1.597
2025-02-26T08:40:43.689644+0300 | INFO | [41,  3800] loss: 1.594
2025-02-26T08:40:52.839433+0300 | INFO | [41,  3900] loss: 1.596
2025-02-26T08:41:01.999023+0300 | INFO | [41,  4000] loss: 1.603
2025-02-26T08:41:11.852868+0300 | INFO | [41,  4100] loss: 1.592
2025-02-26T08:41:21.858072+0300 | INFO | [41,  4200] loss: 1.565
2025-02-26T08:41:31.255756+0300 | INFO | [41,  4300] loss: 1.593
2025-02-26T08:41:41.179025+0300 | INFO | [41,  4400] loss: 1.617
2025-02-26T08:41:50.478839+0300 | INFO | [41,  4500] loss: 1.615
2025-02-26T08:42:00.067284+0300 | INFO | [41,  4600] loss: 1.594
2025-02-26T08:42:09.307023+0300 | INFO | [41,  4700] loss: 1.590
2025-02-26T08:42:19.222838+0300 | INFO | [41,  4800] loss: 1.582
2025-02-26T08:42:28.278901+0300 | INFO | [41,  4900] loss: 1.590
2025-02-26T08:42:37.538342+0300 | DEBUG | Saving model to flat file storage. Save #41
2025-02-26T08:42:37.563359+0300 | INFO | Averaging client parameters
2025-02-26T08:42:37.574081+0300 | INFO | Updating parameters on client #0
2025-02-26T08:42:52.513606+0300 | DEBUG | Test set: Accuracy: 7769/10000 (78%)
2025-02-26T08:42:52.515601+0300 | DEBUG | Test set: Loss: 1.683501124382019
2025-02-26T08:42:52.625425+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.82      0.81      1000
           1       0.86      0.93      0.89      1000
           2       0.71      0.69      0.70      1000
           3       0.67      0.57      0.62      1200
           4       0.70      0.85      0.77      1000
           5       0.55      0.58      0.57       800
           6       0.85      0.81      0.83      1000
           7       0.87      0.79      0.83      1000
           8       0.90      0.86      0.88      1000
           9       0.85      0.87      0.86      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.77     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T08:42:52.627439+0300 | DEBUG | Confusion Matrix:
[[823  26  34  13  26   2   5   5  38  28]
 [ 12 926   1   3   1   1   7   1   6  42]
 [ 69   4 690  21  98  46  41  15  10   6]
 [ 17   5  75 688  74 233  38  32  11  27]
 [  9   4  34  30 846  22  23  27   3   2]
 [ 12   6  50 166  45 462  14  30   7   8]
 [ 13   3  49  52  44  15 810   5   8   1]
 [ 14   2  28  37  58  48   6 793   2  12]
 [ 51  36   9  10   4   3   4   2 857  24]
 [ 18  67   5   9   5   2   6   4  10 874]]
2025-02-26T08:42:52.628437+0300 | DEBUG | Class precision: [0.79287091 0.85820204 0.70769231 0.6686103  0.70441299 0.55395683
 0.8490566  0.86761488 0.90021008 0.85351562]
2025-02-26T08:42:52.631449+0300 | DEBUG | Class recall: [0.823      0.926      0.69       0.57333333 0.846      0.5775
 0.81       0.793      0.857      0.874     ]
2025-02-26T08:42:52.679017+0300 | INFO | Training epoch #42 on client #0
2025-02-26T08:42:52.680027+0300 | DEBUG | Saving model to flat file storage. Save #42
2025-02-26T08:42:52.903308+0300 | INFO | [42,     0] loss: 0.015
2025-02-26T08:43:03.053256+0300 | INFO | [42,   100] loss: 1.600
2025-02-26T08:43:12.614363+0300 | INFO | [42,   200] loss: 1.571
2025-02-26T08:43:22.148704+0300 | INFO | [42,   300] loss: 1.570
2025-02-26T08:43:32.303095+0300 | INFO | [42,   400] loss: 1.578
2025-02-26T08:43:41.855690+0300 | INFO | [42,   500] loss: 1.585
2025-02-26T08:43:50.784732+0300 | INFO | [42,   600] loss: 1.581
2025-02-26T08:44:01.648923+0300 | INFO | [42,   700] loss: 1.573
2025-02-26T08:44:15.973540+0300 | INFO | [42,   800] loss: 1.571
2025-02-26T08:44:27.330641+0300 | INFO | [42,   900] loss: 1.592
2025-02-26T08:44:36.572720+0300 | INFO | [42,  1000] loss: 1.584
2025-02-26T08:44:45.858249+0300 | INFO | [42,  1100] loss: 1.576
2025-02-26T08:44:54.937369+0300 | INFO | [42,  1200] loss: 1.595
2025-02-26T08:45:04.139850+0300 | INFO | [42,  1300] loss: 1.558
2025-02-26T08:45:13.797104+0300 | INFO | [42,  1400] loss: 1.606
2025-02-26T08:45:23.113269+0300 | INFO | [42,  1500] loss: 1.587
2025-02-26T08:45:32.375432+0300 | INFO | [42,  1600] loss: 1.578
2025-02-26T08:45:41.388117+0300 | INFO | [42,  1700] loss: 1.590
2025-02-26T08:45:51.100999+0300 | INFO | [42,  1800] loss: 1.599
2025-02-26T08:46:01.261365+0300 | INFO | [42,  1900] loss: 1.590
2025-02-26T08:46:12.451498+0300 | INFO | [42,  2000] loss: 1.592
2025-02-26T08:46:23.188147+0300 | INFO | [42,  2100] loss: 1.574
2025-02-26T08:46:34.446918+0300 | INFO | [42,  2200] loss: 1.591
2025-02-26T08:46:47.103951+0300 | INFO | [42,  2300] loss: 1.578
2025-02-26T08:46:59.461953+0300 | INFO | [42,  2400] loss: 1.577
2025-02-26T08:47:12.284479+0300 | INFO | [42,  2500] loss: 1.583
2025-02-26T08:47:24.080745+0300 | INFO | [42,  2600] loss: 1.575
2025-02-26T08:47:36.073370+0300 | INFO | [42,  2700] loss: 1.600
2025-02-26T08:47:47.750838+0300 | INFO | [42,  2800] loss: 1.575
2025-02-26T08:48:00.704202+0300 | INFO | [42,  2900] loss: 1.577
2025-02-26T08:48:12.476111+0300 | INFO | [42,  3000] loss: 1.595
2025-02-26T08:48:25.516855+0300 | INFO | [42,  3100] loss: 1.592
2025-02-26T08:48:37.434505+0300 | INFO | [42,  3200] loss: 1.580
2025-02-26T08:48:48.459023+0300 | INFO | [42,  3300] loss: 1.573
2025-02-26T08:49:01.703364+0300 | INFO | [42,  3400] loss: 1.591
2025-02-26T08:49:13.714105+0300 | INFO | [42,  3500] loss: 1.587
2025-02-26T08:49:27.350417+0300 | INFO | [42,  3600] loss: 1.598
2025-02-26T08:49:38.029794+0300 | INFO | [42,  3700] loss: 1.598
2025-02-26T08:49:48.413898+0300 | INFO | [42,  3800] loss: 1.579
2025-02-26T08:49:58.619451+0300 | INFO | [42,  3900] loss: 1.586
2025-02-26T08:50:08.321703+0300 | INFO | [42,  4000] loss: 1.585
2025-02-26T08:50:19.334620+0300 | INFO | [42,  4100] loss: 1.580
2025-02-26T08:50:30.794350+0300 | INFO | [42,  4200] loss: 1.587
2025-02-26T08:50:41.482911+0300 | INFO | [42,  4300] loss: 1.580
2025-02-26T08:50:52.514892+0300 | INFO | [42,  4400] loss: 1.563
2025-02-26T08:51:03.382209+0300 | INFO | [42,  4500] loss: 1.599
2025-02-26T08:51:15.382412+0300 | INFO | [42,  4600] loss: 1.577
2025-02-26T08:51:25.514484+0300 | INFO | [42,  4700] loss: 1.592
2025-02-26T08:51:36.348401+0300 | INFO | [42,  4800] loss: 1.591
2025-02-26T08:51:45.498493+0300 | INFO | [42,  4900] loss: 1.582
2025-02-26T08:51:54.597853+0300 | DEBUG | Saving model to flat file storage. Save #42
2025-02-26T08:51:54.616733+0300 | INFO | Averaging client parameters
2025-02-26T08:51:54.625154+0300 | INFO | Updating parameters on client #0
2025-02-26T08:52:09.399791+0300 | DEBUG | Test set: Accuracy: 7784/10000 (78%)
2025-02-26T08:52:09.401996+0300 | DEBUG | Test set: Loss: 1.680510401725769
2025-02-26T08:52:09.507100+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.81      1000
           1       0.90      0.89      0.90      1000
           2       0.73      0.68      0.70      1000
           3       0.68      0.54      0.60      1200
           4       0.76      0.79      0.77      1000
           5       0.49      0.66      0.57       800
           6       0.81      0.87      0.84      1000
           7       0.87      0.80      0.83      1000
           8       0.87      0.90      0.89      1000
           9       0.86      0.87      0.86      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T08:52:09.509542+0300 | DEBUG | Confusion Matrix:
[[816  19  48  10  16   5   6   6  51  23]
 [ 10 894   1   2   1   3   7   3  19  60]
 [ 52   2 675  31  83  65  64  15   8   5]
 [ 17   5  57 646  52 322  51  18  13  19]
 [ 11   2  38  42 786  38  36  36   8   3]
 [ 10   2  34 143  33 530  13  23   5   7]
 [  9   0  35  36  21  20 866   2   7   4]
 [ 19   4  14  24  42  80   6 798   4   9]
 [ 35  17  11   8   1   5   3   4 900  16]
 [ 27  45   6   5   3   3  13   8  17 873]]
2025-02-26T08:52:09.511556+0300 | DEBUG | Class precision: [0.8111332  0.9030303  0.73449402 0.68215417 0.75722543 0.49486461
 0.81314554 0.87404162 0.87209302 0.85672228]
2025-02-26T08:52:09.513848+0300 | DEBUG | Class recall: [0.816      0.894      0.675      0.53833333 0.786      0.6625
 0.866      0.798      0.9        0.873     ]
2025-02-26T08:52:09.576165+0300 | INFO | Training epoch #43 on client #0
2025-02-26T08:52:09.580177+0300 | DEBUG | Saving model to flat file storage. Save #43
2025-02-26T08:52:09.831656+0300 | INFO | [43,     0] loss: 0.016
2025-02-26T08:52:19.965240+0300 | INFO | [43,   100] loss: 1.579
2025-02-26T08:52:29.530489+0300 | INFO | [43,   200] loss: 1.570
2025-02-26T08:52:41.252718+0300 | INFO | [43,   300] loss: 1.566
2025-02-26T08:52:50.312557+0300 | INFO | [43,   400] loss: 1.584
2025-02-26T08:53:00.707267+0300 | INFO | [43,   500] loss: 1.567
2025-02-26T08:53:15.454343+0300 | INFO | [43,   600] loss: 1.589
2025-02-26T08:53:26.007854+0300 | INFO | [43,   700] loss: 1.563
2025-02-26T08:53:35.919519+0300 | INFO | [43,   800] loss: 1.582
2025-02-26T08:53:45.457711+0300 | INFO | [43,   900] loss: 1.581
2025-02-26T08:53:54.529145+0300 | INFO | [43,  1000] loss: 1.581
2025-02-26T08:54:03.792460+0300 | INFO | [43,  1100] loss: 1.566
2025-02-26T08:54:13.012612+0300 | INFO | [43,  1200] loss: 1.578
2025-02-26T08:54:22.242092+0300 | INFO | [43,  1300] loss: 1.596
2025-02-26T08:54:31.381573+0300 | INFO | [43,  1400] loss: 1.578
2025-02-26T08:54:40.761695+0300 | INFO | [43,  1500] loss: 1.579
2025-02-26T08:54:49.958929+0300 | INFO | [43,  1600] loss: 1.555
2025-02-26T08:54:59.113806+0300 | INFO | [43,  1700] loss: 1.576
2025-02-26T08:55:08.141627+0300 | INFO | [43,  1800] loss: 1.593
2025-02-26T08:55:17.303183+0300 | INFO | [43,  1900] loss: 1.580
2025-02-26T08:55:26.656096+0300 | INFO | [43,  2000] loss: 1.585
2025-02-26T08:55:35.825071+0300 | INFO | [43,  2100] loss: 1.573
2025-02-26T08:55:45.681542+0300 | INFO | [43,  2200] loss: 1.569
2025-02-26T08:55:56.192287+0300 | INFO | [43,  2300] loss: 1.594
2025-02-26T08:56:05.875671+0300 | INFO | [43,  2400] loss: 1.576
2025-02-26T08:56:17.191207+0300 | INFO | [43,  2500] loss: 1.570
2025-02-26T08:56:27.009178+0300 | INFO | [43,  2600] loss: 1.585
2025-02-26T08:56:36.199248+0300 | INFO | [43,  2700] loss: 1.585
2025-02-26T08:56:45.706953+0300 | INFO | [43,  2800] loss: 1.576
2025-02-26T08:56:54.635123+0300 | INFO | [43,  2900] loss: 1.569
2025-02-26T08:57:03.674742+0300 | INFO | [43,  3000] loss: 1.591
2025-02-26T08:57:13.020464+0300 | INFO | [43,  3100] loss: 1.560
2025-02-26T08:57:22.612522+0300 | INFO | [43,  3200] loss: 1.584
2025-02-26T08:57:31.871668+0300 | INFO | [43,  3300] loss: 1.597
2025-02-26T08:57:41.038696+0300 | INFO | [43,  3400] loss: 1.578
2025-02-26T08:57:50.235429+0300 | INFO | [43,  3500] loss: 1.581
2025-02-26T08:57:59.590683+0300 | INFO | [43,  3600] loss: 1.589
2025-02-26T08:58:08.956847+0300 | INFO | [43,  3700] loss: 1.589
2025-02-26T08:58:19.129739+0300 | INFO | [43,  3800] loss: 1.569
2025-02-26T08:58:29.040734+0300 | INFO | [43,  3900] loss: 1.590
2025-02-26T08:58:38.557610+0300 | INFO | [43,  4000] loss: 1.608
2025-02-26T08:58:50.154693+0300 | INFO | [43,  4100] loss: 1.595
2025-02-26T08:58:59.284187+0300 | INFO | [43,  4200] loss: 1.578
2025-02-26T08:59:09.649709+0300 | INFO | [43,  4300] loss: 1.580
2025-02-26T08:59:19.059572+0300 | INFO | [43,  4400] loss: 1.591
2025-02-26T08:59:28.706431+0300 | INFO | [43,  4500] loss: 1.593
2025-02-26T08:59:37.921726+0300 | INFO | [43,  4600] loss: 1.594
2025-02-26T08:59:48.602676+0300 | INFO | [43,  4700] loss: 1.573
2025-02-26T09:00:00.022630+0300 | INFO | [43,  4800] loss: 1.578
2025-02-26T09:00:11.643498+0300 | INFO | [43,  4900] loss: 1.568
2025-02-26T09:00:20.785256+0300 | DEBUG | Saving model to flat file storage. Save #43
2025-02-26T09:00:20.807654+0300 | INFO | Averaging client parameters
2025-02-26T09:00:20.817544+0300 | INFO | Updating parameters on client #0
2025-02-26T09:00:35.417147+0300 | DEBUG | Test set: Accuracy: 7773/10000 (78%)
2025-02-26T09:00:35.419153+0300 | DEBUG | Test set: Loss: 1.6818058490753174
2025-02-26T09:00:35.543236+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.86      0.80      1000
           1       0.85      0.94      0.89      1000
           2       0.79      0.61      0.69      1000
           3       0.65      0.61      0.63      1200
           4       0.78      0.77      0.77      1000
           5       0.58      0.57      0.57       800
           6       0.78      0.87      0.82      1000
           7       0.84      0.82      0.83      1000
           8       0.89      0.86      0.87      1000
           9       0.86      0.86      0.86      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.77     10000
weighted avg       0.78      0.78      0.77     10000

2025-02-26T09:00:35.544237+0300 | DEBUG | Confusion Matrix:
[[861  22  23  15  14   4   2   5  32  22]
 [  8 938   0   0   0   0   4   2  12  36]
 [ 85   6 612  53  62  52  89  26   5  10]
 [ 27  10  36 731  62 201  58  33  19  23]
 [ 13   2  40  49 768  19  57  38  11   3]
 [ 11   6  30 189  32 456  21  38  10   7]
 [ 20   6  20  43  11  11 872   7   7   3]
 [ 26   7   9  37  35  44   7 819   4  12]
 [ 66  30   5   7   1   3   3   2 860  23]
 [ 36  74   3   5   1   3   4   7  11 856]]
2025-02-26T09:00:35.546253+0300 | DEBUG | Class precision: [0.74674761 0.85195277 0.78663239 0.64747564 0.77890467 0.57503153
 0.78066249 0.83828045 0.88568486 0.86030151]
2025-02-26T09:00:35.549272+0300 | DEBUG | Class recall: [0.861      0.938      0.612      0.60916667 0.768      0.57
 0.872      0.819      0.86       0.856     ]
2025-02-26T09:00:35.557234+0300 | INFO | Training epoch #44 on client #0
2025-02-26T09:00:35.557234+0300 | DEBUG | Saving model to flat file storage. Save #44
2025-02-26T09:00:35.815534+0300 | INFO | [44,     0] loss: 0.018
2025-02-26T09:00:45.364579+0300 | INFO | [44,   100] loss: 1.580
2025-02-26T09:00:56.681955+0300 | INFO | [44,   200] loss: 1.568
2025-02-26T09:01:11.032860+0300 | INFO | [44,   300] loss: 1.572
2025-02-26T09:01:20.238867+0300 | INFO | [44,   400] loss: 1.571
2025-02-26T09:01:29.554783+0300 | INFO | [44,   500] loss: 1.579
2025-02-26T09:01:38.688504+0300 | INFO | [44,   600] loss: 1.561
2025-02-26T09:01:48.722663+0300 | INFO | [44,   700] loss: 1.574
2025-02-26T09:01:58.064165+0300 | INFO | [44,   800] loss: 1.570
2025-02-26T09:02:07.991590+0300 | INFO | [44,   900] loss: 1.574
2025-02-26T09:02:17.477302+0300 | INFO | [44,  1000] loss: 1.583
2025-02-26T09:02:26.729410+0300 | INFO | [44,  1100] loss: 1.582
2025-02-26T09:02:37.338562+0300 | INFO | [44,  1200] loss: 1.587
2025-02-26T09:02:46.654853+0300 | INFO | [44,  1300] loss: 1.576
2025-02-26T09:02:55.751518+0300 | INFO | [44,  1400] loss: 1.567
2025-02-26T09:03:05.714254+0300 | INFO | [44,  1500] loss: 1.586
2025-02-26T09:03:15.163629+0300 | INFO | [44,  1600] loss: 1.565
2025-02-26T09:03:24.461142+0300 | INFO | [44,  1700] loss: 1.580
2025-02-26T09:03:33.513210+0300 | INFO | [44,  1800] loss: 1.576
2025-02-26T09:03:42.989375+0300 | INFO | [44,  1900] loss: 1.570
2025-02-26T09:03:52.458375+0300 | INFO | [44,  2000] loss: 1.555
2025-02-26T09:04:01.705588+0300 | INFO | [44,  2100] loss: 1.569
2025-02-26T09:04:11.193748+0300 | INFO | [44,  2200] loss: 1.579
2025-02-26T09:04:22.724462+0300 | INFO | [44,  2300] loss: 1.570
2025-02-26T09:04:32.027707+0300 | INFO | [44,  2400] loss: 1.585
2025-02-26T09:04:41.169214+0300 | INFO | [44,  2500] loss: 1.582
2025-02-26T09:04:50.752603+0300 | INFO | [44,  2600] loss: 1.590
2025-02-26T09:05:00.084239+0300 | INFO | [44,  2700] loss: 1.587
2025-02-26T09:05:09.219426+0300 | INFO | [44,  2800] loss: 1.583
2025-02-26T09:05:18.678903+0300 | INFO | [44,  2900] loss: 1.571
2025-02-26T09:05:28.457192+0300 | INFO | [44,  3000] loss: 1.590
2025-02-26T09:05:38.413770+0300 | INFO | [44,  3100] loss: 1.576
2025-02-26T09:05:48.489140+0300 | INFO | [44,  3200] loss: 1.569
2025-02-26T09:05:59.995999+0300 | INFO | [44,  3300] loss: 1.583
2025-02-26T09:06:09.274084+0300 | INFO | [44,  3400] loss: 1.583
2025-02-26T09:06:18.683165+0300 | INFO | [44,  3500] loss: 1.576
2025-02-26T09:06:27.795906+0300 | INFO | [44,  3600] loss: 1.575
2025-02-26T09:06:37.034621+0300 | INFO | [44,  3700] loss: 1.597
2025-02-26T09:06:47.602873+0300 | INFO | [44,  3800] loss: 1.580
2025-02-26T09:06:57.014812+0300 | INFO | [44,  3900] loss: 1.572
2025-02-26T09:07:07.955009+0300 | INFO | [44,  4000] loss: 1.562
2025-02-26T09:07:18.565105+0300 | INFO | [44,  4100] loss: 1.590
2025-02-26T09:07:27.641113+0300 | INFO | [44,  4200] loss: 1.592
2025-02-26T09:07:37.786800+0300 | INFO | [44,  4300] loss: 1.576
2025-02-26T09:07:48.872426+0300 | INFO | [44,  4400] loss: 1.571
2025-02-26T09:07:59.592607+0300 | INFO | [44,  4500] loss: 1.580
2025-02-26T09:08:11.908700+0300 | INFO | [44,  4600] loss: 1.611
2025-02-26T09:08:22.164498+0300 | INFO | [44,  4700] loss: 1.580
2025-02-26T09:08:32.893385+0300 | INFO | [44,  4800] loss: 1.586
2025-02-26T09:08:42.114845+0300 | INFO | [44,  4900] loss: 1.580
2025-02-26T09:08:52.437077+0300 | DEBUG | Saving model to flat file storage. Save #44
2025-02-26T09:08:52.449241+0300 | INFO | Averaging client parameters
2025-02-26T09:08:52.453238+0300 | INFO | Updating parameters on client #0
2025-02-26T09:09:10.906304+0300 | DEBUG | Test set: Accuracy: 7834/10000 (78%)
2025-02-26T09:09:10.909302+0300 | DEBUG | Test set: Loss: 1.676790475845337
2025-02-26T09:09:11.009330+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.89      0.91      0.90      1000
           2       0.69      0.72      0.71      1000
           3       0.66      0.59      0.62      1200
           4       0.78      0.78      0.78      1000
           5       0.59      0.56      0.58       800
           6       0.78      0.89      0.83      1000
           7       0.88      0.79      0.83      1000
           8       0.89      0.88      0.88      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T09:09:11.012459+0300 | DEBUG | Confusion Matrix:
[[855  18  47  12  12   1   6   6  25  18]
 [ 10 906   0   2   2   3   7   3  12  55]
 [ 61   3 722  35  62  32  59  15   6   5]
 [ 25   4  90 709  50 193  66  23  23  17]
 [ 11   2  50  49 775  22  58  24   7   2]
 [  8   6  62 186  28 447  23  28   9   3]
 [  9   3  34  40  10   5 888   2   9   0]
 [ 22   3  26  31  46  47  14 793   6  12]
 [ 73  15   8   7   1   2   5   1 879   9]
 [ 37  57   7   6   2   2   6   6  17 860]]
2025-02-26T09:09:11.013469+0300 | DEBUG | Class precision: [0.76957696 0.89085546 0.69024857 0.65831012 0.78441296 0.5928382
 0.7844523  0.88013319 0.88519637 0.87665647]
2025-02-26T09:09:11.013469+0300 | DEBUG | Class recall: [0.855      0.906      0.722      0.59083333 0.775      0.55875
 0.888      0.793      0.879      0.86      ]
2025-02-26T09:09:11.060996+0300 | INFO | Training epoch #45 on client #0
2025-02-26T09:09:11.063007+0300 | DEBUG | Saving model to flat file storage. Save #45
2025-02-26T09:09:11.264945+0300 | INFO | [45,     0] loss: 0.016
2025-02-26T09:09:23.007613+0300 | INFO | [45,   100] loss: 1.573
2025-02-26T09:09:32.070684+0300 | INFO | [45,   200] loss: 1.575
2025-02-26T09:09:41.227202+0300 | INFO | [45,   300] loss: 1.571
2025-02-26T09:09:50.542465+0300 | INFO | [45,   400] loss: 1.570
2025-02-26T09:09:59.802820+0300 | INFO | [45,   500] loss: 1.574
2025-02-26T09:10:09.023569+0300 | INFO | [45,   600] loss: 1.574
2025-02-26T09:10:18.205679+0300 | INFO | [45,   700] loss: 1.568
2025-02-26T09:10:27.555498+0300 | INFO | [45,   800] loss: 1.572
2025-02-26T09:10:36.811203+0300 | INFO | [45,   900] loss: 1.572
2025-02-26T09:10:46.746106+0300 | INFO | [45,  1000] loss: 1.571
2025-02-26T09:10:56.046207+0300 | INFO | [45,  1100] loss: 1.582
2025-02-26T09:11:05.575699+0300 | INFO | [45,  1200] loss: 1.572
2025-02-26T09:11:14.688771+0300 | INFO | [45,  1300] loss: 1.575
2025-02-26T09:11:24.428565+0300 | INFO | [45,  1400] loss: 1.565
2025-02-26T09:11:33.959426+0300 | INFO | [45,  1500] loss: 1.584
2025-02-26T09:11:43.335470+0300 | INFO | [45,  1600] loss: 1.550
2025-02-26T09:11:53.303349+0300 | INFO | [45,  1700] loss: 1.575
2025-02-26T09:12:02.599168+0300 | INFO | [45,  1800] loss: 1.561
2025-02-26T09:12:13.632666+0300 | INFO | [45,  1900] loss: 1.581
2025-02-26T09:12:23.893626+0300 | INFO | [45,  2000] loss: 1.573
2025-02-26T09:12:33.116679+0300 | INFO | [45,  2100] loss: 1.576
2025-02-26T09:12:42.437121+0300 | INFO | [45,  2200] loss: 1.573
2025-02-26T09:12:51.414625+0300 | INFO | [45,  2300] loss: 1.572
2025-02-26T09:13:00.646970+0300 | INFO | [45,  2400] loss: 1.563
2025-02-26T09:13:10.522078+0300 | INFO | [45,  2500] loss: 1.585
2025-02-26T09:13:20.320058+0300 | INFO | [45,  2600] loss: 1.574
2025-02-26T09:13:30.283732+0300 | INFO | [45,  2700] loss: 1.578
2025-02-26T09:13:39.363764+0300 | INFO | [45,  2800] loss: 1.606
2025-02-26T09:13:51.073318+0300 | INFO | [45,  2900] loss: 1.580
2025-02-26T09:14:00.439208+0300 | INFO | [45,  3000] loss: 1.572
2025-02-26T09:14:09.623553+0300 | INFO | [45,  3100] loss: 1.566
2025-02-26T09:14:18.884762+0300 | INFO | [45,  3200] loss: 1.572
2025-02-26T09:14:28.050900+0300 | INFO | [45,  3300] loss: 1.580
2025-02-26T09:14:37.320985+0300 | INFO | [45,  3400] loss: 1.594
2025-02-26T09:14:47.034931+0300 | INFO | [45,  3500] loss: 1.595
2025-02-26T09:14:56.157085+0300 | INFO | [45,  3600] loss: 1.577
2025-02-26T09:15:05.242950+0300 | INFO | [45,  3700] loss: 1.565
2025-02-26T09:15:14.485034+0300 | INFO | [45,  3800] loss: 1.587
2025-02-26T09:15:23.664153+0300 | INFO | [45,  3900] loss: 1.585
2025-02-26T09:15:32.776261+0300 | INFO | [45,  4000] loss: 1.574
2025-02-26T09:15:42.194703+0300 | INFO | [45,  4100] loss: 1.583
2025-02-26T09:15:51.249742+0300 | INFO | [45,  4200] loss: 1.566
2025-02-26T09:16:01.355422+0300 | INFO | [45,  4300] loss: 1.584
2025-02-26T09:16:11.161242+0300 | INFO | [45,  4400] loss: 1.566
2025-02-26T09:16:20.827805+0300 | INFO | [45,  4500] loss: 1.592
2025-02-26T09:16:30.209013+0300 | INFO | [45,  4600] loss: 1.579
2025-02-26T09:16:41.637511+0300 | INFO | [45,  4700] loss: 1.582
2025-02-26T09:16:55.251716+0300 | INFO | [45,  4800] loss: 1.574
2025-02-26T09:17:04.638885+0300 | INFO | [45,  4900] loss: 1.565
2025-02-26T09:17:13.628513+0300 | DEBUG | Saving model to flat file storage. Save #45
2025-02-26T09:17:13.654202+0300 | INFO | Averaging client parameters
2025-02-26T09:17:13.663507+0300 | INFO | Updating parameters on client #0
2025-02-26T09:17:27.801306+0300 | DEBUG | Test set: Accuracy: 7752/10000 (78%)
2025-02-26T09:17:27.801306+0300 | DEBUG | Test set: Loss: 1.684088110923767
2025-02-26T09:17:27.873958+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.89      0.89      0.89      1000
           2       0.67      0.73      0.70      1000
           3       0.69      0.54      0.60      1200
           4       0.73      0.83      0.77      1000
           5       0.59      0.53      0.56       800
           6       0.83      0.83      0.83      1000
           7       0.81      0.83      0.82      1000
           8       0.91      0.84      0.88      1000
           9       0.82      0.90      0.85      1000

    accuracy                           0.78     10000
   macro avg       0.77      0.77      0.77     10000
weighted avg       0.77      0.78      0.77     10000

2025-02-26T09:17:27.875959+0300 | DEBUG | Confusion Matrix:
[[826  13  44  10  29   4   7  10  20  37]
 [ 14 890   1   2   0   0   8   1  13  71]
 [ 48   4 732  31  73  27  36  32   5  12]
 [ 17   7  91 648  90 202  55  46  16  28]
 [  7   3  55  23 829  18  22  33   5   5]
 [ 11   5  66 166  39 423  22  55   6   7]
 [ 12  10  57  33  31   9 831   7   8   2]
 [ 17   4  22  23  46  32   8 833   3  12]
 [ 75  25   9   8   1   2   3   4 844  29]
 [ 24  44   8   1   2   3   4  10   8 896]]
2025-02-26T09:17:27.876958+0300 | DEBUG | Class precision: [0.78591817 0.88557214 0.67465438 0.68571429 0.72719298 0.5875
 0.83433735 0.80795344 0.90948276 0.81528662]
2025-02-26T09:17:27.877958+0300 | DEBUG | Class recall: [0.826   0.89    0.732   0.54    0.829   0.52875 0.831   0.833   0.844
 0.896  ]
2025-02-26T09:17:27.952714+0300 | INFO | Training epoch #46 on client #0
2025-02-26T09:17:27.955718+0300 | DEBUG | Saving model to flat file storage. Save #46
2025-02-26T09:17:28.134313+0300 | INFO | [46,     0] loss: 0.016
2025-02-26T09:17:37.335474+0300 | INFO | [46,   100] loss: 1.559
2025-02-26T09:17:47.231931+0300 | INFO | [46,   200] loss: 1.557
2025-02-26T09:17:56.465178+0300 | INFO | [46,   300] loss: 1.572
2025-02-26T09:18:07.176402+0300 | INFO | [46,   400] loss: 1.595
2025-02-26T09:18:16.423690+0300 | INFO | [46,   500] loss: 1.578
2025-02-26T09:18:28.232347+0300 | INFO | [46,   600] loss: 1.559
2025-02-26T09:18:37.612520+0300 | INFO | [46,   700] loss: 1.568
2025-02-26T09:18:46.587159+0300 | INFO | [46,   800] loss: 1.586
2025-02-26T09:18:55.818855+0300 | INFO | [46,   900] loss: 1.566
2025-02-26T09:19:06.137566+0300 | INFO | [46,  1000] loss: 1.571
2025-02-26T09:19:15.535326+0300 | INFO | [46,  1100] loss: 1.570
2025-02-26T09:19:25.027741+0300 | INFO | [46,  1200] loss: 1.570
2025-02-26T09:19:34.205808+0300 | INFO | [46,  1300] loss: 1.554
2025-02-26T09:19:43.596053+0300 | INFO | [46,  1400] loss: 1.568
2025-02-26T09:19:52.613582+0300 | INFO | [46,  1500] loss: 1.570
2025-02-26T09:20:01.843253+0300 | INFO | [46,  1600] loss: 1.577
2025-02-26T09:20:11.045252+0300 | INFO | [46,  1700] loss: 1.578
2025-02-26T09:20:20.453610+0300 | INFO | [46,  1800] loss: 1.578
2025-02-26T09:20:29.818229+0300 | INFO | [46,  1900] loss: 1.562
2025-02-26T09:20:38.914861+0300 | INFO | [46,  2000] loss: 1.569
2025-02-26T09:20:48.858494+0300 | INFO | [46,  2100] loss: 1.555
2025-02-26T09:20:59.831209+0300 | INFO | [46,  2200] loss: 1.591
2025-02-26T09:21:08.968772+0300 | INFO | [46,  2300] loss: 1.571
2025-02-26T09:21:18.202805+0300 | INFO | [46,  2400] loss: 1.577
2025-02-26T09:21:27.345403+0300 | INFO | [46,  2500] loss: 1.561
2025-02-26T09:21:37.032557+0300 | INFO | [46,  2600] loss: 1.575
2025-02-26T09:21:48.972634+0300 | INFO | [46,  2700] loss: 1.582
2025-02-26T09:21:58.097533+0300 | INFO | [46,  2800] loss: 1.562
2025-02-26T09:22:07.364061+0300 | INFO | [46,  2900] loss: 1.592
2025-02-26T09:22:19.088448+0300 | INFO | [46,  3000] loss: 1.572
2025-02-26T09:22:28.234441+0300 | INFO | [46,  3100] loss: 1.584
2025-02-26T09:22:37.314260+0300 | INFO | [46,  3200] loss: 1.578
2025-02-26T09:22:47.159825+0300 | INFO | [46,  3300] loss: 1.580
2025-02-26T09:22:56.023269+0300 | INFO | [46,  3400] loss: 1.581
2025-02-26T09:23:05.361739+0300 | INFO | [46,  3500] loss: 1.568
2025-02-26T09:23:14.984868+0300 | INFO | [46,  3600] loss: 1.554
2025-02-26T09:23:24.597597+0300 | INFO | [46,  3700] loss: 1.565
2025-02-26T09:23:35.645709+0300 | INFO | [46,  3800] loss: 1.563
2025-02-26T09:23:45.188810+0300 | INFO | [46,  3900] loss: 1.579
2025-02-26T09:23:54.328315+0300 | INFO | [46,  4000] loss: 1.575
2025-02-26T09:24:03.579379+0300 | INFO | [46,  4100] loss: 1.576
2025-02-26T09:24:13.216680+0300 | INFO | [46,  4200] loss: 1.571
2025-02-26T09:24:22.435403+0300 | INFO | [46,  4300] loss: 1.569
2025-02-26T09:24:32.807632+0300 | INFO | [46,  4400] loss: 1.586
2025-02-26T09:24:46.888930+0300 | INFO | [46,  4500] loss: 1.575
2025-02-26T09:24:57.935760+0300 | INFO | [46,  4600] loss: 1.585
2025-02-26T09:25:07.097558+0300 | INFO | [46,  4700] loss: 1.582
2025-02-26T09:25:16.841994+0300 | INFO | [46,  4800] loss: 1.567
2025-02-26T09:25:26.227002+0300 | INFO | [46,  4900] loss: 1.571
2025-02-26T09:25:35.509102+0300 | DEBUG | Saving model to flat file storage. Save #46
2025-02-26T09:25:35.537101+0300 | INFO | Averaging client parameters
2025-02-26T09:25:35.542554+0300 | INFO | Updating parameters on client #0
2025-02-26T09:25:50.218188+0300 | DEBUG | Test set: Accuracy: 7828/10000 (78%)
2025-02-26T09:25:50.219183+0300 | DEBUG | Test set: Loss: 1.677703857421875
2025-02-26T09:25:50.311150+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.83      0.80      1000
           1       0.90      0.90      0.90      1000
           2       0.68      0.73      0.71      1000
           3       0.67      0.58      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.61      0.50      0.55       800
           6       0.78      0.89      0.83      1000
           7       0.84      0.82      0.83      1000
           8       0.88      0.89      0.89      1000
           9       0.84      0.89      0.86      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T09:25:50.312246+0300 | DEBUG | Confusion Matrix:
[[835  15  43   6  13   1   6   5  43  33]
 [ 10 896   2   1   1   2   7   2  19  60]
 [ 67   3 733  32  59  17  55  17   9   8]
 [ 35   3  91 692  50 177  76  42  12  22]
 [ 16   2  59  44 787  10  47  24   9   2]
 [ 11   5  74 187  32 400  33  50   3   5]
 [ 13   5  33  27  16   5 890   6   3   2]
 [ 26   3  24  27  40  34  11 819   3  13]
 [ 48  16  10   8   0   2   4   3 890  19]
 [ 23  46   6   6   2   3   6   4  18 886]]
2025-02-26T09:25:50.313255+0300 | DEBUG | Class precision: [0.7702952  0.90140845 0.68186047 0.67184466 0.787      0.61443932
 0.78414097 0.84259259 0.88206145 0.84380952]
2025-02-26T09:25:50.314254+0300 | DEBUG | Class recall: [0.835      0.896      0.733      0.57666667 0.787      0.5
 0.89       0.819      0.89       0.886     ]
2025-02-26T09:25:50.365260+0300 | INFO | Training epoch #47 on client #0
2025-02-26T09:25:50.368262+0300 | DEBUG | Saving model to flat file storage. Save #47
2025-02-26T09:25:50.562090+0300 | INFO | [47,     0] loss: 0.016
2025-02-26T09:26:00.378088+0300 | INFO | [47,   100] loss: 1.564
2025-02-26T09:26:13.147753+0300 | INFO | [47,   200] loss: 1.569
2025-02-26T09:26:22.391548+0300 | INFO | [47,   300] loss: 1.564
2025-02-26T09:26:31.529920+0300 | INFO | [47,   400] loss: 1.572
2025-02-26T09:26:41.014534+0300 | INFO | [47,   500] loss: 1.566
2025-02-26T09:26:50.107754+0300 | INFO | [47,   600] loss: 1.573
2025-02-26T09:26:59.286061+0300 | INFO | [47,   700] loss: 1.561
2025-02-26T09:27:08.243781+0300 | INFO | [47,   800] loss: 1.565
2025-02-26T09:27:17.523592+0300 | INFO | [47,   900] loss: 1.576
2025-02-26T09:27:26.881358+0300 | INFO | [47,  1000] loss: 1.562
2025-02-26T09:27:36.728082+0300 | INFO | [47,  1100] loss: 1.563
2025-02-26T09:27:46.708218+0300 | INFO | [47,  1200] loss: 1.561
2025-02-26T09:27:57.158378+0300 | INFO | [47,  1300] loss: 1.589
2025-02-26T09:28:07.148702+0300 | INFO | [47,  1400] loss: 1.586
2025-02-26T09:28:16.355911+0300 | INFO | [47,  1500] loss: 1.565
2025-02-26T09:28:25.599730+0300 | INFO | [47,  1600] loss: 1.583
2025-02-26T09:28:34.860620+0300 | INFO | [47,  1700] loss: 1.577
2025-02-26T09:28:44.202952+0300 | INFO | [47,  1800] loss: 1.580
2025-02-26T09:28:53.547545+0300 | INFO | [47,  1900] loss: 1.566
2025-02-26T09:29:03.085013+0300 | INFO | [47,  2000] loss: 1.570
2025-02-26T09:29:12.252814+0300 | INFO | [47,  2100] loss: 1.568
2025-02-26T09:29:24.169351+0300 | INFO | [47,  2200] loss: 1.569
2025-02-26T09:29:33.473139+0300 | INFO | [47,  2300] loss: 1.564
2025-02-26T09:29:42.877609+0300 | INFO | [47,  2400] loss: 1.563
2025-02-26T09:29:52.184873+0300 | INFO | [47,  2500] loss: 1.577
2025-02-26T09:30:01.574700+0300 | INFO | [47,  2600] loss: 1.561
2025-02-26T09:30:10.685888+0300 | INFO | [47,  2700] loss: 1.569
2025-02-26T09:30:20.643559+0300 | INFO | [47,  2800] loss: 1.568
2025-02-26T09:30:29.751844+0300 | INFO | [47,  2900] loss: 1.579
2025-02-26T09:30:39.060252+0300 | INFO | [47,  3000] loss: 1.575
2025-02-26T09:30:49.055517+0300 | INFO | [47,  3100] loss: 1.590
2025-02-26T09:30:58.045992+0300 | INFO | [47,  3200] loss: 1.570
2025-02-26T09:31:07.609069+0300 | INFO | [47,  3300] loss: 1.562
2025-02-26T09:31:16.661502+0300 | INFO | [47,  3400] loss: 1.587
2025-02-26T09:31:26.199652+0300 | INFO | [47,  3500] loss: 1.589
2025-02-26T09:31:35.444270+0300 | INFO | [47,  3600] loss: 1.579
2025-02-26T09:31:44.677403+0300 | INFO | [47,  3700] loss: 1.573
2025-02-26T09:31:53.969763+0300 | INFO | [47,  3800] loss: 1.582
2025-02-26T09:32:03.404201+0300 | INFO | [47,  3900] loss: 1.571
2025-02-26T09:32:13.134332+0300 | INFO | [47,  4000] loss: 1.576
2025-02-26T09:32:27.430937+0300 | INFO | [47,  4100] loss: 1.587
2025-02-26T09:32:37.455803+0300 | INFO | [47,  4200] loss: 1.608
2025-02-26T09:32:46.858205+0300 | INFO | [47,  4300] loss: 1.558
2025-02-26T09:32:55.925436+0300 | INFO | [47,  4400] loss: 1.564
2025-02-26T09:33:05.704503+0300 | INFO | [47,  4500] loss: 1.565
2025-02-26T09:33:15.110096+0300 | INFO | [47,  4600] loss: 1.570
2025-02-26T09:33:24.301216+0300 | INFO | [47,  4700] loss: 1.583
2025-02-26T09:33:33.716956+0300 | INFO | [47,  4800] loss: 1.585
2025-02-26T09:33:42.999303+0300 | INFO | [47,  4900] loss: 1.582
2025-02-26T09:33:52.243544+0300 | DEBUG | Saving model to flat file storage. Save #47
2025-02-26T09:33:52.273062+0300 | INFO | Averaging client parameters
2025-02-26T09:33:52.279297+0300 | INFO | Updating parameters on client #0
2025-02-26T09:34:06.218473+0300 | DEBUG | Test set: Accuracy: 7762/10000 (78%)
2025-02-26T09:34:06.219474+0300 | DEBUG | Test set: Loss: 1.6835880279541016
2025-02-26T09:34:06.318143+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.81      0.79      1000
           1       0.89      0.90      0.90      1000
           2       0.77      0.65      0.70      1000
           3       0.64      0.58      0.61      1200
           4       0.74      0.82      0.78      1000
           5       0.58      0.52      0.55       800
           6       0.82      0.84      0.83      1000
           7       0.82      0.84      0.83      1000
           8       0.84      0.90      0.87      1000
           9       0.84      0.89      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.77      0.78      0.77     10000
weighted avg       0.77      0.78      0.77     10000

2025-02-26T09:34:06.320257+0300 | DEBUG | Confusion Matrix:
[[809  19  26   8  26   3   4   8  58  39]
 [  6 899   1   0   1   0   8   4  21  60]
 [ 72   6 650  47  83  34  60  27  13   8]
 [ 26  10  53 695  67 198  49  57  23  22]
 [ 14   3  27  45 819  26  27  24  12   3]
 [ 15   5  38 194  34 419  24  51  14   6]
 [ 12   2  27  57  32  12 840   7   9   2]
 [ 22   3  14  32  40  23   8 840   5  13]
 [ 45  21   6   6   3   1   2   2 902  12]
 [ 21  40   5   6   3   1   6   8  21 889]]
2025-02-26T09:34:06.321249+0300 | DEBUG | Class precision: [0.77639155 0.89186508 0.7674144  0.63761468 0.73916968 0.58437936
 0.81712062 0.81712062 0.83673469 0.84345351]
2025-02-26T09:34:06.322249+0300 | DEBUG | Class recall: [0.809      0.899      0.65       0.57916667 0.819      0.52375
 0.84       0.84       0.902      0.889     ]
2025-02-26T09:34:06.370300+0300 | INFO | Training epoch #48 on client #0
2025-02-26T09:34:06.374301+0300 | DEBUG | Saving model to flat file storage. Save #48
2025-02-26T09:34:06.600574+0300 | INFO | [48,     0] loss: 0.015
2025-02-26T09:34:16.257241+0300 | INFO | [48,   100] loss: 1.566
2025-02-26T09:34:25.587945+0300 | INFO | [48,   200] loss: 1.588
2025-02-26T09:34:34.801503+0300 | INFO | [48,   300] loss: 1.585
2025-02-26T09:34:43.860614+0300 | INFO | [48,   400] loss: 1.577
2025-02-26T09:34:52.914881+0300 | INFO | [48,   500] loss: 1.564
2025-02-26T09:35:02.122631+0300 | INFO | [48,   600] loss: 1.580
2025-02-26T09:35:11.728961+0300 | INFO | [48,   700] loss: 1.577
2025-02-26T09:35:20.704339+0300 | INFO | [48,   800] loss: 1.565
2025-02-26T09:35:29.921549+0300 | INFO | [48,   900] loss: 1.572
2025-02-26T09:35:39.035242+0300 | INFO | [48,  1000] loss: 1.576
2025-02-26T09:35:48.910888+0300 | INFO | [48,  1100] loss: 1.563
2025-02-26T09:36:00.763111+0300 | INFO | [48,  1200] loss: 1.565
2025-02-26T09:36:10.136581+0300 | INFO | [48,  1300] loss: 1.565
2025-02-26T09:36:19.406907+0300 | INFO | [48,  1400] loss: 1.557
2025-02-26T09:36:31.356454+0300 | INFO | [48,  1500] loss: 1.569
2025-02-26T09:36:41.312440+0300 | INFO | [48,  1600] loss: 1.578
2025-02-26T09:36:51.482895+0300 | INFO | [48,  1700] loss: 1.582
2025-02-26T09:37:01.244656+0300 | INFO | [48,  1800] loss: 1.570
2025-02-26T09:37:10.728808+0300 | INFO | [48,  1900] loss: 1.562
2025-02-26T09:37:21.969085+0300 | INFO | [48,  2000] loss: 1.557
2025-02-26T09:37:31.929308+0300 | INFO | [48,  2100] loss: 1.546
2025-02-26T09:37:41.062260+0300 | INFO | [48,  2200] loss: 1.574
2025-02-26T09:37:50.162951+0300 | INFO | [48,  2300] loss: 1.573
2025-02-26T09:38:01.447289+0300 | INFO | [48,  2400] loss: 1.563
2025-02-26T09:38:11.343773+0300 | INFO | [48,  2500] loss: 1.579
2025-02-26T09:38:20.818107+0300 | INFO | [48,  2600] loss: 1.570
2025-02-26T09:38:30.208028+0300 | INFO | [48,  2700] loss: 1.560
2025-02-26T09:38:40.318162+0300 | INFO | [48,  2800] loss: 1.562
2025-02-26T09:38:49.465546+0300 | INFO | [48,  2900] loss: 1.588
2025-02-26T09:38:58.565727+0300 | INFO | [48,  3000] loss: 1.572
2025-02-26T09:39:10.397531+0300 | INFO | [48,  3100] loss: 1.569
2025-02-26T09:39:19.616016+0300 | INFO | [48,  3200] loss: 1.567
2025-02-26T09:39:29.068956+0300 | INFO | [48,  3300] loss: 1.556
2025-02-26T09:39:38.200102+0300 | INFO | [48,  3400] loss: 1.567
2025-02-26T09:39:47.458269+0300 | INFO | [48,  3500] loss: 1.558
2025-02-26T09:39:57.468418+0300 | INFO | [48,  3600] loss: 1.555
2025-02-26T09:40:11.587495+0300 | INFO | [48,  3700] loss: 1.570
2025-02-26T09:40:20.870788+0300 | INFO | [48,  3800] loss: 1.580
2025-02-26T09:40:30.240604+0300 | INFO | [48,  3900] loss: 1.572
2025-02-26T09:40:39.417612+0300 | INFO | [48,  4000] loss: 1.577
2025-02-26T09:40:48.563562+0300 | INFO | [48,  4100] loss: 1.550
2025-02-26T09:40:57.562035+0300 | INFO | [48,  4200] loss: 1.583
2025-02-26T09:41:08.240280+0300 | INFO | [48,  4300] loss: 1.558
2025-02-26T09:41:17.730921+0300 | INFO | [48,  4400] loss: 1.587
2025-02-26T09:41:27.067935+0300 | INFO | [48,  4500] loss: 1.597
2025-02-26T09:41:37.101796+0300 | INFO | [48,  4600] loss: 1.576
2025-02-26T09:41:46.445302+0300 | INFO | [48,  4700] loss: 1.560
2025-02-26T09:41:55.634375+0300 | INFO | [48,  4800] loss: 1.559
2025-02-26T09:42:04.851382+0300 | INFO | [48,  4900] loss: 1.571
2025-02-26T09:42:14.165687+0300 | DEBUG | Saving model to flat file storage. Save #48
2025-02-26T09:42:14.191094+0300 | INFO | Averaging client parameters
2025-02-26T09:42:14.203146+0300 | INFO | Updating parameters on client #0
2025-02-26T09:42:28.717178+0300 | DEBUG | Test set: Accuracy: 7830/10000 (78%)
2025-02-26T09:42:28.719179+0300 | DEBUG | Test set: Loss: 1.6774318218231201
2025-02-26T09:42:28.820110+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.90      0.91      0.90      1000
           2       0.72      0.69      0.70      1000
           3       0.66      0.58      0.62      1200
           4       0.75      0.80      0.78      1000
           5       0.58      0.58      0.58       800
           6       0.79      0.89      0.84      1000
           7       0.86      0.79      0.83      1000
           8       0.89      0.88      0.88      1000
           9       0.86      0.87      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T09:42:28.821113+0300 | DEBUG | Confusion Matrix:
[[838  19  37   8  13   3   6   9  33  34]
 [  7 909   1   3   1   0   7   3  20  49]
 [ 57   2 687  33  83  39  71  17   4   7]
 [ 21   2  72 699  58 218  70  31  13  16]
 [ 11   4  41  48 803  23  43  21   6   0]
 [  9   2  49 173  33 463  22  33   9   7]
 [ 10   6  32  34   9   7 890   4   8   0]
 [ 20   3  20  39  57  46   9 792   3  11]
 [ 59  13  11  11   3   0   5   2 878  18]
 [ 27  51   7  12   4   3   8   5  12 871]]
2025-02-26T09:42:28.823118+0300 | DEBUG | Class precision: [0.79131256 0.89910979 0.71786834 0.65943396 0.75469925 0.57730673
 0.78691424 0.86368593 0.89046653 0.85982231]
2025-02-26T09:42:28.824501+0300 | DEBUG | Class recall: [0.838   0.909   0.687   0.5825  0.803   0.57875 0.89    0.792   0.878
 0.871  ]
2025-02-26T09:42:28.872955+0300 | INFO | Training epoch #49 on client #0
2025-02-26T09:42:28.874951+0300 | DEBUG | Saving model to flat file storage. Save #49
2025-02-26T09:42:29.075137+0300 | INFO | [49,     0] loss: 0.016
2025-02-26T09:42:38.245275+0300 | INFO | [49,   100] loss: 1.570
2025-02-26T09:42:47.412671+0300 | INFO | [49,   200] loss: 1.563
2025-02-26T09:42:56.481817+0300 | INFO | [49,   300] loss: 1.557
2025-02-26T09:43:05.807512+0300 | INFO | [49,   400] loss: 1.563
2025-02-26T09:43:15.100470+0300 | INFO | [49,   500] loss: 1.567
2025-02-26T09:43:24.216734+0300 | INFO | [49,   600] loss: 1.585
2025-02-26T09:43:34.581074+0300 | INFO | [49,   700] loss: 1.567
2025-02-26T09:43:46.424633+0300 | INFO | [49,   800] loss: 1.571
2025-02-26T09:43:57.240542+0300 | INFO | [49,   900] loss: 1.561
2025-02-26T09:44:07.496771+0300 | INFO | [49,  1000] loss: 1.575
2025-02-26T09:44:16.942961+0300 | INFO | [49,  1100] loss: 1.572
2025-02-26T09:44:26.807750+0300 | INFO | [49,  1200] loss: 1.550
2025-02-26T09:44:36.026334+0300 | INFO | [49,  1300] loss: 1.557
2025-02-26T09:44:45.178160+0300 | INFO | [49,  1400] loss: 1.554
2025-02-26T09:44:54.422676+0300 | INFO | [49,  1500] loss: 1.585
2025-02-26T09:45:03.778342+0300 | INFO | [49,  1600] loss: 1.576
2025-02-26T09:45:13.049445+0300 | INFO | [49,  1700] loss: 1.562
2025-02-26T09:45:22.273391+0300 | INFO | [49,  1800] loss: 1.578
2025-02-26T09:45:31.398703+0300 | INFO | [49,  1900] loss: 1.566
2025-02-26T09:45:40.526491+0300 | INFO | [49,  2000] loss: 1.554
2025-02-26T09:45:51.548787+0300 | INFO | [49,  2100] loss: 1.563
2025-02-26T09:46:01.844260+0300 | INFO | [49,  2200] loss: 1.567
2025-02-26T09:46:11.040371+0300 | INFO | [49,  2300] loss: 1.576
2025-02-26T09:46:20.534485+0300 | INFO | [49,  2400] loss: 1.567
2025-02-26T09:46:29.843519+0300 | INFO | [49,  2500] loss: 1.568
2025-02-26T09:46:39.379856+0300 | INFO | [49,  2600] loss: 1.551
2025-02-26T09:46:48.986196+0300 | INFO | [49,  2700] loss: 1.567
2025-02-26T09:46:58.103321+0300 | INFO | [49,  2800] loss: 1.574
2025-02-26T09:47:08.719080+0300 | INFO | [49,  2900] loss: 1.559
2025-02-26T09:47:18.271852+0300 | INFO | [49,  3000] loss: 1.555
2025-02-26T09:47:27.618045+0300 | INFO | [49,  3100] loss: 1.562
2025-02-26T09:47:37.993296+0300 | INFO | [49,  3200] loss: 1.583
2025-02-26T09:47:51.307385+0300 | INFO | [49,  3300] loss: 1.576
2025-02-26T09:48:00.901077+0300 | INFO | [49,  3400] loss: 1.582
2025-02-26T09:48:10.709442+0300 | INFO | [49,  3500] loss: 1.554
2025-02-26T09:48:20.109070+0300 | INFO | [49,  3600] loss: 1.556
2025-02-26T09:48:29.342474+0300 | INFO | [49,  3700] loss: 1.579
2025-02-26T09:48:38.498838+0300 | INFO | [49,  3800] loss: 1.563
2025-02-26T09:48:47.643728+0300 | INFO | [49,  3900] loss: 1.578
2025-02-26T09:48:57.847043+0300 | INFO | [49,  4000] loss: 1.566
2025-02-26T09:49:07.078580+0300 | INFO | [49,  4100] loss: 1.559
2025-02-26T09:49:16.464037+0300 | INFO | [49,  4200] loss: 1.554
2025-02-26T09:49:25.600704+0300 | INFO | [49,  4300] loss: 1.553
2025-02-26T09:49:34.981394+0300 | INFO | [49,  4400] loss: 1.589
2025-02-26T09:49:44.670117+0300 | INFO | [49,  4500] loss: 1.568
2025-02-26T09:49:54.955609+0300 | INFO | [49,  4600] loss: 1.562
2025-02-26T09:50:04.966424+0300 | INFO | [49,  4700] loss: 1.565
2025-02-26T09:50:15.064850+0300 | INFO | [49,  4800] loss: 1.556
2025-02-26T09:50:25.552843+0300 | INFO | [49,  4900] loss: 1.579
2025-02-26T09:50:36.029860+0300 | DEBUG | Saving model to flat file storage. Save #49
2025-02-26T09:50:36.055348+0300 | INFO | Averaging client parameters
2025-02-26T09:50:36.064909+0300 | INFO | Updating parameters on client #0
2025-02-26T09:50:50.746622+0300 | DEBUG | Test set: Accuracy: 7854/10000 (79%)
2025-02-26T09:50:50.748630+0300 | DEBUG | Test set: Loss: 1.6753379106521606
2025-02-26T09:50:50.844560+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.89      0.91      0.90      1000
           2       0.73      0.70      0.72      1000
           3       0.67      0.58      0.62      1200
           4       0.76      0.80      0.78      1000
           5       0.63      0.52      0.56       800
           6       0.78      0.90      0.83      1000
           7       0.83      0.83      0.83      1000
           8       0.87      0.89      0.88      1000
           9       0.84      0.88      0.86      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.79      0.78     10000

2025-02-26T09:50:50.846560+0300 | DEBUG | Confusion Matrix:
[[843  18  17   8  14   3   7   5  51  34]
 [  8 909   2   3   0   1   7   2  13  55]
 [ 71   3 699  40  69  18  65  17  11   7]
 [ 30   4  64 697  66 181  75  43  15  25]
 [ 15   2  45  32 804  12  47  34   6   3]
 [ 14   2  55 190  40 412  26  45   9   7]
 [  7   4  39  22  13   6 895   7   6   1]
 [ 17   4  21  34  47  23  10 827   6  11]
 [ 49  17   8   6   1   1   8   3 886  21]
 [ 17  53   2   7   3   2   8  10  16 882]]
2025-02-26T09:50:50.847552+0300 | DEBUG | Class precision: [0.78711485 0.89468504 0.7342437  0.67083734 0.76064333 0.62518968
 0.77961672 0.83282981 0.86947988 0.84321224]
2025-02-26T09:50:50.850069+0300 | DEBUG | Class recall: [0.843      0.909      0.699      0.58083333 0.804      0.515
 0.895      0.827      0.886      0.882     ]
2025-02-26T09:50:50.899397+0300 | INFO | Training epoch #50 on client #0
2025-02-26T09:50:50.900683+0300 | DEBUG | Saving model to flat file storage. Save #50
2025-02-26T09:50:51.162319+0300 | INFO | [50,     0] loss: 0.015
2025-02-26T09:51:03.216834+0300 | INFO | [50,   100] loss: 1.547
2025-02-26T09:51:14.002457+0300 | INFO | [50,   200] loss: 1.548
2025-02-26T09:51:24.681146+0300 | INFO | [50,   300] loss: 1.569
2025-02-26T09:52:12.631572+0300 | INFO | [50,   400] loss: 1.575
2025-02-26T09:53:20.432621+0300 | INFO | [50,   500] loss: 1.567
2025-02-26T09:54:23.179292+0300 | INFO | [50,   600] loss: 1.562
2025-02-26T09:55:22.509936+0300 | INFO | [50,   700] loss: 1.546
2025-02-26T09:56:35.845601+0300 | INFO | [50,   800] loss: 1.572
2025-02-26T09:57:29.376094+0300 | INFO | [50,   900] loss: 1.557
2025-02-26T09:58:27.794843+0300 | INFO | [50,  1000] loss: 1.564
2025-02-26T09:59:52.594730+0300 | INFO | [50,  1100] loss: 1.584
2025-02-26T10:00:49.988652+0300 | INFO | [50,  1200] loss: 1.567
2025-02-26T10:01:48.375428+0300 | INFO | [50,  1300] loss: 1.553
2025-02-26T10:02:40.097278+0300 | INFO | [50,  1400] loss: 1.576
2025-02-26T10:03:29.289330+0300 | INFO | [50,  1500] loss: 1.547
2025-02-26T10:04:21.171348+0300 | INFO | [50,  1600] loss: 1.570
2025-02-26T10:05:10.251114+0300 | INFO | [50,  1700] loss: 1.586
2025-02-26T10:06:01.396118+0300 | INFO | [50,  1800] loss: 1.561
2025-02-26T10:06:48.959791+0300 | INFO | [50,  1900] loss: 1.556
2025-02-26T10:07:42.217317+0300 | INFO | [50,  2000] loss: 1.581
2025-02-26T10:08:35.150630+0300 | INFO | [50,  2100] loss: 1.569
2025-02-26T10:09:24.189249+0300 | INFO | [50,  2200] loss: 1.569
2025-02-26T10:10:13.985031+0300 | INFO | [50,  2300] loss: 1.569
2025-02-26T10:11:03.864366+0300 | INFO | [50,  2400] loss: 1.570
2025-02-26T10:11:52.769790+0300 | INFO | [50,  2500] loss: 1.549
2025-02-26T10:12:42.143645+0300 | INFO | [50,  2600] loss: 1.556
2025-02-26T10:13:57.546477+0300 | INFO | [50,  2700] loss: 1.570
2025-02-26T10:14:46.435680+0300 | INFO | [50,  2800] loss: 1.553
2025-02-26T10:15:39.752720+0300 | INFO | [50,  2900] loss: 1.566
2025-02-26T10:16:29.122294+0300 | INFO | [50,  3000] loss: 1.581
2025-02-26T10:17:16.944911+0300 | INFO | [50,  3100] loss: 1.562
2025-02-26T10:18:05.809511+0300 | INFO | [50,  3200] loss: 1.567
2025-02-26T10:18:55.503401+0300 | INFO | [50,  3300] loss: 1.556
2025-02-26T10:19:44.082155+0300 | INFO | [50,  3400] loss: 1.563
2025-02-26T10:20:33.380309+0300 | INFO | [50,  3500] loss: 1.566
2025-02-26T10:21:25.185275+0300 | INFO | [50,  3600] loss: 1.571
2025-02-26T10:22:15.262702+0300 | INFO | [50,  3700] loss: 1.562
2025-02-26T10:23:08.680605+0300 | INFO | [50,  3800] loss: 1.561
2025-02-26T10:23:57.866855+0300 | INFO | [50,  3900] loss: 1.568
2025-02-26T10:24:44.419390+0300 | INFO | [50,  4000] loss: 1.558
2025-02-26T10:25:33.744097+0300 | INFO | [50,  4100] loss: 1.571
2025-02-26T10:26:25.192405+0300 | INFO | [50,  4200] loss: 1.573
2025-02-26T10:27:16.816778+0300 | INFO | [50,  4300] loss: 1.572
2025-02-26T10:28:04.283523+0300 | INFO | [50,  4400] loss: 1.566
2025-02-26T10:28:52.276987+0300 | INFO | [50,  4500] loss: 1.567
2025-02-26T10:29:42.369935+0300 | INFO | [50,  4600] loss: 1.568
2025-02-26T10:30:35.780725+0300 | INFO | [50,  4700] loss: 1.567
2025-02-26T10:31:25.297946+0300 | INFO | [50,  4800] loss: 1.562
2025-02-26T10:32:12.649920+0300 | INFO | [50,  4900] loss: 1.580
2025-02-26T10:33:01.250339+0300 | DEBUG | Updating LR for optimizer
2025-02-26T10:33:01.252343+0300 | DEBUG | New LR: 5e-05
2025-02-26T10:33:01.253341+0300 | DEBUG | Saving model to flat file storage. Save #50
2025-02-26T10:33:01.293879+0300 | INFO | Averaging client parameters
2025-02-26T10:33:01.360793+0300 | INFO | Updating parameters on client #0
2025-02-26T10:33:54.332385+0300 | DEBUG | Test set: Accuracy: 7810/10000 (78%)
2025-02-26T10:33:54.333384+0300 | DEBUG | Test set: Loss: 1.6787691116333008
2025-02-26T10:33:54.552266+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.81      0.82      1000
           1       0.89      0.92      0.90      1000
           2       0.74      0.66      0.70      1000
           3       0.67      0.56      0.61      1200
           4       0.72      0.83      0.77      1000
           5       0.57      0.60      0.58       800
           6       0.80      0.86      0.83      1000
           7       0.84      0.81      0.82      1000
           8       0.83      0.92      0.87      1000
           9       0.89      0.84      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T10:33:54.552266+0300 | DEBUG | Confusion Matrix:
[[815  17  38  15  11   5   5   8  71  15]
 [  9 916   0   2   1   2   6   4  18  42]
 [ 50   3 659  38  93  33  80  25  13   6]
 [ 19   2  62 666  73 249  50  39  24  16]
 [  5   1  32  38 834  20  26  32  11   1]
 [  5   2  43 147  44 478  24  41  11   5]
 [  7   4  25  37  38   9 862   4  14   0]
 [ 22   2  16  36  55  33   7 814   6   9]
 [ 32  17   8   5   1   2   3   2 921   9]
 [ 31  66   4  10   3   4  10   5  22 845]]
2025-02-26T10:33:54.557457+0300 | DEBUG | Class precision: [0.81909548 0.88932039 0.74295378 0.67002012 0.72333044 0.57245509
 0.80335508 0.83572895 0.8289829  0.89135021]
2025-02-26T10:33:54.558463+0300 | DEBUG | Class recall: [0.815  0.916  0.659  0.555  0.834  0.5975 0.862  0.814  0.921  0.845 ]
2025-02-26T10:33:54.560351+0300 | INFO | Training epoch #51 on client #0
2025-02-26T10:33:54.561366+0300 | DEBUG | Saving model to flat file storage. Save #51
2025-02-26T10:33:55.515754+0300 | INFO | [51,     0] loss: 0.017
2025-02-26T10:34:45.447025+0300 | INFO | [51,   100] loss: 1.561
2025-02-26T10:35:35.337833+0300 | INFO | [51,   200] loss: 1.555
2025-02-26T10:36:25.252963+0300 | INFO | [51,   300] loss: 1.562
2025-02-26T10:37:11.645234+0300 | INFO | [51,   400] loss: 1.558
2025-02-26T10:38:00.977029+0300 | INFO | [51,   500] loss: 1.554
2025-02-26T10:38:53.190475+0300 | INFO | [51,   600] loss: 1.556
2025-02-26T10:39:45.189594+0300 | INFO | [51,   700] loss: 1.547
2025-02-26T10:40:34.077757+0300 | INFO | [51,   800] loss: 1.551
2025-02-26T10:41:26.023601+0300 | INFO | [51,   900] loss: 1.543
2025-02-26T10:42:14.211717+0300 | INFO | [51,  1000] loss: 1.555
2025-02-26T10:43:03.358513+0300 | INFO | [51,  1100] loss: 1.559
2025-02-26T10:43:52.024282+0300 | INFO | [51,  1200] loss: 1.549
2025-02-26T10:44:04.553873+0300 | INFO | [51,  1300] loss: 1.542
2025-02-26T10:44:15.965316+0300 | INFO | [51,  1400] loss: 1.549
2025-02-26T10:44:25.988872+0300 | INFO | [51,  1500] loss: 1.544
2025-02-26T10:44:34.904517+0300 | INFO | [51,  1600] loss: 1.559
2025-02-26T10:44:43.662161+0300 | INFO | [51,  1700] loss: 1.551
2025-02-26T10:44:53.961404+0300 | INFO | [51,  1800] loss: 1.540
2025-02-26T10:45:02.560330+0300 | INFO | [51,  1900] loss: 1.553
2025-02-26T10:45:10.868065+0300 | INFO | [51,  2000] loss: 1.547
2025-02-26T10:45:23.961804+0300 | INFO | [51,  2100] loss: 1.550
2025-02-26T10:45:37.740373+0300 | INFO | [51,  2200] loss: 1.540
2025-02-26T10:45:47.273995+0300 | INFO | [51,  2300] loss: 1.554
2025-02-26T10:45:56.283193+0300 | INFO | [51,  2400] loss: 1.552
2025-02-26T10:46:05.417344+0300 | INFO | [51,  2500] loss: 1.545
2025-02-26T10:46:14.046544+0300 | INFO | [51,  2600] loss: 1.556
2025-02-26T10:46:22.580139+0300 | INFO | [51,  2700] loss: 1.548
2025-02-26T10:46:31.538363+0300 | INFO | [51,  2800] loss: 1.550
2025-02-26T10:46:41.459492+0300 | INFO | [51,  2900] loss: 1.554
2025-02-26T10:46:52.021077+0300 | INFO | [51,  3000] loss: 1.548
2025-02-26T10:47:02.330398+0300 | INFO | [51,  3100] loss: 1.543
2025-02-26T10:47:11.538906+0300 | INFO | [51,  3200] loss: 1.538
2025-02-26T10:47:22.148003+0300 | INFO | [51,  3300] loss: 1.553
2025-02-26T10:47:31.498617+0300 | INFO | [51,  3400] loss: 1.531
2025-02-26T10:47:40.006160+0300 | INFO | [51,  3500] loss: 1.542
2025-02-26T10:47:48.742484+0300 | INFO | [51,  3600] loss: 1.553
2025-02-26T10:47:57.374966+0300 | INFO | [51,  3700] loss: 1.554
2025-02-26T10:48:06.006795+0300 | INFO | [51,  3800] loss: 1.556
2025-02-26T10:48:14.512351+0300 | INFO | [51,  3900] loss: 1.564
2025-02-26T10:48:22.754728+0300 | INFO | [51,  4000] loss: 1.535
2025-02-26T10:48:31.320444+0300 | INFO | [51,  4100] loss: 1.561
2025-02-26T10:48:39.705820+0300 | INFO | [51,  4200] loss: 1.554
2025-02-26T10:48:48.103599+0300 | INFO | [51,  4300] loss: 1.558
2025-02-26T10:48:56.490671+0300 | INFO | [51,  4400] loss: 1.557
2025-02-26T10:49:04.926862+0300 | INFO | [51,  4500] loss: 1.553
2025-02-26T10:49:13.950426+0300 | INFO | [51,  4600] loss: 1.539
2025-02-26T10:49:22.829393+0300 | INFO | [51,  4700] loss: 1.548
2025-02-26T10:49:34.534724+0300 | INFO | [51,  4800] loss: 1.549
2025-02-26T10:49:43.186852+0300 | INFO | [51,  4900] loss: 1.546
2025-02-26T10:49:51.608562+0300 | DEBUG | Saving model to flat file storage. Save #51
2025-02-26T10:49:51.627939+0300 | INFO | Averaging client parameters
2025-02-26T10:49:51.632047+0300 | INFO | Updating parameters on client #0
2025-02-26T10:50:04.587015+0300 | DEBUG | Test set: Accuracy: 7866/10000 (79%)
2025-02-26T10:50:04.589011+0300 | DEBUG | Test set: Loss: 1.6730825901031494
2025-02-26T10:50:04.680371+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.75      0.67      0.71      1000
           3       0.64      0.61      0.63      1200
           4       0.76      0.82      0.79      1000
           5       0.56      0.56      0.56       800
           6       0.84      0.85      0.84      1000
           7       0.87      0.79      0.83      1000
           8       0.84      0.92      0.88      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T10:50:04.682398+0300 | DEBUG | Confusion Matrix:
[[841  15  32   9  14   3   5   5  52  24]
 [  7 906   1   1   1   1   7   2  26  48]
 [ 57   2 670  47  89  46  53  20  11   5]
 [ 25   4  47 738  50 219  50  20  30  17]
 [ 13   2  39  41 821  22  22  25  11   4]
 [ 11   2  33 212  28 451  19  29  10   5]
 [ 13   2  35  43  29  10 851   4  11   2]
 [ 27   5  19  52  44  41   5 787   6  14]
 [ 38  12   7   6   2   2   2   3 920   8]
 [ 20  41   5  10   3   7   5   5  23 881]]
2025-02-26T10:50:04.683932+0300 | DEBUG | Class precision: [0.79942966 0.91422805 0.7545045  0.63675582 0.75948196 0.56234414
 0.83513248 0.87444444 0.83636364 0.87400794]
2025-02-26T10:50:04.684965+0300 | DEBUG | Class recall: [0.841   0.906   0.67    0.615   0.821   0.56375 0.851   0.787   0.92
 0.881  ]
2025-02-26T10:50:04.734446+0300 | INFO | Training epoch #52 on client #0
2025-02-26T10:50:04.736548+0300 | DEBUG | Saving model to flat file storage. Save #52
2025-02-26T10:50:04.925241+0300 | INFO | [52,     0] loss: 0.015
2025-02-26T10:50:13.582662+0300 | INFO | [52,   100] loss: 1.559
2025-02-26T10:50:25.033751+0300 | INFO | [52,   200] loss: 1.545
2025-02-26T10:50:36.250324+0300 | INFO | [52,   300] loss: 1.550
2025-02-26T10:50:44.993800+0300 | INFO | [52,   400] loss: 1.529
2025-02-26T10:50:53.441798+0300 | INFO | [52,   500] loss: 1.550
2025-02-26T10:51:02.049787+0300 | INFO | [52,   600] loss: 1.552
2025-02-26T10:51:10.563770+0300 | INFO | [52,   700] loss: 1.536
2025-02-26T10:51:19.375167+0300 | INFO | [52,   800] loss: 1.536
2025-02-26T10:51:28.048180+0300 | INFO | [52,   900] loss: 1.544
2025-02-26T10:51:36.667148+0300 | INFO | [52,  1000] loss: 1.544
2025-02-26T10:51:47.814792+0300 | INFO | [52,  1100] loss: 1.550
2025-02-26T10:51:56.057507+0300 | INFO | [52,  1200] loss: 1.545
2025-02-26T10:52:05.072252+0300 | INFO | [52,  1300] loss: 1.542
2025-02-26T10:52:14.132730+0300 | INFO | [52,  1400] loss: 1.532
2025-02-26T10:52:22.877359+0300 | INFO | [52,  1500] loss: 1.553
2025-02-26T10:52:31.774816+0300 | INFO | [52,  1600] loss: 1.541
2025-02-26T10:52:41.606624+0300 | INFO | [52,  1700] loss: 1.540
2025-02-26T10:52:53.685183+0300 | INFO | [52,  1800] loss: 1.546
2025-02-26T10:53:04.384207+0300 | INFO | [52,  1900] loss: 1.556
2025-02-26T10:53:14.409810+0300 | INFO | [52,  2000] loss: 1.545
2025-02-26T10:53:23.205527+0300 | INFO | [52,  2100] loss: 1.541
2025-02-26T10:53:32.136521+0300 | INFO | [52,  2200] loss: 1.535
2025-02-26T10:53:41.290452+0300 | INFO | [52,  2300] loss: 1.546
2025-02-26T10:53:50.279660+0300 | INFO | [52,  2400] loss: 1.548
2025-02-26T10:54:01.746918+0300 | INFO | [52,  2500] loss: 1.542
2025-02-26T10:54:12.312263+0300 | INFO | [52,  2600] loss: 1.534
2025-02-26T10:54:23.335822+0300 | INFO | [52,  2700] loss: 1.539
2025-02-26T10:54:34.064252+0300 | INFO | [52,  2800] loss: 1.538
2025-02-26T10:54:45.546377+0300 | INFO | [52,  2900] loss: 1.541
2025-02-26T10:54:54.717265+0300 | INFO | [52,  3000] loss: 1.546
2025-02-26T10:55:04.260823+0300 | INFO | [52,  3100] loss: 1.544
2025-02-26T10:55:13.464713+0300 | INFO | [52,  3200] loss: 1.548
2025-02-26T10:55:24.906450+0300 | INFO | [52,  3300] loss: 1.547
2025-02-26T10:55:34.957318+0300 | INFO | [52,  3400] loss: 1.563
2025-02-26T10:55:45.331702+0300 | INFO | [52,  3500] loss: 1.540
2025-02-26T10:55:55.453919+0300 | INFO | [52,  3600] loss: 1.517
2025-02-26T10:56:06.944990+0300 | INFO | [52,  3700] loss: 1.548
2025-02-26T10:56:19.790815+0300 | INFO | [52,  3800] loss: 1.538
2025-02-26T10:56:36.728093+0300 | INFO | [52,  3900] loss: 1.540
2025-02-26T10:56:53.072798+0300 | INFO | [52,  4000] loss: 1.533
2025-02-26T10:57:05.809725+0300 | INFO | [52,  4100] loss: 1.540
2025-02-26T10:57:20.834059+0300 | INFO | [52,  4200] loss: 1.539
2025-02-26T10:57:35.212894+0300 | INFO | [52,  4300] loss: 1.543
2025-02-26T10:57:52.484963+0300 | INFO | [52,  4400] loss: 1.548
2025-02-26T10:58:09.020764+0300 | INFO | [52,  4500] loss: 1.538
2025-02-26T10:58:25.314688+0300 | INFO | [52,  4600] loss: 1.537
2025-02-26T10:58:41.384094+0300 | INFO | [52,  4700] loss: 1.544
2025-02-26T10:58:59.210636+0300 | INFO | [52,  4800] loss: 1.534
2025-02-26T10:59:12.367739+0300 | INFO | [52,  4900] loss: 1.551
2025-02-26T10:59:24.786842+0300 | DEBUG | Saving model to flat file storage. Save #52
2025-02-26T10:59:24.819942+0300 | INFO | Averaging client parameters
2025-02-26T10:59:24.826835+0300 | INFO | Updating parameters on client #0
2025-02-26T10:59:43.481841+0300 | DEBUG | Test set: Accuracy: 7891/10000 (79%)
2025-02-26T10:59:43.482848+0300 | DEBUG | Test set: Loss: 1.6709002256393433
2025-02-26T10:59:43.559553+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.84      0.83      1000
           1       0.88      0.93      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.67      0.56      0.61      1200
           4       0.76      0.82      0.79      1000
           5       0.52      0.65      0.58       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.86      0.91      0.88      1000
           9       0.90      0.84      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T10:59:43.560600+0300 | DEBUG | Confusion Matrix:
[[839  15  36  11  15   6   8   8  47  15]
 [  9 928   0   1   1   1   6   4  23  27]
 [ 43   3 675  52  79  60  51  18  11   8]
 [ 19   6  47 672  54 294  43  30  21  14]
 [  8   2  35  39 824  34  28  22   7   1]
 [  7   3  25 162  27 522  16  29   6   3]
 [  8   1  37  31  28  17 863   6   7   2]
 [ 15   4  14  25  47  59   3 818   5  10]
 [ 37  16   8   8   2   3   1   4 912   9]
 [ 28  71   6   3   2   6  11   8  27 838]]
2025-02-26T10:59:43.560600+0300 | DEBUG | Class precision: [0.82823297 0.88465205 0.76443941 0.66932271 0.76367006 0.52095808
 0.83786408 0.86378036 0.85553471 0.90399137]
2025-02-26T10:59:43.563667+0300 | DEBUG | Class recall: [0.839  0.928  0.675  0.56   0.824  0.6525 0.863  0.818  0.912  0.838 ]
2025-02-26T10:59:43.616660+0300 | INFO | Training epoch #53 on client #0
2025-02-26T10:59:43.618661+0300 | DEBUG | Saving model to flat file storage. Save #53
2025-02-26T10:59:43.814917+0300 | INFO | [53,     0] loss: 0.016
2025-02-26T10:59:58.282750+0300 | INFO | [53,   100] loss: 1.534
2025-02-26T11:00:10.684109+0300 | INFO | [53,   200] loss: 1.535
2025-02-26T11:00:21.880273+0300 | INFO | [53,   300] loss: 1.533
2025-02-26T11:00:31.815525+0300 | INFO | [53,   400] loss: 1.537
2025-02-26T11:00:42.127344+0300 | INFO | [53,   500] loss: 1.521
2025-02-26T11:00:54.247137+0300 | INFO | [53,   600] loss: 1.539
2025-02-26T11:01:06.141446+0300 | INFO | [53,   700] loss: 1.549
2025-02-26T11:01:17.700752+0300 | INFO | [53,   800] loss: 1.523
2025-02-26T11:01:29.775869+0300 | INFO | [53,   900] loss: 1.535
2025-02-26T11:01:43.106933+0300 | INFO | [53,  1000] loss: 1.550
2025-02-26T11:01:58.011105+0300 | INFO | [53,  1100] loss: 1.530
2025-02-26T11:02:12.664254+0300 | INFO | [53,  1200] loss: 1.535
2025-02-26T11:02:28.225453+0300 | INFO | [53,  1300] loss: 1.534
2025-02-26T11:02:45.774013+0300 | INFO | [53,  1400] loss: 1.529
2025-02-26T11:03:04.218437+0300 | INFO | [53,  1500] loss: 1.538
2025-02-26T11:03:19.175807+0300 | INFO | [53,  1600] loss: 1.540
2025-02-26T11:03:31.862367+0300 | INFO | [53,  1700] loss: 1.544
2025-02-26T11:03:46.649890+0300 | INFO | [53,  1800] loss: 1.522
2025-02-26T11:03:58.108305+0300 | INFO | [53,  1900] loss: 1.548
2025-02-26T11:04:10.685139+0300 | INFO | [53,  2000] loss: 1.540
2025-02-26T11:04:22.996537+0300 | INFO | [53,  2100] loss: 1.541
2025-02-26T11:04:35.262122+0300 | INFO | [53,  2200] loss: 1.534
2025-02-26T11:04:47.146679+0300 | INFO | [53,  2300] loss: 1.550
2025-02-26T11:04:59.071950+0300 | INFO | [53,  2400] loss: 1.547
2025-02-26T11:05:11.271747+0300 | INFO | [53,  2500] loss: 1.533
2025-02-26T11:05:21.522223+0300 | INFO | [53,  2600] loss: 1.549
2025-02-26T11:05:32.303655+0300 | INFO | [53,  2700] loss: 1.541
2025-02-26T11:05:43.225935+0300 | INFO | [53,  2800] loss: 1.533
2025-02-26T11:05:54.191295+0300 | INFO | [53,  2900] loss: 1.544
2025-02-26T11:06:05.327607+0300 | INFO | [53,  3000] loss: 1.533
2025-02-26T11:06:17.119955+0300 | INFO | [53,  3100] loss: 1.536
2025-02-26T11:06:28.216771+0300 | INFO | [53,  3200] loss: 1.536
2025-02-26T11:06:39.031623+0300 | INFO | [53,  3300] loss: 1.540
2025-02-26T11:06:50.809626+0300 | INFO | [53,  3400] loss: 1.542
2025-02-26T11:07:02.148628+0300 | INFO | [53,  3500] loss: 1.542
2025-02-26T11:07:12.508847+0300 | INFO | [53,  3600] loss: 1.531
2025-02-26T11:07:23.776884+0300 | INFO | [53,  3700] loss: 1.542
2025-02-26T11:07:34.651742+0300 | INFO | [53,  3800] loss: 1.533
2025-02-26T11:07:44.846626+0300 | INFO | [53,  3900] loss: 1.569
2025-02-26T11:07:56.097051+0300 | INFO | [53,  4000] loss: 1.538
2025-02-26T11:08:07.863163+0300 | INFO | [53,  4100] loss: 1.548
2025-02-26T11:08:17.878437+0300 | INFO | [53,  4200] loss: 1.521
2025-02-26T11:08:29.146050+0300 | INFO | [53,  4300] loss: 1.557
2025-02-26T11:08:39.834119+0300 | INFO | [53,  4400] loss: 1.541
2025-02-26T11:08:49.031823+0300 | INFO | [53,  4500] loss: 1.552
2025-02-26T11:09:00.561429+0300 | INFO | [53,  4600] loss: 1.533
2025-02-26T11:09:12.097920+0300 | INFO | [53,  4700] loss: 1.535
2025-02-26T11:09:24.155866+0300 | INFO | [53,  4800] loss: 1.551
2025-02-26T11:09:34.180614+0300 | INFO | [53,  4900] loss: 1.529
2025-02-26T11:09:45.292055+0300 | DEBUG | Saving model to flat file storage. Save #53
2025-02-26T11:09:45.323946+0300 | INFO | Averaging client parameters
2025-02-26T11:09:45.333970+0300 | INFO | Updating parameters on client #0
2025-02-26T11:10:01.377250+0300 | DEBUG | Test set: Accuracy: 7900/10000 (79%)
2025-02-26T11:10:01.379302+0300 | DEBUG | Test set: Loss: 1.6697767972946167
2025-02-26T11:10:01.490166+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.81      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.77      0.67      0.71      1000
           3       0.66      0.63      0.64      1200
           4       0.77      0.79      0.78      1000
           5       0.55      0.59      0.57       800
           6       0.79      0.89      0.84      1000
           7       0.84      0.83      0.83      1000
           8       0.87      0.91      0.89      1000
           9       0.90      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T11:10:01.493173+0300 | DEBUG | Confusion Matrix:
[[807  17  45  11  16   8   8   9  55  24]
 [ 10 926   0   1   0   1   6   5  20  31]
 [ 41   2 666  52  80  56  68  19   9   7]
 [  9   4  37 751  49 233  54  36  15  12]
 [  8   2  39  43 791  26  49  35   7   0]
 [  7   2  29 199  28 474  21  34   4   2]
 [  5   2  25  33  15  14 893   9   3   1]
 [ 15   3   8  39  44  44   6 830   2   9]
 [ 34  15   9   5   1   2   8   2 914  10]
 [ 27  58   6   9   2   7  12  11  20 848]]
2025-02-26T11:10:01.495169+0300 | DEBUG | Class precision: [0.83800623 0.89815713 0.77083333 0.65704287 0.77095517 0.54797688
 0.79377778 0.83838384 0.87130601 0.89830508]
2025-02-26T11:10:01.497170+0300 | DEBUG | Class recall: [0.807      0.926      0.666      0.62583333 0.791      0.5925
 0.893      0.83       0.914      0.848     ]
2025-02-26T11:10:01.545069+0300 | INFO | Training epoch #54 on client #0
2025-02-26T11:10:01.546074+0300 | DEBUG | Saving model to flat file storage. Save #54
2025-02-26T11:10:01.760926+0300 | INFO | [54,     0] loss: 0.016
2025-02-26T11:10:13.667545+0300 | INFO | [54,   100] loss: 1.527
2025-02-26T11:10:25.174976+0300 | INFO | [54,   200] loss: 1.531
2025-02-26T11:10:36.009758+0300 | INFO | [54,   300] loss: 1.542
2025-02-26T11:10:49.097415+0300 | INFO | [54,   400] loss: 1.544
2025-02-26T11:11:00.624132+0300 | INFO | [54,   500] loss: 1.535
2025-02-26T11:11:13.928703+0300 | INFO | [54,   600] loss: 1.540
2025-02-26T11:11:25.744100+0300 | INFO | [54,   700] loss: 1.537
2025-02-26T11:11:37.206484+0300 | INFO | [54,   800] loss: 1.524
2025-02-26T11:11:50.736506+0300 | INFO | [54,   900] loss: 1.521
2025-02-26T11:11:59.451277+0300 | INFO | [54,  1000] loss: 1.544
2025-02-26T11:12:09.034366+0300 | INFO | [54,  1100] loss: 1.524
2025-02-26T11:12:25.890072+0300 | INFO | [54,  1200] loss: 1.522
2025-02-26T11:12:37.073376+0300 | INFO | [54,  1300] loss: 1.528
2025-02-26T11:12:48.106758+0300 | INFO | [54,  1400] loss: 1.540
2025-02-26T11:13:00.539518+0300 | INFO | [54,  1500] loss: 1.520
2025-02-26T11:13:11.876055+0300 | INFO | [54,  1600] loss: 1.531
2025-02-26T11:13:24.711253+0300 | INFO | [54,  1700] loss: 1.516
2025-02-26T11:13:36.064077+0300 | INFO | [54,  1800] loss: 1.554
2025-02-26T11:13:47.703869+0300 | INFO | [54,  1900] loss: 1.532
2025-02-26T11:13:56.923399+0300 | INFO | [54,  2000] loss: 1.535
2025-02-26T11:14:06.276517+0300 | INFO | [54,  2100] loss: 1.535
2025-02-26T11:14:15.946395+0300 | INFO | [54,  2200] loss: 1.538
2025-02-26T11:14:24.996725+0300 | INFO | [54,  2300] loss: 1.538
2025-02-26T11:14:34.645581+0300 | INFO | [54,  2400] loss: 1.539
2025-02-26T11:14:43.844822+0300 | INFO | [54,  2500] loss: 1.534
2025-02-26T11:14:52.909850+0300 | INFO | [54,  2600] loss: 1.531
2025-02-26T11:15:02.246456+0300 | INFO | [54,  2700] loss: 1.537
2025-02-26T11:15:11.259359+0300 | INFO | [54,  2800] loss: 1.551
2025-02-26T11:15:20.820170+0300 | INFO | [54,  2900] loss: 1.527
2025-02-26T11:15:33.287401+0300 | INFO | [54,  3000] loss: 1.526
2025-02-26T11:15:46.444608+0300 | INFO | [54,  3100] loss: 1.533
2025-02-26T11:16:01.192122+0300 | INFO | [54,  3200] loss: 1.534
2025-02-26T11:16:12.735902+0300 | INFO | [54,  3300] loss: 1.531
2025-02-26T11:16:23.137830+0300 | INFO | [54,  3400] loss: 1.544
2025-02-26T11:16:36.458488+0300 | INFO | [54,  3500] loss: 1.539
2025-02-26T11:16:49.903932+0300 | INFO | [54,  3600] loss: 1.553
2025-02-26T11:17:02.198041+0300 | INFO | [54,  3700] loss: 1.540
2025-02-26T11:17:13.866312+0300 | INFO | [54,  3800] loss: 1.528
2025-02-26T11:17:26.332867+0300 | INFO | [54,  3900] loss: 1.521
2025-02-26T11:17:39.621605+0300 | INFO | [54,  4000] loss: 1.543
2025-02-26T11:17:53.476393+0300 | INFO | [54,  4100] loss: 1.528
2025-02-26T11:18:05.566769+0300 | INFO | [54,  4200] loss: 1.525
2025-02-26T11:18:17.573469+0300 | INFO | [54,  4300] loss: 1.546
2025-02-26T11:18:29.562415+0300 | INFO | [54,  4400] loss: 1.545
2025-02-26T11:18:42.762884+0300 | INFO | [54,  4500] loss: 1.537
2025-02-26T11:18:57.231349+0300 | INFO | [54,  4600] loss: 1.524
2025-02-26T11:19:10.923585+0300 | INFO | [54,  4700] loss: 1.531
2025-02-26T11:19:23.839325+0300 | INFO | [54,  4800] loss: 1.525
2025-02-26T11:19:37.503513+0300 | INFO | [54,  4900] loss: 1.545
2025-02-26T11:19:50.814619+0300 | DEBUG | Saving model to flat file storage. Save #54
2025-02-26T11:19:50.837607+0300 | INFO | Averaging client parameters
2025-02-26T11:19:50.844606+0300 | INFO | Updating parameters on client #0
2025-02-26T11:20:08.413574+0300 | DEBUG | Test set: Accuracy: 7933/10000 (79%)
2025-02-26T11:20:08.415575+0300 | DEBUG | Test set: Loss: 1.6666810512542725
2025-02-26T11:20:08.507087+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.65      0.62      0.63      1200
           4       0.77      0.82      0.79      1000
           5       0.57      0.58      0.57       800
           6       0.85      0.85      0.85      1000
           7       0.83      0.84      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T11:20:08.508091+0300 | DEBUG | Confusion Matrix:
[[826  20  26  16  18   7   5   8  53  21]
 [  8 929   0   2   1   0   3   3  15  39]
 [ 45   4 692  45  78  48  45  22  11  10]
 [ 11   3  45 742  56 219  44  46  16  18]
 [ 11   3  42  35 821  18  30  33   5   2]
 [  8   2  32 205  33 462  11  40   4   3]
 [  9   4  45  45  21   9 851   6   9   1]
 [ 17   2   8  38  42  35   4 841   3  10]
 [ 38  18   7   9   0   2   6   3 903  14]
 [ 26  61   4   6   3   7   8   8  11 866]]
2025-02-26T11:20:08.509091+0300 | DEBUG | Class precision: [0.82682683 0.88814532 0.76803552 0.64916885 0.76514445 0.57249071
 0.84508441 0.83267327 0.87669903 0.8800813 ]
2025-02-26T11:20:08.510092+0300 | DEBUG | Class recall: [0.826      0.929      0.692      0.61833333 0.821      0.5775
 0.851      0.841      0.903      0.866     ]
2025-02-26T11:20:08.577655+0300 | INFO | Training epoch #55 on client #0
2025-02-26T11:20:08.578652+0300 | DEBUG | Saving model to flat file storage. Save #55
2025-02-26T11:20:08.843302+0300 | INFO | [55,     0] loss: 0.015
2025-02-26T11:20:23.035323+0300 | INFO | [55,   100] loss: 1.536
2025-02-26T11:20:37.220311+0300 | INFO | [55,   200] loss: 1.536
2025-02-26T11:20:51.602750+0300 | INFO | [55,   300] loss: 1.534
2025-02-26T11:21:05.912762+0300 | INFO | [55,   400] loss: 1.531
2025-02-26T11:21:16.426721+0300 | INFO | [55,   500] loss: 1.538
2025-02-26T11:21:27.285512+0300 | INFO | [55,   600] loss: 1.530
2025-02-26T11:21:37.245054+0300 | INFO | [55,   700] loss: 1.522
2025-02-26T11:21:47.042438+0300 | INFO | [55,   800] loss: 1.518
2025-02-26T11:21:56.734203+0300 | INFO | [55,   900] loss: 1.530
2025-02-26T11:22:06.274166+0300 | INFO | [55,  1000] loss: 1.535
2025-02-26T11:22:15.826760+0300 | INFO | [55,  1100] loss: 1.535
2025-02-26T11:22:25.207375+0300 | INFO | [55,  1200] loss: 1.531
2025-02-26T11:22:34.884593+0300 | INFO | [55,  1300] loss: 1.524
2025-02-26T11:22:44.526785+0300 | INFO | [55,  1400] loss: 1.537
2025-02-26T11:22:58.993625+0300 | INFO | [55,  1500] loss: 1.530
2025-02-26T11:23:11.562612+0300 | INFO | [55,  1600] loss: 1.538
2025-02-26T11:23:21.911914+0300 | INFO | [55,  1700] loss: 1.529
2025-02-26T11:23:31.865243+0300 | INFO | [55,  1800] loss: 1.525
2025-02-26T11:23:41.263874+0300 | INFO | [55,  1900] loss: 1.519
2025-02-26T11:23:50.842436+0300 | INFO | [55,  2000] loss: 1.519
2025-02-26T11:24:00.231819+0300 | INFO | [55,  2100] loss: 1.530
2025-02-26T11:24:09.751523+0300 | INFO | [55,  2200] loss: 1.531
2025-02-26T11:24:18.935508+0300 | INFO | [55,  2300] loss: 1.540
2025-02-26T11:24:30.045915+0300 | INFO | [55,  2400] loss: 1.543
2025-02-26T11:24:44.568590+0300 | INFO | [55,  2500] loss: 1.534
2025-02-26T11:24:58.389301+0300 | INFO | [55,  2600] loss: 1.546
2025-02-26T11:25:09.961670+0300 | INFO | [55,  2700] loss: 1.532
2025-02-26T11:25:23.899878+0300 | INFO | [55,  2800] loss: 1.530
2025-02-26T11:25:37.284561+0300 | INFO | [55,  2900] loss: 1.544
2025-02-26T11:25:51.682560+0300 | INFO | [55,  3000] loss: 1.543
2025-02-26T11:26:06.190282+0300 | INFO | [55,  3100] loss: 1.532
2025-02-26T11:26:20.021842+0300 | INFO | [55,  3200] loss: 1.537
2025-02-26T11:26:34.414417+0300 | INFO | [55,  3300] loss: 1.528
2025-02-26T11:26:47.045308+0300 | INFO | [55,  3400] loss: 1.523
2025-02-26T11:27:00.224550+0300 | INFO | [55,  3500] loss: 1.526
2025-02-26T11:27:11.575242+0300 | INFO | [55,  3600] loss: 1.537
2025-02-26T11:27:22.958580+0300 | INFO | [55,  3700] loss: 1.544
2025-02-26T11:27:34.169415+0300 | INFO | [55,  3800] loss: 1.542
2025-02-26T11:27:45.250922+0300 | INFO | [55,  3900] loss: 1.537
2025-02-26T11:28:01.426794+0300 | INFO | [55,  4000] loss: 1.531
2025-02-26T11:28:14.336141+0300 | INFO | [55,  4100] loss: 1.524
2025-02-26T11:28:26.316078+0300 | INFO | [55,  4200] loss: 1.524
2025-02-26T11:28:37.493703+0300 | INFO | [55,  4300] loss: 1.525
2025-02-26T11:28:48.444425+0300 | INFO | [55,  4400] loss: 1.519
2025-02-26T11:28:59.401604+0300 | INFO | [55,  4500] loss: 1.514
2025-02-26T11:29:10.319582+0300 | INFO | [55,  4600] loss: 1.540
2025-02-26T11:29:21.301638+0300 | INFO | [55,  4700] loss: 1.540
2025-02-26T11:29:33.561145+0300 | INFO | [55,  4800] loss: 1.531
2025-02-26T11:29:44.962445+0300 | INFO | [55,  4900] loss: 1.527
2025-02-26T11:29:59.744677+0300 | DEBUG | Saving model to flat file storage. Save #55
2025-02-26T11:29:59.762678+0300 | INFO | Averaging client parameters
2025-02-26T11:29:59.776678+0300 | INFO | Updating parameters on client #0
2025-02-26T11:30:19.442449+0300 | DEBUG | Test set: Accuracy: 7902/10000 (79%)
2025-02-26T11:30:19.443448+0300 | DEBUG | Test set: Loss: 1.6701369285583496
2025-02-26T11:30:19.555359+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.91      0.90      0.91      1000
           2       0.69      0.74      0.71      1000
           3       0.69      0.57      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.61      0.56      0.58       800
           6       0.77      0.89      0.82      1000
           7       0.86      0.82      0.84      1000
           8       0.86      0.92      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T11:30:19.556359+0300 | DEBUG | Confusion Matrix:
[[839  15  35   8  13   4   5   9  49  23]
 [ 12 903   0   3   1   1  11   4  25  40]
 [ 47   3 740  27  63  22  66  17  10   5]
 [ 25   3  85 681  57 197  83  32  23  14]
 [  8   3  62  30 802  18  48  22   7   0]
 [ 10   1  57 175  37 447  29  35   7   2]
 [  9   1  52  20  13   5 889   4   6   1]
 [ 20   2  28  29  43  34  11 820   3  10]
 [ 41   9   8   6   1   2   6   4 916   7]
 [ 21  55   7   3   2   5  14   7  21 865]]
2025-02-26T11:30:19.559361+0300 | DEBUG | Class precision: [0.8129845  0.90753769 0.68901304 0.69348269 0.77713178 0.60816327
 0.76506024 0.85953878 0.85848172 0.89451913]
2025-02-26T11:30:19.560360+0300 | DEBUG | Class recall: [0.839   0.903   0.74    0.5675  0.802   0.55875 0.889   0.82    0.916
 0.865  ]
2025-02-26T11:30:19.611361+0300 | INFO | Training epoch #56 on client #0
2025-02-26T11:30:19.616360+0300 | DEBUG | Saving model to flat file storage. Save #56
2025-02-26T11:30:19.851239+0300 | INFO | [56,     0] loss: 0.015
2025-02-26T11:30:37.616349+0300 | INFO | [56,   100] loss: 1.532
2025-02-26T11:30:53.032819+0300 | INFO | [56,   200] loss: 1.529
2025-02-26T11:31:05.856992+0300 | INFO | [56,   300] loss: 1.525
2025-02-26T11:31:18.155892+0300 | INFO | [56,   400] loss: 1.527
2025-02-26T11:31:29.313116+0300 | INFO | [56,   500] loss: 1.532
2025-02-26T11:31:40.882377+0300 | INFO | [56,   600] loss: 1.524
2025-02-26T11:31:52.498062+0300 | INFO | [56,   700] loss: 1.521
2025-02-26T11:32:04.000629+0300 | INFO | [56,   800] loss: 1.529
2025-02-26T11:32:14.030877+0300 | INFO | [56,   900] loss: 1.529
2025-02-26T11:32:24.366715+0300 | INFO | [56,  1000] loss: 1.513
2025-02-26T11:32:34.463160+0300 | INFO | [56,  1100] loss: 1.525
2025-02-26T11:32:44.730832+0300 | INFO | [56,  1200] loss: 1.528
2025-02-26T11:32:56.508000+0300 | INFO | [56,  1300] loss: 1.527
2025-02-26T11:33:06.572697+0300 | INFO | [56,  1400] loss: 1.516
2025-02-26T11:33:16.271616+0300 | INFO | [56,  1500] loss: 1.507
2025-02-26T11:33:25.934526+0300 | INFO | [56,  1600] loss: 1.532
2025-02-26T11:33:35.409069+0300 | INFO | [56,  1700] loss: 1.524
2025-02-26T11:33:47.012851+0300 | INFO | [56,  1800] loss: 1.533
2025-02-26T11:33:59.788899+0300 | INFO | [56,  1900] loss: 1.535
2025-02-26T11:34:09.850575+0300 | INFO | [56,  2000] loss: 1.524
2025-02-26T11:34:20.517887+0300 | INFO | [56,  2100] loss: 1.537
2025-02-26T11:34:36.174555+0300 | INFO | [56,  2200] loss: 1.511
2025-02-26T11:34:47.864675+0300 | INFO | [56,  2300] loss: 1.529
2025-02-26T11:35:01.152032+0300 | INFO | [56,  2400] loss: 1.537
2025-02-26T11:35:12.714122+0300 | INFO | [56,  2500] loss: 1.537
2025-02-26T11:35:27.048887+0300 | INFO | [56,  2600] loss: 1.533
2025-02-26T11:35:39.295968+0300 | INFO | [56,  2700] loss: 1.520
2025-02-26T11:35:51.221388+0300 | INFO | [56,  2800] loss: 1.536
2025-02-26T11:36:04.738435+0300 | INFO | [56,  2900] loss: 1.530
2025-02-26T11:36:17.914956+0300 | INFO | [56,  3000] loss: 1.541
2025-02-26T11:36:31.645009+0300 | INFO | [56,  3100] loss: 1.539
2025-02-26T11:36:43.368058+0300 | INFO | [56,  3200] loss: 1.527
2025-02-26T11:36:55.027181+0300 | INFO | [56,  3300] loss: 1.540
2025-02-26T11:37:05.279165+0300 | INFO | [56,  3400] loss: 1.529
2025-02-26T11:37:16.029652+0300 | INFO | [56,  3500] loss: 1.527
2025-02-26T11:37:27.665576+0300 | INFO | [56,  3600] loss: 1.535
2025-02-26T11:37:41.273891+0300 | INFO | [56,  3700] loss: 1.522
2025-02-26T11:37:54.097654+0300 | INFO | [56,  3800] loss: 1.525
2025-02-26T11:38:08.526762+0300 | INFO | [56,  3900] loss: 1.532
2025-02-26T11:38:22.129047+0300 | INFO | [56,  4000] loss: 1.522
2025-02-26T11:38:35.143049+0300 | INFO | [56,  4100] loss: 1.539
2025-02-26T11:38:45.821321+0300 | INFO | [56,  4200] loss: 1.523
2025-02-26T11:38:55.362453+0300 | INFO | [56,  4300] loss: 1.544
2025-02-26T11:39:05.227949+0300 | INFO | [56,  4400] loss: 1.536
2025-02-26T11:39:14.502604+0300 | INFO | [56,  4500] loss: 1.526
2025-02-26T11:39:25.207551+0300 | INFO | [56,  4600] loss: 1.561
2025-02-26T11:39:38.682431+0300 | INFO | [56,  4700] loss: 1.529
2025-02-26T11:39:56.665177+0300 | INFO | [56,  4800] loss: 1.535
2025-02-26T11:40:08.665849+0300 | INFO | [56,  4900] loss: 1.529
2025-02-26T11:40:21.169977+0300 | DEBUG | Saving model to flat file storage. Save #56
2025-02-26T11:40:21.195874+0300 | INFO | Averaging client parameters
2025-02-26T11:40:21.205871+0300 | INFO | Updating parameters on client #0
2025-02-26T11:40:37.946413+0300 | DEBUG | Test set: Accuracy: 7911/10000 (79%)
2025-02-26T11:40:37.948416+0300 | DEBUG | Test set: Loss: 1.6690058708190918
2025-02-26T11:40:38.052114+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.81      0.82      1000
           1       0.88      0.93      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.65      0.64      0.64      1200
           4       0.81      0.78      0.79      1000
           5       0.55      0.61      0.57       800
           6       0.79      0.89      0.84      1000
           7       0.86      0.81      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T11:40:38.054116+0300 | DEBUG | Confusion Matrix:
[[815  18  34  15  19   8   6   6  52  27]
 [  8 933   0   1   0   0   4   4  14  36]
 [ 40   4 676  52  58  56  77  16  13   8]
 [ 14   4  45 764  40 238  45  24  12  14]
 [  9   4  36  45 775  33  56  34   7   1]
 [ 10   3  33 189  23 486  15  33   4   4]
 [  6   2  32  45   8  10 886   4   6   1]
 [ 23   4  13  43  33  47  10 813   3  11]
 [ 42  18   8  10   0   4   5   3 898  12]
 [ 19  65   5   7   2   9  11   4  13 865]]
2025-02-26T11:40:38.055113+0300 | DEBUG | Class precision: [0.82657201 0.88436019 0.76643991 0.65243382 0.80897704 0.54545455
 0.79461883 0.8639745  0.87866928 0.88355465]
2025-02-26T11:40:38.056112+0300 | DEBUG | Class recall: [0.815      0.933      0.676      0.63666667 0.775      0.6075
 0.886      0.813      0.898      0.865     ]
2025-02-26T11:40:38.100694+0300 | INFO | Training epoch #57 on client #0
2025-02-26T11:40:38.101697+0300 | DEBUG | Saving model to flat file storage. Save #57
2025-02-26T11:40:38.326426+0300 | INFO | [57,     0] loss: 0.016
2025-02-26T11:40:48.424248+0300 | INFO | [57,   100] loss: 1.536
2025-02-26T11:40:59.511443+0300 | INFO | [57,   200] loss: 1.526
2025-02-26T11:41:10.241352+0300 | INFO | [57,   300] loss: 1.526
2025-02-26T11:41:21.503986+0300 | INFO | [57,   400] loss: 1.532
2025-02-26T11:41:33.980270+0300 | INFO | [57,   500] loss: 1.526
2025-02-26T11:41:46.471242+0300 | INFO | [57,   600] loss: 1.535
2025-02-26T11:41:58.207190+0300 | INFO | [57,   700] loss: 1.547
2025-02-26T11:42:08.332261+0300 | INFO | [57,   800] loss: 1.516
2025-02-26T11:42:19.196593+0300 | INFO | [57,   900] loss: 1.526
2025-02-26T11:42:30.736280+0300 | INFO | [57,  1000] loss: 1.522
2025-02-26T11:42:40.680919+0300 | INFO | [57,  1100] loss: 1.519
2025-02-26T11:42:51.899848+0300 | INFO | [57,  1200] loss: 1.509
2025-02-26T11:43:03.759950+0300 | INFO | [57,  1300] loss: 1.530
2025-02-26T11:43:13.898402+0300 | INFO | [57,  1400] loss: 1.536
2025-02-26T11:43:25.401463+0300 | INFO | [57,  1500] loss: 1.535
2025-02-26T11:43:37.286740+0300 | INFO | [57,  1600] loss: 1.536
2025-02-26T11:43:48.082853+0300 | INFO | [57,  1700] loss: 1.536
2025-02-26T11:43:58.646077+0300 | INFO | [57,  1800] loss: 1.518
2025-02-26T11:44:10.337086+0300 | INFO | [57,  1900] loss: 1.518
2025-02-26T11:44:21.308838+0300 | INFO | [57,  2000] loss: 1.524
2025-02-26T11:44:31.389351+0300 | INFO | [57,  2100] loss: 1.525
2025-02-26T11:44:42.456544+0300 | INFO | [57,  2200] loss: 1.536
2025-02-26T11:44:53.926364+0300 | INFO | [57,  2300] loss: 1.522
2025-02-26T11:45:04.479684+0300 | INFO | [57,  2400] loss: 1.527
2025-02-26T11:45:15.766185+0300 | INFO | [57,  2500] loss: 1.535
2025-02-26T11:45:26.636121+0300 | INFO | [57,  2600] loss: 1.521
2025-02-26T11:45:37.143835+0300 | INFO | [57,  2700] loss: 1.526
2025-02-26T11:45:48.698862+0300 | INFO | [57,  2800] loss: 1.535
2025-02-26T11:46:00.557466+0300 | INFO | [57,  2900] loss: 1.530
2025-02-26T11:46:11.462923+0300 | INFO | [57,  3000] loss: 1.524
2025-02-26T11:46:22.204967+0300 | INFO | [57,  3100] loss: 1.513
2025-02-26T11:46:34.346514+0300 | INFO | [57,  3200] loss: 1.540
2025-02-26T11:46:45.839914+0300 | INFO | [57,  3300] loss: 1.527
2025-02-26T11:46:56.180017+0300 | INFO | [57,  3400] loss: 1.536
2025-02-26T11:47:09.469999+0300 | INFO | [57,  3500] loss: 1.533
2025-02-26T11:47:24.233228+0300 | INFO | [57,  3600] loss: 1.525
2025-02-26T11:47:40.625001+0300 | INFO | [57,  3700] loss: 1.517
2025-02-26T11:47:54.659262+0300 | INFO | [57,  3800] loss: 1.529
2025-02-26T11:48:08.846210+0300 | INFO | [57,  3900] loss: 1.518
2025-02-26T11:48:21.084600+0300 | INFO | [57,  4000] loss: 1.541
2025-02-26T11:48:32.289467+0300 | INFO | [57,  4100] loss: 1.526
2025-02-26T11:48:46.814039+0300 | INFO | [57,  4200] loss: 1.518
2025-02-26T11:49:05.641978+0300 | INFO | [57,  4300] loss: 1.534
2025-02-26T11:49:18.541273+0300 | INFO | [57,  4400] loss: 1.538
2025-02-26T11:49:32.352422+0300 | INFO | [57,  4500] loss: 1.528
2025-02-26T11:49:46.180658+0300 | INFO | [57,  4600] loss: 1.532
2025-02-26T11:49:59.564693+0300 | INFO | [57,  4700] loss: 1.527
2025-02-26T11:50:12.998542+0300 | INFO | [57,  4800] loss: 1.519
2025-02-26T11:50:25.557820+0300 | INFO | [57,  4900] loss: 1.541
2025-02-26T11:50:39.124817+0300 | DEBUG | Saving model to flat file storage. Save #57
2025-02-26T11:50:39.151334+0300 | INFO | Averaging client parameters
2025-02-26T11:50:39.162336+0300 | INFO | Updating parameters on client #0
2025-02-26T11:51:00.587096+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-26T11:51:00.591099+0300 | DEBUG | Test set: Loss: 1.6739107370376587
2025-02-26T11:51:00.739607+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.87      0.93      0.90      1000
           2       0.77      0.65      0.71      1000
           3       0.67      0.58      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.54      0.62      0.58       800
           6       0.79      0.89      0.83      1000
           7       0.89      0.78      0.83      1000
           8       0.88      0.91      0.89      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T11:51:00.744609+0300 | DEBUG | Confusion Matrix:
[[844  19  24  10  13   4   4   3  46  33]
 [  9 928   0   1   1   1   7   2  18  33]
 [ 67   4 653  45  68  60  75  11   9   8]
 [ 22   8  47 699  50 251  65  24  19  15]
 [ 10   3  36  41 802  26  48  24   8   2]
 [ 13   4  36 165  29 499  18  27   3   6]
 [ 10   3  33  34  11  12 885   2   9   1]
 [ 26   5  12  39  50  61   7 780   4  16]
 [ 42  24   3   8   1   3   2   0 905  12]
 [ 23  68   3   4   3   6   9   4  12 868]]
2025-02-26T11:51:00.746608+0300 | DEBUG | Class precision: [0.79174484 0.87054409 0.77095632 0.66826004 0.78015564 0.54062839
 0.79017857 0.88939567 0.87608906 0.87323944]
2025-02-26T11:51:00.747111+0300 | DEBUG | Class recall: [0.844   0.928   0.653   0.5825  0.802   0.62375 0.885   0.78    0.905
 0.868  ]
2025-02-26T11:51:00.750116+0300 | INFO | Training epoch #58 on client #0
2025-02-26T11:51:00.750116+0300 | DEBUG | Saving model to flat file storage. Save #58
2025-02-26T11:51:01.025150+0300 | INFO | [58,     0] loss: 0.016
2025-02-26T11:51:13.783721+0300 | INFO | [58,   100] loss: 1.530
2025-02-26T11:51:27.555941+0300 | INFO | [58,   200] loss: 1.531
2025-02-26T11:51:39.956333+0300 | INFO | [58,   300] loss: 1.516
2025-02-26T11:51:53.707794+0300 | INFO | [58,   400] loss: 1.527
2025-02-26T11:52:07.939407+0300 | INFO | [58,   500] loss: 1.519
2025-02-26T11:52:19.850182+0300 | INFO | [58,   600] loss: 1.533
2025-02-26T11:52:31.269874+0300 | INFO | [58,   700] loss: 1.528
2025-02-26T11:52:45.284550+0300 | INFO | [58,   800] loss: 1.519
2025-02-26T11:53:00.368204+0300 | INFO | [58,   900] loss: 1.531
2025-02-26T11:53:15.031886+0300 | INFO | [58,  1000] loss: 1.527
2025-02-26T11:53:26.597304+0300 | INFO | [58,  1100] loss: 1.523
2025-02-26T11:53:39.528804+0300 | INFO | [58,  1200] loss: 1.534
2025-02-26T11:53:52.372569+0300 | INFO | [58,  1300] loss: 1.539
2025-02-26T11:54:06.848374+0300 | INFO | [58,  1400] loss: 1.529
2025-02-26T11:54:19.745178+0300 | INFO | [58,  1500] loss: 1.512
2025-02-26T11:54:32.618297+0300 | INFO | [58,  1600] loss: 1.537
2025-02-26T11:54:44.476212+0300 | INFO | [58,  1700] loss: 1.536
2025-02-26T11:54:57.938405+0300 | INFO | [58,  1800] loss: 1.523
2025-02-26T11:55:11.111875+0300 | INFO | [58,  1900] loss: 1.529
2025-02-26T11:55:24.607469+0300 | INFO | [58,  2000] loss: 1.528
2025-02-26T11:55:38.182763+0300 | INFO | [58,  2100] loss: 1.516
2025-02-26T11:55:52.636235+0300 | INFO | [58,  2200] loss: 1.534
2025-02-26T11:56:05.881433+0300 | INFO | [58,  2300] loss: 1.524
2025-02-26T11:56:17.198151+0300 | INFO | [58,  2400] loss: 1.529
2025-02-26T11:56:31.196343+0300 | INFO | [58,  2500] loss: 1.518
2025-02-26T11:56:45.529221+0300 | INFO | [58,  2600] loss: 1.531
2025-02-26T11:56:58.198929+0300 | INFO | [58,  2700] loss: 1.516
2025-02-26T11:57:10.316378+0300 | INFO | [58,  2800] loss: 1.534
2025-02-26T11:57:20.909108+0300 | INFO | [58,  2900] loss: 1.527
2025-02-26T11:57:33.724268+0300 | INFO | [58,  3000] loss: 1.526
2025-02-26T11:57:46.350808+0300 | INFO | [58,  3100] loss: 1.531
2025-02-26T11:58:01.845283+0300 | INFO | [58,  3200] loss: 1.520
2025-02-26T11:58:17.415096+0300 | INFO | [58,  3300] loss: 1.522
2025-02-26T11:58:30.738667+0300 | INFO | [58,  3400] loss: 1.532
2025-02-26T11:58:45.078027+0300 | INFO | [58,  3500] loss: 1.540
2025-02-26T11:58:59.163635+0300 | INFO | [58,  3600] loss: 1.527
2025-02-26T11:59:12.660755+0300 | INFO | [58,  3700] loss: 1.530
2025-02-26T11:59:33.972729+0300 | INFO | [58,  3800] loss: 1.517
2025-02-26T11:59:48.312450+0300 | INFO | [58,  3900] loss: 1.529
2025-02-26T12:00:01.349239+0300 | INFO | [58,  4000] loss: 1.535
2025-02-26T12:00:14.680827+0300 | INFO | [58,  4100] loss: 1.514
2025-02-26T12:00:28.408197+0300 | INFO | [58,  4200] loss: 1.535
2025-02-26T12:00:41.910776+0300 | INFO | [58,  4300] loss: 1.528
2025-02-26T12:00:57.111446+0300 | INFO | [58,  4400] loss: 1.526
2025-02-26T12:01:13.570060+0300 | INFO | [58,  4500] loss: 1.527
2025-02-26T12:01:29.063349+0300 | INFO | [58,  4600] loss: 1.531
2025-02-26T12:01:44.323215+0300 | INFO | [58,  4700] loss: 1.507
2025-02-26T12:02:00.669745+0300 | INFO | [58,  4800] loss: 1.537
2025-02-26T12:02:14.541283+0300 | INFO | [58,  4900] loss: 1.529
2025-02-26T12:02:28.056229+0300 | DEBUG | Saving model to flat file storage. Save #58
2025-02-26T12:02:28.076231+0300 | INFO | Averaging client parameters
2025-02-26T12:02:28.085239+0300 | INFO | Updating parameters on client #0
2025-02-26T12:02:47.991974+0300 | DEBUG | Test set: Accuracy: 7914/10000 (79%)
2025-02-26T12:02:47.994961+0300 | DEBUG | Test set: Loss: 1.6684292554855347
2025-02-26T12:02:48.123707+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.77      0.69      0.73      1000
           3       0.63      0.61      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.57      0.56      0.56       800
           6       0.83      0.86      0.85      1000
           7       0.85      0.82      0.83      1000
           8       0.87      0.91      0.89      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T12:02:48.131709+0300 | DEBUG | Confusion Matrix:
[[829  20  32  10  15   3   7   6  48  30]
 [  8 928   0   0   1   0   8   2  14  39]
 [ 54   5 692  54  62  42  55  18  10   8]
 [ 25  10  54 729  51 208  50  38  20  15]
 [  9   3  40  51 803  23  29  32   8   2]
 [ 13   4  32 211  30 445  16  38   7   4]
 [  7   7  31  48  15  12 865   7   8   0]
 [ 22   4  11  36  45  41   4 820   4  13]
 [ 36  21   4   8   0   1   2   1 913  14]
 [ 18  49   6   5   1   4   6   6  15 890]]
2025-02-26T12:02:48.133702+0300 | DEBUG | Class precision: [0.81194907 0.8829686  0.76718404 0.6328125  0.78494624 0.57124519
 0.83013436 0.84710744 0.87201528 0.87684729]
2025-02-26T12:02:48.135693+0300 | DEBUG | Class recall: [0.829   0.928   0.692   0.6075  0.803   0.55625 0.865   0.82    0.913
 0.89   ]
2025-02-26T12:02:48.198231+0300 | INFO | Training epoch #59 on client #0
2025-02-26T12:02:48.201237+0300 | DEBUG | Saving model to flat file storage. Save #59
2025-02-26T12:02:48.539308+0300 | INFO | [59,     0] loss: 0.016
2025-02-26T12:03:03.698711+0300 | INFO | [59,   100] loss: 1.507
2025-02-26T12:03:19.701427+0300 | INFO | [59,   200] loss: 1.519
2025-02-26T12:03:33.822109+0300 | INFO | [59,   300] loss: 1.523
2025-02-26T12:03:47.603635+0300 | INFO | [59,   400] loss: 1.530
2025-02-26T12:04:00.244408+0300 | INFO | [59,   500] loss: 1.520
2025-02-26T12:04:13.494498+0300 | INFO | [59,   600] loss: 1.517
2025-02-26T12:04:27.739707+0300 | INFO | [59,   700] loss: 1.522
2025-02-26T12:04:41.630427+0300 | INFO | [59,   800] loss: 1.520
2025-02-26T12:04:54.885972+0300 | INFO | [59,   900] loss: 1.524
2025-02-26T12:05:11.652843+0300 | INFO | [59,  1000] loss: 1.528
2025-02-26T12:05:27.122744+0300 | INFO | [59,  1100] loss: 1.535
2025-02-26T12:05:40.611508+0300 | INFO | [59,  1200] loss: 1.524
2025-02-26T12:05:54.193450+0300 | INFO | [59,  1300] loss: 1.523
2025-02-26T12:06:10.158561+0300 | INFO | [59,  1400] loss: 1.532
2025-02-26T12:06:23.323321+0300 | INFO | [59,  1500] loss: 1.524
2025-02-26T12:06:37.277397+0300 | INFO | [59,  1600] loss: 1.517
2025-02-26T12:06:51.200132+0300 | INFO | [59,  1700] loss: 1.524
2025-02-26T12:07:03.094919+0300 | INFO | [59,  1800] loss: 1.531
2025-02-26T12:07:14.262433+0300 | INFO | [59,  1900] loss: 1.526
2025-02-26T12:07:27.506393+0300 | INFO | [59,  2000] loss: 1.532
2025-02-26T12:07:39.928209+0300 | INFO | [59,  2100] loss: 1.520
2025-02-26T12:07:53.263421+0300 | INFO | [59,  2200] loss: 1.522
2025-02-26T12:08:07.791092+0300 | INFO | [59,  2300] loss: 1.524
2025-02-26T12:08:21.489583+0300 | INFO | [59,  2400] loss: 1.534
2025-02-26T12:08:32.717387+0300 | INFO | [59,  2500] loss: 1.526
2025-02-26T12:08:45.421688+0300 | INFO | [59,  2600] loss: 1.505
2025-02-26T12:08:57.975863+0300 | INFO | [59,  2700] loss: 1.518
2025-02-26T12:09:10.586731+0300 | INFO | [59,  2800] loss: 1.519
2025-02-26T12:09:21.804029+0300 | INFO | [59,  2900] loss: 1.522
2025-02-26T12:09:35.979207+0300 | INFO | [59,  3000] loss: 1.522
2025-02-26T12:09:49.986160+0300 | INFO | [59,  3100] loss: 1.521
2025-02-26T12:10:05.312100+0300 | INFO | [59,  3200] loss: 1.540
2025-02-26T12:10:23.731973+0300 | INFO | [59,  3300] loss: 1.525
2025-02-26T12:10:37.399708+0300 | INFO | [59,  3400] loss: 1.523
2025-02-26T12:10:50.086363+0300 | INFO | [59,  3500] loss: 1.542
2025-02-26T12:11:01.526598+0300 | INFO | [59,  3600] loss: 1.517
2025-02-26T12:11:13.179386+0300 | INFO | [59,  3700] loss: 1.523
2025-02-26T12:11:30.072784+0300 | INFO | [59,  3800] loss: 1.523
2025-02-26T12:11:44.674483+0300 | INFO | [59,  3900] loss: 1.514
2025-02-26T12:12:00.947019+0300 | INFO | [59,  4000] loss: 1.519
2025-02-26T12:12:14.336285+0300 | INFO | [59,  4100] loss: 1.523
2025-02-26T12:12:26.378012+0300 | INFO | [59,  4200] loss: 1.520
2025-02-26T12:12:37.465978+0300 | INFO | [59,  4300] loss: 1.534
2025-02-26T12:12:47.585733+0300 | INFO | [59,  4400] loss: 1.527
2025-02-26T12:12:59.013737+0300 | INFO | [59,  4500] loss: 1.526
2025-02-26T12:13:10.405207+0300 | INFO | [59,  4600] loss: 1.529
2025-02-26T12:13:20.593735+0300 | INFO | [59,  4700] loss: 1.526
2025-02-26T12:13:33.957553+0300 | INFO | [59,  4800] loss: 1.514
2025-02-26T12:13:47.833233+0300 | INFO | [59,  4900] loss: 1.538
2025-02-26T12:14:00.193080+0300 | DEBUG | Saving model to flat file storage. Save #59
2025-02-26T12:14:00.214579+0300 | INFO | Averaging client parameters
2025-02-26T12:14:00.225024+0300 | INFO | Updating parameters on client #0
2025-02-26T12:14:20.525489+0300 | DEBUG | Test set: Accuracy: 7868/10000 (79%)
2025-02-26T12:14:20.529813+0300 | DEBUG | Test set: Loss: 1.6732802391052246
2025-02-26T12:14:20.678068+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.85      0.81      1000
           1       0.87      0.94      0.90      1000
           2       0.72      0.70      0.71      1000
           3       0.66      0.59      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.58      0.58      0.58       800
           6       0.83      0.86      0.85      1000
           7       0.87      0.79      0.83      1000
           8       0.86      0.91      0.89      1000
           9       0.92      0.82      0.86      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T12:14:20.682428+0300 | DEBUG | Confusion Matrix:
[[853  17  36   5  11   3   6   6  45  18]
 [ 10 938   1   1   1   0   3   4  21  21]
 [ 63   4 704  40  65  41  55  13   9   6]
 [ 37   8  74 705  56 216  46  26  21  11]
 [ 16   2  43  45 811  22  32  22   7   0]
 [ 15   3  46 180  33 467  17  30   6   3]
 [ 16   5  35  40  16   9 863   8   7   1]
 [ 23   1  22  41  55  45   7 794   5   7]
 [ 42  13  10   6   1   2   4   0 914   8]
 [ 34  90   7   7   2   4   7   8  22 819]]
2025-02-26T12:14:20.683796+0300 | DEBUG | Class precision: [0.76916141 0.86771508 0.7198364  0.6588785  0.77164605 0.57725587
 0.82980769 0.8715697  0.86471145 0.91610738]
2025-02-26T12:14:20.685797+0300 | DEBUG | Class recall: [0.853   0.938   0.704   0.5875  0.811   0.58375 0.863   0.794   0.914
 0.819  ]
2025-02-26T12:14:20.746124+0300 | INFO | Training epoch #60 on client #0
2025-02-26T12:14:20.747122+0300 | DEBUG | Saving model to flat file storage. Save #60
2025-02-26T12:14:21.046665+0300 | INFO | [60,     0] loss: 0.017
2025-02-26T12:14:33.036269+0300 | INFO | [60,   100] loss: 1.515
2025-02-26T12:14:43.867316+0300 | INFO | [60,   200] loss: 1.530
2025-02-26T12:14:54.363484+0300 | INFO | [60,   300] loss: 1.519
2025-02-26T12:15:06.360785+0300 | INFO | [60,   400] loss: 1.532
2025-02-26T12:15:17.853788+0300 | INFO | [60,   500] loss: 1.531
2025-02-26T12:15:29.000380+0300 | INFO | [60,   600] loss: 1.518
2025-02-26T12:15:41.862854+0300 | INFO | [60,   700] loss: 1.525
2025-02-26T12:15:54.758833+0300 | INFO | [60,   800] loss: 1.510
2025-02-26T12:16:07.066282+0300 | INFO | [60,   900] loss: 1.531
2025-02-26T12:16:17.344491+0300 | INFO | [60,  1000] loss: 1.512
2025-02-26T12:16:28.594188+0300 | INFO | [60,  1100] loss: 1.517
2025-02-26T12:16:41.853611+0300 | INFO | [60,  1200] loss: 1.523
2025-02-26T12:16:52.233559+0300 | INFO | [60,  1300] loss: 1.519
2025-02-26T12:17:03.815499+0300 | INFO | [60,  1400] loss: 1.537
2025-02-26T12:17:14.782593+0300 | INFO | [60,  1500] loss: 1.524
2025-02-26T12:17:26.913450+0300 | INFO | [60,  1600] loss: 1.537
2025-02-26T12:17:38.312356+0300 | INFO | [60,  1700] loss: 1.506
2025-02-26T12:17:47.728380+0300 | INFO | [60,  1800] loss: 1.524
2025-02-26T12:17:59.442800+0300 | INFO | [60,  1900] loss: 1.526
2025-02-26T12:18:10.551863+0300 | INFO | [60,  2000] loss: 1.523
2025-02-26T12:18:23.039986+0300 | INFO | [60,  2100] loss: 1.518
2025-02-26T12:18:37.118153+0300 | INFO | [60,  2200] loss: 1.515
2025-02-26T12:18:49.775405+0300 | INFO | [60,  2300] loss: 1.517
2025-02-26T12:18:59.676829+0300 | INFO | [60,  2400] loss: 1.513
2025-02-26T12:19:10.086723+0300 | INFO | [60,  2500] loss: 1.530
2025-02-26T12:19:21.185637+0300 | INFO | [60,  2600] loss: 1.524
2025-02-26T12:19:31.864099+0300 | INFO | [60,  2700] loss: 1.511
2025-02-26T12:19:43.406755+0300 | INFO | [60,  2800] loss: 1.517
2025-02-26T12:19:56.018000+0300 | INFO | [60,  2900] loss: 1.517
2025-02-26T12:20:09.522077+0300 | INFO | [60,  3000] loss: 1.529
2025-02-26T12:20:32.716203+0300 | INFO | [60,  3100] loss: 1.535
2025-02-26T12:20:47.570895+0300 | INFO | [60,  3200] loss: 1.532
2025-02-26T12:21:01.199763+0300 | INFO | [60,  3300] loss: 1.521
2025-02-26T12:21:13.951595+0300 | INFO | [60,  3400] loss: 1.524
2025-02-26T12:21:30.139010+0300 | INFO | [60,  3500] loss: 1.533
2025-02-26T12:21:42.907631+0300 | INFO | [60,  3600] loss: 1.532
2025-02-26T12:21:55.378403+0300 | INFO | [60,  3700] loss: 1.518
2025-02-26T12:22:08.484339+0300 | INFO | [60,  3800] loss: 1.529
2025-02-26T12:22:22.216251+0300 | INFO | [60,  3900] loss: 1.529
2025-02-26T12:22:36.448688+0300 | INFO | [60,  4000] loss: 1.524
2025-02-26T12:22:49.288382+0300 | INFO | [60,  4100] loss: 1.523
2025-02-26T12:23:04.161527+0300 | INFO | [60,  4200] loss: 1.527
2025-02-26T12:23:18.606833+0300 | INFO | [60,  4300] loss: 1.531
2025-02-26T12:23:30.347343+0300 | INFO | [60,  4400] loss: 1.532
2025-02-26T12:23:42.742476+0300 | INFO | [60,  4500] loss: 1.534
2025-02-26T12:23:57.222274+0300 | INFO | [60,  4600] loss: 1.524
2025-02-26T12:24:08.584820+0300 | INFO | [60,  4700] loss: 1.522
2025-02-26T12:24:18.643727+0300 | INFO | [60,  4800] loss: 1.530
2025-02-26T12:24:27.942831+0300 | INFO | [60,  4900] loss: 1.518
2025-02-26T12:24:37.585389+0300 | DEBUG | Saving model to flat file storage. Save #60
2025-02-26T12:24:37.605385+0300 | INFO | Averaging client parameters
2025-02-26T12:24:37.615397+0300 | INFO | Updating parameters on client #0
2025-02-26T12:24:54.140419+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-26T12:24:54.141422+0300 | DEBUG | Test set: Loss: 1.6721599102020264
2025-02-26T12:24:54.242603+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.70      0.53      0.60      1200
           4       0.73      0.84      0.78      1000
           5       0.53      0.64      0.58       800
           6       0.87      0.82      0.84      1000
           7       0.82      0.84      0.83      1000
           8       0.86      0.92      0.89      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T12:24:54.247129+0300 | DEBUG | Confusion Matrix:
[[828  14  32   6  18   5   4  11  57  25]
 [  5 906   0   0   1   0   4   8  24  52]
 [ 57   1 705  32  87  50  33  19   8   8]
 [ 19   3  56 637  75 295  40  44  17  14]
 [  5   1  41  25 841  26  16  36   7   2]
 [  7   1  35 142  39 512  13  42   5   4]
 [ 11   4  49  36  46  19 817   9   8   1]
 [ 19   2  15  20  43  46   4 839   4   8]
 [ 34  11   6   5   4   4   3   5 916  12]
 [ 29  40   7   7   1   7   7  10  19 873]]
2025-02-26T12:24:54.249254+0300 | DEBUG | Class precision: [0.81656805 0.92166836 0.74524313 0.7        0.72813853 0.53112033
 0.86822529 0.82013685 0.8600939  0.87387387]
2025-02-26T12:24:54.250802+0300 | DEBUG | Class recall: [0.828      0.906      0.705      0.53083333 0.841      0.64
 0.817      0.839      0.916      0.873     ]
2025-02-26T12:24:54.299917+0300 | INFO | Training epoch #61 on client #0
2025-02-26T12:24:54.301934+0300 | DEBUG | Saving model to flat file storage. Save #61
2025-02-26T12:24:54.494255+0300 | INFO | [61,     0] loss: 0.015
2025-02-26T12:25:05.810804+0300 | INFO | [61,   100] loss: 1.519
2025-02-26T12:25:19.307945+0300 | INFO | [61,   200] loss: 1.521
2025-02-26T12:25:31.880644+0300 | INFO | [61,   300] loss: 1.530
2025-02-26T12:25:45.041986+0300 | INFO | [61,   400] loss: 1.525
2025-02-26T12:25:57.691524+0300 | INFO | [61,   500] loss: 1.512
2025-02-26T12:26:11.613179+0300 | INFO | [61,   600] loss: 1.521
2025-02-26T12:26:25.462607+0300 | INFO | [61,   700] loss: 1.518
2025-02-26T12:26:38.738531+0300 | INFO | [61,   800] loss: 1.522
2025-02-26T12:26:51.037327+0300 | INFO | [61,   900] loss: 1.513
2025-02-26T12:27:03.570307+0300 | INFO | [61,  1000] loss: 1.526
2025-02-26T12:27:14.715456+0300 | INFO | [61,  1100] loss: 1.517
2025-02-26T12:27:25.585760+0300 | INFO | [61,  1200] loss: 1.524
2025-02-26T12:27:36.752618+0300 | INFO | [61,  1300] loss: 1.517
2025-02-26T12:27:51.145184+0300 | INFO | [61,  1400] loss: 1.535
2025-02-26T12:28:01.420003+0300 | INFO | [61,  1500] loss: 1.527
2025-02-26T12:28:12.219340+0300 | INFO | [61,  1600] loss: 1.534
2025-02-26T12:28:23.309365+0300 | INFO | [61,  1700] loss: 1.531
2025-02-26T12:28:37.562679+0300 | INFO | [61,  1800] loss: 1.525
2025-02-26T12:28:48.347978+0300 | INFO | [61,  1900] loss: 1.512
2025-02-26T12:28:59.425999+0300 | INFO | [61,  2000] loss: 1.532
2025-02-26T12:29:11.078104+0300 | INFO | [61,  2100] loss: 1.536
2025-02-26T12:29:21.271383+0300 | INFO | [61,  2200] loss: 1.521
2025-02-26T12:29:34.022954+0300 | INFO | [61,  2300] loss: 1.519
2025-02-26T12:29:47.018716+0300 | INFO | [61,  2400] loss: 1.514
2025-02-26T12:29:58.742748+0300 | INFO | [61,  2500] loss: 1.516
2025-02-26T12:30:10.723138+0300 | INFO | [61,  2600] loss: 1.518
2025-02-26T12:30:23.172614+0300 | INFO | [61,  2700] loss: 1.513
2025-02-26T12:30:37.939365+0300 | INFO | [61,  2800] loss: 1.517
2025-02-26T12:30:48.934948+0300 | INFO | [61,  2900] loss: 1.520
2025-02-26T12:30:59.822838+0300 | INFO | [61,  3000] loss: 1.527
2025-02-26T12:31:11.450797+0300 | INFO | [61,  3100] loss: 1.530
2025-02-26T12:31:22.564313+0300 | INFO | [61,  3200] loss: 1.521
2025-02-26T12:31:33.453952+0300 | INFO | [61,  3300] loss: 1.533
2025-02-26T12:31:44.906655+0300 | INFO | [61,  3400] loss: 1.541
2025-02-26T12:31:55.977805+0300 | INFO | [61,  3500] loss: 1.514
2025-02-26T12:32:07.453995+0300 | INFO | [61,  3600] loss: 1.511
2025-02-26T12:32:20.293760+0300 | INFO | [61,  3700] loss: 1.515
2025-02-26T12:32:32.648192+0300 | INFO | [61,  3800] loss: 1.523
2025-02-26T12:32:45.787915+0300 | INFO | [61,  3900] loss: 1.526
2025-02-26T12:32:57.898886+0300 | INFO | [61,  4000] loss: 1.506
2025-02-26T12:33:09.059184+0300 | INFO | [61,  4100] loss: 1.520
2025-02-26T12:33:19.407660+0300 | INFO | [61,  4200] loss: 1.514
2025-02-26T12:33:31.467780+0300 | INFO | [61,  4300] loss: 1.518
2025-02-26T12:33:42.511891+0300 | INFO | [61,  4400] loss: 1.527
2025-02-26T12:33:52.863148+0300 | INFO | [61,  4500] loss: 1.518
2025-02-26T12:34:02.449517+0300 | INFO | [61,  4600] loss: 1.521
2025-02-26T12:34:12.259973+0300 | INFO | [61,  4700] loss: 1.529
2025-02-26T12:34:23.885508+0300 | INFO | [61,  4800] loss: 1.520
2025-02-26T12:34:35.881859+0300 | INFO | [61,  4900] loss: 1.522
2025-02-26T12:34:47.049493+0300 | DEBUG | Saving model to flat file storage. Save #61
2025-02-26T12:34:47.072423+0300 | INFO | Averaging client parameters
2025-02-26T12:34:47.080381+0300 | INFO | Updating parameters on client #0
2025-02-26T12:35:03.859191+0300 | DEBUG | Test set: Accuracy: 7897/10000 (79%)
2025-02-26T12:35:03.859191+0300 | DEBUG | Test set: Loss: 1.6702302694320679
2025-02-26T12:35:03.973839+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.65      0.58      0.62      1200
           4       0.81      0.77      0.79      1000
           5       0.52      0.66      0.58       800
           6       0.82      0.86      0.84      1000
           7       0.85      0.84      0.85      1000
           8       0.86      0.92      0.89      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T12:35:03.978910+0300 | DEBUG | Confusion Matrix:
[[825  11  33  13  12   5   6   8  60  27]
 [  5 907   0   3   1   3   3   3  27  48]
 [ 52   3 682  53  58  57  62  16   8   9]
 [ 20   3  45 702  43 283  43  36  15  10]
 [  9   1  39  54 769  50  42  28   6   2]
 [ 14   1  26 158  24 525  15  34   1   2]
 [ 12   2  33  46  10  21 865   4   6   1]
 [ 15   3  14  30  31  51   5 838   6   7]
 [ 33  13   8  12   1   2   3   4 916   8]
 [ 23  50   3   8   1   7   9  10  21 868]]
2025-02-26T12:35:03.980898+0300 | DEBUG | Class precision: [0.81845238 0.91247485 0.77236693 0.65060241 0.80947368 0.52290837
 0.82146249 0.85423038 0.85928705 0.88391039]
2025-02-26T12:35:03.982907+0300 | DEBUG | Class recall: [0.825   0.907   0.682   0.585   0.769   0.65625 0.865   0.838   0.916
 0.868  ]
2025-02-26T12:35:04.030945+0300 | INFO | Training epoch #62 on client #0
2025-02-26T12:35:04.031929+0300 | DEBUG | Saving model to flat file storage. Save #62
2025-02-26T12:35:04.252138+0300 | INFO | [62,     0] loss: 0.016
2025-02-26T12:35:16.672780+0300 | INFO | [62,   100] loss: 1.520
2025-02-26T12:35:27.170857+0300 | INFO | [62,   200] loss: 1.513
2025-02-26T12:35:38.465359+0300 | INFO | [62,   300] loss: 1.529
2025-02-26T12:35:51.117903+0300 | INFO | [62,   400] loss: 1.521
2025-02-26T12:36:01.547996+0300 | INFO | [62,   500] loss: 1.521
2025-02-26T12:36:14.033621+0300 | INFO | [62,   600] loss: 1.521
2025-02-26T12:36:25.353700+0300 | INFO | [62,   700] loss: 1.518
2025-02-26T12:36:38.481147+0300 | INFO | [62,   800] loss: 1.530
2025-02-26T12:36:50.881525+0300 | INFO | [62,   900] loss: 1.530
2025-02-26T12:37:02.686946+0300 | INFO | [62,  1000] loss: 1.518
2025-02-26T12:37:12.438656+0300 | INFO | [62,  1100] loss: 1.514
2025-02-26T12:37:24.193825+0300 | INFO | [62,  1200] loss: 1.511
2025-02-26T12:37:36.493703+0300 | INFO | [62,  1300] loss: 1.526
2025-02-26T12:37:50.935117+0300 | INFO | [62,  1400] loss: 1.533
2025-02-26T12:38:04.212978+0300 | INFO | [62,  1500] loss: 1.523
2025-02-26T12:38:17.846533+0300 | INFO | [62,  1600] loss: 1.523
2025-02-26T12:38:31.309947+0300 | INFO | [62,  1700] loss: 1.509
2025-02-26T12:38:41.804401+0300 | INFO | [62,  1800] loss: 1.535
2025-02-26T12:38:52.827827+0300 | INFO | [62,  1900] loss: 1.529
2025-02-26T12:39:03.844926+0300 | INFO | [62,  2000] loss: 1.521
2025-02-26T12:39:16.380542+0300 | INFO | [62,  2100] loss: 1.517
2025-02-26T12:39:29.310347+0300 | INFO | [62,  2200] loss: 1.516
2025-02-26T12:39:48.252145+0300 | INFO | [62,  2300] loss: 1.516
2025-02-26T12:39:59.909110+0300 | INFO | [62,  2400] loss: 1.532
2025-02-26T12:40:11.935589+0300 | INFO | [62,  2500] loss: 1.517
2025-02-26T12:40:25.853983+0300 | INFO | [62,  2600] loss: 1.523
2025-02-26T12:40:37.090701+0300 | INFO | [62,  2700] loss: 1.528
2025-02-26T12:40:47.397512+0300 | INFO | [62,  2800] loss: 1.529
2025-02-26T12:41:00.159546+0300 | INFO | [62,  2900] loss: 1.528
2025-02-26T12:41:17.365374+0300 | INFO | [62,  3000] loss: 1.518
2025-02-26T12:41:33.765196+0300 | INFO | [62,  3100] loss: 1.521
2025-02-26T12:41:47.036236+0300 | INFO | [62,  3200] loss: 1.518
2025-02-26T12:42:00.266608+0300 | INFO | [62,  3300] loss: 1.509
2025-02-26T12:42:13.408228+0300 | INFO | [62,  3400] loss: 1.524
2025-02-26T12:42:26.254929+0300 | INFO | [62,  3500] loss: 1.510
2025-02-26T12:42:40.975428+0300 | INFO | [62,  3600] loss: 1.507
2025-02-26T12:42:54.360343+0300 | INFO | [62,  3700] loss: 1.518
2025-02-26T12:43:06.120496+0300 | INFO | [62,  3800] loss: 1.514
2025-02-26T12:43:20.263742+0300 | INFO | [62,  3900] loss: 1.516
2025-02-26T12:43:32.247200+0300 | INFO | [62,  4000] loss: 1.518
2025-02-26T12:43:43.261232+0300 | INFO | [62,  4100] loss: 1.514
2025-02-26T12:43:54.719668+0300 | INFO | [62,  4200] loss: 1.515
2025-02-26T12:44:07.129198+0300 | INFO | [62,  4300] loss: 1.520
2025-02-26T12:44:21.808826+0300 | INFO | [62,  4400] loss: 1.523
2025-02-26T12:44:32.651649+0300 | INFO | [62,  4500] loss: 1.530
2025-02-26T12:44:44.102290+0300 | INFO | [62,  4600] loss: 1.512
2025-02-26T12:44:55.570538+0300 | INFO | [62,  4700] loss: 1.523
2025-02-26T12:45:07.875053+0300 | INFO | [62,  4800] loss: 1.524
2025-02-26T12:45:19.614228+0300 | INFO | [62,  4900] loss: 1.515
2025-02-26T12:45:33.446187+0300 | DEBUG | Saving model to flat file storage. Save #62
2025-02-26T12:45:33.480244+0300 | INFO | Averaging client parameters
2025-02-26T12:45:33.490339+0300 | INFO | Updating parameters on client #0
2025-02-26T12:45:50.554000+0300 | DEBUG | Test set: Accuracy: 7906/10000 (79%)
2025-02-26T12:45:50.555853+0300 | DEBUG | Test set: Loss: 1.6690845489501953
2025-02-26T12:45:50.652649+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.71      0.73      0.72      1000
           3       0.66      0.57      0.62      1200
           4       0.79      0.78      0.78      1000
           5       0.55      0.60      0.58       800
           6       0.85      0.86      0.86      1000
           7       0.89      0.80      0.84      1000
           8       0.86      0.91      0.88      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T12:45:50.656665+0300 | DEBUG | Confusion Matrix:
[[850  20  28   8   7   5   5   7  45  25]
 [ 10 923   1   1   1   0   2   4  21  37]
 [ 52   6 735  42  50  40  43  13  10   9]
 [ 23   6  77 690  53 249  43  21  26  12]
 [ 16   4  69  48 775  33  27  20   7   1]
 [ 12   1  44 178  30 482  19  24   4   6]
 [ 13   5  45  39   9  12 862   5   8   2]
 [ 19   3  25  27  49  51   6 802   6  12]
 [ 38  16  12   6   1   2   4   1 914   6]
 [ 28  47   6   4   1   2   4   8  27 873]]
2025-02-26T12:45:50.661880+0300 | DEBUG | Class precision: [0.80113101 0.89524733 0.70537428 0.66155321 0.79405738 0.55022831
 0.84926108 0.88618785 0.85580524 0.88809766]
2025-02-26T12:45:50.663888+0300 | DEBUG | Class recall: [0.85   0.923  0.735  0.575  0.775  0.6025 0.862  0.802  0.914  0.873 ]
2025-02-26T12:45:50.714369+0300 | INFO | Training epoch #63 on client #0
2025-02-26T12:45:50.715381+0300 | DEBUG | Saving model to flat file storage. Save #63
2025-02-26T12:45:50.970983+0300 | INFO | [63,     0] loss: 0.015
2025-02-26T12:46:03.195345+0300 | INFO | [63,   100] loss: 1.519
2025-02-26T12:46:14.554172+0300 | INFO | [63,   200] loss: 1.543
2025-02-26T12:46:26.212252+0300 | INFO | [63,   300] loss: 1.518
2025-02-26T12:46:38.343196+0300 | INFO | [63,   400] loss: 1.521
2025-02-26T12:46:50.211877+0300 | INFO | [63,   500] loss: 1.517
2025-02-26T12:47:01.725224+0300 | INFO | [63,   600] loss: 1.527
2025-02-26T12:47:13.052046+0300 | INFO | [63,   700] loss: 1.522
2025-02-26T12:47:26.875235+0300 | INFO | [63,   800] loss: 1.520
2025-02-26T12:47:38.929406+0300 | INFO | [63,   900] loss: 1.538
2025-02-26T12:47:50.633063+0300 | INFO | [63,  1000] loss: 1.516
2025-02-26T12:48:01.450555+0300 | INFO | [63,  1100] loss: 1.507
2025-02-26T12:48:13.992071+0300 | INFO | [63,  1200] loss: 1.516
2025-02-26T12:48:26.467324+0300 | INFO | [63,  1300] loss: 1.525
2025-02-26T12:48:39.565641+0300 | INFO | [63,  1400] loss: 1.512
2025-02-26T12:48:53.229952+0300 | INFO | [63,  1500] loss: 1.514
2025-02-26T12:49:05.232868+0300 | INFO | [63,  1600] loss: 1.523
2025-02-26T12:49:18.406067+0300 | INFO | [63,  1700] loss: 1.524
2025-02-26T12:49:32.119418+0300 | INFO | [63,  1800] loss: 1.531
2025-02-26T12:49:45.537919+0300 | INFO | [63,  1900] loss: 1.520
2025-02-26T12:50:03.517236+0300 | INFO | [63,  2000] loss: 1.519
2025-02-26T12:50:17.511617+0300 | INFO | [63,  2100] loss: 1.526
2025-02-26T12:50:32.580960+0300 | INFO | [63,  2200] loss: 1.509
2025-02-26T12:50:45.716616+0300 | INFO | [63,  2300] loss: 1.526
2025-02-26T12:50:57.424720+0300 | INFO | [63,  2400] loss: 1.516
2025-02-26T12:51:09.585672+0300 | INFO | [63,  2500] loss: 1.517
2025-02-26T12:51:21.415785+0300 | INFO | [63,  2600] loss: 1.532
2025-02-26T12:51:33.354615+0300 | INFO | [63,  2700] loss: 1.517
2025-02-26T12:51:45.029274+0300 | INFO | [63,  2800] loss: 1.508
2025-02-26T12:51:56.292708+0300 | INFO | [63,  2900] loss: 1.518
2025-02-26T12:52:07.687603+0300 | INFO | [63,  3000] loss: 1.521
2025-02-26T12:52:22.841479+0300 | INFO | [63,  3100] loss: 1.518
2025-02-26T12:52:38.019050+0300 | INFO | [63,  3200] loss: 1.523
2025-02-26T12:52:48.888005+0300 | INFO | [63,  3300] loss: 1.518
2025-02-26T12:53:00.684171+0300 | INFO | [63,  3400] loss: 1.510
2025-02-26T12:53:12.941992+0300 | INFO | [63,  3500] loss: 1.512
2025-02-26T12:53:25.047881+0300 | INFO | [63,  3600] loss: 1.517
2025-02-26T12:53:37.075995+0300 | INFO | [63,  3700] loss: 1.524
2025-02-26T12:53:49.661410+0300 | INFO | [63,  3800] loss: 1.508
2025-02-26T12:54:01.508381+0300 | INFO | [63,  3900] loss: 1.531
2025-02-26T12:54:13.392374+0300 | INFO | [63,  4000] loss: 1.512
2025-02-26T12:54:24.170263+0300 | INFO | [63,  4100] loss: 1.507
2025-02-26T12:54:37.008354+0300 | INFO | [63,  4200] loss: 1.514
2025-02-26T12:54:52.728592+0300 | INFO | [63,  4300] loss: 1.509
2025-02-26T12:55:08.279457+0300 | INFO | [63,  4400] loss: 1.515
2025-02-26T12:55:25.046214+0300 | INFO | [63,  4500] loss: 1.517
2025-02-26T12:55:38.481169+0300 | INFO | [63,  4600] loss: 1.523
2025-02-26T12:55:52.187160+0300 | INFO | [63,  4700] loss: 1.530
2025-02-26T12:56:08.069927+0300 | INFO | [63,  4800] loss: 1.529
2025-02-26T12:56:23.909830+0300 | INFO | [63,  4900] loss: 1.524
2025-02-26T12:56:37.380960+0300 | DEBUG | Saving model to flat file storage. Save #63
2025-02-26T12:56:37.405841+0300 | INFO | Averaging client parameters
2025-02-26T12:56:37.421256+0300 | INFO | Updating parameters on client #0
2025-02-26T12:56:56.178449+0300 | DEBUG | Test set: Accuracy: 7901/10000 (79%)
2025-02-26T12:56:56.178449+0300 | DEBUG | Test set: Loss: 1.670690655708313
2025-02-26T12:56:56.246625+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.91      0.90      0.90      1000
           2       0.79      0.68      0.73      1000
           3       0.65      0.61      0.63      1200
           4       0.81      0.78      0.79      1000
           5       0.51      0.66      0.58       800
           6       0.85      0.86      0.85      1000
           7       0.88      0.80      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.83      0.91      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-26T12:56:56.249634+0300 | DEBUG | Confusion Matrix:
[[823  20  27  12  10   8   5   8  54  33]
 [  8 897   0   1   1   1   2   2  19  69]
 [ 49   4 679  57  54  78  52   9   7  11]
 [ 16   4  36 735  40 271  39  25  14  20]
 [ 11   1  39  61 775  44  33  25   4   7]
 [ 10   1  24 174  19 527  11  27   1   6]
 [ 12   4  28  45  12  26 856   7   7   3]
 [ 13   2   9  39  38  69   7 803   6  14]
 [ 38  11   9  10   1   4   2   1 900  24]
 [ 22  40   4   1   1   2   3   7  14 906]]
2025-02-26T12:56:56.249634+0300 | DEBUG | Class precision: [0.82135729 0.91158537 0.79415205 0.64757709 0.81493165 0.51165049
 0.84752475 0.8785558  0.87719298 0.82891125]
2025-02-26T12:56:56.250633+0300 | DEBUG | Class recall: [0.823   0.897   0.679   0.6125  0.775   0.65875 0.856   0.803   0.9
 0.906  ]
2025-02-26T12:56:56.313387+0300 | INFO | Training epoch #64 on client #0
2025-02-26T12:56:56.314399+0300 | DEBUG | Saving model to flat file storage. Save #64
2025-02-26T12:56:56.494320+0300 | INFO | [64,     0] loss: 0.016
2025-02-26T12:57:08.359944+0300 | INFO | [64,   100] loss: 1.522
2025-02-26T12:57:19.375689+0300 | INFO | [64,   200] loss: 1.516
2025-02-26T12:57:31.715733+0300 | INFO | [64,   300] loss: 1.515
2025-02-26T12:57:43.464610+0300 | INFO | [64,   400] loss: 1.514
2025-02-26T12:57:54.579297+0300 | INFO | [64,   500] loss: 1.510
2025-02-26T12:58:06.462884+0300 | INFO | [64,   600] loss: 1.525
2025-02-26T12:58:17.961772+0300 | INFO | [64,   700] loss: 1.512
2025-02-26T12:58:29.518431+0300 | INFO | [64,   800] loss: 1.511
2025-02-26T12:58:40.382362+0300 | INFO | [64,   900] loss: 1.515
2025-02-26T12:58:53.026736+0300 | INFO | [64,  1000] loss: 1.526
2025-02-26T12:59:08.581367+0300 | INFO | [64,  1100] loss: 1.513
2025-02-26T12:59:24.737178+0300 | INFO | [64,  1200] loss: 1.520
2025-02-26T12:59:37.718826+0300 | INFO | [64,  1300] loss: 1.513
2025-02-26T12:59:50.362843+0300 | INFO | [64,  1400] loss: 1.515
2025-02-26T13:00:01.115311+0300 | INFO | [64,  1500] loss: 1.537
2025-02-26T13:00:13.008598+0300 | INFO | [64,  1600] loss: 1.529
2025-02-26T13:00:27.482080+0300 | INFO | [64,  1700] loss: 1.518
2025-02-26T13:00:45.084149+0300 | INFO | [64,  1800] loss: 1.517
2025-02-26T13:00:59.244050+0300 | INFO | [64,  1900] loss: 1.521
2025-02-26T13:01:12.533742+0300 | INFO | [64,  2000] loss: 1.514
2025-02-26T13:01:24.563457+0300 | INFO | [64,  2100] loss: 1.514
2025-02-26T13:01:35.684993+0300 | INFO | [64,  2200] loss: 1.515
2025-02-26T13:01:55.476479+0300 | INFO | [64,  2300] loss: 1.511
2025-02-26T13:02:11.669756+0300 | INFO | [64,  2400] loss: 1.517
2025-02-26T13:02:26.575355+0300 | INFO | [64,  2500] loss: 1.520
2025-02-26T13:02:39.523047+0300 | INFO | [64,  2600] loss: 1.522
2025-02-26T13:02:51.456220+0300 | INFO | [64,  2700] loss: 1.521
2025-02-26T13:03:04.805456+0300 | INFO | [64,  2800] loss: 1.513
2025-02-26T13:03:17.081805+0300 | INFO | [64,  2900] loss: 1.512
2025-02-26T13:03:28.229551+0300 | INFO | [64,  3000] loss: 1.530
2025-02-26T13:03:42.070608+0300 | INFO | [64,  3100] loss: 1.528
2025-02-26T13:03:58.744789+0300 | INFO | [64,  3200] loss: 1.529
2025-02-26T13:04:16.071794+0300 | INFO | [64,  3300] loss: 1.517
2025-02-26T13:04:35.698629+0300 | INFO | [64,  3400] loss: 1.516
2025-02-26T13:04:49.802031+0300 | INFO | [64,  3500] loss: 1.529
2025-02-26T13:05:06.028704+0300 | INFO | [64,  3600] loss: 1.510
2025-02-26T13:05:21.837991+0300 | INFO | [64,  3700] loss: 1.522
2025-02-26T13:05:44.459153+0300 | INFO | [64,  3800] loss: 1.515
2025-02-26T13:06:01.889243+0300 | INFO | [64,  3900] loss: 1.512
2025-02-26T13:06:24.251693+0300 | INFO | [64,  4000] loss: 1.532
2025-02-26T13:06:42.920487+0300 | INFO | [64,  4100] loss: 1.517
2025-02-26T13:07:00.668758+0300 | INFO | [64,  4200] loss: 1.523
2025-02-26T13:07:18.571125+0300 | INFO | [64,  4300] loss: 1.521
2025-02-26T13:07:35.836831+0300 | INFO | [64,  4400] loss: 1.519
2025-02-26T13:07:53.812345+0300 | INFO | [64,  4500] loss: 1.523
2025-02-26T13:08:12.158871+0300 | INFO | [64,  4600] loss: 1.515
2025-02-26T13:08:26.098349+0300 | INFO | [64,  4700] loss: 1.518
2025-02-26T13:08:42.797341+0300 | INFO | [64,  4800] loss: 1.522
2025-02-26T13:08:58.402529+0300 | INFO | [64,  4900] loss: 1.512
2025-02-26T13:09:12.791734+0300 | DEBUG | Saving model to flat file storage. Save #64
2025-02-26T13:09:12.816553+0300 | INFO | Averaging client parameters
2025-02-26T13:09:12.822975+0300 | INFO | Updating parameters on client #0
2025-02-26T13:09:32.790819+0300 | DEBUG | Test set: Accuracy: 7862/10000 (79%)
2025-02-26T13:09:32.793987+0300 | DEBUG | Test set: Loss: 1.6738002300262451
2025-02-26T13:09:32.905750+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.79      0.82      1000
           1       0.93      0.89      0.91      1000
           2       0.74      0.69      0.71      1000
           3       0.64      0.63      0.63      1200
           4       0.76      0.80      0.78      1000
           5       0.58      0.56      0.57       800
           6       0.75      0.91      0.82      1000
           7       0.88      0.79      0.83      1000
           8       0.86      0.92      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T13:09:32.909849+0300 | DEBUG | Confusion Matrix:
[[793  13  50  17  20   6  11   8  60  22]
 [  8 890   2   4   2   0   9   5  31  49]
 [ 41   3 686  57  68  44  79  10   7   5]
 [ 10   2  53 755  53 200  80  25  12  10]
 [  7   1  45  48 804  22  52  17   4   0]
 [  8   0  30 212  34 451  36  25   3   1]
 [  4   1  25  36   9   6 912   4   3   0]
 [ 17   0  19  37  62  49  14 790   4   8]
 [ 30   8  13   7   2   1   9   1 918  11]
 [ 22  41   8   6   4   5  21   9  21 863]]
2025-02-26T13:09:32.910856+0300 | DEBUG | Class precision: [0.84361702 0.92805005 0.73684211 0.6403732  0.75992439 0.5752551
 0.74570728 0.8836689  0.8635936  0.89060888]
2025-02-26T13:09:32.912863+0300 | DEBUG | Class recall: [0.793      0.89       0.686      0.62916667 0.804      0.56375
 0.912      0.79       0.918      0.863     ]
2025-02-26T13:09:32.976576+0300 | INFO | Training epoch #65 on client #0
2025-02-26T13:09:32.978532+0300 | DEBUG | Saving model to flat file storage. Save #65
2025-02-26T13:09:33.221346+0300 | INFO | [65,     0] loss: 0.015
2025-02-26T13:09:46.840332+0300 | INFO | [65,   100] loss: 1.510
2025-02-26T13:10:01.778662+0300 | INFO | [65,   200] loss: 1.520
2025-02-26T13:10:15.535229+0300 | INFO | [65,   300] loss: 1.509
2025-02-26T13:10:29.246751+0300 | INFO | [65,   400] loss: 1.516
2025-02-26T13:10:45.403130+0300 | INFO | [65,   500] loss: 1.516
2025-02-26T13:11:05.085892+0300 | INFO | [65,   600] loss: 1.520
2025-02-26T13:11:23.037679+0300 | INFO | [65,   700] loss: 1.513
2025-02-26T13:11:37.972519+0300 | INFO | [65,   800] loss: 1.527
2025-02-26T13:11:51.073790+0300 | INFO | [65,   900] loss: 1.512
2025-02-26T13:12:03.618460+0300 | INFO | [65,  1000] loss: 1.512
2025-02-26T13:12:18.816123+0300 | INFO | [65,  1100] loss: 1.520
2025-02-26T13:12:33.030247+0300 | INFO | [65,  1200] loss: 1.515
2025-02-26T13:12:47.585176+0300 | INFO | [65,  1300] loss: 1.506
2025-02-26T13:13:06.659709+0300 | INFO | [65,  1400] loss: 1.513
2025-02-26T13:13:19.244338+0300 | INFO | [65,  1500] loss: 1.525
2025-02-26T13:13:34.668712+0300 | INFO | [65,  1600] loss: 1.511
2025-02-26T13:13:48.198621+0300 | INFO | [65,  1700] loss: 1.529
2025-02-26T13:14:01.024494+0300 | INFO | [65,  1800] loss: 1.522
2025-02-26T13:14:14.076909+0300 | INFO | [65,  1900] loss: 1.515
2025-02-26T13:14:26.644242+0300 | INFO | [65,  2000] loss: 1.520
2025-02-26T13:14:39.212560+0300 | INFO | [65,  2100] loss: 1.517
2025-02-26T13:14:52.762060+0300 | INFO | [65,  2200] loss: 1.529
2025-02-26T13:15:06.761775+0300 | INFO | [65,  2300] loss: 1.520
2025-02-26T13:15:19.775639+0300 | INFO | [65,  2400] loss: 1.531
2025-02-26T13:15:36.127121+0300 | INFO | [65,  2500] loss: 1.523
2025-02-26T13:15:50.214927+0300 | INFO | [65,  2600] loss: 1.516
2025-02-26T13:16:04.482600+0300 | INFO | [65,  2700] loss: 1.520
2025-02-26T13:16:16.961569+0300 | INFO | [65,  2800] loss: 1.533
2025-02-26T13:16:30.549071+0300 | INFO | [65,  2900] loss: 1.514
2025-02-26T13:16:45.765405+0300 | INFO | [65,  3000] loss: 1.511
2025-02-26T13:16:59.259085+0300 | INFO | [65,  3100] loss: 1.510
2025-02-26T13:17:13.969463+0300 | INFO | [65,  3200] loss: 1.515
2025-02-26T13:17:26.944235+0300 | INFO | [65,  3300] loss: 1.514
2025-02-26T13:17:40.046525+0300 | INFO | [65,  3400] loss: 1.513
2025-02-26T13:17:56.157090+0300 | INFO | [65,  3500] loss: 1.518
2025-02-26T13:18:09.616291+0300 | INFO | [65,  3600] loss: 1.517
2025-02-26T13:18:22.964731+0300 | INFO | [65,  3700] loss: 1.524
2025-02-26T13:18:37.102103+0300 | INFO | [65,  3800] loss: 1.514
2025-02-26T13:18:50.254329+0300 | INFO | [65,  3900] loss: 1.528
2025-02-26T13:19:02.751534+0300 | INFO | [65,  4000] loss: 1.518
2025-02-26T13:19:16.221198+0300 | INFO | [65,  4100] loss: 1.529
2025-02-26T13:19:28.099741+0300 | INFO | [65,  4200] loss: 1.524
2025-02-26T13:19:40.265433+0300 | INFO | [65,  4300] loss: 1.513
2025-02-26T13:19:53.689836+0300 | INFO | [65,  4400] loss: 1.524
2025-02-26T13:20:07.907984+0300 | INFO | [65,  4500] loss: 1.508
2025-02-26T13:20:19.783842+0300 | INFO | [65,  4600] loss: 1.515
2025-02-26T13:20:35.778959+0300 | INFO | [65,  4700] loss: 1.525
2025-02-26T13:20:47.859499+0300 | INFO | [65,  4800] loss: 1.517
2025-02-26T13:21:00.021876+0300 | INFO | [65,  4900] loss: 1.519
2025-02-26T13:21:12.503290+0300 | DEBUG | Saving model to flat file storage. Save #65
2025-02-26T13:21:12.534481+0300 | INFO | Averaging client parameters
2025-02-26T13:21:12.545520+0300 | INFO | Updating parameters on client #0
2025-02-26T13:21:33.503173+0300 | DEBUG | Test set: Accuracy: 7919/10000 (79%)
2025-02-26T13:21:33.505142+0300 | DEBUG | Test set: Loss: 1.6690064668655396
2025-02-26T13:21:33.628386+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.66      0.59      0.62      1200
           4       0.81      0.78      0.79      1000
           5       0.52      0.67      0.59       800
           6       0.82      0.88      0.85      1000
           7       0.90      0.78      0.83      1000
           8       0.87      0.92      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-26T13:21:33.631494+0300 | DEBUG | Confusion Matrix:
[[840  16  23  16  10   9   7   8  49  22]
 [  9 921   1   1   1   0   5   3  25  34]
 [ 56   5 688  53  53  67  53   8   9   8]
 [ 19   6  43 713  51 271  53  18  14  12]
 [ 11   2  51  51 781  40  37  19   7   1]
 [ 13   3  26 163  23 533  14  22   2   1]
 [ 12   3  31  39   9  18 878   3   6   1]
 [ 23   2  15  43  40  76   8 778   6   9]
 [ 38  12   6   6   1   3   3   0 922   9]
 [ 28  56   7   2   1   5   8   7  21 865]]
2025-02-26T13:21:33.631494+0300 | DEBUG | Class precision: [0.80076263 0.89766082 0.77216611 0.65593376 0.80515464 0.52152642
 0.82363977 0.89838337 0.86899152 0.8991684 ]
2025-02-26T13:21:33.633519+0300 | DEBUG | Class recall: [0.84       0.921      0.688      0.59416667 0.781      0.66625
 0.878      0.778      0.922      0.865     ]
2025-02-26T13:21:33.693195+0300 | INFO | Training epoch #66 on client #0
2025-02-26T13:21:33.696204+0300 | DEBUG | Saving model to flat file storage. Save #66
2025-02-26T13:21:33.952029+0300 | INFO | [66,     0] loss: 0.015
2025-02-26T13:21:46.593071+0300 | INFO | [66,   100] loss: 1.513
2025-02-26T13:22:00.744499+0300 | INFO | [66,   200] loss: 1.522
2025-02-26T13:22:13.721247+0300 | INFO | [66,   300] loss: 1.521
2025-02-26T13:22:26.600622+0300 | INFO | [66,   400] loss: 1.511
2025-02-26T13:22:40.261069+0300 | INFO | [66,   500] loss: 1.515
2025-02-26T13:22:53.154245+0300 | INFO | [66,   600] loss: 1.514
2025-02-26T13:23:05.728988+0300 | INFO | [66,   700] loss: 1.502
2025-02-26T13:23:19.052088+0300 | INFO | [66,   800] loss: 1.516
2025-02-26T13:23:33.878220+0300 | INFO | [66,   900] loss: 1.516
2025-02-26T13:23:50.761773+0300 | INFO | [66,  1000] loss: 1.522
2025-02-26T13:24:02.737803+0300 | INFO | [66,  1100] loss: 1.528
2025-02-26T13:24:14.836809+0300 | INFO | [66,  1200] loss: 1.511
2025-02-26T13:24:27.873103+0300 | INFO | [66,  1300] loss: 1.515
2025-02-26T13:24:39.988859+0300 | INFO | [66,  1400] loss: 1.516
2025-02-26T13:24:52.141734+0300 | INFO | [66,  1500] loss: 1.513
2025-02-26T13:25:04.782302+0300 | INFO | [66,  1600] loss: 1.514
2025-02-26T13:25:16.516964+0300 | INFO | [66,  1700] loss: 1.507
2025-02-26T13:25:28.879760+0300 | INFO | [66,  1800] loss: 1.501
2025-02-26T13:25:40.742204+0300 | INFO | [66,  1900] loss: 1.518
2025-02-26T13:25:52.844708+0300 | INFO | [66,  2000] loss: 1.517
2025-02-26T13:26:06.099399+0300 | INFO | [66,  2100] loss: 1.513
2025-02-26T13:26:22.826864+0300 | INFO | [66,  2200] loss: 1.522
2025-02-26T13:26:36.826507+0300 | INFO | [66,  2300] loss: 1.523
2025-02-26T13:26:49.308228+0300 | INFO | [66,  2400] loss: 1.519
2025-02-26T13:27:02.927411+0300 | INFO | [66,  2500] loss: 1.518
2025-02-26T13:27:17.125325+0300 | INFO | [66,  2600] loss: 1.509
2025-02-26T13:27:30.365746+0300 | INFO | [66,  2700] loss: 1.502
2025-02-26T13:27:42.969143+0300 | INFO | [66,  2800] loss: 1.524
2025-02-26T13:27:56.392492+0300 | INFO | [66,  2900] loss: 1.507
2025-02-26T13:28:10.149113+0300 | INFO | [66,  3000] loss: 1.528
2025-02-26T13:28:24.574797+0300 | INFO | [66,  3100] loss: 1.520
2025-02-26T13:28:38.375077+0300 | INFO | [66,  3200] loss: 1.517
2025-02-26T13:28:53.204024+0300 | INFO | [66,  3300] loss: 1.522
2025-02-26T13:29:03.349356+0300 | INFO | [66,  3400] loss: 1.515
2025-02-26T13:29:17.433207+0300 | INFO | [66,  3500] loss: 1.515
2025-02-26T13:29:30.512425+0300 | INFO | [66,  3600] loss: 1.517
2025-02-26T13:29:43.099748+0300 | INFO | [66,  3700] loss: 1.521
2025-02-26T13:29:54.938198+0300 | INFO | [66,  3800] loss: 1.511
2025-02-26T13:30:06.744803+0300 | INFO | [66,  3900] loss: 1.533
2025-02-26T13:30:21.413138+0300 | INFO | [66,  4000] loss: 1.516
2025-02-26T13:30:33.819617+0300 | INFO | [66,  4100] loss: 1.522
2025-02-26T13:30:43.697722+0300 | INFO | [66,  4200] loss: 1.514
2025-02-26T13:30:56.701684+0300 | INFO | [66,  4300] loss: 1.517
2025-02-26T13:31:07.320384+0300 | INFO | [66,  4400] loss: 1.515
2025-02-26T13:31:19.754116+0300 | INFO | [66,  4500] loss: 1.512
2025-02-26T13:31:32.653303+0300 | INFO | [66,  4600] loss: 1.514
2025-02-26T13:31:45.331986+0300 | INFO | [66,  4700] loss: 1.518
2025-02-26T13:31:58.290288+0300 | INFO | [66,  4800] loss: 1.521
2025-02-26T13:32:10.104710+0300 | INFO | [66,  4900] loss: 1.510
2025-02-26T13:32:25.143831+0300 | DEBUG | Saving model to flat file storage. Save #66
2025-02-26T13:32:25.177846+0300 | INFO | Averaging client parameters
2025-02-26T13:32:25.190339+0300 | INFO | Updating parameters on client #0
2025-02-26T13:32:43.859818+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-26T13:32:43.861814+0300 | DEBUG | Test set: Loss: 1.672371506690979
2025-02-26T13:32:43.964135+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.90      0.91      0.91      1000
           2       0.74      0.69      0.72      1000
           3       0.69      0.56      0.62      1200
           4       0.78      0.78      0.78      1000
           5       0.56      0.59      0.57       800
           6       0.80      0.88      0.84      1000
           7       0.81      0.85      0.83      1000
           8       0.87      0.91      0.89      1000
           9       0.86      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T13:32:43.965231+0300 | DEBUG | Confusion Matrix:
[[833  18  27  11  10   7   3   9  55  27]
 [  9 912   0   0   0   1   3   3  19  53]
 [ 55   5 692  32  67  39  61  29  11   9]
 [ 21   5  53 671  64 246  64  43  18  15]
 [ 12   2  50  31 781  21  47  46   8   2]
 [ 13   1  42 166  30 470  23  42   5   8]
 [ 15   5  34  28  12  11 878  10   6   1]
 [ 15   3  17  23  30  43   6 847   4  12]
 [ 32  13   8   6   1   2   3   3 914  18]
 [ 23  46   7   2   1   3  10   8  15 885]]
2025-02-26T13:32:43.972296+0300 | DEBUG | Class precision: [0.81031128 0.9029703  0.74408602 0.69175258 0.78413655 0.55753262
 0.7996357  0.81442308 0.86635071 0.8592233 ]
2025-02-26T13:32:43.976142+0300 | DEBUG | Class recall: [0.833      0.912      0.692      0.55916667 0.781      0.5875
 0.878      0.847      0.914      0.885     ]
2025-02-26T13:32:44.049505+0300 | INFO | Training epoch #67 on client #0
2025-02-26T13:32:44.052544+0300 | DEBUG | Saving model to flat file storage. Save #67
2025-02-26T13:32:44.301142+0300 | INFO | [67,     0] loss: 0.015
2025-02-26T13:32:56.365963+0300 | INFO | [67,   100] loss: 1.515
2025-02-26T13:33:09.210654+0300 | INFO | [67,   200] loss: 1.503
2025-02-26T13:33:22.302094+0300 | INFO | [67,   300] loss: 1.522
2025-02-26T13:33:34.584428+0300 | INFO | [67,   400] loss: 1.509
2025-02-26T13:33:48.366576+0300 | INFO | [67,   500] loss: 1.517
2025-02-26T13:34:05.266526+0300 | INFO | [67,   600] loss: 1.512
2025-02-26T13:34:21.271843+0300 | INFO | [67,   700] loss: 1.519
2025-02-26T13:34:33.034348+0300 | INFO | [67,   800] loss: 1.516
2025-02-26T13:34:45.837527+0300 | INFO | [67,   900] loss: 1.524
2025-02-26T13:34:58.604378+0300 | INFO | [67,  1000] loss: 1.514
2025-02-26T13:35:11.721410+0300 | INFO | [67,  1100] loss: 1.524
2025-02-26T13:35:23.967799+0300 | INFO | [67,  1200] loss: 1.525
2025-02-26T13:35:36.889670+0300 | INFO | [67,  1300] loss: 1.509
2025-02-26T13:35:49.180243+0300 | INFO | [67,  1400] loss: 1.513
2025-02-26T13:36:01.982620+0300 | INFO | [67,  1500] loss: 1.522
2025-02-26T13:36:14.875027+0300 | INFO | [67,  1600] loss: 1.520
2025-02-26T13:36:27.130934+0300 | INFO | [67,  1700] loss: 1.517
2025-02-26T13:36:40.113313+0300 | INFO | [67,  1800] loss: 1.510
2025-02-26T13:36:53.287062+0300 | INFO | [67,  1900] loss: 1.514
2025-02-26T13:37:04.590367+0300 | INFO | [67,  2000] loss: 1.525
2025-02-26T13:37:14.047860+0300 | INFO | [67,  2100] loss: 1.515
2025-02-26T13:37:23.234733+0300 | INFO | [67,  2200] loss: 1.510
2025-02-26T13:37:34.999523+0300 | INFO | [67,  2300] loss: 1.519
2025-02-26T13:37:46.457512+0300 | INFO | [67,  2400] loss: 1.513
2025-02-26T13:37:55.786572+0300 | INFO | [67,  2500] loss: 1.514
2025-02-26T13:38:08.514560+0300 | INFO | [67,  2600] loss: 1.513
2025-02-26T13:38:21.267886+0300 | INFO | [67,  2700] loss: 1.525
2025-02-26T13:38:34.209248+0300 | INFO | [67,  2800] loss: 1.521
2025-02-26T13:38:46.959190+0300 | INFO | [67,  2900] loss: 1.519
2025-02-26T13:39:01.516968+0300 | INFO | [67,  3000] loss: 1.515
2025-02-26T13:39:11.613913+0300 | INFO | [67,  3100] loss: 1.503
2025-02-26T13:39:22.557357+0300 | INFO | [67,  3200] loss: 1.521
2025-02-26T13:39:33.747539+0300 | INFO | [67,  3300] loss: 1.520
2025-02-26T13:39:44.010585+0300 | INFO | [67,  3400] loss: 1.509
2025-02-26T13:39:54.929013+0300 | INFO | [67,  3500] loss: 1.502
2025-02-26T13:40:06.036131+0300 | INFO | [67,  3600] loss: 1.517
2025-02-26T13:40:16.264270+0300 | INFO | [67,  3700] loss: 1.519
2025-02-26T13:40:28.515637+0300 | INFO | [67,  3800] loss: 1.501
2025-02-26T13:40:39.381867+0300 | INFO | [67,  3900] loss: 1.522
2025-02-26T13:40:49.249263+0300 | INFO | [67,  4000] loss: 1.533
2025-02-26T13:40:58.966165+0300 | INFO | [67,  4100] loss: 1.511
2025-02-26T13:41:10.039818+0300 | INFO | [67,  4200] loss: 1.516
2025-02-26T13:41:24.495991+0300 | INFO | [67,  4300] loss: 1.516
2025-02-26T13:41:37.110317+0300 | INFO | [67,  4400] loss: 1.514
2025-02-26T13:41:50.293435+0300 | INFO | [67,  4500] loss: 1.519
2025-02-26T13:42:02.737113+0300 | INFO | [67,  4600] loss: 1.524
2025-02-26T13:42:16.126874+0300 | INFO | [67,  4700] loss: 1.533
2025-02-26T13:42:26.533750+0300 | INFO | [67,  4800] loss: 1.521
2025-02-26T13:42:39.493554+0300 | INFO | [67,  4900] loss: 1.522
2025-02-26T13:42:51.202073+0300 | DEBUG | Saving model to flat file storage. Save #67
2025-02-26T13:42:51.230072+0300 | INFO | Averaging client parameters
2025-02-26T13:42:51.240076+0300 | INFO | Updating parameters on client #0
2025-02-26T13:43:09.179070+0300 | DEBUG | Test set: Accuracy: 7845/10000 (78%)
2025-02-26T13:43:09.180130+0300 | DEBUG | Test set: Loss: 1.6760960817337036
2025-02-26T13:43:09.271883+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1000
           1       0.92      0.90      0.91      1000
           2       0.75      0.67      0.71      1000
           3       0.66      0.60      0.63      1200
           4       0.80      0.76      0.78      1000
           5       0.53      0.59      0.56       800
           6       0.81      0.88      0.84      1000
           7       0.88      0.81      0.84      1000
           8       0.82      0.94      0.87      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-26T13:43:09.273318+0300 | DEBUG | Confusion Matrix:
[[813  13  27  11  11   8   3   6  84  24]
 [ 12 899   1   2   1   0   3   2  31  49]
 [ 60   4 672  46  59  55  65  12  15  12]
 [ 14   6  53 723  46 248  49  24  20  17]
 [ 13   4  47  53 760  34  52  23   6   8]
 [ 11   2  37 189  25 474  18  32   9   3]
 [ 14   2  33  33   8  15 882   4   8   1]
 [ 21   2  16  36  37  52   6 808  11  11]
 [ 20   9   9   5   1   3   4   1 939   9]
 [ 26  40   7   5   2   3  11   7  24 875]]
2025-02-26T13:43:09.276270+0300 | DEBUG | Class precision: [0.80976096 0.91641182 0.74501109 0.65548504 0.8        0.53139013
 0.80695334 0.87921654 0.81865737 0.86719524]
2025-02-26T13:43:09.276780+0300 | DEBUG | Class recall: [0.813  0.899  0.672  0.6025 0.76   0.5925 0.882  0.808  0.939  0.875 ]
2025-02-26T13:43:09.319754+0300 | INFO | Training epoch #68 on client #0
2025-02-26T13:43:09.322256+0300 | DEBUG | Saving model to flat file storage. Save #68
2025-02-26T13:43:09.563114+0300 | INFO | [68,     0] loss: 0.015
2025-02-26T13:43:26.308984+0300 | INFO | [68,   100] loss: 1.518
2025-02-26T13:43:39.264749+0300 | INFO | [68,   200] loss: 1.511
2025-02-26T13:43:51.507817+0300 | INFO | [68,   300] loss: 1.501
2025-02-26T13:44:00.685284+0300 | INFO | [68,   400] loss: 1.514
2025-02-26T13:44:14.315475+0300 | INFO | [68,   500] loss: 1.505
2025-02-26T13:44:24.543947+0300 | INFO | [68,   600] loss: 1.503
2025-02-26T13:44:34.262044+0300 | INFO | [68,   700] loss: 1.519
2025-02-26T13:44:43.661254+0300 | INFO | [68,   800] loss: 1.519
2025-02-26T13:44:53.281914+0300 | INFO | [68,   900] loss: 1.526
2025-02-26T13:45:02.732608+0300 | INFO | [68,  1000] loss: 1.521
2025-02-26T13:45:13.621389+0300 | INFO | [68,  1100] loss: 1.518
2025-02-26T13:45:23.570050+0300 | INFO | [68,  1200] loss: 1.518
2025-02-26T13:45:33.187794+0300 | INFO | [68,  1300] loss: 1.520
2025-02-26T13:45:43.335389+0300 | INFO | [68,  1400] loss: 1.535
2025-02-26T13:45:53.450456+0300 | INFO | [68,  1500] loss: 1.522
2025-02-26T13:46:04.751545+0300 | INFO | [68,  1600] loss: 1.511
2025-02-26T13:46:15.054704+0300 | INFO | [68,  1700] loss: 1.519
2025-02-26T13:46:27.741819+0300 | INFO | [68,  1800] loss: 1.509
2025-02-26T13:46:41.842174+0300 | INFO | [68,  1900] loss: 1.508
2025-02-26T13:46:56.456495+0300 | INFO | [68,  2000] loss: 1.510
2025-02-26T13:47:14.603142+0300 | INFO | [68,  2100] loss: 1.498
2025-02-26T13:47:30.164505+0300 | INFO | [68,  2200] loss: 1.513
2025-02-26T13:47:45.416312+0300 | INFO | [68,  2300] loss: 1.517
2025-02-26T13:48:01.392367+0300 | INFO | [68,  2400] loss: 1.518
2025-02-26T13:48:14.961443+0300 | INFO | [68,  2500] loss: 1.513
2025-02-26T13:48:28.444816+0300 | INFO | [68,  2600] loss: 1.513
2025-02-26T13:48:38.205074+0300 | INFO | [68,  2700] loss: 1.510
2025-02-26T13:48:47.769787+0300 | INFO | [68,  2800] loss: 1.516
2025-02-26T13:48:58.397320+0300 | INFO | [68,  2900] loss: 1.518
2025-02-26T13:49:13.053699+0300 | INFO | [68,  3000] loss: 1.515
2025-02-26T13:49:25.217172+0300 | INFO | [68,  3100] loss: 1.510
2025-02-26T13:49:37.417405+0300 | INFO | [68,  3200] loss: 1.511
2025-02-26T13:49:50.279484+0300 | INFO | [68,  3300] loss: 1.514
2025-02-26T13:50:02.926623+0300 | INFO | [68,  3400] loss: 1.519
2025-02-26T13:50:16.252192+0300 | INFO | [68,  3500] loss: 1.516
2025-02-26T13:50:29.758376+0300 | INFO | [68,  3600] loss: 1.528
2025-02-26T13:50:39.890254+0300 | INFO | [68,  3700] loss: 1.527
2025-02-26T13:50:52.746005+0300 | INFO | [68,  3800] loss: 1.510
2025-02-26T13:51:06.242035+0300 | INFO | [68,  3900] loss: 1.533
2025-02-26T13:51:19.225336+0300 | INFO | [68,  4000] loss: 1.522
2025-02-26T13:51:32.858131+0300 | INFO | [68,  4100] loss: 1.505
2025-02-26T13:51:44.985598+0300 | INFO | [68,  4200] loss: 1.526
2025-02-26T13:51:57.512456+0300 | INFO | [68,  4300] loss: 1.512
2025-02-26T13:52:10.677448+0300 | INFO | [68,  4400] loss: 1.521
2025-02-26T13:52:24.211631+0300 | INFO | [68,  4500] loss: 1.511
2025-02-26T13:52:37.812255+0300 | INFO | [68,  4600] loss: 1.504
2025-02-26T13:52:54.446046+0300 | INFO | [68,  4700] loss: 1.520
2025-02-26T13:53:13.280016+0300 | INFO | [68,  4800] loss: 1.511
2025-02-26T13:53:25.918928+0300 | INFO | [68,  4900] loss: 1.506
2025-02-26T13:53:41.268608+0300 | DEBUG | Saving model to flat file storage. Save #68
2025-02-26T13:53:41.301606+0300 | INFO | Averaging client parameters
2025-02-26T13:53:41.316606+0300 | INFO | Updating parameters on client #0
2025-02-26T13:54:04.509243+0300 | DEBUG | Test set: Accuracy: 7859/10000 (79%)
2025-02-26T13:54:04.510736+0300 | DEBUG | Test set: Loss: 1.674316644668579
2025-02-26T13:54:04.662132+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.92      0.89      0.90      1000
           2       0.78      0.64      0.70      1000
           3       0.65      0.58      0.61      1200
           4       0.79      0.78      0.79      1000
           5       0.49      0.67      0.56       800
           6       0.85      0.86      0.86      1000
           7       0.87      0.81      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T13:54:04.666178+0300 | DEBUG | Confusion Matrix:
[[849  15  28  15  12   9   3  11  38  20]
 [ 13 886   0   2   0   1   5   1  28  64]
 [ 63   3 644  57  69  82  50  14  12   6]
 [ 17   3  40 699  46 305  35  28  15  12]
 [ 11   1  35  51 784  50  29  28   8   3]
 [  8   1  22 165  24 533  14  28   2   3]
 [ 10   2  37  51  12  20 859   4   4   1]
 [ 18   1   9  29  39  80   2 808   5   9]
 [ 39  11   8   4   1   7   4   1 917   8]
 [ 23  38   6   8   2   4   8  10  21 880]]
2025-02-26T13:54:04.670181+0300 | DEBUG | Class precision: [0.80780209 0.9219563  0.77683957 0.6466235  0.79271992 0.48854262
 0.85133796 0.86602358 0.87333333 0.87475149]
2025-02-26T13:54:04.674777+0300 | DEBUG | Class recall: [0.849   0.886   0.644   0.5825  0.784   0.66625 0.859   0.808   0.917
 0.88   ]
2025-02-26T13:54:04.740892+0300 | INFO | Training epoch #69 on client #0
2025-02-26T13:54:04.744887+0300 | DEBUG | Saving model to flat file storage. Save #69
2025-02-26T13:54:05.068549+0300 | INFO | [69,     0] loss: 0.016
2025-02-26T13:54:18.449323+0300 | INFO | [69,   100] loss: 1.517
2025-02-26T13:54:31.368421+0300 | INFO | [69,   200] loss: 1.523
2025-02-26T13:54:43.460653+0300 | INFO | [69,   300] loss: 1.514
2025-02-26T13:54:55.963367+0300 | INFO | [69,   400] loss: 1.515
2025-02-26T13:55:08.578147+0300 | INFO | [69,   500] loss: 1.506
2025-02-26T13:55:20.908051+0300 | INFO | [69,   600] loss: 1.503
2025-02-26T13:55:33.261947+0300 | INFO | [69,   700] loss: 1.517
2025-02-26T13:55:46.461272+0300 | INFO | [69,   800] loss: 1.515
2025-02-26T13:55:59.695224+0300 | INFO | [69,   900] loss: 1.513
2025-02-26T13:56:14.645619+0300 | INFO | [69,  1000] loss: 1.512
2025-02-26T13:56:27.775982+0300 | INFO | [69,  1100] loss: 1.514
2025-02-26T13:56:41.744693+0300 | INFO | [69,  1200] loss: 1.521
2025-02-26T13:56:56.348363+0300 | INFO | [69,  1300] loss: 1.512
2025-02-26T13:57:10.029138+0300 | INFO | [69,  1400] loss: 1.510
2025-02-26T13:57:20.875201+0300 | INFO | [69,  1500] loss: 1.499
2025-02-26T13:57:32.986462+0300 | INFO | [69,  1600] loss: 1.509
2025-02-26T13:57:44.911752+0300 | INFO | [69,  1700] loss: 1.517
2025-02-26T13:57:54.510005+0300 | INFO | [69,  1800] loss: 1.512
2025-02-26T13:58:05.726674+0300 | INFO | [69,  1900] loss: 1.508
2025-02-26T13:58:18.694904+0300 | INFO | [69,  2000] loss: 1.505
2025-02-26T13:58:29.729157+0300 | INFO | [69,  2100] loss: 1.520
2025-02-26T13:58:41.124372+0300 | INFO | [69,  2200] loss: 1.506
2025-02-26T13:58:53.540045+0300 | INFO | [69,  2300] loss: 1.508
2025-02-26T13:59:07.066509+0300 | INFO | [69,  2400] loss: 1.513
2025-02-26T13:59:19.355515+0300 | INFO | [69,  2500] loss: 1.515
2025-02-26T13:59:30.176996+0300 | INFO | [69,  2600] loss: 1.517
2025-02-26T13:59:42.148498+0300 | INFO | [69,  2700] loss: 1.511
2025-02-26T13:59:56.277820+0300 | INFO | [69,  2800] loss: 1.513
2025-02-26T14:00:09.018925+0300 | INFO | [69,  2900] loss: 1.509
2025-02-26T14:00:21.413388+0300 | INFO | [69,  3000] loss: 1.523
2025-02-26T14:00:36.432591+0300 | INFO | [69,  3100] loss: 1.518
2025-02-26T14:00:49.414481+0300 | INFO | [69,  3200] loss: 1.514
2025-02-26T14:01:03.378046+0300 | INFO | [69,  3300] loss: 1.512
2025-02-26T14:01:16.260346+0300 | INFO | [69,  3400] loss: 1.525
2025-02-26T14:01:28.827637+0300 | INFO | [69,  3500] loss: 1.518
2025-02-26T14:01:41.099197+0300 | INFO | [69,  3600] loss: 1.509
2025-02-26T14:01:53.900306+0300 | INFO | [69,  3700] loss: 1.533
2025-02-26T14:02:06.422990+0300 | INFO | [69,  3800] loss: 1.518
2025-02-26T14:02:19.463171+0300 | INFO | [69,  3900] loss: 1.519
2025-02-26T14:02:34.070145+0300 | INFO | [69,  4000] loss: 1.516
2025-02-26T14:02:47.163328+0300 | INFO | [69,  4100] loss: 1.502
2025-02-26T14:03:00.149162+0300 | INFO | [69,  4200] loss: 1.516
2025-02-26T14:03:13.320253+0300 | INFO | [69,  4300] loss: 1.527
2025-02-26T14:03:25.635834+0300 | INFO | [69,  4400] loss: 1.506
2025-02-26T14:03:45.360527+0300 | INFO | [69,  4500] loss: 1.528
2025-02-26T14:03:58.003129+0300 | INFO | [69,  4600] loss: 1.518
2025-02-26T14:04:10.251198+0300 | INFO | [69,  4700] loss: 1.514
2025-02-26T14:04:24.086441+0300 | INFO | [69,  4800] loss: 1.515
2025-02-26T14:04:36.948206+0300 | INFO | [69,  4900] loss: 1.509
2025-02-26T14:04:49.364209+0300 | DEBUG | Saving model to flat file storage. Save #69
2025-02-26T14:04:49.393309+0300 | INFO | Averaging client parameters
2025-02-26T14:04:49.403491+0300 | INFO | Updating parameters on client #0
2025-02-26T14:05:06.726316+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-26T14:05:06.727319+0300 | DEBUG | Test set: Loss: 1.6729075908660889
2025-02-26T14:05:06.798976+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.76      0.67      0.71      1000
           3       0.69      0.55      0.61      1200
           4       0.76      0.81      0.78      1000
           5       0.54      0.62      0.58       800
           6       0.78      0.89      0.83      1000
           7       0.86      0.82      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T14:05:06.801415+0300 | DEBUG | Confusion Matrix:
[[838  19  40   7  13   8   7   6  41  21]
 [ 10 926   0   2   1   0   4   2  13  42]
 [ 53   4 667  38  75  57  71  20   8   7]
 [ 23   3  41 660  62 269  76  36  17  13]
 [  8   2  40  29 808  29  53  23   7   1]
 [ 12   1  30 162  32 497  28  31   3   4]
 [ 13   4  31  25  16  12 887   5   6   1]
 [ 20   3  13  28  47  46   7 818   7  11]
 [ 42  22   8   5   3   2   4   1 904   9]
 [ 31  56   6   2   3   3   5   8  17 869]]
2025-02-26T14:05:06.802807+0300 | DEBUG | Class precision: [0.79809524 0.89038462 0.76141553 0.68893528 0.76226415 0.53846154
 0.77670753 0.86105263 0.88367546 0.88854806]
2025-02-26T14:05:06.805027+0300 | DEBUG | Class recall: [0.838   0.926   0.667   0.55    0.808   0.62125 0.887   0.818   0.904
 0.869  ]
2025-02-26T14:05:06.868755+0300 | INFO | Training epoch #70 on client #0
2025-02-26T14:05:06.870756+0300 | DEBUG | Saving model to flat file storage. Save #70
2025-02-26T14:05:07.118955+0300 | INFO | [70,     0] loss: 0.015
2025-02-26T14:05:20.508300+0300 | INFO | [70,   100] loss: 1.509
2025-02-26T14:05:33.723532+0300 | INFO | [70,   200] loss: 1.508
2025-02-26T14:05:46.544240+0300 | INFO | [70,   300] loss: 1.517
2025-02-26T14:05:59.709284+0300 | INFO | [70,   400] loss: 1.523
2025-02-26T14:06:11.804105+0300 | INFO | [70,   500] loss: 1.525
2025-02-26T14:06:24.808407+0300 | INFO | [70,   600] loss: 1.507
2025-02-26T14:06:37.675628+0300 | INFO | [70,   700] loss: 1.511
2025-02-26T14:06:52.444763+0300 | INFO | [70,   800] loss: 1.503
2025-02-26T14:07:05.944336+0300 | INFO | [70,   900] loss: 1.516
2025-02-26T14:07:18.664310+0300 | INFO | [70,  1000] loss: 1.514
2025-02-26T14:07:29.972789+0300 | INFO | [70,  1100] loss: 1.517
2025-02-26T14:07:42.590719+0300 | INFO | [70,  1200] loss: 1.518
2025-02-26T14:07:55.053645+0300 | INFO | [70,  1300] loss: 1.512
2025-02-26T14:08:08.330096+0300 | INFO | [70,  1400] loss: 1.509
2025-02-26T14:08:19.451255+0300 | INFO | [70,  1500] loss: 1.519
2025-02-26T14:08:31.102771+0300 | INFO | [70,  1600] loss: 1.515
2025-02-26T14:08:43.629604+0300 | INFO | [70,  1700] loss: 1.509
2025-02-26T14:08:55.621272+0300 | INFO | [70,  1800] loss: 1.526
2025-02-26T14:09:07.292730+0300 | INFO | [70,  1900] loss: 1.513
2025-02-26T14:09:18.520318+0300 | INFO | [70,  2000] loss: 1.515
2025-02-26T14:09:30.201777+0300 | INFO | [70,  2100] loss: 1.508
2025-02-26T14:09:42.322611+0300 | INFO | [70,  2200] loss: 1.507
2025-02-26T14:09:53.364520+0300 | INFO | [70,  2300] loss: 1.515
2025-02-26T14:10:05.505161+0300 | INFO | [70,  2400] loss: 1.516
2025-02-26T14:10:17.510813+0300 | INFO | [70,  2500] loss: 1.514
2025-02-26T14:10:29.117226+0300 | INFO | [70,  2600] loss: 1.525
2025-02-26T14:10:41.856061+0300 | INFO | [70,  2700] loss: 1.513
2025-02-26T14:10:55.866947+0300 | INFO | [70,  2800] loss: 1.515
2025-02-26T14:11:09.151664+0300 | INFO | [70,  2900] loss: 1.511
2025-02-26T14:11:21.592808+0300 | INFO | [70,  3000] loss: 1.515
2025-02-26T14:11:34.155199+0300 | INFO | [70,  3100] loss: 1.516
2025-02-26T14:11:46.298443+0300 | INFO | [70,  3200] loss: 1.514
2025-02-26T14:11:59.720539+0300 | INFO | [70,  3300] loss: 1.513
2025-02-26T14:12:12.292296+0300 | INFO | [70,  3400] loss: 1.506
2025-02-26T14:12:24.590469+0300 | INFO | [70,  3500] loss: 1.510
2025-02-26T14:12:37.272607+0300 | INFO | [70,  3600] loss: 1.516
2025-02-26T14:12:49.204155+0300 | INFO | [70,  3700] loss: 1.517
2025-02-26T14:13:02.983280+0300 | INFO | [70,  3800] loss: 1.515
2025-02-26T14:13:16.704608+0300 | INFO | [70,  3900] loss: 1.509
2025-02-26T14:13:33.445693+0300 | INFO | [70,  4000] loss: 1.510
2025-02-26T14:13:54.775547+0300 | INFO | [70,  4100] loss: 1.511
2025-02-26T14:14:11.609909+0300 | INFO | [70,  4200] loss: 1.514
2025-02-26T14:14:29.700654+0300 | INFO | [70,  4300] loss: 1.508
2025-02-26T14:14:41.296143+0300 | INFO | [70,  4400] loss: 1.516
2025-02-26T14:14:52.822900+0300 | INFO | [70,  4500] loss: 1.507
2025-02-26T14:15:04.974367+0300 | INFO | [70,  4600] loss: 1.512
2025-02-26T14:15:16.675878+0300 | INFO | [70,  4700] loss: 1.518
2025-02-26T14:15:27.910997+0300 | INFO | [70,  4800] loss: 1.512
2025-02-26T14:15:40.070018+0300 | INFO | [70,  4900] loss: 1.506
2025-02-26T14:15:52.259818+0300 | DEBUG | Saving model to flat file storage. Save #70
2025-02-26T14:15:52.284431+0300 | INFO | Averaging client parameters
2025-02-26T14:15:52.290600+0300 | INFO | Updating parameters on client #0
2025-02-26T14:16:08.783134+0300 | DEBUG | Test set: Accuracy: 7914/10000 (79%)
2025-02-26T14:16:08.784467+0300 | DEBUG | Test set: Loss: 1.6691254377365112
2025-02-26T14:16:08.896972+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.82      0.83      1000
           1       0.91      0.91      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.66      0.58      0.62      1200
           4       0.80      0.80      0.80      1000
           5       0.54      0.59      0.56       800
           6       0.82      0.87      0.84      1000
           7       0.85      0.84      0.84      1000
           8       0.85      0.93      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T14:16:08.900972+0300 | DEBUG | Confusion Matrix:
[[825  21  35   7  12   4   3   5  61  27]
 [  7 908   1   1   0   0   4   2  27  50]
 [ 53   4 690  45  66  49  54  20  11   8]
 [ 17   3  46 697  50 265  51  41  17  13]
 [  7   2  43  45 800  29  41  23   7   3]
 [  9   1  36 181  25 476  27  40   4   1]
 [ 10   4  43  40  10  13 870   4   5   1]
 [ 16   2  14  23  36  45   6 839   7  12]
 [ 24  14   6   7   2   1   3   4 927  12]
 [ 28  38   5   6   2   3   7  10  19 882]]
2025-02-26T14:16:08.903458+0300 | DEBUG | Class precision: [0.82831325 0.9107322  0.7508161  0.66254753 0.79760718 0.53785311
 0.81613508 0.84919028 0.85437788 0.8741328 ]
2025-02-26T14:16:08.904786+0300 | DEBUG | Class recall: [0.825      0.908      0.69       0.58083333 0.8        0.595
 0.87       0.839      0.927      0.882     ]
2025-02-26T14:16:08.952997+0300 | INFO | Training epoch #71 on client #0
2025-02-26T14:16:08.954986+0300 | DEBUG | Saving model to flat file storage. Save #71
2025-02-26T14:16:09.178400+0300 | INFO | [71,     0] loss: 0.015
2025-02-26T14:16:20.745399+0300 | INFO | [71,   100] loss: 1.512
2025-02-26T14:16:32.834252+0300 | INFO | [71,   200] loss: 1.512
2025-02-26T14:16:45.251033+0300 | INFO | [71,   300] loss: 1.512
2025-02-26T14:16:57.030936+0300 | INFO | [71,   400] loss: 1.516
2025-02-26T14:17:09.099690+0300 | INFO | [71,   500] loss: 1.505
2025-02-26T14:17:21.026880+0300 | INFO | [71,   600] loss: 1.504
2025-02-26T14:17:32.412996+0300 | INFO | [71,   700] loss: 1.516
2025-02-26T14:17:44.528834+0300 | INFO | [71,   800] loss: 1.513
2025-02-26T14:17:57.353200+0300 | INFO | [71,   900] loss: 1.497
2025-02-26T14:18:08.307484+0300 | INFO | [71,  1000] loss: 1.511
2025-02-26T14:18:21.007768+0300 | INFO | [71,  1100] loss: 1.514
2025-02-26T14:18:32.474781+0300 | INFO | [71,  1200] loss: 1.514
2025-02-26T14:18:46.807010+0300 | INFO | [71,  1300] loss: 1.511
2025-02-26T14:19:01.198448+0300 | INFO | [71,  1400] loss: 1.507
2025-02-26T14:19:13.452264+0300 | INFO | [71,  1500] loss: 1.509
2025-02-26T14:19:26.126207+0300 | INFO | [71,  1600] loss: 1.511
2025-02-26T14:19:39.004616+0300 | INFO | [71,  1700] loss: 1.512
2025-02-26T14:19:51.609197+0300 | INFO | [71,  1800] loss: 1.521
2025-02-26T14:20:04.345210+0300 | INFO | [71,  1900] loss: 1.521
2025-02-26T14:20:16.234248+0300 | INFO | [71,  2000] loss: 1.516
2025-02-26T14:20:31.025589+0300 | INFO | [71,  2100] loss: 1.509
2025-02-26T14:20:45.243753+0300 | INFO | [71,  2200] loss: 1.518
2025-02-26T14:21:04.178713+0300 | INFO | [71,  2300] loss: 1.522
2025-02-26T14:21:16.653349+0300 | INFO | [71,  2400] loss: 1.513
2025-02-26T14:21:30.416145+0300 | INFO | [71,  2500] loss: 1.518
2025-02-26T14:21:43.440906+0300 | INFO | [71,  2600] loss: 1.518
2025-02-26T14:21:56.686275+0300 | INFO | [71,  2700] loss: 1.520
2025-02-26T14:22:08.738409+0300 | INFO | [71,  2800] loss: 1.507
2025-02-26T14:22:21.127441+0300 | INFO | [71,  2900] loss: 1.500
2025-02-26T14:22:34.056986+0300 | INFO | [71,  3000] loss: 1.521
2025-02-26T14:22:47.124446+0300 | INFO | [71,  3100] loss: 1.513
2025-02-26T14:22:59.889691+0300 | INFO | [71,  3200] loss: 1.508
2025-02-26T14:23:12.822962+0300 | INFO | [71,  3300] loss: 1.510
2025-02-26T14:23:26.735485+0300 | INFO | [71,  3400] loss: 1.506
2025-02-26T14:23:40.234415+0300 | INFO | [71,  3500] loss: 1.507
2025-02-26T14:23:55.082827+0300 | INFO | [71,  3600] loss: 1.511
2025-02-26T14:24:13.010218+0300 | INFO | [71,  3700] loss: 1.511
2025-02-26T14:24:26.155357+0300 | INFO | [71,  3800] loss: 1.514
2025-02-26T14:24:40.224747+0300 | INFO | [71,  3900] loss: 1.516
2025-02-26T14:24:53.506572+0300 | INFO | [71,  4000] loss: 1.518
2025-02-26T14:25:06.826515+0300 | INFO | [71,  4100] loss: 1.516
2025-02-26T14:25:20.506891+0300 | INFO | [71,  4200] loss: 1.518
2025-02-26T14:25:33.227827+0300 | INFO | [71,  4300] loss: 1.513
2025-02-26T14:25:46.353275+0300 | INFO | [71,  4400] loss: 1.510
2025-02-26T14:26:00.001040+0300 | INFO | [71,  4500] loss: 1.527
2025-02-26T14:26:13.114698+0300 | INFO | [71,  4600] loss: 1.520
2025-02-26T14:26:25.479860+0300 | INFO | [71,  4700] loss: 1.505
2025-02-26T14:26:38.219465+0300 | INFO | [71,  4800] loss: 1.522
2025-02-26T14:26:51.250294+0300 | INFO | [71,  4900] loss: 1.513
2025-02-26T14:27:03.980415+0300 | DEBUG | Saving model to flat file storage. Save #71
2025-02-26T14:27:04.002265+0300 | INFO | Averaging client parameters
2025-02-26T14:27:04.013166+0300 | INFO | Updating parameters on client #0
2025-02-26T14:27:22.568158+0300 | DEBUG | Test set: Accuracy: 7885/10000 (79%)
2025-02-26T14:27:22.569291+0300 | DEBUG | Test set: Loss: 1.6721833944320679
2025-02-26T14:27:22.657626+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.74      0.68      0.71      1000
           3       0.64      0.61      0.62      1200
           4       0.84      0.75      0.79      1000
           5       0.56      0.59      0.57       800
           6       0.81      0.88      0.84      1000
           7       0.84      0.83      0.84      1000
           8       0.89      0.90      0.89      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T14:27:22.660682+0300 | DEBUG | Confusion Matrix:
[[851  21  31  10  11   3   6   6  36  25]
 [  8 928   0   1   0   0   5   2  16  40]
 [ 72   5 680  59  47  45  57  20   8   7]
 [ 18   6  54 728  37 234  49  42  14  18]
 [ 16   2  50  62 747  28  47  37   7   4]
 [  9   4  38 197  16 472  20  36   4   4]
 [ 12   5  34  37   7  13 880   5   6   1]
 [ 16   4  21  33  26  45   6 833   4  12]
 [ 44  19   5   7   2   1   6   2 898  16]
 [ 25  63   5   4   1   3   8   7  16 868]]
2025-02-26T14:27:22.663110+0300 | DEBUG | Class precision: [0.7945845  0.87795648 0.74074074 0.6397188  0.83557047 0.55924171
 0.81180812 0.84141414 0.88999009 0.87236181]
2025-02-26T14:27:22.663965+0300 | DEBUG | Class recall: [0.851      0.928      0.68       0.60666667 0.747      0.59
 0.88       0.833      0.898      0.868     ]
2025-02-26T14:27:22.716937+0300 | INFO | Training epoch #72 on client #0
2025-02-26T14:27:22.718433+0300 | DEBUG | Saving model to flat file storage. Save #72
2025-02-26T14:27:22.965708+0300 | INFO | [72,     0] loss: 0.016
2025-02-26T14:27:39.051454+0300 | INFO | [72,   100] loss: 1.503
2025-02-26T14:27:53.039735+0300 | INFO | [72,   200] loss: 1.525
2025-02-26T14:28:08.414087+0300 | INFO | [72,   300] loss: 1.518
2025-02-26T14:28:22.152881+0300 | INFO | [72,   400] loss: 1.509
2025-02-26T14:28:34.809418+0300 | INFO | [72,   500] loss: 1.519
2025-02-26T14:28:48.511296+0300 | INFO | [72,   600] loss: 1.512
2025-02-26T14:29:02.731762+0300 | INFO | [72,   700] loss: 1.520
2025-02-26T14:29:16.234733+0300 | INFO | [72,   800] loss: 1.508
2025-02-26T14:29:29.592426+0300 | INFO | [72,   900] loss: 1.517
2025-02-26T14:29:43.295668+0300 | INFO | [72,  1000] loss: 1.506
2025-02-26T14:29:57.865319+0300 | INFO | [72,  1100] loss: 1.515
2025-02-26T14:30:11.775148+0300 | INFO | [72,  1200] loss: 1.510
2025-02-26T14:30:26.373495+0300 | INFO | [72,  1300] loss: 1.519
2025-02-26T14:30:40.541267+0300 | INFO | [72,  1400] loss: 1.512
2025-02-26T14:30:54.947428+0300 | INFO | [72,  1500] loss: 1.505
2025-02-26T14:31:09.054532+0300 | INFO | [72,  1600] loss: 1.513
2025-02-26T14:31:23.139284+0300 | INFO | [72,  1700] loss: 1.505
2025-02-26T14:31:39.877548+0300 | INFO | [72,  1800] loss: 1.511
2025-02-26T14:31:55.382230+0300 | INFO | [72,  1900] loss: 1.509
2025-02-26T14:32:09.713974+0300 | INFO | [72,  2000] loss: 1.508
2025-02-26T14:32:22.485721+0300 | INFO | [72,  2100] loss: 1.496
2025-02-26T14:32:35.795274+0300 | INFO | [72,  2200] loss: 1.497
2025-02-26T14:32:48.960436+0300 | INFO | [72,  2300] loss: 1.529
2025-02-26T14:33:02.867807+0300 | INFO | [72,  2400] loss: 1.507
2025-02-26T14:33:16.355427+0300 | INFO | [72,  2500] loss: 1.514
2025-02-26T14:33:30.079914+0300 | INFO | [72,  2600] loss: 1.509
2025-02-26T14:33:43.043478+0300 | INFO | [72,  2700] loss: 1.516
2025-02-26T14:33:56.045087+0300 | INFO | [72,  2800] loss: 1.509
2025-02-26T14:34:10.694412+0300 | INFO | [72,  2900] loss: 1.510
2025-02-26T14:34:23.895274+0300 | INFO | [72,  3000] loss: 1.518
2025-02-26T14:34:37.205383+0300 | INFO | [72,  3100] loss: 1.512
2025-02-26T14:34:52.642606+0300 | INFO | [72,  3200] loss: 1.527
2025-02-26T14:35:07.355513+0300 | INFO | [72,  3300] loss: 1.509
2025-02-26T14:35:27.294624+0300 | INFO | [72,  3400] loss: 1.522
2025-02-26T14:35:41.165166+0300 | INFO | [72,  3500] loss: 1.520
2025-02-26T14:35:54.896813+0300 | INFO | [72,  3600] loss: 1.510
2025-02-26T14:36:08.775263+0300 | INFO | [72,  3700] loss: 1.515
2025-02-26T14:36:22.187312+0300 | INFO | [72,  3800] loss: 1.502
2025-02-26T14:36:35.852301+0300 | INFO | [72,  3900] loss: 1.513
2025-02-26T14:36:50.598057+0300 | INFO | [72,  4000] loss: 1.517
2025-02-26T14:37:04.591676+0300 | INFO | [72,  4100] loss: 1.498
2025-02-26T14:37:18.875762+0300 | INFO | [72,  4200] loss: 1.521
2025-02-26T14:37:33.051470+0300 | INFO | [72,  4300] loss: 1.526
2025-02-26T14:37:47.856933+0300 | INFO | [72,  4400] loss: 1.533
2025-02-26T14:38:01.916169+0300 | INFO | [72,  4500] loss: 1.510
2025-02-26T14:38:16.043642+0300 | INFO | [72,  4600] loss: 1.514
2025-02-26T14:38:29.263613+0300 | INFO | [72,  4700] loss: 1.505
2025-02-26T14:38:44.683267+0300 | INFO | [72,  4800] loss: 1.511
2025-02-26T14:38:57.834085+0300 | INFO | [72,  4900] loss: 1.517
2025-02-26T14:39:12.914607+0300 | DEBUG | Saving model to flat file storage. Save #72
2025-02-26T14:39:12.949036+0300 | INFO | Averaging client parameters
2025-02-26T14:39:12.976390+0300 | INFO | Updating parameters on client #0
2025-02-26T14:39:31.281390+0300 | DEBUG | Test set: Accuracy: 7834/10000 (78%)
2025-02-26T14:39:31.282382+0300 | DEBUG | Test set: Loss: 1.6761597394943237
2025-02-26T14:39:31.389599+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.81      1000
           1       0.87      0.92      0.90      1000
           2       0.76      0.65      0.70      1000
           3       0.65      0.58      0.61      1200
           4       0.78      0.79      0.78      1000
           5       0.53      0.65      0.58       800
           6       0.82      0.87      0.84      1000
           7       0.85      0.82      0.84      1000
           8       0.85      0.93      0.89      1000
           9       0.90      0.83      0.86      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.78      0.78     10000

2025-02-26T14:39:31.393137+0300 | DEBUG | Confusion Matrix:
[[819  21  38  16  23   4   3   8  53  15]
 [ 13 919   0   3   0   1   4   2  22  36]
 [ 54   5 650  59  65  59  65  21  14   8]
 [ 19   6  35 691  57 275  47  33  25  12]
 [  8   6  46  42 789  32  41  26   7   3]
 [  9   1  33 162  22 518  14  36   4   1]
 [  9   3  26  43  12  23 868   7   9   0]
 [ 17   2  12  31  42  53   6 822   6   9]
 [ 30  15   6   6   1   2   3   3 926   8]
 [ 33  75   7   5   2   7   7   7  25 832]]
2025-02-26T14:39:31.395150+0300 | DEBUG | Class precision: [0.81008902 0.87274454 0.76201641 0.65311909 0.77887463 0.53182752
 0.82041588 0.85181347 0.8487626  0.9004329 ]
2025-02-26T14:39:31.397161+0300 | DEBUG | Class recall: [0.819      0.919      0.65       0.57583333 0.789      0.6475
 0.868      0.822      0.926      0.832     ]
2025-02-26T14:39:31.448295+0300 | INFO | Training epoch #73 on client #0
2025-02-26T14:39:31.449767+0300 | DEBUG | Saving model to flat file storage. Save #73
2025-02-26T14:39:31.718292+0300 | INFO | [73,     0] loss: 0.016
2025-02-26T14:39:45.232081+0300 | INFO | [73,   100] loss: 1.506
2025-02-26T14:39:59.841301+0300 | INFO | [73,   200] loss: 1.523
2025-02-26T14:40:15.434211+0300 | INFO | [73,   300] loss: 1.506
2025-02-26T14:40:30.531630+0300 | INFO | [73,   400] loss: 1.507
2025-02-26T14:40:45.837468+0300 | INFO | [73,   500] loss: 1.520
2025-02-26T14:41:02.013588+0300 | INFO | [73,   600] loss: 1.525
2025-02-26T14:41:16.958232+0300 | INFO | [73,   700] loss: 1.518
2025-02-26T14:41:30.882689+0300 | INFO | [73,   800] loss: 1.508
2025-02-26T14:41:44.516864+0300 | INFO | [73,   900] loss: 1.509
2025-02-26T14:41:58.987961+0300 | INFO | [73,  1000] loss: 1.510
2025-02-26T14:42:12.765443+0300 | INFO | [73,  1100] loss: 1.519
2025-02-26T14:42:25.935284+0300 | INFO | [73,  1200] loss: 1.517
2025-02-26T14:42:39.284831+0300 | INFO | [73,  1300] loss: 1.510
2025-02-26T14:42:54.341203+0300 | INFO | [73,  1400] loss: 1.513
2025-02-26T14:43:09.048174+0300 | INFO | [73,  1500] loss: 1.515
2025-02-26T14:43:23.120707+0300 | INFO | [73,  1600] loss: 1.515
2025-02-26T14:43:37.689565+0300 | INFO | [73,  1700] loss: 1.518
2025-02-26T14:43:53.531354+0300 | INFO | [73,  1800] loss: 1.517
2025-02-26T14:44:08.557344+0300 | INFO | [73,  1900] loss: 1.500
2025-02-26T14:44:22.256269+0300 | INFO | [73,  2000] loss: 1.500
2025-02-26T14:44:35.363551+0300 | INFO | [73,  2100] loss: 1.508
2025-02-26T14:44:49.978174+0300 | INFO | [73,  2200] loss: 1.516
2025-02-26T14:45:04.605531+0300 | INFO | [73,  2300] loss: 1.514
2025-02-26T14:45:19.153355+0300 | INFO | [73,  2400] loss: 1.506
2025-02-26T14:45:33.765556+0300 | INFO | [73,  2500] loss: 1.513
2025-02-26T14:45:49.343216+0300 | INFO | [73,  2600] loss: 1.508
2025-02-26T14:46:03.858420+0300 | INFO | [73,  2700] loss: 1.519
2025-02-26T14:46:20.645377+0300 | INFO | [73,  2800] loss: 1.499
2025-02-26T14:46:41.955857+0300 | INFO | [73,  2900] loss: 1.514
2025-02-26T14:46:57.562696+0300 | INFO | [73,  3000] loss: 1.521
2025-02-26T14:47:11.236102+0300 | INFO | [73,  3100] loss: 1.508
2025-02-26T14:47:24.420707+0300 | INFO | [73,  3200] loss: 1.517
2025-02-26T14:47:38.025251+0300 | INFO | [73,  3300] loss: 1.512
2025-02-26T14:47:55.085792+0300 | INFO | [73,  3400] loss: 1.507
2025-02-26T14:48:09.446996+0300 | INFO | [73,  3500] loss: 1.503
2025-02-26T14:48:22.930633+0300 | INFO | [73,  3600] loss: 1.502
2025-02-26T14:48:36.332046+0300 | INFO | [73,  3700] loss: 1.511
2025-02-26T14:48:51.493454+0300 | INFO | [73,  3800] loss: 1.509
2025-02-26T14:49:05.670342+0300 | INFO | [73,  3900] loss: 1.515
2025-02-26T14:49:19.645223+0300 | INFO | [73,  4000] loss: 1.532
2025-02-26T14:49:33.457090+0300 | INFO | [73,  4100] loss: 1.519
2025-02-26T14:49:47.097499+0300 | INFO | [73,  4200] loss: 1.496
2025-02-26T14:50:01.084714+0300 | INFO | [73,  4300] loss: 1.509
2025-02-26T14:50:15.358081+0300 | INFO | [73,  4400] loss: 1.512
2025-02-26T14:50:30.030200+0300 | INFO | [73,  4500] loss: 1.506
2025-02-26T14:50:43.983515+0300 | INFO | [73,  4600] loss: 1.512
2025-02-26T14:50:58.020997+0300 | INFO | [73,  4700] loss: 1.513
2025-02-26T14:51:12.891533+0300 | INFO | [73,  4800] loss: 1.515
2025-02-26T14:51:27.873836+0300 | INFO | [73,  4900] loss: 1.523
2025-02-26T14:51:41.697382+0300 | DEBUG | Saving model to flat file storage. Save #73
2025-02-26T14:51:41.734566+0300 | INFO | Averaging client parameters
2025-02-26T14:51:41.742543+0300 | INFO | Updating parameters on client #0
2025-02-26T14:52:02.106068+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-26T14:52:02.107935+0300 | DEBUG | Test set: Loss: 1.67195463180542
2025-02-26T14:52:02.243698+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.92      0.90      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.66      0.56      0.61      1200
           4       0.83      0.75      0.79      1000
           5       0.53      0.64      0.58       800
           6       0.83      0.87      0.85      1000
           7       0.87      0.83      0.85      1000
           8       0.86      0.90      0.88      1000
           9       0.86      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T14:52:02.246028+0300 | DEBUG | Confusion Matrix:
[[850  15  38  12   6   5   4   6  43  21]
 [ 14 899   1   2   0   0   5   4  21  54]
 [ 61   6 696  41  53  53  55  15  10  10]
 [ 21   4  54 678  35 285  45  35  23  20]
 [ 15   2  54  55 754  39  50  19   8   4]
 [ 14   0  39 164  19 512  12  30   4   6]
 [ 13   1  31  41  10  17 866   7  12   2]
 [ 18   3  19  23  34  48   2 831   6  16]
 [ 53  12   8   6   0   2   3   2 898  16]
 [ 30  39   3   5   1   3   6   7  15 891]]
2025-02-26T14:52:02.253496+0300 | DEBUG | Class precision: [0.7805326  0.91641182 0.73806999 0.66017527 0.82675439 0.53112033
 0.82633588 0.86924686 0.86346154 0.85673077]
2025-02-26T14:52:02.254822+0300 | DEBUG | Class recall: [0.85  0.899 0.696 0.565 0.754 0.64  0.866 0.831 0.898 0.891]
2025-02-26T14:52:02.311638+0300 | INFO | Training epoch #74 on client #0
2025-02-26T14:52:02.314210+0300 | DEBUG | Saving model to flat file storage. Save #74
2025-02-26T14:52:02.666697+0300 | INFO | [74,     0] loss: 0.015
2025-02-26T14:52:17.099425+0300 | INFO | [74,   100] loss: 1.512
2025-02-26T14:52:30.730547+0300 | INFO | [74,   200] loss: 1.522
2025-02-26T14:52:44.585455+0300 | INFO | [74,   300] loss: 1.504
2025-02-26T14:52:59.680041+0300 | INFO | [74,   400] loss: 1.506
2025-02-26T14:53:16.937296+0300 | INFO | [74,   500] loss: 1.521
2025-02-26T14:53:31.071773+0300 | INFO | [74,   600] loss: 1.513
2025-02-26T14:53:44.697141+0300 | INFO | [74,   700] loss: 1.508
2025-02-26T14:53:58.790158+0300 | INFO | [74,   800] loss: 1.515
2025-02-26T14:54:13.046443+0300 | INFO | [74,   900] loss: 1.515
2025-02-26T14:54:26.431822+0300 | INFO | [74,  1000] loss: 1.511
2025-02-26T14:54:39.687276+0300 | INFO | [74,  1100] loss: 1.516
2025-02-26T14:54:53.521642+0300 | INFO | [74,  1200] loss: 1.515
2025-02-26T14:55:07.664971+0300 | INFO | [74,  1300] loss: 1.517
2025-02-26T14:55:22.540365+0300 | INFO | [74,  1400] loss: 1.516
2025-02-26T14:55:39.278670+0300 | INFO | [74,  1500] loss: 1.505
2025-02-26T14:55:59.238581+0300 | INFO | [74,  1600] loss: 1.508
2025-02-26T14:56:09.661940+0300 | INFO | [74,  1700] loss: 1.511
2025-02-26T14:56:19.201727+0300 | INFO | [74,  1800] loss: 1.507
2025-02-26T14:56:28.825758+0300 | INFO | [74,  1900] loss: 1.499
2025-02-26T14:56:39.428158+0300 | INFO | [74,  2000] loss: 1.516
2025-02-26T14:56:48.756521+0300 | INFO | [74,  2100] loss: 1.505
2025-02-26T14:56:58.606206+0300 | INFO | [74,  2200] loss: 1.515
2025-02-26T14:57:08.069680+0300 | INFO | [74,  2300] loss: 1.515
2025-02-26T14:57:24.495023+0300 | INFO | [74,  2400] loss: 1.514
2025-02-26T14:57:35.377215+0300 | INFO | [74,  2500] loss: 1.512
2025-02-26T14:57:47.662963+0300 | INFO | [74,  2600] loss: 1.508
2025-02-26T14:57:57.334778+0300 | INFO | [74,  2700] loss: 1.505
2025-02-26T14:58:06.995114+0300 | INFO | [74,  2800] loss: 1.516
2025-02-26T14:58:16.667803+0300 | INFO | [74,  2900] loss: 1.514
2025-02-26T14:58:26.103280+0300 | INFO | [74,  3000] loss: 1.515
2025-02-26T14:58:35.786377+0300 | INFO | [74,  3100] loss: 1.512
2025-02-26T14:58:45.431993+0300 | INFO | [74,  3200] loss: 1.508
2025-02-26T14:58:55.184384+0300 | INFO | [74,  3300] loss: 1.512
2025-02-26T14:59:05.356204+0300 | INFO | [74,  3400] loss: 1.512
2025-02-26T14:59:15.200864+0300 | INFO | [74,  3500] loss: 1.510
2025-02-26T14:59:24.903522+0300 | INFO | [74,  3600] loss: 1.509
2025-02-26T14:59:35.285048+0300 | INFO | [74,  3700] loss: 1.511
2025-02-26T14:59:45.085690+0300 | INFO | [74,  3800] loss: 1.498
2025-02-26T14:59:54.642079+0300 | INFO | [74,  3900] loss: 1.514
2025-02-26T15:00:04.791078+0300 | INFO | [74,  4000] loss: 1.499
2025-02-26T15:00:14.695729+0300 | INFO | [74,  4100] loss: 1.515
2025-02-26T15:00:24.447366+0300 | INFO | [74,  4200] loss: 1.506
2025-02-26T15:00:33.925962+0300 | INFO | [74,  4300] loss: 1.506
2025-02-26T15:00:44.033570+0300 | INFO | [74,  4400] loss: 1.527
2025-02-26T15:00:53.691318+0300 | INFO | [74,  4500] loss: 1.517
2025-02-26T15:01:03.481510+0300 | INFO | [74,  4600] loss: 1.510
2025-02-26T15:01:13.199524+0300 | INFO | [74,  4700] loss: 1.519
2025-02-26T15:01:22.834484+0300 | INFO | [74,  4800] loss: 1.520
2025-02-26T15:01:32.636324+0300 | INFO | [74,  4900] loss: 1.519
2025-02-26T15:01:42.419602+0300 | DEBUG | Saving model to flat file storage. Save #74
2025-02-26T15:01:42.450736+0300 | INFO | Averaging client parameters
2025-02-26T15:01:42.462575+0300 | INFO | Updating parameters on client #0
2025-02-26T15:01:57.449137+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-26T15:01:57.450153+0300 | DEBUG | Test set: Loss: 1.6721729040145874
2025-02-26T15:01:57.548560+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.83      0.82      1000
           1       0.88      0.94      0.91      1000
           2       0.71      0.72      0.72      1000
           3       0.68      0.57      0.62      1200
           4       0.83      0.75      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.83      0.85      0.84      1000
           7       0.88      0.82      0.85      1000
           8       0.88      0.91      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T15:01:57.550801+0300 | DEBUG | Confusion Matrix:
[[831  23  44   7  12   6   3   6  47  21]
 [  7 938   0   1   0   0   3   2  10  39]
 [ 54   3 725  42  45  58  40  11  12  10]
 [ 27   6  55 681  42 276  46  35  18  14]
 [ 11   5  66  38 748  50  47  21  10   4]
 [ 11   0  45 163  19 514  13  28   5   2]
 [ 14   4  49  38  10  22 850   3   9   1]
 [ 16   3  22  26  25  63   6 821   4  14]
 [ 35  19  10   6   1   3   3   2 911  10]
 [ 29  62   9   6   1   2   7   5  15 864]]
2025-02-26T15:01:57.553799+0300 | DEBUG | Class precision: [0.80289855 0.88240828 0.70731707 0.67559524 0.82834994 0.51710262
 0.83497053 0.87901499 0.87512008 0.8825332 ]
2025-02-26T15:01:57.555146+0300 | DEBUG | Class recall: [0.831  0.938  0.725  0.5675 0.748  0.6425 0.85   0.821  0.911  0.864 ]
2025-02-26T15:01:57.604701+0300 | INFO | Training epoch #75 on client #0
2025-02-26T15:01:57.606220+0300 | DEBUG | Saving model to flat file storage. Save #75
2025-02-26T15:01:57.829272+0300 | INFO | [75,     0] loss: 0.015
2025-02-26T15:02:08.241689+0300 | INFO | [75,   100] loss: 1.510
2025-02-26T15:02:18.621101+0300 | INFO | [75,   200] loss: 1.515
2025-02-26T15:02:28.711300+0300 | INFO | [75,   300] loss: 1.516
2025-02-26T15:02:38.598231+0300 | INFO | [75,   400] loss: 1.512
2025-02-26T15:02:48.374352+0300 | INFO | [75,   500] loss: 1.507
2025-02-26T15:02:58.542174+0300 | INFO | [75,   600] loss: 1.513
2025-02-26T15:03:08.407176+0300 | INFO | [75,   700] loss: 1.512
2025-02-26T15:03:17.949439+0300 | INFO | [75,   800] loss: 1.506
2025-02-26T15:03:27.835923+0300 | INFO | [75,   900] loss: 1.502
2025-02-26T15:03:39.581835+0300 | INFO | [75,  1000] loss: 1.507
2025-02-26T15:03:50.555426+0300 | INFO | [75,  1100] loss: 1.508
2025-02-26T15:04:02.885402+0300 | INFO | [75,  1200] loss: 1.508
2025-02-26T15:04:13.466842+0300 | INFO | [75,  1300] loss: 1.508
2025-02-26T15:04:22.879416+0300 | INFO | [75,  1400] loss: 1.514
2025-02-26T15:04:32.588611+0300 | INFO | [75,  1500] loss: 1.510
2025-02-26T15:04:42.242529+0300 | INFO | [75,  1600] loss: 1.504
2025-02-26T15:04:51.923748+0300 | INFO | [75,  1700] loss: 1.500
2025-02-26T15:05:01.758678+0300 | INFO | [75,  1800] loss: 1.505
2025-02-26T15:05:12.366108+0300 | INFO | [75,  1900] loss: 1.518
2025-02-26T15:05:23.883868+0300 | INFO | [75,  2000] loss: 1.496
2025-02-26T15:05:36.112626+0300 | INFO | [75,  2100] loss: 1.512
2025-02-26T15:05:46.064476+0300 | INFO | [75,  2200] loss: 1.509
2025-02-26T15:05:55.855389+0300 | INFO | [75,  2300] loss: 1.515
2025-02-26T15:06:05.412390+0300 | INFO | [75,  2400] loss: 1.512
2025-02-26T15:06:15.193332+0300 | INFO | [75,  2500] loss: 1.513
2025-02-26T15:06:24.795530+0300 | INFO | [75,  2600] loss: 1.511
2025-02-26T15:06:34.298427+0300 | INFO | [75,  2700] loss: 1.521
2025-02-26T15:06:44.342155+0300 | INFO | [75,  2800] loss: 1.508
2025-02-26T15:06:54.391486+0300 | INFO | [75,  2900] loss: 1.517
2025-02-26T15:07:04.448383+0300 | INFO | [75,  3000] loss: 1.515
2025-02-26T15:07:14.019161+0300 | INFO | [75,  3100] loss: 1.512
2025-02-26T15:07:23.882262+0300 | INFO | [75,  3200] loss: 1.509
2025-02-26T15:07:33.432583+0300 | INFO | [75,  3300] loss: 1.510
2025-02-26T15:07:42.928486+0300 | INFO | [75,  3400] loss: 1.526
2025-02-26T15:07:52.798480+0300 | INFO | [75,  3500] loss: 1.512
2025-02-26T15:08:03.476232+0300 | INFO | [75,  3600] loss: 1.512
2025-02-26T15:08:13.826949+0300 | INFO | [75,  3700] loss: 1.509
2025-02-26T15:08:23.247624+0300 | INFO | [75,  3800] loss: 1.527
2025-02-26T15:08:35.202276+0300 | INFO | [75,  3900] loss: 1.515
2025-02-26T15:08:44.760718+0300 | INFO | [75,  4000] loss: 1.506
2025-02-26T15:08:54.455975+0300 | INFO | [75,  4100] loss: 1.503
2025-02-26T15:09:04.131963+0300 | INFO | [75,  4200] loss: 1.525
2025-02-26T15:09:15.704904+0300 | INFO | [75,  4300] loss: 1.503
2025-02-26T15:09:26.160821+0300 | INFO | [75,  4400] loss: 1.508
2025-02-26T15:09:35.839791+0300 | INFO | [75,  4500] loss: 1.513
2025-02-26T15:09:45.386749+0300 | INFO | [75,  4600] loss: 1.508
2025-02-26T15:09:54.954819+0300 | INFO | [75,  4700] loss: 1.506
2025-02-26T15:10:04.656303+0300 | INFO | [75,  4800] loss: 1.508
2025-02-26T15:10:14.204880+0300 | INFO | [75,  4900] loss: 1.503
2025-02-26T15:10:23.676617+0300 | DEBUG | Saving model to flat file storage. Save #75
2025-02-26T15:10:23.707067+0300 | INFO | Averaging client parameters
2025-02-26T15:10:23.716834+0300 | INFO | Updating parameters on client #0
2025-02-26T15:10:38.441712+0300 | DEBUG | Test set: Accuracy: 7886/10000 (79%)
2025-02-26T15:10:38.443718+0300 | DEBUG | Test set: Loss: 1.6704365015029907
2025-02-26T15:10:38.537450+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.71      0.72      0.72      1000
           3       0.66      0.61      0.63      1200
           4       0.82      0.74      0.78      1000
           5       0.59      0.54      0.56       800
           6       0.82      0.86      0.84      1000
           7       0.80      0.85      0.82      1000
           8       0.87      0.93      0.90      1000
           9       0.88      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T15:10:38.539471+0300 | DEBUG | Confusion Matrix:
[[836  17  40  10   9   2   5  14  49  18]
 [  9 931   0   1   0   1   3   6  11  38]
 [ 56   3 717  46  53  29  52  24  11   9]
 [ 29   7  62 731  40 198  47  56  17  13]
 [ 10   4  59  48 744  28  49  43  10   5]
 [ 11   3  49 201  23 433  18  53   3   6]
 [ 13   4  41  42  10  10 862   9   8   1]
 [ 14   4  20  28  28  30   4 852   3  17]
 [ 25  19   8   5   1   1   3   4 927   7]
 [ 27  66   7   4   1   1   5  10  26 853]]
2025-02-26T15:10:38.540580+0300 | DEBUG | Class precision: [0.81165049 0.87996219 0.71485543 0.65501792 0.81848185 0.59072306
 0.82251908 0.79551821 0.87042254 0.88210962]
2025-02-26T15:10:38.542490+0300 | DEBUG | Class recall: [0.836      0.931      0.717      0.60916667 0.744      0.54125
 0.862      0.852      0.927      0.853     ]
2025-02-26T15:10:38.595813+0300 | INFO | Training epoch #76 on client #0
2025-02-26T15:10:38.599386+0300 | DEBUG | Saving model to flat file storage. Save #76
2025-02-26T15:10:38.816088+0300 | INFO | [76,     0] loss: 0.015
2025-02-26T15:10:50.298317+0300 | INFO | [76,   100] loss: 1.502
2025-02-26T15:11:00.678290+0300 | INFO | [76,   200] loss: 1.511
2025-02-26T15:11:12.208154+0300 | INFO | [76,   300] loss: 1.519
2025-02-26T15:11:29.338304+0300 | INFO | [76,   400] loss: 1.495
2025-02-26T15:11:45.691893+0300 | INFO | [76,   500] loss: 1.505
2025-02-26T15:11:59.693473+0300 | INFO | [76,   600] loss: 1.506
2025-02-26T15:12:14.825523+0300 | INFO | [76,   700] loss: 1.502
2025-02-26T15:12:28.989760+0300 | INFO | [76,   800] loss: 1.512
2025-02-26T15:12:42.895914+0300 | INFO | [76,   900] loss: 1.507
2025-02-26T15:12:57.619998+0300 | INFO | [76,  1000] loss: 1.507
2025-02-26T15:13:16.008068+0300 | INFO | [76,  1100] loss: 1.513
2025-02-26T15:13:30.989017+0300 | INFO | [76,  1200] loss: 1.511
2025-02-26T15:13:45.540001+0300 | INFO | [76,  1300] loss: 1.515
2025-02-26T15:14:04.585586+0300 | INFO | [76,  1400] loss: 1.506
2025-02-26T15:14:20.754679+0300 | INFO | [76,  1500] loss: 1.511
2025-02-26T15:14:43.112046+0300 | INFO | [76,  1600] loss: 1.507
2025-02-26T15:15:00.483248+0300 | INFO | [76,  1700] loss: 1.514
2025-02-26T15:15:16.335226+0300 | INFO | [76,  1800] loss: 1.516
2025-02-26T15:15:31.990057+0300 | INFO | [76,  1900] loss: 1.511
2025-02-26T15:15:47.284637+0300 | INFO | [76,  2000] loss: 1.515
2025-02-26T15:16:02.973079+0300 | INFO | [76,  2100] loss: 1.517
2025-02-26T15:16:18.217318+0300 | INFO | [76,  2200] loss: 1.514
2025-02-26T15:16:33.488215+0300 | INFO | [76,  2300] loss: 1.520
2025-02-26T15:16:48.292585+0300 | INFO | [76,  2400] loss: 1.508
2025-02-26T15:17:03.752528+0300 | INFO | [76,  2500] loss: 1.511
2025-02-26T15:17:19.126877+0300 | INFO | [76,  2600] loss: 1.506
2025-02-26T15:17:33.155089+0300 | INFO | [76,  2700] loss: 1.509
2025-02-26T15:17:48.339577+0300 | INFO | [76,  2800] loss: 1.512
2025-02-26T15:18:03.338059+0300 | INFO | [76,  2900] loss: 1.507
2025-02-26T15:18:18.299020+0300 | INFO | [76,  3000] loss: 1.513
2025-02-26T15:18:34.814532+0300 | INFO | [76,  3100] loss: 1.513
2025-02-26T15:18:49.398204+0300 | INFO | [76,  3200] loss: 1.518
2025-02-26T15:19:04.625229+0300 | INFO | [76,  3300] loss: 1.526
2025-02-26T15:19:20.303204+0300 | INFO | [76,  3400] loss: 1.502
2025-02-26T15:19:36.540102+0300 | INFO | [76,  3500] loss: 1.502
2025-02-26T15:19:50.626677+0300 | INFO | [76,  3600] loss: 1.508
2025-02-26T15:20:06.027241+0300 | INFO | [76,  3700] loss: 1.499
2025-02-26T15:20:21.129044+0300 | INFO | [76,  3800] loss: 1.516
2025-02-26T15:20:35.652232+0300 | INFO | [76,  3900] loss: 1.505
2025-02-26T15:20:50.213929+0300 | INFO | [76,  4000] loss: 1.518
2025-02-26T15:21:05.158158+0300 | INFO | [76,  4100] loss: 1.513
2025-02-26T15:21:18.797113+0300 | INFO | [76,  4200] loss: 1.509
2025-02-26T15:21:33.184123+0300 | INFO | [76,  4300] loss: 1.515
2025-02-26T15:21:47.666624+0300 | INFO | [76,  4400] loss: 1.518
2025-02-26T15:22:01.876043+0300 | INFO | [76,  4500] loss: 1.512
2025-02-26T15:22:16.376365+0300 | INFO | [76,  4600] loss: 1.513
2025-02-26T15:22:30.496033+0300 | INFO | [76,  4700] loss: 1.510
2025-02-26T15:22:44.996402+0300 | INFO | [76,  4800] loss: 1.519
2025-02-26T15:23:00.004417+0300 | INFO | [76,  4900] loss: 1.524
2025-02-26T15:23:16.632508+0300 | DEBUG | Saving model to flat file storage. Save #76
2025-02-26T15:23:16.673836+0300 | INFO | Averaging client parameters
2025-02-26T15:23:16.683444+0300 | INFO | Updating parameters on client #0
2025-02-26T15:23:38.362265+0300 | DEBUG | Test set: Accuracy: 7872/10000 (79%)
2025-02-26T15:23:38.366290+0300 | DEBUG | Test set: Loss: 1.6724672317504883
2025-02-26T15:23:38.510784+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.85      0.81      1000
           1       0.86      0.94      0.90      1000
           2       0.74      0.70      0.72      1000
           3       0.65      0.61      0.63      1200
           4       0.80      0.76      0.78      1000
           5       0.56      0.57      0.57       800
           6       0.82      0.86      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.89      0.89      0.89      1000
           9       0.90      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T15:23:38.514203+0300 | DEBUG | Confusion Matrix:
[[852  19  27  11  13   4   4   9  42  19]
 [ 10 944   0   1   0   1   3   3   9  29]
 [ 68   6 696  48  54  43  58  14   8   5]
 [ 31  14  53 729  55 214  46  34  13  11]
 [ 12   4  57  47 764  25  51  28  11   1]
 [ 11   7  40 198  30 459  15  34   3   3]
 [ 15   5  37  44  10  18 863   4   3   1]
 [ 18   6  22  33  31  44   6 828   2  10]
 [ 46  25   8   9   1   3   5   1 887  15]
 [ 33  68   5   2   2   4   6  10  20 850]]
2025-02-26T15:23:38.516227+0300 | DEBUG | Class precision: [0.77737226 0.85974499 0.73650794 0.64973262 0.79583333 0.56319018
 0.81646168 0.85803109 0.88877756 0.90042373]
2025-02-26T15:23:38.517237+0300 | DEBUG | Class recall: [0.852   0.944   0.696   0.6075  0.764   0.57375 0.863   0.828   0.887
 0.85   ]
2025-02-26T15:23:38.605695+0300 | INFO | Training epoch #77 on client #0
2025-02-26T15:23:38.608254+0300 | DEBUG | Saving model to flat file storage. Save #77
2025-02-26T15:23:38.885368+0300 | INFO | [77,     0] loss: 0.015
2025-02-26T15:23:57.594146+0300 | INFO | [77,   100] loss: 1.515
2025-02-26T15:24:12.418349+0300 | INFO | [77,   200] loss: 1.513
2025-02-26T15:24:26.764776+0300 | INFO | [77,   300] loss: 1.506
2025-02-26T15:24:40.872446+0300 | INFO | [77,   400] loss: 1.513
2025-02-26T15:24:55.508864+0300 | INFO | [77,   500] loss: 1.503
2025-02-26T15:25:08.754841+0300 | INFO | [77,   600] loss: 1.508
2025-02-26T15:25:22.775450+0300 | INFO | [77,   700] loss: 1.498
2025-02-26T15:25:36.660362+0300 | INFO | [77,   800] loss: 1.514
2025-02-26T15:25:51.016703+0300 | INFO | [77,   900] loss: 1.509
2025-02-26T15:26:06.074181+0300 | INFO | [77,  1000] loss: 1.516
2025-02-26T15:26:24.898478+0300 | INFO | [77,  1100] loss: 1.512
2025-02-26T15:26:45.969716+0300 | INFO | [77,  1200] loss: 1.505
2025-02-26T15:27:05.120858+0300 | INFO | [77,  1300] loss: 1.512
2025-02-26T15:27:17.947100+0300 | INFO | [77,  1400] loss: 1.497
2025-02-26T15:27:33.102354+0300 | INFO | [77,  1500] loss: 1.516
2025-02-26T15:27:47.268218+0300 | INFO | [77,  1600] loss: 1.496
2025-02-26T15:28:02.569864+0300 | INFO | [77,  1700] loss: 1.511
2025-02-26T15:28:18.331062+0300 | INFO | [77,  1800] loss: 1.505
2025-02-26T15:28:33.536997+0300 | INFO | [77,  1900] loss: 1.508
2025-02-26T15:28:47.507999+0300 | INFO | [77,  2000] loss: 1.518
2025-02-26T15:29:02.426403+0300 | INFO | [77,  2100] loss: 1.507
2025-02-26T15:29:18.229089+0300 | INFO | [77,  2200] loss: 1.501
2025-02-26T15:29:32.835981+0300 | INFO | [77,  2300] loss: 1.521
2025-02-26T15:29:47.434970+0300 | INFO | [77,  2400] loss: 1.504
2025-02-26T15:30:01.897268+0300 | INFO | [77,  2500] loss: 1.515
2025-02-26T15:30:16.371283+0300 | INFO | [77,  2600] loss: 1.517
2025-02-26T15:30:31.240484+0300 | INFO | [77,  2700] loss: 1.506
2025-02-26T15:30:48.070852+0300 | INFO | [77,  2800] loss: 1.511
2025-02-26T15:31:04.502057+0300 | INFO | [77,  2900] loss: 1.503
2025-02-26T15:31:18.768830+0300 | INFO | [77,  3000] loss: 1.510
2025-02-26T15:31:33.893879+0300 | INFO | [77,  3100] loss: 1.501
2025-02-26T15:31:47.692174+0300 | INFO | [77,  3200] loss: 1.517
2025-02-26T15:32:01.779350+0300 | INFO | [77,  3300] loss: 1.513
2025-02-26T15:32:16.387659+0300 | INFO | [77,  3400] loss: 1.501
2025-02-26T15:32:29.718708+0300 | INFO | [77,  3500] loss: 1.512
2025-02-26T15:32:43.172212+0300 | INFO | [77,  3600] loss: 1.513
2025-02-26T15:32:57.271156+0300 | INFO | [77,  3700] loss: 1.520
2025-02-26T15:33:09.974288+0300 | INFO | [77,  3800] loss: 1.519
2025-02-26T15:33:22.432834+0300 | INFO | [77,  3900] loss: 1.505
2025-02-26T15:33:35.118627+0300 | INFO | [77,  4000] loss: 1.509
2025-02-26T15:33:50.260030+0300 | INFO | [77,  4100] loss: 1.510
2025-02-26T15:34:03.896657+0300 | INFO | [77,  4200] loss: 1.519
2025-02-26T15:34:20.708781+0300 | INFO | [77,  4300] loss: 1.511
2025-02-26T15:34:33.178357+0300 | INFO | [77,  4400] loss: 1.508
2025-02-26T15:34:45.824487+0300 | INFO | [77,  4500] loss: 1.504
2025-02-26T15:34:58.809753+0300 | INFO | [77,  4600] loss: 1.504
2025-02-26T15:35:16.228199+0300 | INFO | [77,  4700] loss: 1.509
2025-02-26T15:35:33.391110+0300 | INFO | [77,  4800] loss: 1.513
2025-02-26T15:35:48.184926+0300 | INFO | [77,  4900] loss: 1.515
2025-02-26T15:36:04.658843+0300 | DEBUG | Saving model to flat file storage. Save #77
2025-02-26T15:36:04.688088+0300 | INFO | Averaging client parameters
2025-02-26T15:36:04.698782+0300 | INFO | Updating parameters on client #0
2025-02-26T15:36:29.013832+0300 | DEBUG | Test set: Accuracy: 7889/10000 (79%)
2025-02-26T15:36:29.016411+0300 | DEBUG | Test set: Loss: 1.6701984405517578
2025-02-26T15:36:29.125133+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.81      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.65      0.61      0.63      1200
           4       0.79      0.79      0.79      1000
           5       0.55      0.58      0.57       800
           6       0.85      0.84      0.84      1000
           7       0.84      0.84      0.84      1000
           8       0.86      0.92      0.88      1000
           9       0.85      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T15:36:29.129127+0300 | DEBUG | Confusion Matrix:
[[813  16  30  10  12   6   4  13  57  39]
 [  8 911   0   0   0   1   5   2  21  52]
 [ 52   4 702  45  66  50  43  19  10   9]
 [ 22   7  52 728  44 236  40  36  19  16]
 [  8   2  44  56 786  24  34  35   9   2]
 [  8   2  38 193  26 468  11  40   7   7]
 [ 11   4  47  48  15  19 842   6   6   2]
 [ 13   3  17  28  38  37   6 837   6  15]
 [ 30  13  11   7   1   2   2   3 916  15]
 [ 16  43   7   6   1   4   8   9  20 886]]
2025-02-26T15:36:29.132687+0300 | DEBUG | Class precision: [0.82874618 0.90646766 0.74050633 0.64942016 0.79474216 0.55253837
 0.84623116 0.837      0.85527544 0.84947267]
2025-02-26T15:36:29.135767+0300 | DEBUG | Class recall: [0.813      0.911      0.702      0.60666667 0.786      0.585
 0.842      0.837      0.916      0.886     ]
2025-02-26T15:36:29.191134+0300 | INFO | Training epoch #78 on client #0
2025-02-26T15:36:29.194599+0300 | DEBUG | Saving model to flat file storage. Save #78
2025-02-26T15:36:29.353219+0300 | INFO | [78,     0] loss: 0.015
2025-02-26T15:36:41.985590+0300 | INFO | [78,   100] loss: 1.514
2025-02-26T15:36:56.711087+0300 | INFO | [78,   200] loss: 1.501
2025-02-26T15:37:10.900277+0300 | INFO | [78,   300] loss: 1.505
2025-02-26T15:37:24.051160+0300 | INFO | [78,   400] loss: 1.501
2025-02-26T15:37:38.062762+0300 | INFO | [78,   500] loss: 1.498
2025-02-26T15:37:54.411031+0300 | INFO | [78,   600] loss: 1.510
2025-02-26T15:38:11.648092+0300 | INFO | [78,   700] loss: 1.511
2025-02-26T15:38:24.793545+0300 | INFO | [78,   800] loss: 1.506
2025-02-26T15:38:42.572659+0300 | INFO | [78,   900] loss: 1.501
2025-02-26T15:38:57.939375+0300 | INFO | [78,  1000] loss: 1.517
2025-02-26T15:39:11.817013+0300 | INFO | [78,  1100] loss: 1.516
2025-02-26T15:39:26.781748+0300 | INFO | [78,  1200] loss: 1.507
2025-02-26T15:39:42.812127+0300 | INFO | [78,  1300] loss: 1.513
2025-02-26T15:39:58.714923+0300 | INFO | [78,  1400] loss: 1.518
2025-02-26T15:40:14.484144+0300 | INFO | [78,  1500] loss: 1.522
2025-02-26T15:40:28.555248+0300 | INFO | [78,  1600] loss: 1.512
2025-02-26T15:40:41.254625+0300 | INFO | [78,  1700] loss: 1.498
2025-02-26T15:40:53.796028+0300 | INFO | [78,  1800] loss: 1.513
2025-02-26T15:41:06.445565+0300 | INFO | [78,  1900] loss: 1.515
2025-02-26T15:41:18.913630+0300 | INFO | [78,  2000] loss: 1.522
2025-02-26T15:41:31.317023+0300 | INFO | [78,  2100] loss: 1.511
2025-02-26T15:41:43.957992+0300 | INFO | [78,  2200] loss: 1.524
2025-02-26T15:41:56.094121+0300 | INFO | [78,  2300] loss: 1.518
2025-02-26T15:42:13.319090+0300 | INFO | [78,  2400] loss: 1.512
2025-02-26T15:42:26.663098+0300 | INFO | [78,  2500] loss: 1.503
2025-02-26T15:42:42.267604+0300 | INFO | [78,  2600] loss: 1.516
2025-02-26T15:42:55.086220+0300 | INFO | [78,  2700] loss: 1.508
2025-02-26T15:43:08.022699+0300 | INFO | [78,  2800] loss: 1.506
2025-02-26T15:43:20.981551+0300 | INFO | [78,  2900] loss: 1.519
2025-02-26T15:43:34.279408+0300 | INFO | [78,  3000] loss: 1.512
2025-02-26T15:43:46.902017+0300 | INFO | [78,  3100] loss: 1.506
2025-02-26T15:43:59.650632+0300 | INFO | [78,  3200] loss: 1.500
2025-02-26T15:44:14.173385+0300 | INFO | [78,  3300] loss: 1.510
2025-02-26T15:44:28.336386+0300 | INFO | [78,  3400] loss: 1.511
2025-02-26T15:44:41.448944+0300 | INFO | [78,  3500] loss: 1.507
2025-02-26T15:44:54.064841+0300 | INFO | [78,  3600] loss: 1.511
2025-02-26T15:45:06.147986+0300 | INFO | [78,  3700] loss: 1.504
2025-02-26T15:45:19.006599+0300 | INFO | [78,  3800] loss: 1.516
2025-02-26T15:45:32.310236+0300 | INFO | [78,  3900] loss: 1.505
2025-02-26T15:45:45.769801+0300 | INFO | [78,  4000] loss: 1.495
2025-02-26T15:45:59.728560+0300 | INFO | [78,  4100] loss: 1.516
2025-02-26T15:46:13.758391+0300 | INFO | [78,  4200] loss: 1.502
2025-02-26T15:46:29.059908+0300 | INFO | [78,  4300] loss: 1.502
2025-02-26T15:46:42.785110+0300 | INFO | [78,  4400] loss: 1.519
2025-02-26T15:46:55.546783+0300 | INFO | [78,  4500] loss: 1.503
2025-02-26T15:47:08.619859+0300 | INFO | [78,  4600] loss: 1.508
2025-02-26T15:47:20.677792+0300 | INFO | [78,  4700] loss: 1.502
2025-02-26T15:47:32.067794+0300 | INFO | [78,  4800] loss: 1.509
2025-02-26T15:47:44.050318+0300 | INFO | [78,  4900] loss: 1.514
2025-02-26T15:47:56.164174+0300 | DEBUG | Saving model to flat file storage. Save #78
2025-02-26T15:47:56.191745+0300 | INFO | Averaging client parameters
2025-02-26T15:47:56.206430+0300 | INFO | Updating parameters on client #0
2025-02-26T15:48:16.281511+0300 | DEBUG | Test set: Accuracy: 7884/10000 (79%)
2025-02-26T15:48:16.284649+0300 | DEBUG | Test set: Loss: 1.6717207431793213
2025-02-26T15:48:16.402166+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.87      0.82      1000
           1       0.88      0.93      0.91      1000
           2       0.74      0.71      0.72      1000
           3       0.67      0.56      0.61      1200
           4       0.81      0.75      0.78      1000
           5       0.54      0.65      0.59       800
           6       0.83      0.85      0.84      1000
           7       0.83      0.85      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.89      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T15:48:16.403931+0300 | DEBUG | Confusion Matrix:
[[867  20  29   7  11   5   6  11  30  14]
 [ 11 932   0   2   0   2   6   1  10  36]
 [ 70   4 706  42  50  39  49  23   8   9]
 [ 27   7  58 669  45 285  45  38  10  16]
 [ 12   4  49  50 753  37  40  47   6   2]
 [ 13   3  36 155  22 519  12  33   3   4]
 [ 12   2  43  43  15  18 855   7   4   1]
 [ 16   6  18  25  30  44   5 847   1   8]
 [ 50  20  10   5   2   4   5   4 890  10]
 [ 39  60   7   4   1   4  12   9  18 846]]
2025-02-26T15:48:16.407358+0300 | DEBUG | Class precision: [0.77618621 0.88090737 0.73849372 0.66766467 0.81054898 0.54231975
 0.82608696 0.83039216 0.90816327 0.89429175]
2025-02-26T15:48:16.409828+0300 | DEBUG | Class recall: [0.867   0.932   0.706   0.5575  0.753   0.64875 0.855   0.847   0.89
 0.846  ]
2025-02-26T15:48:16.469030+0300 | INFO | Training epoch #79 on client #0
2025-02-26T15:48:16.470082+0300 | DEBUG | Saving model to flat file storage. Save #79
2025-02-26T15:48:16.733187+0300 | INFO | [79,     0] loss: 0.015
2025-02-26T15:48:29.042781+0300 | INFO | [79,   100] loss: 1.492
2025-02-26T15:48:40.837552+0300 | INFO | [79,   200] loss: 1.503
2025-02-26T15:48:52.872528+0300 | INFO | [79,   300] loss: 1.501
2025-02-26T15:49:04.927695+0300 | INFO | [79,   400] loss: 1.509
2025-02-26T15:49:27.002302+0300 | INFO | [79,   500] loss: 1.518
2025-02-26T15:49:43.769367+0300 | INFO | [79,   600] loss: 1.500
2025-02-26T15:50:00.044750+0300 | INFO | [79,   700] loss: 1.509
2025-02-26T15:50:13.301860+0300 | INFO | [79,   800] loss: 1.519
2025-02-26T15:50:28.438116+0300 | INFO | [79,   900] loss: 1.513
2025-02-26T15:50:46.873893+0300 | INFO | [79,  1000] loss: 1.511
2025-02-26T15:51:05.404219+0300 | INFO | [79,  1100] loss: 1.512
2025-02-26T15:51:20.332102+0300 | INFO | [79,  1200] loss: 1.509
2025-02-26T15:51:35.212532+0300 | INFO | [79,  1300] loss: 1.516
2025-02-26T15:51:52.358027+0300 | INFO | [79,  1400] loss: 1.502
2025-02-26T15:52:09.260118+0300 | INFO | [79,  1500] loss: 1.504
2025-02-26T15:52:24.303537+0300 | INFO | [79,  1600] loss: 1.511
2025-02-26T15:52:38.130796+0300 | INFO | [79,  1700] loss: 1.518
2025-02-26T15:52:50.977104+0300 | INFO | [79,  1800] loss: 1.509
2025-02-26T15:53:03.899958+0300 | INFO | [79,  1900] loss: 1.515
2025-02-26T15:53:17.606936+0300 | INFO | [79,  2000] loss: 1.519
2025-02-26T15:53:30.449400+0300 | INFO | [79,  2100] loss: 1.502
2025-02-26T15:53:44.117058+0300 | INFO | [79,  2200] loss: 1.510
2025-02-26T15:53:56.961587+0300 | INFO | [79,  2300] loss: 1.497
2025-02-26T15:54:09.728015+0300 | INFO | [79,  2400] loss: 1.518
2025-02-26T15:54:21.936073+0300 | INFO | [79,  2500] loss: 1.510
2025-02-26T15:54:33.864189+0300 | INFO | [79,  2600] loss: 1.508
2025-02-26T15:54:47.232598+0300 | INFO | [79,  2700] loss: 1.506
2025-02-26T15:55:03.308821+0300 | INFO | [79,  2800] loss: 1.509
2025-02-26T15:55:20.650079+0300 | INFO | [79,  2900] loss: 1.507
2025-02-26T15:55:32.461403+0300 | INFO | [79,  3000] loss: 1.507
2025-02-26T15:55:44.113957+0300 | INFO | [79,  3100] loss: 1.504
2025-02-26T15:55:56.102295+0300 | INFO | [79,  3200] loss: 1.507
2025-02-26T15:56:08.738735+0300 | INFO | [79,  3300] loss: 1.519
2025-02-26T15:56:20.696983+0300 | INFO | [79,  3400] loss: 1.501
2025-02-26T15:56:33.407959+0300 | INFO | [79,  3500] loss: 1.499
2025-02-26T15:56:48.403124+0300 | INFO | [79,  3600] loss: 1.512
2025-02-26T15:57:04.478796+0300 | INFO | [79,  3700] loss: 1.499
2025-02-26T15:57:17.106815+0300 | INFO | [79,  3800] loss: 1.506
2025-02-26T15:57:31.302811+0300 | INFO | [79,  3900] loss: 1.510
2025-02-26T15:57:45.893569+0300 | INFO | [79,  4000] loss: 1.500
2025-02-26T15:58:44.654399+0300 | INFO | [79,  4100] loss: 1.512
2025-02-26T15:59:45.360195+0300 | INFO | [79,  4200] loss: 1.502
2025-02-26T16:00:40.683485+0300 | INFO | [79,  4300] loss: 1.514
2025-02-26T16:01:39.702732+0300 | INFO | [79,  4400] loss: 1.520
2025-02-26T16:02:35.157758+0300 | INFO | [79,  4500] loss: 1.526
2025-02-26T16:03:34.273569+0300 | INFO | [79,  4600] loss: 1.503
2025-02-26T16:04:31.793952+0300 | INFO | [79,  4700] loss: 1.499
2025-02-26T16:05:29.634945+0300 | INFO | [79,  4800] loss: 1.514
2025-02-26T16:06:26.263961+0300 | INFO | [79,  4900] loss: 1.517
2025-02-26T16:07:22.938598+0300 | DEBUG | Saving model to flat file storage. Save #79
2025-02-26T16:07:23.077911+0300 | INFO | Averaging client parameters
2025-02-26T16:07:23.093911+0300 | INFO | Updating parameters on client #0
2025-02-26T16:08:46.214021+0300 | DEBUG | Test set: Accuracy: 7898/10000 (79%)
2025-02-26T16:08:46.215012+0300 | DEBUG | Test set: Loss: 1.6709624528884888
2025-02-26T16:08:46.371700+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.67      0.55      0.60      1200
           4       0.79      0.78      0.79      1000
           5       0.52      0.64      0.58       800
           6       0.80      0.90      0.84      1000
           7       0.84      0.85      0.84      1000
           8       0.88      0.91      0.90      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T16:08:46.375682+0300 | DEBUG | Confusion Matrix:
[[826  22  36   8  15   9   8  15  40  21]
 [  7 915   0   0   0   1   8   4  19  46]
 [ 52   4 680  43  64  60  59  25   7   6]
 [ 16   3  48 660  55 287  62  35  17  17]
 [  9   1  40  45 781  39  46  32   6   1]
 [ 10   3  28 161  22 512  23  32   5   4]
 [  5   2  33  30  11  16 896   3   3   1]
 [  9   1  14  29  34  45   7 848   5   8]
 [ 31  11   9   4   3   6   5   3 914  14]
 [ 28  50   6   2   2   5  12  11  18 866]]
2025-02-26T16:08:46.411618+0300 | DEBUG | Class precision: [0.83182276 0.9041502  0.7606264  0.67209776 0.79128673 0.52244898
 0.79573712 0.84126984 0.88394584 0.8800813 ]
2025-02-26T16:08:46.413614+0300 | DEBUG | Class recall: [0.826 0.915 0.68  0.55  0.781 0.64  0.896 0.848 0.914 0.866]
2025-02-26T16:08:46.416615+0300 | INFO | Training epoch #80 on client #0
2025-02-26T16:08:46.417602+0300 | DEBUG | Saving model to flat file storage. Save #80
2025-02-26T16:08:46.997237+0300 | INFO | [80,     0] loss: 0.015
2025-02-26T16:09:36.305452+0300 | INFO | [80,   100] loss: 1.507
2025-02-26T16:10:25.728502+0300 | INFO | [80,   200] loss: 1.506
2025-02-26T16:11:15.392491+0300 | INFO | [80,   300] loss: 1.506
2025-02-26T16:12:03.597917+0300 | INFO | [80,   400] loss: 1.514
2025-02-26T16:12:50.972096+0300 | INFO | [80,   500] loss: 1.517
2025-02-26T16:13:38.949036+0300 | INFO | [80,   600] loss: 1.497
2025-02-26T16:14:32.770264+0300 | INFO | [80,   700] loss: 1.497
2025-02-26T16:15:21.856836+0300 | INFO | [80,   800] loss: 1.520
2025-02-26T16:16:17.930079+0300 | INFO | [80,   900] loss: 1.494
2025-02-26T16:17:09.488458+0300 | INFO | [80,  1000] loss: 1.514
2025-02-26T16:18:08.607086+0300 | INFO | [80,  1100] loss: 1.514
2025-02-26T16:18:58.399123+0300 | INFO | [80,  1200] loss: 1.510
2025-02-26T16:19:50.181938+0300 | INFO | [80,  1300] loss: 1.503
2025-02-26T16:20:38.912809+0300 | INFO | [80,  1400] loss: 1.506
2025-02-26T16:21:27.867596+0300 | INFO | [80,  1500] loss: 1.512
2025-02-26T16:22:39.395445+0300 | INFO | [80,  1600] loss: 1.518
2025-02-26T16:23:51.546263+0300 | INFO | [80,  1700] loss: 1.508
2025-02-26T16:24:53.292238+0300 | INFO | [80,  1800] loss: 1.512
2025-02-26T16:26:07.153709+0300 | INFO | [80,  1900] loss: 1.515
2025-02-26T16:27:11.284157+0300 | INFO | [80,  2000] loss: 1.507
2025-02-26T16:28:25.709551+0300 | INFO | [80,  2100] loss: 1.515
2025-02-26T16:29:42.565250+0300 | INFO | [80,  2200] loss: 1.510
2025-02-26T16:30:54.761769+0300 | INFO | [80,  2300] loss: 1.517
2025-02-26T16:32:01.566970+0300 | INFO | [80,  2400] loss: 1.522
2025-02-26T16:32:58.077071+0300 | INFO | [80,  2500] loss: 1.504
2025-02-26T16:33:57.739584+0300 | INFO | [80,  2600] loss: 1.509
2025-02-26T16:34:54.298932+0300 | INFO | [80,  2700] loss: 1.516
2025-02-26T16:35:49.530041+0300 | INFO | [80,  2800] loss: 1.506
2025-02-26T16:36:44.758558+0300 | INFO | [80,  2900] loss: 1.497
2025-02-26T16:37:44.636287+0300 | INFO | [80,  3000] loss: 1.507
2025-02-26T16:38:45.408544+0300 | INFO | [80,  3100] loss: 1.509
2025-02-26T16:39:43.180448+0300 | INFO | [80,  3200] loss: 1.498
2025-02-26T16:40:43.414977+0300 | INFO | [80,  3300] loss: 1.508
2025-02-26T16:41:39.964850+0300 | INFO | [80,  3400] loss: 1.505
2025-02-26T16:42:32.019631+0300 | INFO | [80,  3500] loss: 1.510
2025-02-26T16:43:32.845656+0300 | INFO | [80,  3600] loss: 1.505
2025-02-26T16:44:28.016163+0300 | INFO | [80,  3700] loss: 1.506
2025-02-26T16:45:28.495768+0300 | INFO | [80,  3800] loss: 1.506
2025-02-26T16:46:27.377787+0300 | INFO | [80,  3900] loss: 1.500
2025-02-26T16:47:24.378944+0300 | INFO | [80,  4000] loss: 1.516
2025-02-26T16:48:19.758427+0300 | INFO | [80,  4100] loss: 1.510
2025-02-26T16:49:07.035608+0300 | INFO | [80,  4200] loss: 1.510
2025-02-26T16:50:11.297921+0300 | INFO | [80,  4300] loss: 1.505
2025-02-26T16:51:03.812617+0300 | INFO | [80,  4400] loss: 1.506
2025-02-26T16:52:28.118086+0300 | INFO | [80,  4500] loss: 1.506
2025-02-26T16:53:29.062310+0300 | INFO | [80,  4600] loss: 1.507
2025-02-26T16:54:30.440145+0300 | INFO | [80,  4700] loss: 1.520
2025-02-26T16:55:26.736862+0300 | INFO | [80,  4800] loss: 1.502
2025-02-26T16:56:23.883248+0300 | INFO | [80,  4900] loss: 1.506
2025-02-26T16:57:22.963444+0300 | DEBUG | Saving model to flat file storage. Save #80
2025-02-26T16:57:23.014984+0300 | INFO | Averaging client parameters
2025-02-26T16:57:23.037738+0300 | INFO | Updating parameters on client #0
2025-02-26T16:58:22.273670+0300 | DEBUG | Test set: Accuracy: 7866/10000 (79%)
2025-02-26T16:58:22.285788+0300 | DEBUG | Test set: Loss: 1.6735576391220093
2025-02-26T16:58:22.493512+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.87      0.94      0.90      1000
           2       0.77      0.67      0.72      1000
           3       0.67      0.55      0.60      1200
           4       0.77      0.80      0.78      1000
           5       0.52      0.65      0.58       800
           6       0.85      0.84      0.85      1000
           7       0.83      0.83      0.83      1000
           8       0.89      0.90      0.90      1000
           9       0.89      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T16:58:22.496514+0300 | DEBUG | Confusion Matrix:
[[847  22  29   5  18   5   6  11  37  20]
 [  7 940   0   1   0   1   3   5  10  33]
 [ 60   5 671  45  72  57  44  25  10  11]
 [ 27   6  45 657  58 288  42  44  18  15]
 [  9   2  40  46 799  37  29  29   7   2]
 [ 12   2  29 153  26 518  13  40   3   4]
 [  8   5  31  47  27  24 843   7   6   2]
 [ 17   4  12  27  39  53   5 831   1  11]
 [ 43  27   5   5   1   3   3   4 899  10]
 [ 30  69   5   1   2   1   6  10  15 861]]
2025-02-26T16:58:22.499512+0300 | DEBUG | Class precision: [0.7990566  0.86876155 0.7739331  0.6656535  0.76679463 0.5248227
 0.84808853 0.82604374 0.89363817 0.88854489]
2025-02-26T16:58:22.511525+0300 | DEBUG | Class recall: [0.847  0.94   0.671  0.5475 0.799  0.6475 0.843  0.831  0.899  0.861 ]
2025-02-26T16:58:22.519513+0300 | INFO | Training epoch #81 on client #0
2025-02-26T16:58:22.524524+0300 | DEBUG | Saving model to flat file storage. Save #81
2025-02-26T16:58:23.158184+0300 | INFO | [81,     0] loss: 0.015
2025-02-26T16:59:24.118400+0300 | INFO | [81,   100] loss: 1.517
2025-02-26T17:00:18.041052+0300 | INFO | [81,   200] loss: 1.504
2025-02-26T17:01:18.660086+0300 | INFO | [81,   300] loss: 1.509
2025-02-26T17:02:14.544515+0300 | INFO | [81,   400] loss: 1.503
2025-02-26T17:03:16.981564+0300 | INFO | [81,   500] loss: 1.507
2025-02-26T17:04:23.882361+0300 | INFO | [81,   600] loss: 1.501
2025-02-26T17:05:22.446929+0300 | INFO | [81,   700] loss: 1.506
2025-02-26T17:06:18.957789+0300 | INFO | [81,   800] loss: 1.500
2025-02-26T17:07:16.427840+0300 | INFO | [81,   900] loss: 1.502
2025-02-26T17:08:19.582875+0300 | INFO | [81,  1000] loss: 1.503
2025-02-26T17:09:25.079049+0300 | INFO | [81,  1100] loss: 1.507
2025-02-26T17:10:28.691098+0300 | INFO | [81,  1200] loss: 1.522
2025-02-26T17:11:39.692734+0300 | INFO | [81,  1300] loss: 1.510
2025-02-26T17:12:33.849321+0300 | INFO | [81,  1400] loss: 1.505
2025-02-26T17:13:26.574522+0300 | INFO | [81,  1500] loss: 1.503
2025-02-26T17:14:20.177452+0300 | INFO | [81,  1600] loss: 1.502
2025-02-26T17:15:12.918500+0300 | INFO | [81,  1700] loss: 1.514
2025-02-26T17:16:08.175021+0300 | INFO | [81,  1800] loss: 1.500
2025-02-26T17:17:10.175244+0300 | INFO | [81,  1900] loss: 1.502
2025-02-26T17:18:02.867750+0300 | INFO | [81,  2000] loss: 1.512
2025-02-26T17:18:55.034587+0300 | INFO | [81,  2100] loss: 1.492
2025-02-26T17:19:50.209716+0300 | INFO | [81,  2200] loss: 1.509
2025-02-26T17:20:46.227513+0300 | INFO | [81,  2300] loss: 1.517
2025-02-26T17:21:45.133545+0300 | INFO | [81,  2400] loss: 1.510
2025-02-26T17:22:37.865514+0300 | INFO | [81,  2500] loss: 1.516
2025-02-26T17:23:40.544321+0300 | INFO | [81,  2600] loss: 1.505
2025-02-26T17:24:38.629708+0300 | INFO | [81,  2700] loss: 1.511
2025-02-26T17:25:34.247566+0300 | INFO | [81,  2800] loss: 1.502
2025-02-26T17:26:34.665435+0300 | INFO | [81,  2900] loss: 1.499
2025-02-26T17:27:35.247712+0300 | INFO | [81,  3000] loss: 1.506
2025-02-26T17:28:28.619999+0300 | INFO | [81,  3100] loss: 1.525
2025-02-26T17:29:32.302664+0300 | INFO | [81,  3200] loss: 1.495
2025-02-26T17:30:38.799674+0300 | INFO | [81,  3300] loss: 1.506
2025-02-26T17:31:36.210809+0300 | INFO | [81,  3400] loss: 1.517
2025-02-26T17:32:32.717070+0300 | INFO | [81,  3500] loss: 1.500
2025-02-26T17:33:33.088876+0300 | INFO | [81,  3600] loss: 1.510
2025-02-26T17:34:39.758172+0300 | INFO | [81,  3700] loss: 1.508
2025-02-26T17:35:49.331887+0300 | INFO | [81,  3800] loss: 1.518
2025-02-26T17:37:18.365402+0300 | INFO | [81,  3900] loss: 1.511
2025-02-26T17:38:33.808150+0300 | INFO | [81,  4000] loss: 1.509
2025-02-26T17:39:36.090300+0300 | INFO | [81,  4100] loss: 1.504
2025-02-26T17:40:42.990154+0300 | INFO | [81,  4200] loss: 1.506
2025-02-26T17:41:44.074995+0300 | INFO | [81,  4300] loss: 1.516
2025-02-26T17:42:46.892059+0300 | INFO | [81,  4400] loss: 1.501
2025-02-26T17:43:38.093745+0300 | INFO | [81,  4500] loss: 1.506
2025-02-26T17:44:42.277197+0300 | INFO | [81,  4600] loss: 1.511
2025-02-26T17:45:37.554628+0300 | INFO | [81,  4700] loss: 1.509
2025-02-26T17:46:34.594051+0300 | INFO | [81,  4800] loss: 1.502
2025-02-26T17:47:31.725358+0300 | INFO | [81,  4900] loss: 1.517
2025-02-26T17:48:30.762551+0300 | DEBUG | Saving model to flat file storage. Save #81
2025-02-26T17:48:30.855216+0300 | INFO | Averaging client parameters
2025-02-26T17:48:30.874697+0300 | INFO | Updating parameters on client #0
2025-02-26T17:49:32.230621+0300 | DEBUG | Test set: Accuracy: 7880/10000 (79%)
2025-02-26T17:49:32.231621+0300 | DEBUG | Test set: Loss: 1.6721277236938477
2025-02-26T17:49:32.391409+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.90      0.93      0.91      1000
           2       0.80      0.64      0.71      1000
           3       0.67      0.54      0.60      1200
           4       0.75      0.81      0.78      1000
           5       0.52      0.67      0.59       800
           6       0.79      0.90      0.84      1000
           7       0.87      0.80      0.83      1000
           8       0.89      0.91      0.90      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T17:49:32.395411+0300 | DEBUG | Confusion Matrix:
[[838  20  27   7  18   7  10   7  43  23]
 [  7 928   0   3   1   2   6   4   8  41]
 [ 60   3 637  50  79  59  72  24   8   8]
 [ 26   7  40 652  64 304  61  21  13  12]
 [  7   2  28  37 813  33  53  18   7   2]
 [ 10   0  25 150  28 539  16  26   4   2]
 [  9   2  18  33  13  15 901   4   4   1]
 [ 17   2   9  28  58  71   7 798   2   8]
 [ 30  20   5   6   3   5   5   5 905  16]
 [ 26  52   6   4   1   5  11   7  19 869]]
2025-02-26T17:49:32.396411+0300 | DEBUG | Class precision: [0.81359223 0.8957529  0.80125786 0.67216495 0.7541744  0.51826923
 0.78896673 0.87308534 0.89338598 0.88492872]
2025-02-26T17:49:32.399411+0300 | DEBUG | Class recall: [0.838      0.928      0.637      0.54333333 0.813      0.67375
 0.901      0.798      0.905      0.869     ]
2025-02-26T17:49:32.401409+0300 | INFO | Training epoch #82 on client #0
2025-02-26T17:49:32.403409+0300 | DEBUG | Saving model to flat file storage. Save #82
2025-02-26T17:49:32.993403+0300 | INFO | [82,     0] loss: 0.015
2025-02-26T17:50:32.609206+0300 | INFO | [82,   100] loss: 1.519
2025-02-26T17:51:26.724269+0300 | INFO | [82,   200] loss: 1.507
2025-02-26T17:52:28.490890+0300 | INFO | [82,   300] loss: 1.500
2025-02-26T17:53:25.638639+0300 | INFO | [82,   400] loss: 1.504
2025-02-26T17:54:20.606751+0300 | INFO | [82,   500] loss: 1.509
2025-02-26T17:55:19.224856+0300 | INFO | [82,   600] loss: 1.502
2025-02-26T17:56:11.606735+0300 | INFO | [82,   700] loss: 1.513
2025-02-26T17:57:05.269012+0300 | INFO | [82,   800] loss: 1.506
2025-02-26T17:57:57.713324+0300 | INFO | [82,   900] loss: 1.511
2025-02-26T17:59:00.852541+0300 | INFO | [82,  1000] loss: 1.512
2025-02-26T18:00:07.482745+0300 | INFO | [82,  1100] loss: 1.496
2025-02-26T18:01:00.110286+0300 | INFO | [82,  1200] loss: 1.507
2025-02-26T18:02:00.712446+0300 | INFO | [82,  1300] loss: 1.505
2025-02-26T18:02:56.716256+0300 | INFO | [82,  1400] loss: 1.508
2025-02-26T18:04:24.808073+0300 | INFO | [82,  1500] loss: 1.498
2025-02-26T18:05:53.291901+0300 | INFO | [82,  1600] loss: 1.523
2025-02-26T18:07:22.705489+0300 | INFO | [82,  1700] loss: 1.509
2025-02-26T18:08:56.091522+0300 | INFO | [82,  1800] loss: 1.501
2025-02-26T18:10:25.677595+0300 | INFO | [82,  1900] loss: 1.508
2025-02-26T18:11:45.533471+0300 | INFO | [82,  2000] loss: 1.507
2025-02-26T18:13:01.995757+0300 | INFO | [82,  2100] loss: 1.517
2025-02-26T18:14:17.593778+0300 | INFO | [82,  2200] loss: 1.506
2025-02-26T18:15:33.196897+0300 | INFO | [82,  2300] loss: 1.505
2025-02-26T18:17:04.123998+0300 | INFO | [82,  2400] loss: 1.495
2025-02-26T18:18:30.833489+0300 | INFO | [82,  2500] loss: 1.508
2025-02-26T18:19:50.632212+0300 | INFO | [82,  2600] loss: 1.497
2025-02-26T18:21:13.915250+0300 | INFO | [82,  2700] loss: 1.512
2025-02-26T18:22:36.610962+0300 | INFO | [82,  2800] loss: 1.510
2025-02-26T18:24:07.753506+0300 | INFO | [82,  2900] loss: 1.507
2025-02-26T18:25:28.116190+0300 | INFO | [82,  3000] loss: 1.512
2025-02-26T18:26:53.983368+0300 | INFO | [82,  3100] loss: 1.510
2025-02-26T18:28:15.924146+0300 | INFO | [82,  3200] loss: 1.512
2025-02-26T18:29:49.706082+0300 | INFO | [82,  3300] loss: 1.508
2025-02-26T18:31:52.012711+0300 | INFO | [82,  3400] loss: 1.512
2025-02-26T18:33:15.533599+0300 | INFO | [82,  3500] loss: 1.495
2025-02-26T18:34:37.816795+0300 | INFO | [82,  3600] loss: 1.500
2025-02-26T18:36:06.167426+0300 | INFO | [82,  3700] loss: 1.503
2025-02-26T18:37:28.366819+0300 | INFO | [82,  3800] loss: 1.501
2025-02-26T18:38:50.998847+0300 | INFO | [82,  3900] loss: 1.503
2025-02-26T18:40:10.782988+0300 | INFO | [82,  4000] loss: 1.508
2025-02-26T18:41:32.236604+0300 | INFO | [82,  4100] loss: 1.513
2025-02-26T18:42:57.572359+0300 | INFO | [82,  4200] loss: 1.512
2025-02-26T18:44:33.713920+0300 | INFO | [82,  4300] loss: 1.523
2025-02-26T18:46:13.689974+0300 | INFO | [82,  4400] loss: 1.509
2025-02-26T18:48:09.011966+0300 | INFO | [82,  4500] loss: 1.504
2025-02-26T18:49:50.895220+0300 | INFO | [82,  4600] loss: 1.505
2025-02-26T18:51:29.741977+0300 | INFO | [82,  4700] loss: 1.522
2025-02-26T18:53:11.359606+0300 | INFO | [82,  4800] loss: 1.507
2025-02-26T18:54:35.454086+0300 | INFO | [82,  4900] loss: 1.505
2025-02-26T18:55:55.351409+0300 | DEBUG | Saving model to flat file storage. Save #82
2025-02-26T18:55:55.428042+0300 | INFO | Averaging client parameters
2025-02-26T18:55:55.451751+0300 | INFO | Updating parameters on client #0
2025-02-26T18:57:19.198926+0300 | DEBUG | Test set: Accuracy: 7890/10000 (79%)
2025-02-26T18:57:19.205935+0300 | DEBUG | Test set: Loss: 1.6714659929275513
2025-02-26T18:57:19.417649+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.89      0.92      0.91      1000
           2       0.73      0.71      0.72      1000
           3       0.66      0.60      0.63      1200
           4       0.79      0.78      0.79      1000
           5       0.53      0.63      0.58       800
           6       0.83      0.85      0.84      1000
           7       0.86      0.81      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T18:57:19.420667+0300 | DEBUG | Confusion Matrix:
[[830  24  36  13  15   7   9   9  31  26]
 [  7 923   1   4   0   4   7   1   8  45]
 [ 63   3 706  42  55  47  52  18   6   8]
 [ 20   6  66 718  48 250  41  28  11  12]
 [  8   1  51  52 779  36  35  30   7   1]
 [ 11   2  37 169  25 507  13  30   3   3]
 [  8   3  37  49  16  30 847   4   3   3]
 [ 18   4  21  29  38  64   3 814   1   8]
 [ 42  21   8   8   4   5   4   4 886  18]
 [ 22  48  10   8   1   6   5   6  14 880]]
2025-02-26T18:57:19.427186+0300 | DEBUG | Class precision: [0.80660836 0.89178744 0.72559096 0.65750916 0.79408767 0.53033473
 0.83366142 0.86228814 0.91340206 0.87649402]
2025-02-26T18:57:19.430206+0300 | DEBUG | Class recall: [0.83       0.923      0.706      0.59833333 0.779      0.63375
 0.847      0.814      0.886      0.88      ]
2025-02-26T18:57:19.435584+0300 | INFO | Training epoch #83 on client #0
2025-02-26T18:57:19.436589+0300 | DEBUG | Saving model to flat file storage. Save #83
2025-02-26T18:57:20.262787+0300 | INFO | [83,     0] loss: 0.015
2025-02-26T18:58:33.655567+0300 | INFO | [83,   100] loss: 1.508
2025-02-26T18:59:53.377256+0300 | INFO | [83,   200] loss: 1.493
2025-02-26T19:01:08.748981+0300 | INFO | [83,   300] loss: 1.497
2025-02-26T19:02:31.288873+0300 | INFO | [83,   400] loss: 1.506
2025-02-26T19:03:52.862984+0300 | INFO | [83,   500] loss: 1.500
2025-02-26T19:05:14.418290+0300 | INFO | [83,   600] loss: 1.502
2025-02-26T19:06:40.778660+0300 | INFO | [83,   700] loss: 1.500
2025-02-26T19:12:09.412933+0300 | INFO | [83,   800] loss: 1.520
2025-02-26T19:12:21.972368+0300 | INFO | [83,   900] loss: 1.502
2025-02-26T19:12:32.885589+0300 | INFO | [83,  1000] loss: 1.516
2025-02-26T19:12:43.886959+0300 | INFO | [83,  1100] loss: 1.513
2025-02-26T19:12:55.430787+0300 | INFO | [83,  1200] loss: 1.506
2025-02-26T19:13:05.166568+0300 | INFO | [83,  1300] loss: 1.499
2025-02-26T19:13:16.789157+0300 | INFO | [83,  1400] loss: 1.502
2025-02-26T19:13:27.307663+0300 | INFO | [83,  1500] loss: 1.519
2025-02-26T19:13:37.451044+0300 | INFO | [83,  1600] loss: 1.495
2025-02-26T19:13:52.867070+0300 | INFO | [83,  1700] loss: 1.523
2025-02-26T19:14:07.566424+0300 | INFO | [83,  1800] loss: 1.506
2025-02-26T19:14:18.958092+0300 | INFO | [83,  1900] loss: 1.501
2025-02-26T19:14:30.832513+0300 | INFO | [83,  2000] loss: 1.508
2025-02-26T19:14:42.488318+0300 | INFO | [83,  2100] loss: 1.509
2025-02-26T19:14:53.528210+0300 | INFO | [83,  2200] loss: 1.506
2025-02-26T19:15:04.592668+0300 | INFO | [83,  2300] loss: 1.499
2025-02-26T19:15:18.347239+0300 | INFO | [83,  2400] loss: 1.502
2025-02-26T19:15:29.529807+0300 | INFO | [83,  2500] loss: 1.514
2025-02-26T19:15:41.183462+0300 | INFO | [83,  2600] loss: 1.505
2025-02-26T19:15:52.967058+0300 | INFO | [83,  2700] loss: 1.499
2025-02-26T19:16:04.158161+0300 | INFO | [83,  2800] loss: 1.518
2025-02-26T19:16:15.825351+0300 | INFO | [83,  2900] loss: 1.509
2025-02-26T19:16:30.910503+0300 | INFO | [83,  3000] loss: 1.507
2025-02-26T19:16:41.805777+0300 | INFO | [83,  3100] loss: 1.517
2025-02-26T19:16:52.350678+0300 | INFO | [83,  3200] loss: 1.502
2025-02-26T19:17:02.691132+0300 | INFO | [83,  3300] loss: 1.505
2025-02-26T19:17:13.998716+0300 | INFO | [83,  3400] loss: 1.503
2025-02-26T19:17:24.901735+0300 | INFO | [83,  3500] loss: 1.519
2025-02-26T19:17:35.865487+0300 | INFO | [83,  3600] loss: 1.504
2025-02-26T19:17:46.617276+0300 | INFO | [83,  3700] loss: 1.505
2025-02-26T19:17:57.155329+0300 | INFO | [83,  3800] loss: 1.516
2025-02-26T19:18:07.782101+0300 | INFO | [83,  3900] loss: 1.509
2025-02-26T19:18:18.263765+0300 | INFO | [83,  4000] loss: 1.515
2025-02-26T19:18:28.505793+0300 | INFO | [83,  4100] loss: 1.521
2025-02-26T19:18:39.360918+0300 | INFO | [83,  4200] loss: 1.517
2025-02-26T19:18:50.524403+0300 | INFO | [83,  4300] loss: 1.509
2025-02-26T19:19:01.989395+0300 | INFO | [83,  4400] loss: 1.492
2025-02-26T19:19:13.391401+0300 | INFO | [83,  4500] loss: 1.514
2025-02-26T19:19:26.181385+0300 | INFO | [83,  4600] loss: 1.513
2025-02-26T19:19:36.179462+0300 | INFO | [83,  4700] loss: 1.504
2025-02-26T19:19:58.598343+0300 | INFO | [83,  4800] loss: 1.503
2025-02-26T19:20:09.742034+0300 | INFO | [83,  4900] loss: 1.511
2025-02-26T19:20:21.220154+0300 | DEBUG | Saving model to flat file storage. Save #83
2025-02-26T19:20:21.248347+0300 | INFO | Averaging client parameters
2025-02-26T19:20:21.261563+0300 | INFO | Updating parameters on client #0
2025-02-26T19:20:44.242135+0300 | DEBUG | Test set: Accuracy: 7850/10000 (78%)
2025-02-26T19:20:44.244256+0300 | DEBUG | Test set: Loss: 1.675536870956421
2025-02-26T19:20:44.340208+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.81      1000
           1       0.91      0.90      0.90      1000
           2       0.78      0.66      0.72      1000
           3       0.63      0.62      0.62      1200
           4       0.82      0.75      0.78      1000
           5       0.52      0.59      0.55       800
           6       0.82      0.87      0.85      1000
           7       0.82      0.83      0.83      1000
           8       0.89      0.90      0.89      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.78      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T19:20:44.343308+0300 | DEBUG | Confusion Matrix:
[[844  17  29  13   8  11   7  13  37  21]
 [ 15 898   1   6   0   3   8   5  18  46]
 [ 66   4 663  60  53  57  55  28   9   5]
 [ 23   4  37 744  35 245  41  45  13  13]
 [ 14   2  41  65 750  39  46  37   5   1]
 [ 10   1  26 205  22 475  13  42   3   3]
 [  8   1  31  43  14  21 872   4   5   1]
 [ 20   2  10  37  30  49   6 834   3   9]
 [ 47  12   6   9   0   5   4   4 896  17]
 [ 27  45   8   7   1   7   9   7  15 874]]
2025-02-26T19:20:44.347195+0300 | DEBUG | Class precision: [0.7858473  0.91075051 0.77816901 0.62573591 0.82146769 0.52083333
 0.82186616 0.81844946 0.89243028 0.88282828]
2025-02-26T19:20:44.348195+0300 | DEBUG | Class recall: [0.844   0.898   0.663   0.62    0.75    0.59375 0.872   0.834   0.896
 0.874  ]
2025-02-26T19:20:44.393128+0300 | INFO | Training epoch #84 on client #0
2025-02-26T19:20:44.395119+0300 | DEBUG | Saving model to flat file storage. Save #84
2025-02-26T19:20:44.687957+0300 | INFO | [84,     0] loss: 0.016
2025-02-26T19:21:02.190535+0300 | INFO | [84,   100] loss: 1.499
2025-02-26T19:21:14.913474+0300 | INFO | [84,   200] loss: 1.506
2025-02-26T19:21:32.917639+0300 | INFO | [84,   300] loss: 1.512
2025-02-26T19:21:43.979880+0300 | INFO | [84,   400] loss: 1.513
2025-02-26T19:21:57.116637+0300 | INFO | [84,   500] loss: 1.502
2025-02-26T19:22:09.890178+0300 | INFO | [84,   600] loss: 1.500
2025-02-26T19:22:29.395990+0300 | INFO | [84,   700] loss: 1.509
2025-02-26T19:22:40.775178+0300 | INFO | [84,   800] loss: 1.517
2025-02-26T19:22:53.703359+0300 | INFO | [84,   900] loss: 1.503
2025-02-26T19:23:06.413813+0300 | INFO | [84,  1000] loss: 1.511
2025-02-26T19:23:20.957030+0300 | INFO | [84,  1100] loss: 1.497
2025-02-26T19:23:34.043452+0300 | INFO | [84,  1200] loss: 1.501
2025-02-26T19:23:47.023724+0300 | INFO | [84,  1300] loss: 1.513
2025-02-26T19:23:59.869558+0300 | INFO | [84,  1400] loss: 1.505
2025-02-26T19:24:14.833305+0300 | INFO | [84,  1500] loss: 1.509
2025-02-26T19:24:28.071975+0300 | INFO | [84,  1600] loss: 1.520
2025-02-26T19:24:41.763340+0300 | INFO | [84,  1700] loss: 1.515
2025-02-26T19:24:54.457054+0300 | INFO | [84,  1800] loss: 1.523
2025-02-26T19:25:07.113461+0300 | INFO | [84,  1900] loss: 1.516
2025-02-26T19:25:19.173393+0300 | INFO | [84,  2000] loss: 1.512
2025-02-26T19:25:31.871071+0300 | INFO | [84,  2100] loss: 1.511
2025-02-26T19:25:44.934158+0300 | INFO | [84,  2200] loss: 1.504
2025-02-26T19:25:58.907954+0300 | INFO | [84,  2300] loss: 1.504
2025-02-26T19:26:12.160714+0300 | INFO | [84,  2400] loss: 1.508
2025-02-26T19:26:25.347251+0300 | INFO | [84,  2500] loss: 1.504
2025-02-26T19:26:40.928124+0300 | INFO | [84,  2600] loss: 1.505
2025-02-26T19:26:59.408309+0300 | INFO | [84,  2700] loss: 1.506
2025-02-26T19:27:12.175471+0300 | INFO | [84,  2800] loss: 1.501
2025-02-26T19:27:24.975409+0300 | INFO | [84,  2900] loss: 1.501
2025-02-26T19:27:37.198034+0300 | INFO | [84,  3000] loss: 1.513
2025-02-26T19:27:49.846157+0300 | INFO | [84,  3100] loss: 1.503
2025-02-26T19:28:03.207413+0300 | INFO | [84,  3200] loss: 1.500
2025-02-26T19:28:15.453554+0300 | INFO | [84,  3300] loss: 1.516
2025-02-26T19:28:28.320837+0300 | INFO | [84,  3400] loss: 1.497
2025-02-26T19:28:41.408278+0300 | INFO | [84,  3500] loss: 1.497
2025-02-26T19:28:53.931298+0300 | INFO | [84,  3600] loss: 1.503
2025-02-26T19:29:06.767466+0300 | INFO | [84,  3700] loss: 1.503
2025-02-26T19:29:20.515704+0300 | INFO | [84,  3800] loss: 1.514
2025-02-26T19:29:34.386430+0300 | INFO | [84,  3900] loss: 1.516
2025-02-26T19:29:46.997711+0300 | INFO | [84,  4000] loss: 1.504
2025-02-26T19:29:59.839086+0300 | INFO | [84,  4100] loss: 1.506
2025-02-26T19:30:13.308576+0300 | INFO | [84,  4200] loss: 1.507
2025-02-26T19:30:25.665093+0300 | INFO | [84,  4300] loss: 1.512
2025-02-26T19:30:38.619493+0300 | INFO | [84,  4400] loss: 1.494
2025-02-26T19:30:51.562370+0300 | INFO | [84,  4500] loss: 1.497
2025-02-26T19:31:06.135264+0300 | INFO | [84,  4600] loss: 1.508
2025-02-26T19:31:18.586242+0300 | INFO | [84,  4700] loss: 1.498
2025-02-26T19:31:31.240659+0300 | INFO | [84,  4800] loss: 1.508
2025-02-26T19:31:43.475689+0300 | INFO | [84,  4900] loss: 1.516
2025-02-26T19:31:56.443944+0300 | DEBUG | Saving model to flat file storage. Save #84
2025-02-26T19:31:56.473546+0300 | INFO | Averaging client parameters
2025-02-26T19:31:56.479662+0300 | INFO | Updating parameters on client #0
2025-02-26T19:32:15.246224+0300 | DEBUG | Test set: Accuracy: 7866/10000 (79%)
2025-02-26T19:32:15.248334+0300 | DEBUG | Test set: Loss: 1.674172282218933
2025-02-26T19:32:15.362106+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.89      0.91      0.90      1000
           2       0.76      0.67      0.71      1000
           3       0.66      0.61      0.63      1200
           4       0.81      0.76      0.79      1000
           5       0.54      0.59      0.56       800
           6       0.81      0.87      0.84      1000
           7       0.84      0.83      0.83      1000
           8       0.85      0.93      0.89      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T19:32:15.364113+0300 | DEBUG | Confusion Matrix:
[[827  22  32  10   9  10   8  12  46  24]
 [ 10 911   0   4   0   2   5   2  21  45]
 [ 62   5 669  37  58  59  65  27  11   7]
 [ 27  10  49 728  38 222  48  34  27  17]
 [ 14   4  40  55 760  35  45  35  10   2]
 [  9   2  33 193  22 474  18  37   7   5]
 [  9   4  28  43  15  20 867   6   8   0]
 [ 20   2  16  29  30  52   3 831   6  11]
 [ 27  11   6   4   1   5   4   3 929  10]
 [ 22  53   7   4   1   1   7   8  27 870]]
2025-02-26T19:32:15.366112+0300 | DEBUG | Class precision: [0.80525803 0.88964844 0.76022727 0.65763324 0.8137045  0.53863636
 0.81028037 0.83517588 0.8507326  0.87790111]
2025-02-26T19:32:15.368212+0300 | DEBUG | Class recall: [0.827      0.911      0.669      0.60666667 0.76       0.5925
 0.867      0.831      0.929      0.87      ]
2025-02-26T19:32:15.442665+0300 | INFO | Training epoch #85 on client #0
2025-02-26T19:32:15.445767+0300 | DEBUG | Saving model to flat file storage. Save #85
2025-02-26T19:32:15.638407+0300 | INFO | [85,     0] loss: 0.015
2025-02-26T19:32:28.928190+0300 | INFO | [85,   100] loss: 1.505
2025-02-26T19:32:41.363891+0300 | INFO | [85,   200] loss: 1.499
2025-02-26T19:32:56.650194+0300 | INFO | [85,   300] loss: 1.509
2025-02-26T19:33:09.394892+0300 | INFO | [85,   400] loss: 1.501
2025-02-26T19:33:22.343086+0300 | INFO | [85,   500] loss: 1.516
2025-02-26T19:33:34.862271+0300 | INFO | [85,   600] loss: 1.502
2025-02-26T19:33:47.752231+0300 | INFO | [85,   700] loss: 1.498
2025-02-26T19:34:00.783329+0300 | INFO | [85,   800] loss: 1.500
2025-02-26T19:34:15.657042+0300 | INFO | [85,   900] loss: 1.506
2025-02-26T19:34:29.268301+0300 | INFO | [85,  1000] loss: 1.514
2025-02-26T19:34:44.775199+0300 | INFO | [85,  1100] loss: 1.505
2025-02-26T19:34:57.686027+0300 | INFO | [85,  1200] loss: 1.497
2025-02-26T19:35:10.798265+0300 | INFO | [85,  1300] loss: 1.504
2025-02-26T19:35:23.519424+0300 | INFO | [85,  1400] loss: 1.505
2025-02-26T19:35:37.778091+0300 | INFO | [85,  1500] loss: 1.500
2025-02-26T19:35:50.739656+0300 | INFO | [85,  1600] loss: 1.499
2025-02-26T19:36:04.138038+0300 | INFO | [85,  1700] loss: 1.517
2025-02-26T19:36:17.290725+0300 | INFO | [85,  1800] loss: 1.515
2025-02-26T19:36:30.582296+0300 | INFO | [85,  1900] loss: 1.499
2025-02-26T19:36:43.886414+0300 | INFO | [85,  2000] loss: 1.519
2025-02-26T19:36:56.941372+0300 | INFO | [85,  2100] loss: 1.502
2025-02-26T19:37:10.189359+0300 | INFO | [85,  2200] loss: 1.519
2025-02-26T19:37:27.803782+0300 | INFO | [85,  2300] loss: 1.498
2025-02-26T19:37:45.700732+0300 | INFO | [85,  2400] loss: 1.500
2025-02-26T19:37:59.691773+0300 | INFO | [85,  2500] loss: 1.513
2025-02-26T19:38:14.875197+0300 | INFO | [85,  2600] loss: 1.501
2025-02-26T19:38:31.940384+0300 | INFO | [85,  2700] loss: 1.506
2025-02-26T19:38:45.655974+0300 | INFO | [85,  2800] loss: 1.500
2025-02-26T19:38:55.582330+0300 | INFO | [85,  2900] loss: 1.504
2025-02-26T19:39:05.744804+0300 | INFO | [85,  3000] loss: 1.514
2025-02-26T19:39:15.444522+0300 | INFO | [85,  3100] loss: 1.517
2025-02-26T19:39:25.708716+0300 | INFO | [85,  3200] loss: 1.519
2025-02-26T19:39:36.000436+0300 | INFO | [85,  3300] loss: 1.497
2025-02-26T19:39:47.067121+0300 | INFO | [85,  3400] loss: 1.507
2025-02-26T19:39:56.684831+0300 | INFO | [85,  3500] loss: 1.515
2025-02-26T19:40:06.437413+0300 | INFO | [85,  3600] loss: 1.507
2025-02-26T19:40:16.242074+0300 | INFO | [85,  3700] loss: 1.510
2025-02-26T19:40:39.780481+0300 | INFO | [85,  3800] loss: 1.507
2025-02-26T19:40:51.134844+0300 | INFO | [85,  3900] loss: 1.504
2025-02-26T19:41:04.886124+0300 | INFO | [85,  4000] loss: 1.504
2025-02-26T19:41:17.688918+0300 | INFO | [85,  4100] loss: 1.520
2025-02-26T19:41:30.637847+0300 | INFO | [85,  4200] loss: 1.524
2025-02-26T19:41:42.979307+0300 | INFO | [85,  4300] loss: 1.500
2025-02-26T19:41:54.788222+0300 | INFO | [85,  4400] loss: 1.506
2025-02-26T19:42:07.388003+0300 | INFO | [85,  4500] loss: 1.510
2025-02-26T19:42:21.709852+0300 | INFO | [85,  4600] loss: 1.520
2025-02-26T19:42:35.529445+0300 | INFO | [85,  4700] loss: 1.509
2025-02-26T19:42:47.759248+0300 | INFO | [85,  4800] loss: 1.506
2025-02-26T19:42:59.136442+0300 | INFO | [85,  4900] loss: 1.512
2025-02-26T19:43:11.634688+0300 | DEBUG | Saving model to flat file storage. Save #85
2025-02-26T19:43:11.659363+0300 | INFO | Averaging client parameters
2025-02-26T19:43:11.666912+0300 | INFO | Updating parameters on client #0
2025-02-26T19:43:26.389768+0300 | DEBUG | Test set: Accuracy: 7874/10000 (79%)
2025-02-26T19:43:26.392754+0300 | DEBUG | Test set: Loss: 1.67257559299469
2025-02-26T19:43:26.518564+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1000
           1       0.89      0.92      0.90      1000
           2       0.77      0.66      0.71      1000
           3       0.64      0.63      0.64      1200
           4       0.80      0.75      0.77      1000
           5       0.53      0.59      0.56       800
           6       0.82      0.86      0.84      1000
           7       0.85      0.83      0.84      1000
           8       0.86      0.92      0.89      1000
           9       0.89      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T19:43:26.522565+0300 | DEBUG | Confusion Matrix:
[[838  17  28   9  10   7   8  11  44  28]
 [ 11 919   1   1   0   2   6   3  18  39]
 [ 62   4 661  62  60  55  54  24  12   6]
 [ 16   7  39 758  44 235  44  23  22  12]
 [ 16   5  49  55 751  43  40  33   7   1]
 [ 12   1  33 196  21 474  17  35   6   5]
 [  5   2  27  49  17  22 863   4  11   0]
 [ 15   3  14  37  34  48   4 830   5  10]
 [ 33  13   6   8   1   4   4   4 916  11]
 [ 20  63   5   7   1   4   8   6  22 864]]
2025-02-26T19:43:26.524565+0300 | DEBUG | Class precision: [0.8151751  0.88878143 0.76593279 0.64128596 0.79978701 0.53020134
 0.82347328 0.85303186 0.86171214 0.8852459 ]
2025-02-26T19:43:26.528210+0300 | DEBUG | Class recall: [0.838      0.919      0.661      0.63166667 0.751      0.5925
 0.863      0.83       0.916      0.864     ]
2025-02-26T19:43:26.585065+0300 | INFO | Training epoch #86 on client #0
2025-02-26T19:43:26.588614+0300 | DEBUG | Saving model to flat file storage. Save #86
2025-02-26T19:43:26.833947+0300 | INFO | [86,     0] loss: 0.015
2025-02-26T19:43:39.084625+0300 | INFO | [86,   100] loss: 1.505
2025-02-26T19:43:51.317475+0300 | INFO | [86,   200] loss: 1.500
2025-02-26T19:44:03.780281+0300 | INFO | [86,   300] loss: 1.509
2025-02-26T19:44:15.336359+0300 | INFO | [86,   400] loss: 1.511
2025-02-26T19:44:27.496226+0300 | INFO | [86,   500] loss: 1.515
2025-02-26T19:44:39.489867+0300 | INFO | [86,   600] loss: 1.502
2025-02-26T19:44:52.433204+0300 | INFO | [86,   700] loss: 1.508
2025-02-26T19:45:07.739204+0300 | INFO | [86,   800] loss: 1.498
2025-02-26T19:45:21.308478+0300 | INFO | [86,   900] loss: 1.506
2025-02-26T19:45:37.352501+0300 | INFO | [86,  1000] loss: 1.500
2025-02-26T19:45:51.474663+0300 | INFO | [86,  1100] loss: 1.510
2025-02-26T19:46:07.511319+0300 | INFO | [86,  1200] loss: 1.501
2025-02-26T19:46:22.454368+0300 | INFO | [86,  1300] loss: 1.510
2025-02-26T19:46:35.182049+0300 | INFO | [86,  1400] loss: 1.501
2025-02-26T19:46:47.884282+0300 | INFO | [86,  1500] loss: 1.501
2025-02-26T19:47:02.086258+0300 | INFO | [86,  1600] loss: 1.506
2025-02-26T19:47:15.904963+0300 | INFO | [86,  1700] loss: 1.498
2025-02-26T19:47:29.593389+0300 | INFO | [86,  1800] loss: 1.489
2025-02-26T19:47:42.151066+0300 | INFO | [86,  1900] loss: 1.505
2025-02-26T19:47:55.273676+0300 | INFO | [86,  2000] loss: 1.508
2025-02-26T19:48:12.794067+0300 | INFO | [86,  2100] loss: 1.508
2025-02-26T19:48:24.316343+0300 | INFO | [86,  2200] loss: 1.497
2025-02-26T19:48:35.289461+0300 | INFO | [86,  2300] loss: 1.522
2025-02-26T19:48:46.668319+0300 | INFO | [86,  2400] loss: 1.505
2025-02-26T19:48:57.956244+0300 | INFO | [86,  2500] loss: 1.506
2025-02-26T19:49:09.558969+0300 | INFO | [86,  2600] loss: 1.510
2025-02-26T19:49:20.422324+0300 | INFO | [86,  2700] loss: 1.513
2025-02-26T19:49:33.014203+0300 | INFO | [86,  2800] loss: 1.513
2025-02-26T19:49:47.378665+0300 | INFO | [86,  2900] loss: 1.499
2025-02-26T19:50:01.024496+0300 | INFO | [86,  3000] loss: 1.506
2025-02-26T19:50:14.470120+0300 | INFO | [86,  3100] loss: 1.505
2025-02-26T19:50:29.814370+0300 | INFO | [86,  3200] loss: 1.512
2025-02-26T19:50:44.364329+0300 | INFO | [86,  3300] loss: 1.504
2025-02-26T19:50:57.308334+0300 | INFO | [86,  3400] loss: 1.499
2025-02-26T19:51:11.046025+0300 | INFO | [86,  3500] loss: 1.505
2025-02-26T19:51:24.212964+0300 | INFO | [86,  3600] loss: 1.516
2025-02-26T19:51:36.361618+0300 | INFO | [86,  3700] loss: 1.507
2025-02-26T19:51:49.363723+0300 | INFO | [86,  3800] loss: 1.521
2025-02-26T19:52:02.421061+0300 | INFO | [86,  3900] loss: 1.504
2025-02-26T19:52:14.358253+0300 | INFO | [86,  4000] loss: 1.496
2025-02-26T19:52:27.477759+0300 | INFO | [86,  4100] loss: 1.515
2025-02-26T19:52:40.111221+0300 | INFO | [86,  4200] loss: 1.517
2025-02-26T19:52:53.134126+0300 | INFO | [86,  4300] loss: 1.513
2025-02-26T19:53:04.917129+0300 | INFO | [86,  4400] loss: 1.495
2025-02-26T19:53:17.092697+0300 | INFO | [86,  4500] loss: 1.505
2025-02-26T19:53:30.235505+0300 | INFO | [86,  4600] loss: 1.513
2025-02-26T19:53:41.583309+0300 | INFO | [86,  4700] loss: 1.513
2025-02-26T19:53:52.078559+0300 | INFO | [86,  4800] loss: 1.511
2025-02-26T19:54:03.338759+0300 | INFO | [86,  4900] loss: 1.508
2025-02-26T19:54:15.459134+0300 | DEBUG | Saving model to flat file storage. Save #86
2025-02-26T19:54:15.476713+0300 | INFO | Averaging client parameters
2025-02-26T19:54:15.481608+0300 | INFO | Updating parameters on client #0
2025-02-26T19:54:33.152614+0300 | DEBUG | Test set: Accuracy: 7892/10000 (79%)
2025-02-26T19:54:33.153600+0300 | DEBUG | Test set: Loss: 1.6704578399658203
2025-02-26T19:54:33.263176+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.80      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.70      0.72      1000
           3       0.69      0.55      0.61      1200
           4       0.77      0.80      0.79      1000
           5       0.52      0.65      0.58       800
           6       0.80      0.87      0.84      1000
           7       0.85      0.85      0.85      1000
           8       0.89      0.89      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T19:54:33.265176+0300 | DEBUG | Confusion Matrix:
[[799  19  46  12  21  10  11  17  39  26]
 [  6 926   1   5   0   3   7   5  12  35]
 [ 46   1 705  31  67  57  59  19   9   6]
 [ 16   5  47 659  63 296  60  29  14  11]
 [  6   1  47  32 804  32  45  26   7   0]
 [  8   1  37 152  29 523  15  31   1   3]
 [  4   2  36  36  16  25 874   3   4   0]
 [ 10   3  17  20  39  46   5 852   2   6]
 [ 33  21  13   8   1   8   6   6 890  14]
 [ 19  59   8   5   2   8   8  11  20 860]]
2025-02-26T19:54:33.265176+0300 | DEBUG | Class precision: [0.843717   0.89210019 0.73667712 0.68645833 0.77159309 0.51884921
 0.80183486 0.85285285 0.89178357 0.89490114]
2025-02-26T19:54:33.266292+0300 | DEBUG | Class recall: [0.799      0.926      0.705      0.54916667 0.804      0.65375
 0.874      0.852      0.89       0.86      ]
2025-02-26T19:54:33.313090+0300 | INFO | Training epoch #87 on client #0
2025-02-26T19:54:33.316184+0300 | DEBUG | Saving model to flat file storage. Save #87
2025-02-26T19:54:33.540425+0300 | INFO | [87,     0] loss: 0.015
2025-02-26T19:54:45.345447+0300 | INFO | [87,   100] loss: 1.508
2025-02-26T19:54:55.876861+0300 | INFO | [87,   200] loss: 1.501
2025-02-26T19:55:07.282933+0300 | INFO | [87,   300] loss: 1.501
2025-02-26T19:55:19.140331+0300 | INFO | [87,   400] loss: 1.504
2025-02-26T19:55:31.074968+0300 | INFO | [87,   500] loss: 1.500
2025-02-26T19:55:43.324816+0300 | INFO | [87,   600] loss: 1.503
2025-02-26T19:55:55.631958+0300 | INFO | [87,   700] loss: 1.511
2025-02-26T19:56:09.593722+0300 | INFO | [87,   800] loss: 1.506
2025-02-26T19:56:21.803929+0300 | INFO | [87,   900] loss: 1.499
2025-02-26T19:56:32.808689+0300 | INFO | [87,  1000] loss: 1.503
2025-02-26T19:56:45.099648+0300 | INFO | [87,  1100] loss: 1.498
2025-02-26T19:56:57.756383+0300 | INFO | [87,  1200] loss: 1.504
2025-02-26T19:57:11.545361+0300 | INFO | [87,  1300] loss: 1.509
2025-02-26T19:57:24.442068+0300 | INFO | [87,  1400] loss: 1.502
2025-02-26T19:57:35.738259+0300 | INFO | [87,  1500] loss: 1.512
2025-02-26T19:57:48.924561+0300 | INFO | [87,  1600] loss: 1.514
2025-02-26T19:58:05.087125+0300 | INFO | [87,  1700] loss: 1.509
2025-02-26T19:58:17.037174+0300 | INFO | [87,  1800] loss: 1.502
2025-02-26T19:58:29.063231+0300 | INFO | [87,  1900] loss: 1.504
2025-02-26T19:58:39.244439+0300 | INFO | [87,  2000] loss: 1.506
2025-02-26T19:58:50.168869+0300 | INFO | [87,  2100] loss: 1.505
2025-02-26T19:59:01.055684+0300 | INFO | [87,  2200] loss: 1.511
2025-02-26T19:59:12.033835+0300 | INFO | [87,  2300] loss: 1.505
2025-02-26T19:59:22.981131+0300 | INFO | [87,  2400] loss: 1.517
2025-02-26T19:59:33.775213+0300 | INFO | [87,  2500] loss: 1.496
2025-02-26T19:59:44.538718+0300 | INFO | [87,  2600] loss: 1.499
2025-02-26T19:59:55.693766+0300 | INFO | [87,  2700] loss: 1.506
2025-02-26T20:00:07.111870+0300 | INFO | [87,  2800] loss: 1.509
2025-02-26T20:00:17.398236+0300 | INFO | [87,  2900] loss: 1.502
2025-02-26T20:00:28.736592+0300 | INFO | [87,  3000] loss: 1.492
2025-02-26T20:00:39.718756+0300 | INFO | [87,  3100] loss: 1.504
2025-02-26T20:00:51.081014+0300 | INFO | [87,  3200] loss: 1.500
2025-02-26T20:01:01.977461+0300 | INFO | [87,  3300] loss: 1.508
2025-02-26T20:01:13.043199+0300 | INFO | [87,  3400] loss: 1.505
2025-02-26T20:01:24.111215+0300 | INFO | [87,  3500] loss: 1.509
2025-02-26T20:01:34.311929+0300 | INFO | [87,  3600] loss: 1.507
2025-02-26T20:01:45.661571+0300 | INFO | [87,  3700] loss: 1.510
2025-02-26T20:01:56.549705+0300 | INFO | [87,  3800] loss: 1.506
2025-02-26T20:02:07.106630+0300 | INFO | [87,  3900] loss: 1.516
2025-02-26T20:02:18.934194+0300 | INFO | [87,  4000] loss: 1.515
2025-02-26T20:02:29.916867+0300 | INFO | [87,  4100] loss: 1.502
2025-02-26T20:02:40.023943+0300 | INFO | [87,  4200] loss: 1.520
2025-02-26T20:02:50.885219+0300 | INFO | [87,  4300] loss: 1.508
2025-02-26T20:03:02.228175+0300 | INFO | [87,  4400] loss: 1.509
2025-02-26T20:03:12.583182+0300 | INFO | [87,  4500] loss: 1.502
2025-02-26T20:03:23.539738+0300 | INFO | [87,  4600] loss: 1.497
2025-02-26T20:03:34.601995+0300 | INFO | [87,  4700] loss: 1.505
2025-02-26T20:03:44.861238+0300 | INFO | [87,  4800] loss: 1.509
2025-02-26T20:03:57.136517+0300 | INFO | [87,  4900] loss: 1.507
2025-02-26T20:04:08.131968+0300 | DEBUG | Saving model to flat file storage. Save #87
2025-02-26T20:04:08.155075+0300 | INFO | Averaging client parameters
2025-02-26T20:04:08.167990+0300 | INFO | Updating parameters on client #0
2025-02-26T20:04:24.013988+0300 | DEBUG | Test set: Accuracy: 7859/10000 (79%)
2025-02-26T20:04:24.017971+0300 | DEBUG | Test set: Loss: 1.6743614673614502
2025-02-26T20:04:24.112657+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.76      0.67      0.71      1000
           3       0.69      0.55      0.61      1200
           4       0.75      0.81      0.78      1000
           5       0.57      0.58      0.58       800
           6       0.77      0.90      0.83      1000
           7       0.84      0.84      0.84      1000
           8       0.87      0.89      0.88      1000
           9       0.85      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.78      0.79      0.78     10000

2025-02-26T20:04:24.116666+0300 | DEBUG | Confusion Matrix:
[[841  13  27   5  12   8   8  10  39  37]
 [ 11 899   1   0   0   2  10   3  16  58]
 [ 66   2 669  32  81  40  69  25  10   6]
 [ 28   4  45 655  66 232  89  42  23  16]
 [ 11   3  37  30 811  22  55  24   6   1]
 [ 11   0  43 170  39 467  18  42   4   6]
 [  5   1  27  27  17   9 898   5  10   1]
 [ 17   2  14  15  48  37  10 843   4  10]
 [ 46  21   6   7   2   2   5   4 889  18]
 [ 21  36  10   2   2   3  11   7  21 887]]
2025-02-26T20:04:24.118558+0300 | DEBUG | Class precision: [0.79564806 0.91641182 0.76109215 0.69459173 0.75231911 0.56812652
 0.7655584  0.83880597 0.86986301 0.85288462]
2025-02-26T20:04:24.120548+0300 | DEBUG | Class recall: [0.841      0.899      0.669      0.54583333 0.811      0.58375
 0.898      0.843      0.889      0.887     ]
2025-02-26T20:04:24.168551+0300 | INFO | Training epoch #88 on client #0
2025-02-26T20:04:24.169620+0300 | DEBUG | Saving model to flat file storage. Save #88
2025-02-26T20:04:24.393239+0300 | INFO | [88,     0] loss: 0.015
2025-02-26T20:04:35.159717+0300 | INFO | [88,   100] loss: 1.512
2025-02-26T20:04:45.790640+0300 | INFO | [88,   200] loss: 1.498
2025-02-26T20:04:56.991431+0300 | INFO | [88,   300] loss: 1.510
2025-02-26T20:05:07.741428+0300 | INFO | [88,   400] loss: 1.506
2025-02-26T20:05:18.809166+0300 | INFO | [88,   500] loss: 1.498
2025-02-26T20:05:30.221509+0300 | INFO | [88,   600] loss: 1.504
2025-02-26T20:05:40.985899+0300 | INFO | [88,   700] loss: 1.506
2025-02-26T20:05:53.327108+0300 | INFO | [88,   800] loss: 1.502
2025-02-26T20:06:04.667398+0300 | INFO | [88,   900] loss: 1.504
2025-02-26T20:06:16.575900+0300 | INFO | [88,  1000] loss: 1.517
2025-02-26T20:06:27.556224+0300 | INFO | [88,  1100] loss: 1.500
2025-02-26T20:06:41.443520+0300 | INFO | [88,  1200] loss: 1.505
2025-02-26T20:06:53.990680+0300 | INFO | [88,  1300] loss: 1.506
2025-02-26T20:07:05.157243+0300 | INFO | [88,  1400] loss: 1.503
2025-02-26T20:07:16.466516+0300 | INFO | [88,  1500] loss: 1.503
2025-02-26T20:07:27.192742+0300 | INFO | [88,  1600] loss: 1.498
2025-02-26T20:07:38.193418+0300 | INFO | [88,  1700] loss: 1.506
2025-02-26T20:07:49.390937+0300 | INFO | [88,  1800] loss: 1.515
2025-02-26T20:08:01.044701+0300 | INFO | [88,  1900] loss: 1.509
2025-02-26T20:08:12.789418+0300 | INFO | [88,  2000] loss: 1.514
2025-02-26T20:08:24.428053+0300 | INFO | [88,  2100] loss: 1.515
2025-02-26T20:08:36.535471+0300 | INFO | [88,  2200] loss: 1.502
2025-02-26T20:08:46.782285+0300 | INFO | [88,  2300] loss: 1.510
2025-02-26T20:08:58.578105+0300 | INFO | [88,  2400] loss: 1.512
2025-02-26T20:09:10.037188+0300 | INFO | [88,  2500] loss: 1.506
2025-02-26T20:09:20.162178+0300 | INFO | [88,  2600] loss: 1.504
2025-02-26T20:09:32.437448+0300 | INFO | [88,  2700] loss: 1.511
2025-02-26T20:09:43.450505+0300 | INFO | [88,  2800] loss: 1.508
2025-02-26T20:09:55.031051+0300 | INFO | [88,  2900] loss: 1.502
2025-02-26T20:10:05.506052+0300 | INFO | [88,  3000] loss: 1.501
2025-02-26T20:10:16.665224+0300 | INFO | [88,  3100] loss: 1.506
2025-02-26T20:10:27.961780+0300 | INFO | [88,  3200] loss: 1.510
2025-02-26T20:10:38.058871+0300 | INFO | [88,  3300] loss: 1.498
2025-02-26T20:10:49.456010+0300 | INFO | [88,  3400] loss: 1.497
2025-02-26T20:11:00.986359+0300 | INFO | [88,  3500] loss: 1.499
2025-02-26T20:11:11.400714+0300 | INFO | [88,  3600] loss: 1.506
2025-02-26T20:11:22.378808+0300 | INFO | [88,  3700] loss: 1.508
2025-02-26T20:11:33.853499+0300 | INFO | [88,  3800] loss: 1.507
2025-02-26T20:11:44.905995+0300 | INFO | [88,  3900] loss: 1.510
2025-02-26T20:11:56.094137+0300 | INFO | [88,  4000] loss: 1.506
2025-02-26T20:12:07.204026+0300 | INFO | [88,  4100] loss: 1.508
2025-02-26T20:12:18.474646+0300 | INFO | [88,  4200] loss: 1.507
2025-02-26T20:12:29.863933+0300 | INFO | [88,  4300] loss: 1.501
2025-02-26T20:12:40.957711+0300 | INFO | [88,  4400] loss: 1.499
2025-02-26T20:12:52.200051+0300 | INFO | [88,  4500] loss: 1.499
2025-02-26T20:13:03.894608+0300 | INFO | [88,  4600] loss: 1.505
2025-02-26T20:13:15.204929+0300 | INFO | [88,  4700] loss: 1.496
2025-02-26T20:13:26.330984+0300 | INFO | [88,  4800] loss: 1.507
2025-02-26T20:13:36.528903+0300 | INFO | [88,  4900] loss: 1.504
2025-02-26T20:13:47.532887+0300 | DEBUG | Saving model to flat file storage. Save #88
2025-02-26T20:13:47.558345+0300 | INFO | Averaging client parameters
2025-02-26T20:13:47.563363+0300 | INFO | Updating parameters on client #0
2025-02-26T20:14:04.297668+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-26T20:14:04.298775+0300 | DEBUG | Test set: Loss: 1.6717251539230347
2025-02-26T20:14:04.403444+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.83      0.96      0.89      1000
           2       0.76      0.67      0.71      1000
           3       0.71      0.54      0.61      1200
           4       0.77      0.79      0.78      1000
           5       0.54      0.66      0.59       800
           6       0.80      0.88      0.84      1000
           7       0.87      0.82      0.85      1000
           8       0.91      0.87      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T20:14:04.405443+0300 | DEBUG | Confusion Matrix:
[[845  30  25   7  12  11   8   7  29  26]
 [  5 959   0   0   0   2   4   0   6  24]
 [ 64   7 670  36  60  58  68  18  10   9]
 [ 27  14  50 647  65 285  50  33  14  15]
 [ 16   5  42  36 794  28  47  21   8   3]
 [ 10   6  33 132  32 531  20  29   2   5]
 [ 11   7  29  29  12  19 880   4   7   2]
 [ 17   4  17  16  51  48   8 822   2  15]
 [ 47  41   6   6   4   2   3   4 868  19]
 [ 22  83   6   3   1   2   7   7  10 859]]
2025-02-26T20:14:04.409457+0300 | DEBUG | Class precision: [0.79417293 0.82958478 0.76309795 0.70942982 0.77012609 0.53853955
 0.80365297 0.86984127 0.90794979 0.87922211]
2025-02-26T20:14:04.413430+0300 | DEBUG | Class recall: [0.845      0.959      0.67       0.53916667 0.794      0.66375
 0.88       0.822      0.868      0.859     ]
2025-02-26T20:14:04.468474+0300 | INFO | Training epoch #89 on client #0
2025-02-26T20:14:04.473475+0300 | DEBUG | Saving model to flat file storage. Save #89
2025-02-26T20:14:04.699435+0300 | INFO | [89,     0] loss: 0.015
2025-02-26T20:14:16.006127+0300 | INFO | [89,   100] loss: 1.505
2025-02-26T20:14:27.311866+0300 | INFO | [89,   200] loss: 1.511
2025-02-26T20:14:37.585787+0300 | INFO | [89,   300] loss: 1.492
2025-02-26T20:14:49.457095+0300 | INFO | [89,   400] loss: 1.502
2025-02-26T20:15:00.574707+0300 | INFO | [89,   500] loss: 1.498
2025-02-26T20:15:10.838737+0300 | INFO | [89,   600] loss: 1.499
2025-02-26T20:15:22.777990+0300 | INFO | [89,   700] loss: 1.500
2025-02-26T20:15:37.841655+0300 | INFO | [89,   800] loss: 1.509
2025-02-26T20:15:49.370125+0300 | INFO | [89,   900] loss: 1.509
2025-02-26T20:16:00.447904+0300 | INFO | [89,  1000] loss: 1.507
2025-02-26T20:16:11.936339+0300 | INFO | [89,  1100] loss: 1.502
2025-02-26T20:16:22.876613+0300 | INFO | [89,  1200] loss: 1.508
2025-02-26T20:16:32.852461+0300 | INFO | [89,  1300] loss: 1.519
2025-02-26T20:16:44.925709+0300 | INFO | [89,  1400] loss: 1.505
2025-02-26T20:16:56.021267+0300 | INFO | [89,  1500] loss: 1.504
2025-02-26T20:17:06.890069+0300 | INFO | [89,  1600] loss: 1.505
2025-02-26T20:17:17.705350+0300 | INFO | [89,  1700] loss: 1.494
2025-02-26T20:17:28.590068+0300 | INFO | [89,  1800] loss: 1.510
2025-02-26T20:17:39.712204+0300 | INFO | [89,  1900] loss: 1.501
2025-02-26T20:17:52.713500+0300 | INFO | [89,  2000] loss: 1.503
2025-02-26T20:18:04.905585+0300 | INFO | [89,  2100] loss: 1.508
2025-02-26T20:18:16.095697+0300 | INFO | [89,  2200] loss: 1.511
2025-02-26T20:18:26.951722+0300 | INFO | [89,  2300] loss: 1.509
2025-02-26T20:18:37.819832+0300 | INFO | [89,  2400] loss: 1.495
2025-02-26T20:18:48.758697+0300 | INFO | [89,  2500] loss: 1.505
2025-02-26T20:18:59.911992+0300 | INFO | [89,  2600] loss: 1.513
2025-02-26T20:19:10.386256+0300 | INFO | [89,  2700] loss: 1.508
2025-02-26T20:19:21.811516+0300 | INFO | [89,  2800] loss: 1.495
2025-02-26T20:19:32.897793+0300 | INFO | [89,  2900] loss: 1.513
2025-02-26T20:19:44.469367+0300 | INFO | [89,  3000] loss: 1.503
2025-02-26T20:19:55.859901+0300 | INFO | [89,  3100] loss: 1.502
2025-02-26T20:20:07.090024+0300 | INFO | [89,  3200] loss: 1.509
2025-02-26T20:20:17.661231+0300 | INFO | [89,  3300] loss: 1.504
2025-02-26T20:20:29.001935+0300 | INFO | [89,  3400] loss: 1.500
2025-02-26T20:20:40.005861+0300 | INFO | [89,  3500] loss: 1.513
2025-02-26T20:20:51.311118+0300 | INFO | [89,  3600] loss: 1.503
2025-02-26T20:21:04.978564+0300 | INFO | [89,  3700] loss: 1.497
2025-02-26T20:21:15.988577+0300 | INFO | [89,  3800] loss: 1.502
2025-02-26T20:21:26.917645+0300 | INFO | [89,  3900] loss: 1.503
2025-02-26T20:21:37.120619+0300 | INFO | [89,  4000] loss: 1.503
2025-02-26T20:21:48.256060+0300 | INFO | [89,  4100] loss: 1.505
2025-02-26T20:21:59.405029+0300 | INFO | [89,  4200] loss: 1.518
2025-02-26T20:22:10.182440+0300 | INFO | [89,  4300] loss: 1.517
2025-02-26T20:22:20.965676+0300 | INFO | [89,  4400] loss: 1.507
2025-02-26T20:22:31.996195+0300 | INFO | [89,  4500] loss: 1.506
2025-02-26T20:22:43.688374+0300 | INFO | [89,  4600] loss: 1.508
2025-02-26T20:22:54.052570+0300 | INFO | [89,  4700] loss: 1.503
2025-02-26T20:23:05.485805+0300 | INFO | [89,  4800] loss: 1.507
2025-02-26T20:23:16.617375+0300 | INFO | [89,  4900] loss: 1.502
2025-02-26T20:23:26.912779+0300 | DEBUG | Saving model to flat file storage. Save #89
2025-02-26T20:23:26.934257+0300 | INFO | Averaging client parameters
2025-02-26T20:23:26.941256+0300 | INFO | Updating parameters on client #0
2025-02-26T20:23:42.449984+0300 | DEBUG | Test set: Accuracy: 7896/10000 (79%)
2025-02-26T20:23:42.453084+0300 | DEBUG | Test set: Loss: 1.670396089553833
2025-02-26T20:23:42.555835+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.91      0.92      0.92      1000
           2       0.74      0.71      0.72      1000
           3       0.71      0.54      0.61      1200
           4       0.75      0.81      0.78      1000
           5       0.53      0.64      0.58       800
           6       0.79      0.89      0.84      1000
           7       0.87      0.82      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T20:23:42.557835+0300 | DEBUG | Confusion Matrix:
[[819  14  44   8  23  10   8   6  46  22]
 [ 16 923   0   2   1   4   6   1  17  30]
 [ 45   1 710  24  64  53  66  22  10   5]
 [ 22   4  60 644  75 273  66  25  17  14]
 [ 10   2  38  35 806  31  45  26   5   2]
 [ 10   3  39 137  34 510  26  33   5   3]
 [  6   0  35  27  14  16 893   4   5   0]
 [ 16   2  16  21  55  50  10 820   2   8]
 [ 33  15   7   6   3   4   5   3 915   9]
 [ 31  51  10   4   3   4   9   6  26 856]]
2025-02-26T20:23:42.560196+0300 | DEBUG | Class precision: [0.8125     0.90935961 0.74035454 0.7092511  0.74768089 0.53403141
 0.78747795 0.86680761 0.8730916  0.90200211]
2025-02-26T20:23:42.561583+0300 | DEBUG | Class recall: [0.819      0.923      0.71       0.53666667 0.806      0.6375
 0.893      0.82       0.915      0.856     ]
2025-02-26T20:23:42.603915+0300 | INFO | Training epoch #90 on client #0
2025-02-26T20:23:42.608407+0300 | DEBUG | Saving model to flat file storage. Save #90
2025-02-26T20:23:42.830241+0300 | INFO | [90,     0] loss: 0.015
2025-02-26T20:23:53.782657+0300 | INFO | [90,   100] loss: 1.498
2025-02-26T20:24:04.909513+0300 | INFO | [90,   200] loss: 1.501
2025-02-26T20:24:15.835654+0300 | INFO | [90,   300] loss: 1.516
2025-02-26T20:24:30.235459+0300 | INFO | [90,   400] loss: 1.498
2025-02-26T20:24:43.873432+0300 | INFO | [90,   500] loss: 1.504
2025-02-26T20:24:55.458852+0300 | INFO | [90,   600] loss: 1.495
2025-02-26T20:25:05.838517+0300 | INFO | [90,   700] loss: 1.499
2025-02-26T20:25:17.311587+0300 | INFO | [90,   800] loss: 1.510
2025-02-26T20:25:28.657269+0300 | INFO | [90,   900] loss: 1.498
2025-02-26T20:25:40.870096+0300 | INFO | [90,  1000] loss: 1.504
2025-02-26T20:25:51.899343+0300 | INFO | [90,  1100] loss: 1.503
2025-02-26T20:26:03.185690+0300 | INFO | [90,  1200] loss: 1.507
2025-02-26T20:26:14.370686+0300 | INFO | [90,  1300] loss: 1.497
2025-02-26T20:26:24.639802+0300 | INFO | [90,  1400] loss: 1.504
2025-02-26T20:26:35.919185+0300 | INFO | [90,  1500] loss: 1.492
2025-02-26T20:26:46.669484+0300 | INFO | [90,  1600] loss: 1.505
2025-02-26T20:26:57.298257+0300 | INFO | [90,  1700] loss: 1.502
2025-02-26T20:27:08.332246+0300 | INFO | [90,  1800] loss: 1.511
2025-02-26T20:27:20.459396+0300 | INFO | [90,  1900] loss: 1.507
2025-02-26T20:27:31.248218+0300 | INFO | [90,  2000] loss: 1.515
2025-02-26T20:27:41.755473+0300 | INFO | [90,  2100] loss: 1.518
2025-02-26T20:27:52.637793+0300 | INFO | [90,  2200] loss: 1.518
2025-02-26T20:28:04.155443+0300 | INFO | [90,  2300] loss: 1.505
2025-02-26T20:28:14.627166+0300 | INFO | [90,  2400] loss: 1.504
2025-02-26T20:28:27.023293+0300 | INFO | [90,  2500] loss: 1.499
2025-02-26T20:28:37.828199+0300 | INFO | [90,  2600] loss: 1.509
2025-02-26T20:28:49.745650+0300 | INFO | [90,  2700] loss: 1.503
2025-02-26T20:29:00.805741+0300 | INFO | [90,  2800] loss: 1.496
2025-02-26T20:29:12.301583+0300 | INFO | [90,  2900] loss: 1.502
2025-02-26T20:29:24.219498+0300 | INFO | [90,  3000] loss: 1.510
2025-02-26T20:29:35.194768+0300 | INFO | [90,  3100] loss: 1.507
2025-02-26T20:29:46.367630+0300 | INFO | [90,  3200] loss: 1.508
2025-02-26T20:29:57.582247+0300 | INFO | [90,  3300] loss: 1.502
2025-02-26T20:30:07.758133+0300 | INFO | [90,  3400] loss: 1.503
2025-02-26T20:30:19.138465+0300 | INFO | [90,  3500] loss: 1.506
2025-02-26T20:30:31.294050+0300 | INFO | [90,  3600] loss: 1.509
2025-02-26T20:30:41.881339+0300 | INFO | [90,  3700] loss: 1.494
2025-02-26T20:30:52.561939+0300 | INFO | [90,  3800] loss: 1.505
2025-02-26T20:31:03.596078+0300 | INFO | [90,  3900] loss: 1.500
2025-02-26T20:31:14.233112+0300 | INFO | [90,  4000] loss: 1.506
2025-02-26T20:31:26.543173+0300 | INFO | [90,  4100] loss: 1.503
2025-02-26T20:31:37.473280+0300 | INFO | [90,  4200] loss: 1.507
2025-02-26T20:31:48.467682+0300 | INFO | [90,  4300] loss: 1.502
2025-02-26T20:31:59.116646+0300 | INFO | [90,  4400] loss: 1.504
2025-02-26T20:32:10.473818+0300 | INFO | [90,  4500] loss: 1.510
2025-02-26T20:32:21.575120+0300 | INFO | [90,  4600] loss: 1.503
2025-02-26T20:32:32.093894+0300 | INFO | [90,  4700] loss: 1.504
2025-02-26T20:32:43.286301+0300 | INFO | [90,  4800] loss: 1.501
2025-02-26T20:32:54.286671+0300 | INFO | [90,  4900] loss: 1.510
2025-02-26T20:33:04.755070+0300 | DEBUG | Saving model to flat file storage. Save #90
2025-02-26T20:33:04.779556+0300 | INFO | Averaging client parameters
2025-02-26T20:33:04.789012+0300 | INFO | Updating parameters on client #0
2025-02-26T20:33:21.522737+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-26T20:33:21.523735+0300 | DEBUG | Test set: Loss: 1.6725709438323975
2025-02-26T20:33:21.580948+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.86      0.82      1000
           1       0.88      0.91      0.90      1000
           2       0.76      0.67      0.71      1000
           3       0.66      0.58      0.62      1200
           4       0.82      0.76      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.79      0.89      0.84      1000
           7       0.88      0.80      0.84      1000
           8       0.88      0.91      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T20:33:21.582394+0300 | DEBUG | Confusion Matrix:
[[860  17  29   7   4   5   5   5  42  26]
 [ 11 914   1   3   0   2   6   2  14  47]
 [ 69   3 666  47  53  60  64  18  15   5]
 [ 29   6  40 701  39 265  64  21  19  16]
 [ 17   7  48  48 761  37  45  27   8   2]
 [ 12   4  30 178  23 493  23  29   3   5]
 [ 10   1  27  38   8  14 890   2   8   2]
 [ 23   3  17  32  37  54  12 804   4  14]
 [ 32  29   6   7   1   0   5   2 908  10]
 [ 27  49   7   4   1   2   9   5  15 881]]
2025-02-26T20:33:21.584410+0300 | DEBUG | Class precision: [0.78899083 0.88480155 0.76463835 0.65821596 0.82092772 0.52896996
 0.79252004 0.87868852 0.87644788 0.87400794]
2025-02-26T20:33:21.585411+0300 | DEBUG | Class recall: [0.86       0.914      0.666      0.58416667 0.761      0.61625
 0.89       0.804      0.908      0.881     ]
2025-02-26T20:33:21.648177+0300 | INFO | Training epoch #91 on client #0
2025-02-26T20:33:21.649135+0300 | DEBUG | Saving model to flat file storage. Save #91
2025-02-26T20:33:22.041368+0300 | INFO | [91,     0] loss: 0.015
2025-02-26T20:33:36.987488+0300 | INFO | [91,   100] loss: 1.501
2025-02-26T20:33:49.152508+0300 | INFO | [91,   200] loss: 1.503
2025-02-26T20:34:00.230452+0300 | INFO | [91,   300] loss: 1.494
2025-02-26T20:34:11.057025+0300 | INFO | [91,   400] loss: 1.507
2025-02-26T20:34:21.853894+0300 | INFO | [91,   500] loss: 1.498
2025-02-26T20:34:32.885215+0300 | INFO | [91,   600] loss: 1.519
2025-02-26T20:34:43.662367+0300 | INFO | [91,   700] loss: 1.501
2025-02-26T20:34:53.764230+0300 | INFO | [91,   800] loss: 1.497
2025-02-26T20:35:05.048989+0300 | INFO | [91,   900] loss: 1.498
2025-02-26T20:35:16.138766+0300 | INFO | [91,  1000] loss: 1.508
2025-02-26T20:35:26.365620+0300 | INFO | [91,  1100] loss: 1.496
2025-02-26T20:35:37.512318+0300 | INFO | [91,  1200] loss: 1.496
2025-02-26T20:35:48.993988+0300 | INFO | [91,  1300] loss: 1.500
2025-02-26T20:36:01.051690+0300 | INFO | [91,  1400] loss: 1.504
2025-02-26T20:36:12.462463+0300 | INFO | [91,  1500] loss: 1.504
2025-02-26T20:36:23.621095+0300 | INFO | [91,  1600] loss: 1.503
2025-02-26T20:36:34.773810+0300 | INFO | [91,  1700] loss: 1.502
2025-02-26T20:36:47.446425+0300 | INFO | [91,  1800] loss: 1.498
2025-02-26T20:36:59.688945+0300 | INFO | [91,  1900] loss: 1.506
2025-02-26T20:37:10.850237+0300 | INFO | [91,  2000] loss: 1.510
2025-02-26T20:37:21.536569+0300 | INFO | [91,  2100] loss: 1.504
2025-02-26T20:37:32.974304+0300 | INFO | [91,  2200] loss: 1.505
2025-02-26T20:37:44.181182+0300 | INFO | [91,  2300] loss: 1.499
2025-02-26T20:37:55.658874+0300 | INFO | [91,  2400] loss: 1.501
2025-02-26T20:38:07.058659+0300 | INFO | [91,  2500] loss: 1.522
2025-02-26T20:38:18.431861+0300 | INFO | [91,  2600] loss: 1.500
2025-02-26T20:38:30.163082+0300 | INFO | [91,  2700] loss: 1.507
2025-02-26T20:38:40.973493+0300 | INFO | [91,  2800] loss: 1.499
2025-02-26T20:38:53.959895+0300 | INFO | [91,  2900] loss: 1.503
2025-02-26T20:39:05.467119+0300 | INFO | [91,  3000] loss: 1.510
2025-02-26T20:39:16.882109+0300 | INFO | [91,  3100] loss: 1.513
2025-02-26T20:39:27.921744+0300 | INFO | [91,  3200] loss: 1.512
2025-02-26T20:39:39.564448+0300 | INFO | [91,  3300] loss: 1.502
2025-02-26T20:39:50.713130+0300 | INFO | [91,  3400] loss: 1.510
2025-02-26T20:40:02.852929+0300 | INFO | [91,  3500] loss: 1.497
2025-02-26T20:40:13.555721+0300 | INFO | [91,  3600] loss: 1.502
2025-02-26T20:40:24.395460+0300 | INFO | [91,  3700] loss: 1.515
2025-02-26T20:40:35.509384+0300 | INFO | [91,  3800] loss: 1.493
2025-02-26T20:40:45.995662+0300 | INFO | [91,  3900] loss: 1.502
2025-02-26T20:40:57.565625+0300 | INFO | [91,  4000] loss: 1.511
2025-02-26T20:41:08.566381+0300 | INFO | [91,  4100] loss: 1.502
2025-02-26T20:41:19.256933+0300 | INFO | [91,  4200] loss: 1.518
2025-02-26T20:41:30.563117+0300 | INFO | [91,  4300] loss: 1.505
2025-02-26T20:41:41.659004+0300 | INFO | [91,  4400] loss: 1.506
2025-02-26T20:41:53.441986+0300 | INFO | [91,  4500] loss: 1.515
2025-02-26T20:42:04.303568+0300 | INFO | [91,  4600] loss: 1.496
2025-02-26T20:42:21.105472+0300 | INFO | [91,  4700] loss: 1.503
2025-02-26T20:42:32.324648+0300 | INFO | [91,  4800] loss: 1.495
2025-02-26T20:42:43.588966+0300 | INFO | [91,  4900] loss: 1.505
2025-02-26T20:42:53.778110+0300 | DEBUG | Saving model to flat file storage. Save #91
2025-02-26T20:42:53.806314+0300 | INFO | Averaging client parameters
2025-02-26T20:42:53.820322+0300 | INFO | Updating parameters on client #0
2025-02-26T20:43:09.818244+0300 | DEBUG | Test set: Accuracy: 7900/10000 (79%)
2025-02-26T20:43:09.822255+0300 | DEBUG | Test set: Loss: 1.6707818508148193
2025-02-26T20:43:09.904318+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.86      0.94      0.90      1000
           2       0.76      0.68      0.72      1000
           3       0.71      0.54      0.61      1200
           4       0.79      0.77      0.78      1000
           5       0.54      0.63      0.58       800
           6       0.81      0.88      0.84      1000
           7       0.81      0.86      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T20:43:09.907317+0300 | DEBUG | Confusion Matrix:
[[838  31  24   8  10   9   6   8  43  23]
 [  7 939   0   0   0   1   3   4  16  30]
 [ 65   9 676  32  72  48  56  26  12   4]
 [ 22   8  47 644  56 277  57  50  25  14]
 [ 12   4  47  31 774  32  43  46   9   2]
 [ 13   5  40 136  25 502  24  45   6   4]
 [ 10   8  24  27  13  16 880   9  10   3]
 [ 20   1  14  16  30  40   7 860   2  10]
 [ 26  20   5   6   1   2   5   2 923  10]
 [ 23  64   7   2   1   2   7   9  21 864]]
2025-02-26T20:43:09.908315+0300 | DEBUG | Class precision: [0.80888031 0.86225895 0.76470588 0.71396896 0.78818737 0.54036598
 0.80882353 0.81208687 0.86504217 0.89626556]
2025-02-26T20:43:09.910314+0300 | DEBUG | Class recall: [0.838      0.939      0.676      0.53666667 0.774      0.6275
 0.88       0.86       0.923      0.864     ]
2025-02-26T20:43:09.980450+0300 | INFO | Training epoch #92 on client #0
2025-02-26T20:43:09.981455+0300 | DEBUG | Saving model to flat file storage. Save #92
2025-02-26T20:43:10.154288+0300 | INFO | [92,     0] loss: 0.016
2025-02-26T20:43:21.044004+0300 | INFO | [92,   100] loss: 1.499
2025-02-26T20:43:32.266957+0300 | INFO | [92,   200] loss: 1.497
2025-02-26T20:43:42.780688+0300 | INFO | [92,   300] loss: 1.501
2025-02-26T20:43:53.738381+0300 | INFO | [92,   400] loss: 1.506
2025-02-26T20:44:04.792449+0300 | INFO | [92,   500] loss: 1.503
2025-02-26T20:44:15.353387+0300 | INFO | [92,   600] loss: 1.517
2025-02-26T20:44:26.738771+0300 | INFO | [92,   700] loss: 1.505
2025-02-26T20:44:37.464102+0300 | INFO | [92,   800] loss: 1.497
2025-02-26T20:44:49.906082+0300 | INFO | [92,   900] loss: 1.502
2025-02-26T20:45:00.993374+0300 | INFO | [92,  1000] loss: 1.500
2025-02-26T20:45:11.889188+0300 | INFO | [92,  1100] loss: 1.504
2025-02-26T20:45:23.846022+0300 | INFO | [92,  1200] loss: 1.506
2025-02-26T20:45:34.524550+0300 | INFO | [92,  1300] loss: 1.496
2025-02-26T20:45:45.901809+0300 | INFO | [92,  1400] loss: 1.507
2025-02-26T20:45:57.517955+0300 | INFO | [92,  1500] loss: 1.513
2025-02-26T20:46:09.291650+0300 | INFO | [92,  1600] loss: 1.514
2025-02-26T20:46:21.337308+0300 | INFO | [92,  1700] loss: 1.509
2025-02-26T20:46:32.467018+0300 | INFO | [92,  1800] loss: 1.502
2025-02-26T20:46:43.863873+0300 | INFO | [92,  1900] loss: 1.508
2025-02-26T20:46:54.500597+0300 | INFO | [92,  2000] loss: 1.507
2025-02-26T20:47:05.496851+0300 | INFO | [92,  2100] loss: 1.502
2025-02-26T20:47:16.743875+0300 | INFO | [92,  2200] loss: 1.502
2025-02-26T20:47:27.218780+0300 | INFO | [92,  2300] loss: 1.497
2025-02-26T20:47:38.264282+0300 | INFO | [92,  2400] loss: 1.498
2025-02-26T20:47:49.566400+0300 | INFO | [92,  2500] loss: 1.500
2025-02-26T20:48:00.408662+0300 | INFO | [92,  2600] loss: 1.497
2025-02-26T20:48:11.717822+0300 | INFO | [92,  2700] loss: 1.512
2025-02-26T20:48:22.851985+0300 | INFO | [92,  2800] loss: 1.510
2025-02-26T20:48:32.994231+0300 | INFO | [92,  2900] loss: 1.510
2025-02-26T20:48:44.020492+0300 | INFO | [92,  3000] loss: 1.503
2025-02-26T20:48:55.403770+0300 | INFO | [92,  3100] loss: 1.501
2025-02-26T20:49:05.913260+0300 | INFO | [92,  3200] loss: 1.500
2025-02-26T20:49:16.730284+0300 | INFO | [92,  3300] loss: 1.502
2025-02-26T20:49:30.807717+0300 | INFO | [92,  3400] loss: 1.502
2025-02-26T20:49:41.700980+0300 | INFO | [92,  3500] loss: 1.504
2025-02-26T20:49:53.388619+0300 | INFO | [92,  3600] loss: 1.511
2025-02-26T20:50:04.147651+0300 | INFO | [92,  3700] loss: 1.516
2025-02-26T20:50:15.276804+0300 | INFO | [92,  3800] loss: 1.500
2025-02-26T20:50:25.587771+0300 | INFO | [92,  3900] loss: 1.518
2025-02-26T20:50:36.519605+0300 | INFO | [92,  4000] loss: 1.503
2025-02-26T20:50:47.851928+0300 | INFO | [92,  4100] loss: 1.505
2025-02-26T20:50:59.113097+0300 | INFO | [92,  4200] loss: 1.499
2025-02-26T20:51:11.228669+0300 | INFO | [92,  4300] loss: 1.508
2025-02-26T20:51:25.983339+0300 | INFO | [92,  4400] loss: 1.510
2025-02-26T20:51:37.100330+0300 | INFO | [92,  4500] loss: 1.500
2025-02-26T20:51:48.482702+0300 | INFO | [92,  4600] loss: 1.514
2025-02-26T20:51:58.987499+0300 | INFO | [92,  4700] loss: 1.496
2025-02-26T20:52:10.651459+0300 | INFO | [92,  4800] loss: 1.512
2025-02-26T20:52:21.798411+0300 | INFO | [92,  4900] loss: 1.503
2025-02-26T20:52:33.265674+0300 | DEBUG | Saving model to flat file storage. Save #92
2025-02-26T20:52:33.289729+0300 | INFO | Averaging client parameters
2025-02-26T20:52:33.297749+0300 | INFO | Updating parameters on client #0
2025-02-26T20:52:49.047978+0300 | DEBUG | Test set: Accuracy: 7916/10000 (79%)
2025-02-26T20:52:49.048979+0300 | DEBUG | Test set: Loss: 1.6689972877502441
2025-02-26T20:52:49.143483+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.83      1000
           1       0.91      0.93      0.92      1000
           2       0.73      0.71      0.72      1000
           3       0.69      0.55      0.61      1200
           4       0.79      0.79      0.79      1000
           5       0.53      0.61      0.56       800
           6       0.81      0.89      0.85      1000
           7       0.83      0.84      0.83      1000
           8       0.88      0.91      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T20:52:49.145490+0300 | DEBUG | Confusion Matrix:
[[832  14  41   8   9  12   7  10  42  25]
 [  5 929   2   1   0   3   5   3  15  37]
 [ 53   3 706  37  56  54  53  20  12   6]
 [ 17   2  56 660  54 271  66  49  14  11]
 [ 15   1  48  36 790  32  42  31   5   0]
 [ 10   2  41 156  30 485  25  44   5   2]
 [  8   2  29  29  17  11 894   5   5   0]
 [ 18   1  18  21  37  50   4 841   3   7]
 [ 28  19   9   5   3   2   5   3 911  15]
 [ 23  51  11   5   2   3   6   9  22 868]]
2025-02-26T20:52:49.147489+0300 | DEBUG | Class precision: [0.82457879 0.90722656 0.7346514  0.68893528 0.79158317 0.52546046
 0.80758808 0.82857143 0.88104449 0.89392379]
2025-02-26T20:52:49.150491+0300 | DEBUG | Class recall: [0.832   0.929   0.706   0.55    0.79    0.60625 0.894   0.841   0.911
 0.868  ]
2025-02-26T20:52:49.196849+0300 | INFO | Training epoch #93 on client #0
2025-02-26T20:52:49.198853+0300 | DEBUG | Saving model to flat file storage. Save #93
2025-02-26T20:52:49.399511+0300 | INFO | [93,     0] loss: 0.015
2025-02-26T20:53:00.461425+0300 | INFO | [93,   100] loss: 1.498
2025-02-26T20:53:11.758707+0300 | INFO | [93,   200] loss: 1.501
2025-02-26T20:53:23.977543+0300 | INFO | [93,   300] loss: 1.502
2025-02-26T20:53:36.572691+0300 | INFO | [93,   400] loss: 1.505
2025-02-26T20:53:47.549854+0300 | INFO | [93,   500] loss: 1.504
2025-02-26T20:53:58.963212+0300 | INFO | [93,   600] loss: 1.509
2025-02-26T20:54:10.018872+0300 | INFO | [93,   700] loss: 1.495
2025-02-26T20:54:21.741407+0300 | INFO | [93,   800] loss: 1.502
2025-02-26T20:54:35.218554+0300 | INFO | [93,   900] loss: 1.503
2025-02-26T20:54:47.570286+0300 | INFO | [93,  1000] loss: 1.499
2025-02-26T20:54:58.777903+0300 | INFO | [93,  1100] loss: 1.512
2025-02-26T20:55:09.594306+0300 | INFO | [93,  1200] loss: 1.498
2025-02-26T20:55:20.874109+0300 | INFO | [93,  1300] loss: 1.512
2025-02-26T20:55:32.564145+0300 | INFO | [93,  1400] loss: 1.504
2025-02-26T20:55:44.201834+0300 | INFO | [93,  1500] loss: 1.495
2025-02-26T20:55:55.722007+0300 | INFO | [93,  1600] loss: 1.496
2025-02-26T20:56:06.882267+0300 | INFO | [93,  1700] loss: 1.496
2025-02-26T20:56:17.564390+0300 | INFO | [93,  1800] loss: 1.512
2025-02-26T20:56:28.862827+0300 | INFO | [93,  1900] loss: 1.513
2025-02-26T20:56:39.821840+0300 | INFO | [93,  2000] loss: 1.509
2025-02-26T20:56:50.820371+0300 | INFO | [93,  2100] loss: 1.500
2025-02-26T20:57:01.701673+0300 | INFO | [93,  2200] loss: 1.507
2025-02-26T20:57:13.504587+0300 | INFO | [93,  2300] loss: 1.505
2025-02-26T20:57:24.377808+0300 | INFO | [93,  2400] loss: 1.505
2025-02-26T20:57:35.662628+0300 | INFO | [93,  2500] loss: 1.510
2025-02-26T20:57:46.829618+0300 | INFO | [93,  2600] loss: 1.504
2025-02-26T20:57:57.785100+0300 | INFO | [93,  2700] loss: 1.501
2025-02-26T20:58:07.860851+0300 | INFO | [93,  2800] loss: 1.499
2025-02-26T20:58:18.834035+0300 | INFO | [93,  2900] loss: 1.496
2025-02-26T20:58:30.215784+0300 | INFO | [93,  3000] loss: 1.506
2025-02-26T20:58:42.630337+0300 | INFO | [93,  3100] loss: 1.503
2025-02-26T20:58:55.034613+0300 | INFO | [93,  3200] loss: 1.495
2025-02-26T20:59:06.809361+0300 | INFO | [93,  3300] loss: 1.507
2025-02-26T20:59:18.917010+0300 | INFO | [93,  3400] loss: 1.508
2025-02-26T20:59:31.227597+0300 | INFO | [93,  3500] loss: 1.510
2025-02-26T20:59:44.192974+0300 | INFO | [93,  3600] loss: 1.503
2025-02-26T20:59:55.929636+0300 | INFO | [93,  3700] loss: 1.508
2025-02-26T21:00:07.855471+0300 | INFO | [93,  3800] loss: 1.500
2025-02-26T21:00:21.507868+0300 | INFO | [93,  3900] loss: 1.500
2025-02-26T21:00:32.926158+0300 | INFO | [93,  4000] loss: 1.499
2025-02-26T21:00:50.897062+0300 | INFO | [93,  4100] loss: 1.508
2025-02-26T21:01:02.284658+0300 | INFO | [93,  4200] loss: 1.507
2025-02-26T21:01:14.814934+0300 | INFO | [93,  4300] loss: 1.512
2025-02-26T21:01:26.947121+0300 | INFO | [93,  4400] loss: 1.503
2025-02-26T21:01:38.399636+0300 | INFO | [93,  4500] loss: 1.501
2025-02-26T21:01:50.613255+0300 | INFO | [93,  4600] loss: 1.508
2025-02-26T21:02:02.432199+0300 | INFO | [93,  4700] loss: 1.509
2025-02-26T21:02:14.536255+0300 | INFO | [93,  4800] loss: 1.505
2025-02-26T21:02:25.561338+0300 | INFO | [93,  4900] loss: 1.500
2025-02-26T21:02:37.666238+0300 | DEBUG | Saving model to flat file storage. Save #93
2025-02-26T21:02:37.687442+0300 | INFO | Averaging client parameters
2025-02-26T21:02:37.696428+0300 | INFO | Updating parameters on client #0
2025-02-26T21:02:53.146013+0300 | DEBUG | Test set: Accuracy: 7885/10000 (79%)
2025-02-26T21:02:53.150028+0300 | DEBUG | Test set: Loss: 1.6716734170913696
2025-02-26T21:02:53.248521+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.89      0.92      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.71      0.53      0.60      1200
           4       0.77      0.81      0.79      1000
           5       0.53      0.65      0.58       800
           6       0.81      0.87      0.84      1000
           7       0.84      0.84      0.84      1000
           8       0.87      0.91      0.89      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T21:02:53.252670+0300 | DEBUG | Confusion Matrix:
[[830  14  45  10  16   8   6  10  41  20]
 [ 11 923   1   1   0   4   3   1  17  39]
 [ 55   6 686  37  64  63  51  22  11   5]
 [ 23   8  47 631  64 281  65  43  24  14]
 [ 10   3  35  31 805  38  46  26   5   1]
 [ 10   2  33 132  29 523  19  41   6   5]
 [  9   3  29  31  21  21 874   7   5   0]
 [ 17   3  17  16  41  49   8 839   2   8]
 [ 33  20   8   4   3   2   4   4 908  14]
 [ 28  50  11   1   2   4   7  10  21 866]]
2025-02-26T21:02:53.257280+0300 | DEBUG | Class precision: [0.80896686 0.89437984 0.75219298 0.70581655 0.77033493 0.52668681
 0.80701754 0.83649053 0.87307692 0.8909465 ]
2025-02-26T21:02:53.259927+0300 | DEBUG | Class recall: [0.83       0.923      0.686      0.52583333 0.805      0.65375
 0.874      0.839      0.908      0.866     ]
2025-02-26T21:02:53.321711+0300 | INFO | Training epoch #94 on client #0
2025-02-26T21:02:53.324703+0300 | DEBUG | Saving model to flat file storage. Save #94
2025-02-26T21:02:53.525728+0300 | INFO | [94,     0] loss: 0.016
2025-02-26T21:03:04.904784+0300 | INFO | [94,   100] loss: 1.503
2025-02-26T21:03:15.894115+0300 | INFO | [94,   200] loss: 1.502
2025-02-26T21:03:26.315812+0300 | INFO | [94,   300] loss: 1.501
2025-02-26T21:03:37.724363+0300 | INFO | [94,   400] loss: 1.499
2025-02-26T21:03:49.090184+0300 | INFO | [94,   500] loss: 1.500
2025-02-26T21:04:00.024404+0300 | INFO | [94,   600] loss: 1.504
2025-02-26T21:04:12.007846+0300 | INFO | [94,   700] loss: 1.510
2025-02-26T21:04:22.952251+0300 | INFO | [94,   800] loss: 1.511
2025-02-26T21:04:34.602261+0300 | INFO | [94,   900] loss: 1.504
2025-02-26T21:04:45.281819+0300 | INFO | [94,  1000] loss: 1.503
2025-02-26T21:04:56.239130+0300 | INFO | [94,  1100] loss: 1.504
2025-02-26T21:05:08.663943+0300 | INFO | [94,  1200] loss: 1.494
2025-02-26T21:05:20.182488+0300 | INFO | [94,  1300] loss: 1.505
2025-02-26T21:05:32.723317+0300 | INFO | [94,  1400] loss: 1.507
2025-02-26T21:05:43.633634+0300 | INFO | [94,  1500] loss: 1.508
2025-02-26T21:05:54.881603+0300 | INFO | [94,  1600] loss: 1.505
2025-02-26T21:06:06.117085+0300 | INFO | [94,  1700] loss: 1.512
2025-02-26T21:06:17.416740+0300 | INFO | [94,  1800] loss: 1.506
2025-02-26T21:06:28.716330+0300 | INFO | [94,  1900] loss: 1.509
2025-02-26T21:06:39.272696+0300 | INFO | [94,  2000] loss: 1.492
2025-02-26T21:06:50.276655+0300 | INFO | [94,  2100] loss: 1.504
2025-02-26T21:07:01.231907+0300 | INFO | [94,  2200] loss: 1.499
2025-02-26T21:07:11.537919+0300 | INFO | [94,  2300] loss: 1.499
2025-02-26T21:07:22.470231+0300 | INFO | [94,  2400] loss: 1.497
2025-02-26T21:07:33.663039+0300 | INFO | [94,  2500] loss: 1.507
2025-02-26T21:07:43.866853+0300 | INFO | [94,  2600] loss: 1.494
2025-02-26T21:07:55.798820+0300 | INFO | [94,  2700] loss: 1.493
2025-02-26T21:08:08.604273+0300 | INFO | [94,  2800] loss: 1.505
2025-02-26T21:08:20.382169+0300 | INFO | [94,  2900] loss: 1.505
2025-02-26T21:08:31.154563+0300 | INFO | [94,  3000] loss: 1.501
2025-02-26T21:08:43.479463+0300 | INFO | [94,  3100] loss: 1.509
2025-02-26T21:08:55.098967+0300 | INFO | [94,  3200] loss: 1.502
2025-02-26T21:09:05.493931+0300 | INFO | [94,  3300] loss: 1.504
2025-02-26T21:09:17.154149+0300 | INFO | [94,  3400] loss: 1.495
2025-02-26T21:09:29.626224+0300 | INFO | [94,  3500] loss: 1.506
2025-02-26T21:09:42.339422+0300 | INFO | [94,  3600] loss: 1.515
2025-02-26T21:09:57.224886+0300 | INFO | [94,  3700] loss: 1.499
2025-02-26T21:10:09.040887+0300 | INFO | [94,  3800] loss: 1.504
2025-02-26T21:10:20.685011+0300 | INFO | [94,  3900] loss: 1.510
2025-02-26T21:10:32.112604+0300 | INFO | [94,  4000] loss: 1.516
2025-02-26T21:10:43.684548+0300 | INFO | [94,  4100] loss: 1.505
2025-02-26T21:10:55.006235+0300 | INFO | [94,  4200] loss: 1.500
2025-02-26T21:11:06.342104+0300 | INFO | [94,  4300] loss: 1.510
2025-02-26T21:11:17.971386+0300 | INFO | [94,  4400] loss: 1.511
2025-02-26T21:11:29.480101+0300 | INFO | [94,  4500] loss: 1.491
2025-02-26T21:11:40.376681+0300 | INFO | [94,  4600] loss: 1.500
2025-02-26T21:11:52.536664+0300 | INFO | [94,  4700] loss: 1.508
2025-02-26T21:12:04.348523+0300 | INFO | [94,  4800] loss: 1.508
2025-02-26T21:12:15.278872+0300 | INFO | [94,  4900] loss: 1.506
2025-02-26T21:12:26.397311+0300 | DEBUG | Saving model to flat file storage. Save #94
2025-02-26T21:12:26.421799+0300 | INFO | Averaging client parameters
2025-02-26T21:12:26.429880+0300 | INFO | Updating parameters on client #0
2025-02-26T21:12:42.479886+0300 | DEBUG | Test set: Accuracy: 7936/10000 (79%)
2025-02-26T21:12:42.481882+0300 | DEBUG | Test set: Loss: 1.6666910648345947
2025-02-26T21:12:42.599918+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.82      0.83      1000
           1       0.91      0.91      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.68      0.59      0.63      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.87      0.86      0.86      1000
           7       0.85      0.82      0.84      1000
           8       0.87      0.92      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-26T21:12:42.601963+0300 | DEBUG | Confusion Matrix:
[[820  13  39  12  14   9   6  12  53  22]
 [  9 911   1   2   0   3   5   3  23  43]
 [ 52   6 705  44  75  56  25  21   8   8]
 [ 17   3  48 711  49 280  37  33  10  12]
 [  6   3  40  46 808  41  27  23   6   0]
 [ 10   3  38 153  30 515  12  35   3   1]
 [  5   1  38  42  20  29 856   5   4   0]
 [ 15   1  18  29  46  54   5 821   2   9]
 [ 28  14   7   4   5   5   4   3 920  10]
 [ 25  47  10   4   2   4   8   6  25 869]]
2025-02-26T21:12:42.605970+0300 | DEBUG | Class precision: [0.83080041 0.90918164 0.74682203 0.67908309 0.77025739 0.51706827
 0.86903553 0.85343035 0.87286528 0.89219713]
2025-02-26T21:12:42.608015+0300 | DEBUG | Class recall: [0.82    0.911   0.705   0.5925  0.808   0.64375 0.856   0.821   0.92
 0.869  ]
2025-02-26T21:12:42.671961+0300 | INFO | Training epoch #95 on client #0
2025-02-26T21:12:42.673969+0300 | DEBUG | Saving model to flat file storage. Save #95
2025-02-26T21:12:42.920335+0300 | INFO | [95,     0] loss: 0.015
2025-02-26T21:12:54.708350+0300 | INFO | [95,   100] loss: 1.500
2025-02-26T21:13:05.187085+0300 | INFO | [95,   200] loss: 1.500
2025-02-26T21:13:16.484722+0300 | INFO | [95,   300] loss: 1.500
2025-02-26T21:13:27.326051+0300 | INFO | [95,   400] loss: 1.511
2025-02-26T21:13:37.561086+0300 | INFO | [95,   500] loss: 1.498
2025-02-26T21:13:48.710677+0300 | INFO | [95,   600] loss: 1.514
2025-02-26T21:13:59.614641+0300 | INFO | [95,   700] loss: 1.500
2025-02-26T21:14:09.946935+0300 | INFO | [95,   800] loss: 1.501
2025-02-26T21:14:20.815157+0300 | INFO | [95,   900] loss: 1.512
2025-02-26T21:14:31.827234+0300 | INFO | [95,  1000] loss: 1.510
2025-02-26T21:14:42.726865+0300 | INFO | [95,  1100] loss: 1.503
2025-02-26T21:14:53.378756+0300 | INFO | [95,  1200] loss: 1.502
2025-02-26T21:15:05.248437+0300 | INFO | [95,  1300] loss: 1.502
2025-02-26T21:15:16.107999+0300 | INFO | [95,  1400] loss: 1.510
2025-02-26T21:15:26.745015+0300 | INFO | [95,  1500] loss: 1.493
2025-02-26T21:15:37.858410+0300 | INFO | [95,  1600] loss: 1.517
2025-02-26T21:15:49.218000+0300 | INFO | [95,  1700] loss: 1.500
2025-02-26T21:16:00.105812+0300 | INFO | [95,  1800] loss: 1.500
2025-02-26T21:16:11.260752+0300 | INFO | [95,  1900] loss: 1.508
2025-02-26T21:16:22.307029+0300 | INFO | [95,  2000] loss: 1.507
2025-02-26T21:16:32.728839+0300 | INFO | [95,  2100] loss: 1.497
2025-02-26T21:16:43.802824+0300 | INFO | [95,  2200] loss: 1.499
2025-02-26T21:16:55.622236+0300 | INFO | [95,  2300] loss: 1.508
2025-02-26T21:17:06.391519+0300 | INFO | [95,  2400] loss: 1.501
2025-02-26T21:17:17.614774+0300 | INFO | [95,  2500] loss: 1.500
2025-02-26T21:17:28.482014+0300 | INFO | [95,  2600] loss: 1.498
2025-02-26T21:17:40.151528+0300 | INFO | [95,  2700] loss: 1.498
2025-02-26T21:17:50.980899+0300 | INFO | [95,  2800] loss: 1.496
2025-02-26T21:18:02.142114+0300 | INFO | [95,  2900] loss: 1.500
2025-02-26T21:18:13.727834+0300 | INFO | [95,  3000] loss: 1.513
2025-02-26T21:18:24.463362+0300 | INFO | [95,  3100] loss: 1.500
2025-02-26T21:18:37.555781+0300 | INFO | [95,  3200] loss: 1.515
2025-02-26T21:18:52.570805+0300 | INFO | [95,  3300] loss: 1.498
2025-02-26T21:19:04.095442+0300 | INFO | [95,  3400] loss: 1.497
2025-02-26T21:19:15.006199+0300 | INFO | [95,  3500] loss: 1.499
2025-02-26T21:19:25.704728+0300 | INFO | [95,  3600] loss: 1.506
2025-02-26T21:19:38.414031+0300 | INFO | [95,  3700] loss: 1.496
2025-02-26T21:19:49.477846+0300 | INFO | [95,  3800] loss: 1.505
2025-02-26T21:20:00.150015+0300 | INFO | [95,  3900] loss: 1.505
2025-02-26T21:20:11.557076+0300 | INFO | [95,  4000] loss: 1.502
2025-02-26T21:20:22.608725+0300 | INFO | [95,  4100] loss: 1.519
2025-02-26T21:20:33.122749+0300 | INFO | [95,  4200] loss: 1.511
2025-02-26T21:20:45.960800+0300 | INFO | [95,  4300] loss: 1.505
2025-02-26T21:20:57.481886+0300 | INFO | [95,  4400] loss: 1.500
2025-02-26T21:21:08.688259+0300 | INFO | [95,  4500] loss: 1.498
2025-02-26T21:21:20.982148+0300 | INFO | [95,  4600] loss: 1.506
2025-02-26T21:21:32.005414+0300 | INFO | [95,  4700] loss: 1.501
2025-02-26T21:21:43.253631+0300 | INFO | [95,  4800] loss: 1.507
2025-02-26T21:21:53.850942+0300 | INFO | [95,  4900] loss: 1.507
2025-02-26T21:22:04.840249+0300 | DEBUG | Saving model to flat file storage. Save #95
2025-02-26T21:22:04.858602+0300 | INFO | Averaging client parameters
2025-02-26T21:22:04.868606+0300 | INFO | Updating parameters on client #0
2025-02-26T21:22:22.092857+0300 | DEBUG | Test set: Accuracy: 7916/10000 (79%)
2025-02-26T21:22:22.094861+0300 | DEBUG | Test set: Loss: 1.6690845489501953
2025-02-26T21:22:22.194806+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.90      0.91      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.67      0.58      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.55      0.60      0.57       800
           6       0.84      0.87      0.86      1000
           7       0.81      0.86      0.83      1000
           8       0.89      0.89      0.89      1000
           9       0.85      0.90      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T21:22:22.196816+0300 | DEBUG | Confusion Matrix:
[[829  17  33   8  10   6   5  13  39  40]
 [  7 914   0   0   0   2   5   3  15  54]
 [ 59   6 685  46  63  57  40  26  10   8]
 [ 23   5  42 697  59 244  48  49  16  17]
 [ 11   6  40  48 789  28  31  36   7   4]
 [ 12   2  36 173  23 479  16  50   3   6]
 [  8   1  30  35  22  17 871   8   7   1]
 [ 16   3   8  23  35  35   7 859   1  13]
 [ 32  24   6  10   1   2   6   5 894  20]
 [ 18  38   7   5   1   1   6  11  14 899]]
2025-02-26T21:22:22.198832+0300 | DEBUG | Class precision: [0.81674877 0.8996063  0.77226607 0.66698565 0.78664008 0.54994259
 0.84154589 0.81037736 0.88866799 0.84651601]
2025-02-26T21:22:22.200830+0300 | DEBUG | Class recall: [0.829      0.914      0.685      0.58083333 0.789      0.59875
 0.871      0.859      0.894      0.899     ]
2025-02-26T21:22:22.262790+0300 | INFO | Training epoch #96 on client #0
2025-02-26T21:22:22.265792+0300 | DEBUG | Saving model to flat file storage. Save #96
2025-02-26T21:22:22.477667+0300 | INFO | [96,     0] loss: 0.016
2025-02-26T21:22:33.712604+0300 | INFO | [96,   100] loss: 1.499
2025-02-26T21:22:44.877944+0300 | INFO | [96,   200] loss: 1.500
2025-02-26T21:22:55.699304+0300 | INFO | [96,   300] loss: 1.504
2025-02-26T21:23:06.623836+0300 | INFO | [96,   400] loss: 1.493
2025-02-26T21:23:18.202135+0300 | INFO | [96,   500] loss: 1.499
2025-02-26T21:23:28.285333+0300 | INFO | [96,   600] loss: 1.500
2025-02-26T21:23:40.030713+0300 | INFO | [96,   700] loss: 1.515
2025-02-26T21:23:51.266133+0300 | INFO | [96,   800] loss: 1.501
2025-02-26T21:24:01.422198+0300 | INFO | [96,   900] loss: 1.499
2025-02-26T21:24:12.446404+0300 | INFO | [96,  1000] loss: 1.504
2025-02-26T21:24:29.161271+0300 | INFO | [96,  1100] loss: 1.499
2025-02-26T21:24:44.214657+0300 | INFO | [96,  1200] loss: 1.498
2025-02-26T21:24:57.657715+0300 | INFO | [96,  1300] loss: 1.508
2025-02-26T21:25:10.414311+0300 | INFO | [96,  1400] loss: 1.506
2025-02-26T21:25:22.444301+0300 | INFO | [96,  1500] loss: 1.500
2025-02-26T21:25:33.342258+0300 | INFO | [96,  1600] loss: 1.504
2025-02-26T21:25:46.378840+0300 | INFO | [96,  1700] loss: 1.500
2025-02-26T21:26:01.134519+0300 | INFO | [96,  1800] loss: 1.496
2025-02-26T21:26:14.709418+0300 | INFO | [96,  1900] loss: 1.511
2025-02-26T21:26:28.482323+0300 | INFO | [96,  2000] loss: 1.502
2025-02-26T21:26:41.242159+0300 | INFO | [96,  2100] loss: 1.502
2025-02-26T21:26:54.475646+0300 | INFO | [96,  2200] loss: 1.491
2025-02-26T21:27:06.959041+0300 | INFO | [96,  2300] loss: 1.504
2025-02-26T21:27:19.849606+0300 | INFO | [96,  2400] loss: 1.496
2025-02-26T21:27:32.184697+0300 | INFO | [96,  2500] loss: 1.506
2025-02-26T21:27:45.774162+0300 | INFO | [96,  2600] loss: 1.502
2025-02-26T21:27:57.278154+0300 | INFO | [96,  2700] loss: 1.499
2025-02-26T21:28:09.538209+0300 | INFO | [96,  2800] loss: 1.504
2025-02-26T21:28:26.780394+0300 | INFO | [96,  2900] loss: 1.513
2025-02-26T21:28:41.238326+0300 | INFO | [96,  3000] loss: 1.521
2025-02-26T21:28:55.732027+0300 | INFO | [96,  3100] loss: 1.506
2025-02-26T21:29:09.728999+0300 | INFO | [96,  3200] loss: 1.501
2025-02-26T21:29:23.125748+0300 | INFO | [96,  3300] loss: 1.505
2025-02-26T21:29:36.231740+0300 | INFO | [96,  3400] loss: 1.505
2025-02-26T21:29:48.050664+0300 | INFO | [96,  3500] loss: 1.507
2025-02-26T21:30:00.191999+0300 | INFO | [96,  3600] loss: 1.501
2025-02-26T21:30:12.465837+0300 | INFO | [96,  3700] loss: 1.504
2025-02-26T21:30:24.485401+0300 | INFO | [96,  3800] loss: 1.497
2025-02-26T21:30:35.779575+0300 | INFO | [96,  3900] loss: 1.488
2025-02-26T21:30:47.402254+0300 | INFO | [96,  4000] loss: 1.509
2025-02-26T21:30:57.023763+0300 | INFO | [96,  4100] loss: 1.505
2025-02-26T21:31:06.992360+0300 | INFO | [96,  4200] loss: 1.515
2025-02-26T21:31:20.560511+0300 | INFO | [96,  4300] loss: 1.491
2025-02-26T21:31:32.481950+0300 | INFO | [96,  4400] loss: 1.515
2025-02-26T21:31:45.167880+0300 | INFO | [96,  4500] loss: 1.505
2025-02-26T21:31:57.426713+0300 | INFO | [96,  4600] loss: 1.502
2025-02-26T21:32:08.595118+0300 | INFO | [96,  4700] loss: 1.508
2025-02-26T21:32:18.091902+0300 | INFO | [96,  4800] loss: 1.511
2025-02-26T21:32:28.281830+0300 | INFO | [96,  4900] loss: 1.500
2025-02-26T21:32:38.555811+0300 | DEBUG | Saving model to flat file storage. Save #96
2025-02-26T21:32:38.580816+0300 | INFO | Averaging client parameters
2025-02-26T21:32:38.592599+0300 | INFO | Updating parameters on client #0
2025-02-26T21:32:54.534147+0300 | DEBUG | Test set: Accuracy: 7859/10000 (79%)
2025-02-26T21:32:54.535135+0300 | DEBUG | Test set: Loss: 1.6744128465652466
2025-02-26T21:32:54.651163+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.83      0.81      1000
           1       0.88      0.93      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.63      0.61      0.62      1200
           4       0.75      0.81      0.78      1000
           5       0.54      0.54      0.54       800
           6       0.87      0.86      0.86      1000
           7       0.85      0.82      0.84      1000
           8       0.92      0.87      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T21:32:54.652156+0300 | DEBUG | Confusion Matrix:
[[833  19  34  10  22   5   6  10  31  30]
 [  7 927   2   0   0   0   3   2   9  50]
 [ 60   5 687  50  83  47  32  24   7   5]
 [ 28   3  47 738  54 236  34  35  12  13]
 [ 11   2  39  51 812  25  33  21   4   2]
 [ 16   2  37 224  35 435  13  33   2   3]
 [  8   3  37  49  18  18 857   6   3   1]
 [ 19   3  17  35  51  40   3 825   1   6]
 [ 49  30  10   8   3   2   4   4 870  20]
 [ 26  54   9   7   1   1   5  13   9 875]]
2025-02-26T21:32:54.653144+0300 | DEBUG | Class precision: [0.78807947 0.88454198 0.74755169 0.62969283 0.75254866 0.53770087
 0.86565657 0.84789311 0.91772152 0.87064677]
2025-02-26T21:32:54.657546+0300 | DEBUG | Class recall: [0.833   0.927   0.687   0.615   0.812   0.54375 0.857   0.825   0.87
 0.875  ]
2025-02-26T21:32:54.714320+0300 | INFO | Training epoch #97 on client #0
2025-02-26T21:32:54.716316+0300 | DEBUG | Saving model to flat file storage. Save #97
2025-02-26T21:32:55.122298+0300 | INFO | [97,     0] loss: 0.015
2025-02-26T21:33:07.813725+0300 | INFO | [97,   100] loss: 1.495
2025-02-26T21:33:19.920237+0300 | INFO | [97,   200] loss: 1.513
2025-02-26T21:33:30.763270+0300 | INFO | [97,   300] loss: 1.509
2025-02-26T21:33:43.929687+0300 | INFO | [97,   400] loss: 1.506
2025-02-26T21:33:58.439210+0300 | INFO | [97,   500] loss: 1.508
2025-02-26T21:34:12.400014+0300 | INFO | [97,   600] loss: 1.502
2025-02-26T21:34:26.041425+0300 | INFO | [97,   700] loss: 1.495
2025-02-26T21:34:39.400573+0300 | INFO | [97,   800] loss: 1.503
2025-02-26T21:34:53.321051+0300 | INFO | [97,   900] loss: 1.506
2025-02-26T21:35:07.975847+0300 | INFO | [97,  1000] loss: 1.512
2025-02-26T21:35:22.005474+0300 | INFO | [97,  1100] loss: 1.502
2025-02-26T21:35:35.180982+0300 | INFO | [97,  1200] loss: 1.504
2025-02-26T21:35:48.493091+0300 | INFO | [97,  1300] loss: 1.497
2025-02-26T21:35:59.857609+0300 | INFO | [97,  1400] loss: 1.502
2025-02-26T21:36:12.126522+0300 | INFO | [97,  1500] loss: 1.504
2025-02-26T21:36:24.210933+0300 | INFO | [97,  1600] loss: 1.498
2025-02-26T21:36:36.289313+0300 | INFO | [97,  1700] loss: 1.493
2025-02-26T21:36:49.161153+0300 | INFO | [97,  1800] loss: 1.503
2025-02-26T21:37:02.675269+0300 | INFO | [97,  1900] loss: 1.514
2025-02-26T21:37:14.550009+0300 | INFO | [97,  2000] loss: 1.507
2025-02-26T21:37:27.826580+0300 | INFO | [97,  2100] loss: 1.509
2025-02-26T21:37:39.868921+0300 | INFO | [97,  2200] loss: 1.509
2025-02-26T21:37:52.032813+0300 | INFO | [97,  2300] loss: 1.504
2025-02-26T21:38:02.812314+0300 | INFO | [97,  2400] loss: 1.507
2025-02-26T21:38:17.505300+0300 | INFO | [97,  2500] loss: 1.498
2025-02-26T21:38:27.287784+0300 | INFO | [97,  2600] loss: 1.507
2025-02-26T21:38:37.925804+0300 | INFO | [97,  2700] loss: 1.496
2025-02-26T21:38:47.691843+0300 | INFO | [97,  2800] loss: 1.506
2025-02-26T21:38:57.290339+0300 | INFO | [97,  2900] loss: 1.504
2025-02-26T21:39:06.689124+0300 | INFO | [97,  3000] loss: 1.491
2025-02-26T21:39:16.167017+0300 | INFO | [97,  3100] loss: 1.500
2025-02-26T21:39:26.180601+0300 | INFO | [97,  3200] loss: 1.499
2025-02-26T21:39:37.651691+0300 | INFO | [97,  3300] loss: 1.508
2025-02-26T21:39:50.169723+0300 | INFO | [97,  3400] loss: 1.504
2025-02-26T21:39:59.524986+0300 | INFO | [97,  3500] loss: 1.505
2025-02-26T21:40:09.028078+0300 | INFO | [97,  3600] loss: 1.498
2025-02-26T21:40:20.391789+0300 | INFO | [97,  3700] loss: 1.509
2025-02-26T21:40:29.767046+0300 | INFO | [97,  3800] loss: 1.506
2025-02-26T21:40:39.450216+0300 | INFO | [97,  3900] loss: 1.496
2025-02-26T21:40:49.099504+0300 | INFO | [97,  4000] loss: 1.497
2025-02-26T21:40:58.683903+0300 | INFO | [97,  4100] loss: 1.496
2025-02-26T21:41:07.847591+0300 | INFO | [97,  4200] loss: 1.503
2025-02-26T21:41:21.186603+0300 | INFO | [97,  4300] loss: 1.498
2025-02-26T21:41:31.161979+0300 | INFO | [97,  4400] loss: 1.508
2025-02-26T21:41:42.255801+0300 | INFO | [97,  4500] loss: 1.503
2025-02-26T21:41:52.549406+0300 | INFO | [97,  4600] loss: 1.513
2025-02-26T21:42:03.160850+0300 | INFO | [97,  4700] loss: 1.501
2025-02-26T21:42:19.209433+0300 | INFO | [97,  4800] loss: 1.511
2025-02-26T21:42:31.837760+0300 | INFO | [97,  4900] loss: 1.495
2025-02-26T21:42:45.354863+0300 | DEBUG | Saving model to flat file storage. Save #97
2025-02-26T21:42:45.381404+0300 | INFO | Averaging client parameters
2025-02-26T21:42:45.393508+0300 | INFO | Updating parameters on client #0
2025-02-26T21:42:59.793280+0300 | DEBUG | Test set: Accuracy: 7855/10000 (79%)
2025-02-26T21:42:59.794618+0300 | DEBUG | Test set: Loss: 1.6747817993164062
2025-02-26T21:42:59.896122+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.81      0.81      1000
           1       0.86      0.94      0.90      1000
           2       0.73      0.70      0.71      1000
           3       0.66      0.58      0.62      1200
           4       0.75      0.81      0.78      1000
           5       0.56      0.58      0.57       800
           6       0.82      0.87      0.85      1000
           7       0.87      0.80      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.90      0.84      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.78      0.79      0.78     10000

2025-02-26T21:42:59.897126+0300 | DEBUG | Confusion Matrix:
[[814  20  46   7  16   5   6   6  53  27]
 [  4 942   2   0   0   0   4   2  20  26]
 [ 51   5 702  49  71  42  43  20  10   7]
 [ 23   7  52 696  63 232  62  31  23  11]
 [ 12   5  42  37 807  32  38  17   8   2]
 [ 14   5  41 192  35 464  20  23   3   3]
 [  8   4  42  30  15  14 874   7   5   1]
 [ 23   3  22  28  65  42   8 801   1   7]
 [ 26  21   9   9   1   2   3   3 916  10]
 [ 27  85   7   5   2   2   8   7  18 839]]
2025-02-26T21:42:59.899125+0300 | DEBUG | Class precision: [0.81237525 0.85870556 0.72746114 0.66096866 0.75069767 0.55568862
 0.81988743 0.87350055 0.8666036  0.89924973]
2025-02-26T21:42:59.900127+0300 | DEBUG | Class recall: [0.814 0.942 0.702 0.58  0.807 0.58  0.874 0.801 0.916 0.839]
2025-02-26T21:42:59.952480+0300 | INFO | Training epoch #98 on client #0
2025-02-26T21:42:59.954480+0300 | DEBUG | Saving model to flat file storage. Save #98
2025-02-26T21:43:00.197064+0300 | INFO | [98,     0] loss: 0.016
2025-02-26T21:43:11.107114+0300 | INFO | [98,   100] loss: 1.509
2025-02-26T21:43:29.813468+0300 | INFO | [98,   200] loss: 1.501
2025-02-26T21:43:43.902950+0300 | INFO | [98,   300] loss: 1.502
2025-02-26T21:43:58.184455+0300 | INFO | [98,   400] loss: 1.499
2025-02-26T21:44:13.332072+0300 | INFO | [98,   500] loss: 1.500
2025-02-26T21:44:27.383801+0300 | INFO | [98,   600] loss: 1.506
2025-02-26T21:44:40.858124+0300 | INFO | [98,   700] loss: 1.516
2025-02-26T21:44:54.249419+0300 | INFO | [98,   800] loss: 1.510
2025-02-26T21:45:08.236506+0300 | INFO | [98,   900] loss: 1.505
2025-02-26T21:45:21.287458+0300 | INFO | [98,  1000] loss: 1.499
2025-02-26T21:45:34.192254+0300 | INFO | [98,  1100] loss: 1.499
2025-02-26T21:45:48.056229+0300 | INFO | [98,  1200] loss: 1.510
2025-02-26T21:46:00.991807+0300 | INFO | [98,  1300] loss: 1.502
2025-02-26T21:46:14.357756+0300 | INFO | [98,  1400] loss: 1.509
2025-02-26T21:46:28.100417+0300 | INFO | [98,  1500] loss: 1.497
2025-02-26T21:46:41.491321+0300 | INFO | [98,  1600] loss: 1.506
2025-02-26T21:46:54.763492+0300 | INFO | [98,  1700] loss: 1.509
2025-02-26T21:47:07.977626+0300 | INFO | [98,  1800] loss: 1.506
2025-02-26T21:47:23.230432+0300 | INFO | [98,  1900] loss: 1.496
2025-02-26T21:47:34.649972+0300 | INFO | [98,  2000] loss: 1.499
2025-02-26T21:47:47.572976+0300 | INFO | [98,  2100] loss: 1.505
2025-02-26T21:48:06.728937+0300 | INFO | [98,  2200] loss: 1.502
2025-02-26T21:48:19.686960+0300 | INFO | [98,  2300] loss: 1.492
2025-02-26T21:48:32.093665+0300 | INFO | [98,  2400] loss: 1.514
2025-02-26T21:48:45.938277+0300 | INFO | [98,  2500] loss: 1.501
2025-02-26T21:48:58.297855+0300 | INFO | [98,  2600] loss: 1.504
2025-02-26T21:49:10.313572+0300 | INFO | [98,  2700] loss: 1.509
2025-02-26T21:49:22.206102+0300 | INFO | [98,  2800] loss: 1.513
2025-02-26T21:49:34.688363+0300 | INFO | [98,  2900] loss: 1.513
2025-02-26T21:49:46.729736+0300 | INFO | [98,  3000] loss: 1.502
2025-02-26T21:49:59.033917+0300 | INFO | [98,  3100] loss: 1.499
2025-02-26T21:50:12.160592+0300 | INFO | [98,  3200] loss: 1.493
2025-02-26T21:50:22.108286+0300 | INFO | [98,  3300] loss: 1.509
2025-02-26T21:50:35.855390+0300 | INFO | [98,  3400] loss: 1.505
2025-02-26T21:50:49.904211+0300 | INFO | [98,  3500] loss: 1.504
2025-02-26T21:51:01.596126+0300 | INFO | [98,  3600] loss: 1.504
2025-02-26T21:51:14.564869+0300 | INFO | [98,  3700] loss: 1.502
2025-02-26T21:51:27.798653+0300 | INFO | [98,  3800] loss: 1.502
2025-02-26T21:51:39.624277+0300 | INFO | [98,  3900] loss: 1.504
2025-02-26T21:51:49.415053+0300 | INFO | [98,  4000] loss: 1.513
2025-02-26T21:51:59.173673+0300 | INFO | [98,  4100] loss: 1.515
2025-02-26T21:52:11.757438+0300 | INFO | [98,  4200] loss: 1.505
2025-02-26T21:52:23.854443+0300 | INFO | [98,  4300] loss: 1.493
2025-02-26T21:52:33.588505+0300 | INFO | [98,  4400] loss: 1.496
2025-02-26T21:52:45.021210+0300 | INFO | [98,  4500] loss: 1.511
2025-02-26T21:52:55.088683+0300 | INFO | [98,  4600] loss: 1.505
2025-02-26T21:53:04.583290+0300 | INFO | [98,  4700] loss: 1.502
2025-02-26T21:53:13.979960+0300 | INFO | [98,  4800] loss: 1.520
2025-02-26T21:53:23.466180+0300 | INFO | [98,  4900] loss: 1.507
2025-02-26T21:53:32.784475+0300 | DEBUG | Saving model to flat file storage. Save #98
2025-02-26T21:53:32.808533+0300 | INFO | Averaging client parameters
2025-02-26T21:53:32.816308+0300 | INFO | Updating parameters on client #0
2025-02-26T21:53:47.500575+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-26T21:53:47.502598+0300 | DEBUG | Test set: Loss: 1.6722133159637451
2025-02-26T21:53:47.598529+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.88      0.92      0.90      1000
           2       0.73      0.70      0.72      1000
           3       0.66      0.60      0.63      1200
           4       0.82      0.76      0.78      1000
           5       0.53      0.62      0.57       800
           6       0.83      0.87      0.85      1000
           7       0.85      0.82      0.83      1000
           8       0.90      0.88      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T21:53:47.599039+0300 | DEBUG | Confusion Matrix:
[[840  21  35   7  10   6   9  11  34  27]
 [  6 922   1   2   0   2   5   4  15  43]
 [ 60   3 700  50  48  53  45  26   7   8]
 [ 19   6  54 717  40 254  49  27  15  19]
 [  9   4  55  51 755  43  37  37   7   2]
 [ 11   1  39 178  20 500  16  29   1   5]
 [  8   1  31  39  14  21 870   6   9   1]
 [ 15   3  22  30  34  59   4 821   2  10]
 [ 45  26  14   8   2   2   6   1 879  17]
 [ 29  56   4   5   1   2   7   7  10 879]]
2025-02-26T21:53:47.601324+0300 | DEBUG | Class precision: [0.80614203 0.88398849 0.73298429 0.65961362 0.81709957 0.53078556
 0.83015267 0.84726522 0.89785495 0.8694362 ]
2025-02-26T21:53:47.603615+0300 | DEBUG | Class recall: [0.84   0.922  0.7    0.5975 0.755  0.625  0.87   0.821  0.879  0.879 ]
2025-02-26T21:53:47.657122+0300 | INFO | Training epoch #99 on client #0
2025-02-26T21:53:47.659425+0300 | DEBUG | Saving model to flat file storage. Save #99
2025-02-26T21:53:47.856499+0300 | INFO | [99,     0] loss: 0.015
2025-02-26T21:53:57.367510+0300 | INFO | [99,   100] loss: 1.499
2025-02-26T21:54:06.615016+0300 | INFO | [99,   200] loss: 1.512
2025-02-26T21:54:16.114029+0300 | INFO | [99,   300] loss: 1.494
2025-02-26T21:54:25.559607+0300 | INFO | [99,   400] loss: 1.505
2025-02-26T21:54:35.527466+0300 | INFO | [99,   500] loss: 1.495
2025-02-26T21:54:45.151445+0300 | INFO | [99,   600] loss: 1.496
2025-02-26T21:54:57.164124+0300 | INFO | [99,   700] loss: 1.499
2025-02-26T21:55:06.757888+0300 | INFO | [99,   800] loss: 1.504
2025-02-26T21:55:18.799482+0300 | INFO | [99,   900] loss: 1.497
2025-02-26T21:55:28.008712+0300 | INFO | [99,  1000] loss: 1.501
2025-02-26T21:55:37.626630+0300 | INFO | [99,  1100] loss: 1.512
2025-02-26T21:55:47.027586+0300 | INFO | [99,  1200] loss: 1.499
2025-02-26T21:55:56.956031+0300 | INFO | [99,  1300] loss: 1.500
2025-02-26T21:56:06.693214+0300 | INFO | [99,  1400] loss: 1.510
2025-02-26T21:56:15.981646+0300 | INFO | [99,  1500] loss: 1.498
2025-02-26T21:56:25.853011+0300 | INFO | [99,  1600] loss: 1.501
2025-02-26T21:56:35.315674+0300 | INFO | [99,  1700] loss: 1.512
2025-02-26T21:56:45.975985+0300 | INFO | [99,  1800] loss: 1.492
2025-02-26T21:56:57.181265+0300 | INFO | [99,  1900] loss: 1.509
2025-02-26T21:57:10.044547+0300 | INFO | [99,  2000] loss: 1.494
2025-02-26T21:57:19.492934+0300 | INFO | [99,  2100] loss: 1.512
2025-02-26T21:57:29.288778+0300 | INFO | [99,  2200] loss: 1.497
2025-02-26T21:57:38.840138+0300 | INFO | [99,  2300] loss: 1.499
2025-02-26T21:57:49.204050+0300 | INFO | [99,  2400] loss: 1.519
2025-02-26T21:57:58.921399+0300 | INFO | [99,  2500] loss: 1.496
2025-02-26T21:58:08.384434+0300 | INFO | [99,  2600] loss: 1.495
2025-02-26T21:58:17.846477+0300 | INFO | [99,  2700] loss: 1.522
2025-02-26T21:58:27.359626+0300 | INFO | [99,  2800] loss: 1.512
2025-02-26T21:58:37.024930+0300 | INFO | [99,  2900] loss: 1.500
2025-02-26T21:58:46.410299+0300 | INFO | [99,  3000] loss: 1.496
2025-02-26T21:58:56.039293+0300 | INFO | [99,  3100] loss: 1.504
2025-02-26T21:59:05.721380+0300 | INFO | [99,  3200] loss: 1.504
2025-02-26T21:59:15.163231+0300 | INFO | [99,  3300] loss: 1.503
2025-02-26T21:59:24.560472+0300 | INFO | [99,  3400] loss: 1.504
2025-02-26T21:59:34.203698+0300 | INFO | [99,  3500] loss: 1.503
2025-02-26T21:59:43.751284+0300 | INFO | [99,  3600] loss: 1.501
2025-02-26T21:59:53.429965+0300 | INFO | [99,  3700] loss: 1.513
2025-02-26T22:00:03.241360+0300 | INFO | [99,  3800] loss: 1.501
2025-02-26T22:00:13.196814+0300 | INFO | [99,  3900] loss: 1.503
2025-02-26T22:00:23.752792+0300 | INFO | [99,  4000] loss: 1.498
2025-02-26T22:00:34.184245+0300 | INFO | [99,  4100] loss: 1.500
2025-02-26T22:00:44.101652+0300 | INFO | [99,  4200] loss: 1.506
2025-02-26T22:00:53.961793+0300 | INFO | [99,  4300] loss: 1.500
2025-02-26T22:01:03.473026+0300 | INFO | [99,  4400] loss: 1.502
2025-02-26T22:01:13.278672+0300 | INFO | [99,  4500] loss: 1.511
2025-02-26T22:01:25.055869+0300 | INFO | [99,  4600] loss: 1.508
2025-02-26T22:01:34.604287+0300 | INFO | [99,  4700] loss: 1.526
2025-02-26T22:01:44.326026+0300 | INFO | [99,  4800] loss: 1.503
2025-02-26T22:01:53.949908+0300 | INFO | [99,  4900] loss: 1.508
2025-02-26T22:02:04.324256+0300 | DEBUG | Saving model to flat file storage. Save #99
2025-02-26T22:02:04.344656+0300 | INFO | Averaging client parameters
2025-02-26T22:02:04.351649+0300 | INFO | Updating parameters on client #0
2025-02-26T22:02:18.681729+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-26T22:02:18.682748+0300 | DEBUG | Test set: Loss: 1.6720404624938965
2025-02-26T22:02:18.777140+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.87      0.94      0.90      1000
           2       0.76      0.69      0.72      1000
           3       0.66      0.59      0.62      1200
           4       0.75      0.80      0.78      1000
           5       0.52      0.64      0.57       800
           6       0.86      0.86      0.86      1000
           7       0.89      0.79      0.84      1000
           8       0.87      0.90      0.89      1000
           9       0.90      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T22:02:18.778139+0300 | DEBUG | Confusion Matrix:
[[828  20  38  12  23   7   4   7  40  21]
 [  7 939   2   2   1   2   4   2  13  28]
 [ 51   6 691  50  63  62  45  16  11   5]
 [ 20   5  45 707  64 271  31  21  20  16]
 [  6   3  40  53 799  39  31  21   6   2]
 [ 10   4  34 165  30 509  11  26   9   2]
 [  8   4  26  43  15  30 864   3   6   1]
 [ 15   3  17  32  61  58   6 793   4  11]
 [ 37  23  11   8   1   2   7   1 899  11]
 [ 31  72   7   6   2   5   6   4  21 846]]
2025-02-26T22:02:18.780143+0300 | DEBUG | Class precision: [0.81737414 0.87025023 0.75850714 0.65584416 0.75448536 0.51675127
 0.85629336 0.88702461 0.87366375 0.8971368 ]
2025-02-26T22:02:18.781659+0300 | DEBUG | Class recall: [0.828      0.939      0.691      0.58916667 0.799      0.63625
 0.864      0.793      0.899      0.846     ]
2025-02-26T22:02:18.831430+0300 | INFO | Training epoch #100 on client #0
2025-02-26T22:02:18.834442+0300 | DEBUG | Saving model to flat file storage. Save #100
2025-02-26T22:02:19.045865+0300 | INFO | [100,     0] loss: 0.015
2025-02-26T22:02:29.087440+0300 | INFO | [100,   100] loss: 1.507
2025-02-26T22:02:39.426494+0300 | INFO | [100,   200] loss: 1.503
2025-02-26T22:02:49.864769+0300 | INFO | [100,   300] loss: 1.502
2025-02-26T22:03:00.391199+0300 | INFO | [100,   400] loss: 1.509
2025-02-26T22:03:10.636330+0300 | INFO | [100,   500] loss: 1.499
2025-02-26T22:03:20.881866+0300 | INFO | [100,   600] loss: 1.514
2025-02-26T22:03:31.928367+0300 | INFO | [100,   700] loss: 1.503
2025-02-26T22:03:42.262852+0300 | INFO | [100,   800] loss: 1.508
2025-02-26T22:03:52.866051+0300 | INFO | [100,   900] loss: 1.493
2025-02-26T22:04:03.260149+0300 | INFO | [100,  1000] loss: 1.507
2025-02-26T22:04:13.914567+0300 | INFO | [100,  1100] loss: 1.504
2025-02-26T22:04:24.534056+0300 | INFO | [100,  1200] loss: 1.509
2025-02-26T22:04:35.131146+0300 | INFO | [100,  1300] loss: 1.503
2025-02-26T22:04:48.536773+0300 | INFO | [100,  1400] loss: 1.505
2025-02-26T22:05:00.899838+0300 | INFO | [100,  1500] loss: 1.507
2025-02-26T22:05:11.319231+0300 | INFO | [100,  1600] loss: 1.506
2025-02-26T22:05:22.967701+0300 | INFO | [100,  1700] loss: 1.504
2025-02-26T22:05:34.850033+0300 | INFO | [100,  1800] loss: 1.499
2025-02-26T22:05:45.765902+0300 | INFO | [100,  1900] loss: 1.500
2025-02-26T22:05:56.771150+0300 | INFO | [100,  2000] loss: 1.507
2025-02-26T22:06:07.843312+0300 | INFO | [100,  2100] loss: 1.511
2025-02-26T22:06:19.747743+0300 | INFO | [100,  2200] loss: 1.511
2025-02-26T22:06:32.456230+0300 | INFO | [100,  2300] loss: 1.495
2025-02-26T22:06:42.922455+0300 | INFO | [100,  2400] loss: 1.502
2025-02-26T22:06:53.413563+0300 | INFO | [100,  2500] loss: 1.495
2025-02-26T22:07:03.503616+0300 | INFO | [100,  2600] loss: 1.502
2025-02-26T22:07:14.484411+0300 | INFO | [100,  2700] loss: 1.500
2025-02-26T22:07:24.745633+0300 | INFO | [100,  2800] loss: 1.509
2025-02-26T22:07:34.830763+0300 | INFO | [100,  2900] loss: 1.498
2025-02-26T22:07:44.948530+0300 | INFO | [100,  3000] loss: 1.506
2025-02-26T22:07:55.073326+0300 | INFO | [100,  3100] loss: 1.499
2025-02-26T22:08:05.560430+0300 | INFO | [100,  3200] loss: 1.495
2025-02-26T22:08:15.685965+0300 | INFO | [100,  3300] loss: 1.490
2025-02-26T22:08:28.352642+0300 | INFO | [100,  3400] loss: 1.493
2025-02-26T22:08:38.381241+0300 | INFO | [100,  3500] loss: 1.503
2025-02-26T22:08:47.989729+0300 | INFO | [100,  3600] loss: 1.496
2025-02-26T22:08:59.046353+0300 | INFO | [100,  3700] loss: 1.493
2025-02-26T22:09:08.865607+0300 | INFO | [100,  3800] loss: 1.519
2025-02-26T22:09:18.693429+0300 | INFO | [100,  3900] loss: 1.492
2025-02-26T22:09:30.280122+0300 | INFO | [100,  4000] loss: 1.499
2025-02-26T22:09:40.188822+0300 | INFO | [100,  4100] loss: 1.509
2025-02-26T22:09:50.116265+0300 | INFO | [100,  4200] loss: 1.499
2025-02-26T22:10:00.135087+0300 | INFO | [100,  4300] loss: 1.501
2025-02-26T22:10:10.801540+0300 | INFO | [100,  4400] loss: 1.505
2025-02-26T22:10:21.097769+0300 | INFO | [100,  4500] loss: 1.509
2025-02-26T22:10:31.133328+0300 | INFO | [100,  4600] loss: 1.492
2025-02-26T22:10:40.856818+0300 | INFO | [100,  4700] loss: 1.496
2025-02-26T22:10:50.965088+0300 | INFO | [100,  4800] loss: 1.502
2025-02-26T22:11:02.051461+0300 | INFO | [100,  4900] loss: 1.493
2025-02-26T22:11:12.744309+0300 | DEBUG | Updating LR for optimizer
2025-02-26T22:11:12.746709+0300 | DEBUG | New LR: 2.5e-05
2025-02-26T22:11:12.748713+0300 | DEBUG | Saving model to flat file storage. Save #100
2025-02-26T22:11:12.773481+0300 | INFO | Averaging client parameters
2025-02-26T22:11:12.780390+0300 | INFO | Updating parameters on client #0
2025-02-26T22:11:29.389646+0300 | DEBUG | Test set: Accuracy: 7798/10000 (78%)
2025-02-26T22:11:29.391644+0300 | DEBUG | Test set: Loss: 1.6800525188446045
2025-02-26T22:11:29.490493+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.78      0.81      1000
           1       0.85      0.94      0.89      1000
           2       0.71      0.71      0.71      1000
           3       0.66      0.54      0.60      1200
           4       0.75      0.79      0.77      1000
           5       0.52      0.61      0.56       800
           6       0.85      0.86      0.86      1000
           7       0.86      0.80      0.83      1000
           8       0.84      0.92      0.88      1000
           9       0.89      0.86      0.87      1000

    accuracy                           0.78     10000
   macro avg       0.78      0.78      0.78     10000
weighted avg       0.78      0.78      0.78     10000

2025-02-26T22:11:29.491503+0300 | DEBUG | Confusion Matrix:
[[776  30  48   7  23   6   5  12  66  27]
 [  4 939   2   1   0   0   1   1  23  29]
 [ 46   8 713  43  68  48  35  23  10   6]
 [ 20  12  57 651  66 281  39  29  27  18]
 [  7   4  56  38 792  39  31  23   7   3]
 [ 10   5  46 168  30 487  17  27   7   3]
 [  7   4  44  37  18  17 857   6   9   1]
 [ 13   4  19  27  65  47   5 803   4  13]
 [ 21  18  12   6   0   4   6   2 922   9]
 [ 19  77   6   4   1   2   7   4  22 858]]
2025-02-26T22:11:29.493514+0300 | DEBUG | Class precision: [0.84073673 0.85286104 0.7108674  0.66293279 0.74506115 0.52309345
 0.85443669 0.86344086 0.84047402 0.88728025]
2025-02-26T22:11:29.495031+0300 | DEBUG | Class recall: [0.776   0.939   0.713   0.5425  0.792   0.60875 0.857   0.803   0.922
 0.858  ]
2025-02-26T22:11:29.545776+0300 | INFO | Training epoch #101 on client #0
2025-02-26T22:11:29.547777+0300 | DEBUG | Saving model to flat file storage. Save #101
2025-02-26T22:11:29.772419+0300 | INFO | [101,     0] loss: 0.015
2025-02-26T22:11:39.927677+0300 | INFO | [101,   100] loss: 1.508
2025-02-26T22:11:50.193325+0300 | INFO | [101,   200] loss: 1.499
2025-02-26T22:12:00.135822+0300 | INFO | [101,   300] loss: 1.502
2025-02-26T22:12:10.278354+0300 | INFO | [101,   400] loss: 1.500
2025-02-26T22:12:20.119980+0300 | INFO | [101,   500] loss: 1.498
2025-02-26T22:12:30.808766+0300 | INFO | [101,   600] loss: 1.499
2025-02-26T22:12:40.984451+0300 | INFO | [101,   700] loss: 1.495
2025-02-26T22:12:51.066493+0300 | INFO | [101,   800] loss: 1.509
2025-02-26T22:13:05.144263+0300 | INFO | [101,   900] loss: 1.508
2025-02-26T22:13:15.995893+0300 | INFO | [101,  1000] loss: 1.490
2025-02-26T22:13:26.221286+0300 | INFO | [101,  1100] loss: 1.504
2025-02-26T22:13:36.064855+0300 | INFO | [101,  1200] loss: 1.506
2025-02-26T22:13:46.054843+0300 | INFO | [101,  1300] loss: 1.496
2025-02-26T22:13:56.090482+0300 | INFO | [101,  1400] loss: 1.492
2025-02-26T22:14:06.034286+0300 | INFO | [101,  1500] loss: 1.503
2025-02-26T22:14:15.853287+0300 | INFO | [101,  1600] loss: 1.489
2025-02-26T22:14:25.686802+0300 | INFO | [101,  1700] loss: 1.496
2025-02-26T22:14:35.613564+0300 | INFO | [101,  1800] loss: 1.504
2025-02-26T22:14:45.677851+0300 | INFO | [101,  1900] loss: 1.517
2025-02-26T22:14:57.237760+0300 | INFO | [101,  2000] loss: 1.504
2025-02-26T22:15:07.235619+0300 | INFO | [101,  2100] loss: 1.494
2025-02-26T22:15:17.264570+0300 | INFO | [101,  2200] loss: 1.485
2025-02-26T22:15:28.510150+0300 | INFO | [101,  2300] loss: 1.500
2025-02-26T22:15:38.958297+0300 | INFO | [101,  2400] loss: 1.501
2025-02-26T22:15:49.471646+0300 | INFO | [101,  2500] loss: 1.503
2025-02-26T22:16:00.435998+0300 | INFO | [101,  2600] loss: 1.506
2025-02-26T22:16:11.171243+0300 | INFO | [101,  2700] loss: 1.503
2025-02-26T22:16:21.296562+0300 | INFO | [101,  2800] loss: 1.496
2025-02-26T22:16:31.156371+0300 | INFO | [101,  2900] loss: 1.517
2025-02-26T22:16:41.810455+0300 | INFO | [101,  3000] loss: 1.499
2025-02-26T22:16:53.851393+0300 | INFO | [101,  3100] loss: 1.499
2025-02-26T22:17:04.240685+0300 | INFO | [101,  3200] loss: 1.497
2025-02-26T22:17:17.041396+0300 | INFO | [101,  3300] loss: 1.489
2025-02-26T22:17:27.281188+0300 | INFO | [101,  3400] loss: 1.503
2025-02-26T22:17:38.812438+0300 | INFO | [101,  3500] loss: 1.500
2025-02-26T22:17:48.815533+0300 | INFO | [101,  3600] loss: 1.500
2025-02-26T22:17:58.910939+0300 | INFO | [101,  3700] loss: 1.501
2025-02-26T22:18:08.742973+0300 | INFO | [101,  3800] loss: 1.493
2025-02-26T22:18:18.525933+0300 | INFO | [101,  3900] loss: 1.508
2025-02-26T22:18:29.462228+0300 | INFO | [101,  4000] loss: 1.505
2025-02-26T22:18:39.406174+0300 | INFO | [101,  4100] loss: 1.499
2025-02-26T22:18:49.604600+0300 | INFO | [101,  4200] loss: 1.500
2025-02-26T22:18:59.777817+0300 | INFO | [101,  4300] loss: 1.502
2025-02-26T22:19:10.861981+0300 | INFO | [101,  4400] loss: 1.499
2025-02-26T22:19:21.223388+0300 | INFO | [101,  4500] loss: 1.500
2025-02-26T22:19:31.296675+0300 | INFO | [101,  4600] loss: 1.503
2025-02-26T22:19:41.603332+0300 | INFO | [101,  4700] loss: 1.496
2025-02-26T22:19:51.914719+0300 | INFO | [101,  4800] loss: 1.503
2025-02-26T22:20:01.871025+0300 | INFO | [101,  4900] loss: 1.505
2025-02-26T22:20:12.135652+0300 | DEBUG | Saving model to flat file storage. Save #101
2025-02-26T22:20:12.157977+0300 | INFO | Averaging client parameters
2025-02-26T22:20:12.168239+0300 | INFO | Updating parameters on client #0
2025-02-26T22:20:28.234859+0300 | DEBUG | Test set: Accuracy: 7872/10000 (79%)
2025-02-26T22:20:28.237283+0300 | DEBUG | Test set: Loss: 1.6725417375564575
2025-02-26T22:20:28.344659+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.83      1000
           1       0.87      0.94      0.90      1000
           2       0.76      0.68      0.72      1000
           3       0.68      0.56      0.61      1200
           4       0.78      0.77      0.77      1000
           5       0.54      0.59      0.56       800
           6       0.81      0.88      0.84      1000
           7       0.82      0.86      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-26T22:20:28.348996+0300 | DEBUG | Confusion Matrix:
[[834  22  31   8  13   5   5  15  44  23]
 [  5 935   1   1   0   1   4   2  14  37]
 [ 55   7 682  37  66  53  53  28  11   8]
 [ 19   6  43 666  64 260  59  40  19  24]
 [ 11   8  46  34 768  33  46  44   7   3]
 [ 12   5  34 170  26 475  18  46   9   5]
 [ 10   5  32  33  15  13 877   7   7   1]
 [ 11   3  16  22  35  39   6 858   2   8]
 [ 32  21   8   8   0   3   6   2 900  20]
 [ 24  61   3   6   1   1   7   9  11 877]]
2025-02-26T22:20:28.350956+0300 | DEBUG | Class precision: [0.82329714 0.87138863 0.76116071 0.67614213 0.77732794 0.53793884
 0.81128585 0.81636537 0.87890625 0.87176938]
2025-02-26T22:20:28.353845+0300 | DEBUG | Class recall: [0.834   0.935   0.682   0.555   0.768   0.59375 0.877   0.858   0.9
 0.877  ]
2025-02-26T22:20:28.406363+0300 | INFO | Training epoch #102 on client #0
2025-02-26T22:20:28.408632+0300 | DEBUG | Saving model to flat file storage. Save #102
2025-02-26T22:20:28.620986+0300 | INFO | [102,     0] loss: 0.017
2025-02-26T22:20:39.108624+0300 | INFO | [102,   100] loss: 1.493
2025-02-26T22:20:49.957485+0300 | INFO | [102,   200] loss: 1.496
2025-02-26T22:21:00.283454+0300 | INFO | [102,   300] loss: 1.502
2025-02-26T22:21:10.684419+0300 | INFO | [102,   400] loss: 1.500
2025-02-26T22:21:27.082530+0300 | INFO | [102,   500] loss: 1.506
2025-02-26T22:21:36.949307+0300 | INFO | [102,   600] loss: 1.497
2025-02-26T22:21:47.392689+0300 | INFO | [102,   700] loss: 1.485
2025-02-26T22:21:57.664430+0300 | INFO | [102,   800] loss: 1.488
2025-02-26T22:22:07.520441+0300 | INFO | [102,   900] loss: 1.500
2025-02-26T22:22:17.570032+0300 | INFO | [102,  1000] loss: 1.504
2025-02-26T22:22:27.849301+0300 | INFO | [102,  1100] loss: 1.501
2025-02-26T22:22:37.679310+0300 | INFO | [102,  1200] loss: 1.499
2025-02-26T22:22:48.586009+0300 | INFO | [102,  1300] loss: 1.497
2025-02-26T22:22:58.726543+0300 | INFO | [102,  1400] loss: 1.502
2025-02-26T22:23:08.530708+0300 | INFO | [102,  1500] loss: 1.499
2025-02-26T22:23:20.057623+0300 | INFO | [102,  1600] loss: 1.500
2025-02-26T22:23:30.167152+0300 | INFO | [102,  1700] loss: 1.499
2025-02-26T22:23:40.052233+0300 | INFO | [102,  1800] loss: 1.500
2025-02-26T22:23:50.276388+0300 | INFO | [102,  1900] loss: 1.505
2025-02-26T22:24:02.704227+0300 | INFO | [102,  2000] loss: 1.503
2025-02-26T22:24:13.019540+0300 | INFO | [102,  2100] loss: 1.491
2025-02-26T22:24:23.880470+0300 | INFO | [102,  2200] loss: 1.494
2025-02-26T22:24:34.324653+0300 | INFO | [102,  2300] loss: 1.494
2025-02-26T22:24:44.530362+0300 | INFO | [102,  2400] loss: 1.502
2025-02-26T22:24:56.397505+0300 | INFO | [102,  2500] loss: 1.508
2025-02-26T22:25:06.069468+0300 | INFO | [102,  2600] loss: 1.491
2025-02-26T22:25:16.033220+0300 | INFO | [102,  2700] loss: 1.493
2025-02-26T22:25:26.608441+0300 | INFO | [102,  2800] loss: 1.493
2025-02-26T22:25:36.547362+0300 | INFO | [102,  2900] loss: 1.502
2025-02-26T22:25:49.200504+0300 | INFO | [102,  3000] loss: 1.502
2025-02-26T22:25:59.158208+0300 | INFO | [102,  3100] loss: 1.494
2025-02-26T22:26:11.562719+0300 | INFO | [102,  3200] loss: 1.505
2025-02-26T22:26:21.408059+0300 | INFO | [102,  3300] loss: 1.503
2025-02-26T22:26:31.620518+0300 | INFO | [102,  3400] loss: 1.495
2025-02-26T22:26:41.807800+0300 | INFO | [102,  3500] loss: 1.502
2025-02-26T22:26:51.927894+0300 | INFO | [102,  3600] loss: 1.501
2025-02-26T22:27:01.981788+0300 | INFO | [102,  3700] loss: 1.501
2025-02-26T22:27:13.485244+0300 | INFO | [102,  3800] loss: 1.501
2025-02-26T22:27:24.854083+0300 | INFO | [102,  3900] loss: 1.500
2025-02-26T22:27:36.647377+0300 | INFO | [102,  4000] loss: 1.493
2025-02-26T22:27:46.626283+0300 | INFO | [102,  4100] loss: 1.491
2025-02-26T22:27:56.614277+0300 | INFO | [102,  4200] loss: 1.494
2025-02-26T22:28:06.689338+0300 | INFO | [102,  4300] loss: 1.508
2025-02-26T22:28:16.412043+0300 | INFO | [102,  4400] loss: 1.494
2025-02-26T22:28:28.034719+0300 | INFO | [102,  4500] loss: 1.487
2025-02-26T22:28:38.695489+0300 | INFO | [102,  4600] loss: 1.504
2025-02-26T22:28:48.754616+0300 | INFO | [102,  4700] loss: 1.501
2025-02-26T22:29:01.083895+0300 | INFO | [102,  4800] loss: 1.497
2025-02-26T22:29:13.073640+0300 | INFO | [102,  4900] loss: 1.498
2025-02-26T22:29:24.661895+0300 | DEBUG | Saving model to flat file storage. Save #102
2025-02-26T22:29:24.680947+0300 | INFO | Averaging client parameters
2025-02-26T22:29:24.687957+0300 | INFO | Updating parameters on client #0
2025-02-26T22:29:40.110182+0300 | DEBUG | Test set: Accuracy: 7902/10000 (79%)
2025-02-26T22:29:40.112200+0300 | DEBUG | Test set: Loss: 1.6699610948562622
2025-02-26T22:29:40.220209+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.82      0.82      1000
           1       0.90      0.91      0.91      1000
           2       0.74      0.69      0.72      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.80      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.82      0.89      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T22:29:40.221473+0300 | DEBUG | Confusion Matrix:
[[817  21  43  11  16  10   7  15  34  26]
 [  7 912   2   1   0   3   5   5  15  50]
 [ 51   4 692  36  68  59  54  24   6   6]
 [ 17   2  47 670  55 299  49  35  11  15]
 [  7   2  44  36 802  39  35  27   5   3]
 [ 11   0  38 149  34 508  19  37   2   2]
 [  9   3  31  32  13  14 887   5   5   1]
 [ 11   1  16  25  49  48   4 840   0   6]
 [ 39  19  10   7   1   4   7   3 889  21]
 [ 21  49   6   6   2   1  11   8  11 885]]
2025-02-26T22:29:40.223922+0300 | DEBUG | Class precision: [0.82525253 0.90029615 0.74488698 0.68859198 0.77115385 0.51573604
 0.82282004 0.84084084 0.90899796 0.87192118]
2025-02-26T22:29:40.226144+0300 | DEBUG | Class recall: [0.817      0.912      0.692      0.55833333 0.802      0.635
 0.887      0.84       0.889      0.885     ]
2025-02-26T22:29:40.281250+0300 | INFO | Training epoch #103 on client #0
2025-02-26T22:29:40.284777+0300 | DEBUG | Saving model to flat file storage. Save #103
2025-02-26T22:29:40.534768+0300 | INFO | [103,     0] loss: 0.015
2025-02-26T22:29:50.916472+0300 | INFO | [103,   100] loss: 1.501
2025-02-26T22:30:03.252847+0300 | INFO | [103,   200] loss: 1.510
2025-02-26T22:30:16.977519+0300 | INFO | [103,   300] loss: 1.491
2025-02-26T22:30:28.272049+0300 | INFO | [103,   400] loss: 1.497
2025-02-26T22:30:38.576968+0300 | INFO | [103,   500] loss: 1.502
2025-02-26T22:30:49.178683+0300 | INFO | [103,   600] loss: 1.495
2025-02-26T22:30:59.437766+0300 | INFO | [103,   700] loss: 1.496
2025-02-26T22:31:09.801531+0300 | INFO | [103,   800] loss: 1.502
2025-02-26T22:31:20.136697+0300 | INFO | [103,   900] loss: 1.503
2025-02-26T22:31:30.233249+0300 | INFO | [103,  1000] loss: 1.507
2025-02-26T22:31:40.323014+0300 | INFO | [103,  1100] loss: 1.488
2025-02-26T22:31:53.270421+0300 | INFO | [103,  1200] loss: 1.490
2025-02-26T22:32:03.577539+0300 | INFO | [103,  1300] loss: 1.498
2025-02-26T22:32:13.539498+0300 | INFO | [103,  1400] loss: 1.509
2025-02-26T22:32:23.742101+0300 | INFO | [103,  1500] loss: 1.499
2025-02-26T22:32:35.302726+0300 | INFO | [103,  1600] loss: 1.501
2025-02-26T22:32:45.722516+0300 | INFO | [103,  1700] loss: 1.505
2025-02-26T22:32:55.965771+0300 | INFO | [103,  1800] loss: 1.497
2025-02-26T22:33:06.164570+0300 | INFO | [103,  1900] loss: 1.499
2025-02-26T22:33:16.262363+0300 | INFO | [103,  2000] loss: 1.503
2025-02-26T22:33:30.920165+0300 | INFO | [103,  2100] loss: 1.490
2025-02-26T22:33:42.552129+0300 | INFO | [103,  2200] loss: 1.499
2025-02-26T22:33:53.181450+0300 | INFO | [103,  2300] loss: 1.496
2025-02-26T22:34:03.437014+0300 | INFO | [103,  2400] loss: 1.493
2025-02-26T22:34:13.966648+0300 | INFO | [103,  2500] loss: 1.497
2025-02-26T22:34:24.010106+0300 | INFO | [103,  2600] loss: 1.500
2025-02-26T22:34:34.320231+0300 | INFO | [103,  2700] loss: 1.487
2025-02-26T22:34:44.467195+0300 | INFO | [103,  2800] loss: 1.493
2025-02-26T22:34:54.384844+0300 | INFO | [103,  2900] loss: 1.492
2025-02-26T22:35:04.180937+0300 | INFO | [103,  3000] loss: 1.495
2025-02-26T22:35:14.386334+0300 | INFO | [103,  3100] loss: 1.496
2025-02-26T22:35:25.723171+0300 | INFO | [103,  3200] loss: 1.497
2025-02-26T22:35:36.535387+0300 | INFO | [103,  3300] loss: 1.499
2025-02-26T22:35:47.625465+0300 | INFO | [103,  3400] loss: 1.486
2025-02-26T22:35:58.301755+0300 | INFO | [103,  3500] loss: 1.499
2025-02-26T22:36:09.249573+0300 | INFO | [103,  3600] loss: 1.507
2025-02-26T22:36:20.016340+0300 | INFO | [103,  3700] loss: 1.500
2025-02-26T22:36:31.938374+0300 | INFO | [103,  3800] loss: 1.499
2025-02-26T22:36:42.745176+0300 | INFO | [103,  3900] loss: 1.497
2025-02-26T22:36:55.308179+0300 | INFO | [103,  4000] loss: 1.497
2025-02-26T22:37:06.060259+0300 | INFO | [103,  4100] loss: 1.498
2025-02-26T22:37:16.873629+0300 | INFO | [103,  4200] loss: 1.493
2025-02-26T22:37:28.187349+0300 | INFO | [103,  4300] loss: 1.499
2025-02-26T22:37:39.033050+0300 | INFO | [103,  4400] loss: 1.499
2025-02-26T22:37:49.948141+0300 | INFO | [103,  4500] loss: 1.493
2025-02-26T22:38:01.321593+0300 | INFO | [103,  4600] loss: 1.490
2025-02-26T22:38:12.573218+0300 | INFO | [103,  4700] loss: 1.504
2025-02-26T22:38:26.614698+0300 | INFO | [103,  4800] loss: 1.500
2025-02-26T22:38:39.381577+0300 | INFO | [103,  4900] loss: 1.501
2025-02-26T22:38:54.517606+0300 | DEBUG | Saving model to flat file storage. Save #103
2025-02-26T22:38:54.544850+0300 | INFO | Averaging client parameters
2025-02-26T22:38:54.553382+0300 | INFO | Updating parameters on client #0
2025-02-26T22:39:10.671420+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-26T22:39:10.672419+0300 | DEBUG | Test set: Loss: 1.672653079032898
2025-02-26T22:39:10.772252+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.68      0.54      0.60      1200
           4       0.74      0.82      0.78      1000
           5       0.53      0.62      0.57       800
           6       0.81      0.89      0.85      1000
           7       0.87      0.80      0.83      1000
           8       0.88      0.91      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T22:39:10.776268+0300 | DEBUG | Confusion Matrix:
[[839  16  30  10  15   4   7  13  41  25]
 [  7 919   2   1   0   1   6   1  22  41]
 [ 53   3 678  36  86  51  59  19   8   7]
 [ 19   4  36 650  73 294  59  28  18  19]
 [  6   3  39  32 819  31  37  22   7   4]
 [ 11   5  35 154  38 500  16  28   9   4]
 [ 12   1  26  31  13  18 886   4   6   3]
 [ 16   3  21  29  60  48   8 799   3  13]
 [ 34  10   9   6   2   2   7   2 910  18]
 [ 25  56   6   5   1   2  10   6  14 875]]
2025-02-26T22:39:10.778269+0300 | DEBUG | Class precision: [0.82093933 0.90098039 0.76870748 0.68134172 0.7398374  0.52576236
 0.80913242 0.86659436 0.87668593 0.86719524]
2025-02-26T22:39:10.780263+0300 | DEBUG | Class recall: [0.839      0.919      0.678      0.54166667 0.819      0.625
 0.886      0.799      0.91       0.875     ]
2025-02-26T22:39:10.834548+0300 | INFO | Training epoch #104 on client #0
2025-02-26T22:39:10.835553+0300 | DEBUG | Saving model to flat file storage. Save #104
2025-02-26T22:39:11.051740+0300 | INFO | [104,     0] loss: 0.016
2025-02-26T22:39:24.201100+0300 | INFO | [104,   100] loss: 1.492
2025-02-26T22:39:35.921802+0300 | INFO | [104,   200] loss: 1.496
2025-02-26T22:39:46.897956+0300 | INFO | [104,   300] loss: 1.480
2025-02-26T22:39:58.404245+0300 | INFO | [104,   400] loss: 1.507
2025-02-26T22:40:09.329037+0300 | INFO | [104,   500] loss: 1.499
2025-02-26T22:40:20.218949+0300 | INFO | [104,   600] loss: 1.499
2025-02-26T22:40:31.239438+0300 | INFO | [104,   700] loss: 1.486
2025-02-26T22:40:42.219563+0300 | INFO | [104,   800] loss: 1.493
2025-02-26T22:40:53.113971+0300 | INFO | [104,   900] loss: 1.505
2025-02-26T22:41:03.891363+0300 | INFO | [104,  1000] loss: 1.492
2025-02-26T22:41:15.256142+0300 | INFO | [104,  1100] loss: 1.498
2025-02-26T22:41:26.359260+0300 | INFO | [104,  1200] loss: 1.493
2025-02-26T22:41:37.233012+0300 | INFO | [104,  1300] loss: 1.490
2025-02-26T22:41:48.963211+0300 | INFO | [104,  1400] loss: 1.516
2025-02-26T22:42:00.176959+0300 | INFO | [104,  1500] loss: 1.498
2025-02-26T22:42:11.387044+0300 | INFO | [104,  1600] loss: 1.515
2025-02-26T22:42:24.729269+0300 | INFO | [104,  1700] loss: 1.498
2025-02-26T22:42:35.757569+0300 | INFO | [104,  1800] loss: 1.499
2025-02-26T22:42:46.925914+0300 | INFO | [104,  1900] loss: 1.495
2025-02-26T22:42:57.576203+0300 | INFO | [104,  2000] loss: 1.502
2025-02-26T22:43:09.486667+0300 | INFO | [104,  2100] loss: 1.494
2025-02-26T22:43:23.298610+0300 | INFO | [104,  2200] loss: 1.506
2025-02-26T22:43:36.698018+0300 | INFO | [104,  2300] loss: 1.497
2025-02-26T22:43:47.712110+0300 | INFO | [104,  2400] loss: 1.491
2025-02-26T22:43:58.458482+0300 | INFO | [104,  2500] loss: 1.506
2025-02-26T22:44:09.748600+0300 | INFO | [104,  2600] loss: 1.495
2025-02-26T22:44:21.973101+0300 | INFO | [104,  2700] loss: 1.492
2025-02-26T22:44:34.364504+0300 | INFO | [104,  2800] loss: 1.495
2025-02-26T22:44:45.099536+0300 | INFO | [104,  2900] loss: 1.494
2025-02-26T22:44:55.952289+0300 | INFO | [104,  3000] loss: 1.503
2025-02-26T22:45:06.457265+0300 | INFO | [104,  3100] loss: 1.495
2025-02-26T22:45:17.378053+0300 | INFO | [104,  3200] loss: 1.491
2025-02-26T22:45:28.532210+0300 | INFO | [104,  3300] loss: 1.489
2025-02-26T22:45:39.357650+0300 | INFO | [104,  3400] loss: 1.491
2025-02-26T22:45:50.349626+0300 | INFO | [104,  3500] loss: 1.492
2025-02-26T22:46:01.002759+0300 | INFO | [104,  3600] loss: 1.500
2025-02-26T22:46:11.933187+0300 | INFO | [104,  3700] loss: 1.491
2025-02-26T22:46:23.648867+0300 | INFO | [104,  3800] loss: 1.498
2025-02-26T22:46:34.762326+0300 | INFO | [104,  3900] loss: 1.497
2025-02-26T22:46:45.731444+0300 | INFO | [104,  4000] loss: 1.500
2025-02-26T22:46:56.492302+0300 | INFO | [104,  4100] loss: 1.493
2025-02-26T22:47:07.342921+0300 | INFO | [104,  4200] loss: 1.501
2025-02-26T22:47:18.166518+0300 | INFO | [104,  4300] loss: 1.495
2025-02-26T22:47:30.006753+0300 | INFO | [104,  4400] loss: 1.494
2025-02-26T22:47:40.587941+0300 | INFO | [104,  4500] loss: 1.500
2025-02-26T22:47:56.949500+0300 | INFO | [104,  4600] loss: 1.492
2025-02-26T22:48:08.146883+0300 | INFO | [104,  4700] loss: 1.496
2025-02-26T22:48:18.881743+0300 | INFO | [104,  4800] loss: 1.495
2025-02-26T22:48:29.632632+0300 | INFO | [104,  4900] loss: 1.502
2025-02-26T22:48:40.456654+0300 | DEBUG | Saving model to flat file storage. Save #104
2025-02-26T22:48:40.479033+0300 | INFO | Averaging client parameters
2025-02-26T22:48:40.495064+0300 | INFO | Updating parameters on client #0
2025-02-26T22:48:58.209691+0300 | DEBUG | Test set: Accuracy: 7880/10000 (79%)
2025-02-26T22:48:58.210769+0300 | DEBUG | Test set: Loss: 1.6715044975280762
2025-02-26T22:48:58.321396+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.75      0.69      0.72      1000
           3       0.69      0.53      0.60      1200
           4       0.75      0.81      0.78      1000
           5       0.53      0.61      0.57       800
           6       0.85      0.86      0.86      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.91      0.89      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T22:48:58.323407+0300 | DEBUG | Confusion Matrix:
[[843  17  34   7  13   3   7  10  40  26]
 [  8 930   1   1   0   1   2   1  16  40]
 [ 61   7 689  26  78  53  41  26  10   9]
 [ 32   6  50 637  72 276  47  37  20  23]
 [ 11   5  45  32 814  31  28  25   6   3]
 [ 12   6  39 153  36 487  13  36  11   7]
 [ 12   6  39  31  17  16 859   7  10   3]
 [ 18   3  16  23  49  41   3 834   1  12]
 [ 38  16   5   7   1   3   4   0 911  15]
 [ 30  60   3   6   1   1   4   6  13 876]]
2025-02-26T22:48:58.325917+0300 | DEBUG | Class precision: [0.7915493  0.88068182 0.74809989 0.69014085 0.75300648 0.53399123
 0.85218254 0.84928717 0.87764933 0.86390533]
2025-02-26T22:48:58.327203+0300 | DEBUG | Class recall: [0.843      0.93       0.689      0.53083333 0.814      0.60875
 0.859      0.834      0.911      0.876     ]
2025-02-26T22:48:58.379867+0300 | INFO | Training epoch #105 on client #0
2025-02-26T22:48:58.380380+0300 | DEBUG | Saving model to flat file storage. Save #105
2025-02-26T22:48:58.628700+0300 | INFO | [105,     0] loss: 0.016
2025-02-26T22:49:11.603823+0300 | INFO | [105,   100] loss: 1.502
2025-02-26T22:49:24.196406+0300 | INFO | [105,   200] loss: 1.493
2025-02-26T22:49:36.551320+0300 | INFO | [105,   300] loss: 1.501
2025-02-26T22:49:47.787593+0300 | INFO | [105,   400] loss: 1.499
2025-02-26T22:49:59.173596+0300 | INFO | [105,   500] loss: 1.500
2025-02-26T22:50:10.278861+0300 | INFO | [105,   600] loss: 1.502
2025-02-26T22:50:21.581380+0300 | INFO | [105,   700] loss: 1.495
2025-02-26T22:50:32.536258+0300 | INFO | [105,   800] loss: 1.503
2025-02-26T22:50:43.402010+0300 | INFO | [105,   900] loss: 1.489
2025-02-26T22:50:54.238556+0300 | INFO | [105,  1000] loss: 1.500
2025-02-26T22:51:05.143782+0300 | INFO | [105,  1100] loss: 1.491
2025-02-26T22:51:17.926548+0300 | INFO | [105,  1200] loss: 1.510
2025-02-26T22:51:28.733645+0300 | INFO | [105,  1300] loss: 1.492
2025-02-26T22:51:39.540420+0300 | INFO | [105,  1400] loss: 1.496
2025-02-26T22:51:50.633318+0300 | INFO | [105,  1500] loss: 1.487
2025-02-26T22:52:01.642416+0300 | INFO | [105,  1600] loss: 1.501
2025-02-26T22:52:12.866603+0300 | INFO | [105,  1700] loss: 1.504
2025-02-26T22:52:26.098417+0300 | INFO | [105,  1800] loss: 1.493
2025-02-26T22:52:36.029757+0300 | INFO | [105,  1900] loss: 1.496
2025-02-26T22:52:46.040494+0300 | INFO | [105,  2000] loss: 1.497
2025-02-26T22:52:55.963573+0300 | INFO | [105,  2100] loss: 1.504
2025-02-26T22:53:07.645608+0300 | INFO | [105,  2200] loss: 1.490
2025-02-26T22:53:19.876234+0300 | INFO | [105,  2300] loss: 1.500
2025-02-26T22:53:31.149584+0300 | INFO | [105,  2400] loss: 1.495
2025-02-26T22:53:42.276668+0300 | INFO | [105,  2500] loss: 1.509
2025-02-26T22:53:54.983137+0300 | INFO | [105,  2600] loss: 1.493
2025-02-26T22:54:05.702478+0300 | INFO | [105,  2700] loss: 1.495
2025-02-26T22:54:16.773880+0300 | INFO | [105,  2800] loss: 1.504
2025-02-26T22:54:28.482976+0300 | INFO | [105,  2900] loss: 1.487
2025-02-26T22:54:39.143747+0300 | INFO | [105,  3000] loss: 1.498
2025-02-26T22:54:50.258781+0300 | INFO | [105,  3100] loss: 1.492
2025-02-26T22:55:01.277781+0300 | INFO | [105,  3200] loss: 1.498
2025-02-26T22:55:11.364526+0300 | INFO | [105,  3300] loss: 1.501
2025-02-26T22:55:22.294298+0300 | INFO | [105,  3400] loss: 1.509
2025-02-26T22:55:33.570635+0300 | INFO | [105,  3500] loss: 1.501
2025-02-26T22:55:43.994631+0300 | INFO | [105,  3600] loss: 1.496
2025-02-26T22:55:57.289189+0300 | INFO | [105,  3700] loss: 1.502
2025-02-26T22:56:08.226871+0300 | INFO | [105,  3800] loss: 1.499
2025-02-26T22:56:18.728443+0300 | INFO | [105,  3900] loss: 1.500
2025-02-26T22:56:31.322421+0300 | INFO | [105,  4000] loss: 1.489
2025-02-26T22:56:42.473373+0300 | INFO | [105,  4100] loss: 1.496
2025-02-26T22:56:58.612724+0300 | INFO | [105,  4200] loss: 1.493
2025-02-26T22:57:09.519416+0300 | INFO | [105,  4300] loss: 1.492
2025-02-26T22:57:19.461043+0300 | INFO | [105,  4400] loss: 1.503
2025-02-26T22:57:30.730586+0300 | INFO | [105,  4500] loss: 1.494
2025-02-26T22:57:42.193556+0300 | INFO | [105,  4600] loss: 1.501
2025-02-26T22:57:52.500586+0300 | INFO | [105,  4700] loss: 1.488
2025-02-26T22:58:04.817254+0300 | INFO | [105,  4800] loss: 1.486
2025-02-26T22:58:16.978820+0300 | INFO | [105,  4900] loss: 1.500
2025-02-26T22:58:27.913209+0300 | DEBUG | Saving model to flat file storage. Save #105
2025-02-26T22:58:27.936196+0300 | INFO | Averaging client parameters
2025-02-26T22:58:27.946184+0300 | INFO | Updating parameters on client #0
2025-02-26T22:58:44.576811+0300 | DEBUG | Test set: Accuracy: 7911/10000 (79%)
2025-02-26T22:58:44.578812+0300 | DEBUG | Test set: Loss: 1.6692605018615723
2025-02-26T22:58:44.667363+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.92      0.91      0.91      1000
           2       0.77      0.67      0.72      1000
           3       0.65      0.62      0.64      1200
           4       0.80      0.79      0.79      1000
           5       0.52      0.61      0.56       800
           6       0.83      0.87      0.85      1000
           7       0.89      0.80      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.86      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T22:58:44.670878+0300 | DEBUG | Confusion Matrix:
[[844  17  32  14  11   5   5   6  37  29]
 [  8 911   1   2   0   2   5   1  18  52]
 [ 64   5 671  53  60  63  56  13   9   6]
 [ 20   5  39 744  46 252  42  23  14  15]
 [ 15   4  40  43 789  41  39  21   6   2]
 [  9   1  33 195  25 486  17  25   5   4]
 [ 11   1  30  40  10  21 868   5  10   4]
 [ 17   3  16  34  50  65   4 796   3  12]
 [ 41   9   4   9   0   2   7   0 909  19]
 [ 29  38   6   7   1   3   5   4  14 893]]
2025-02-26T22:58:44.672882+0300 | DEBUG | Class precision: [0.79773157 0.91649899 0.76949541 0.6520596  0.7953629  0.51702128
 0.82824427 0.89038031 0.88682927 0.86196911]
2025-02-26T22:58:44.673877+0300 | DEBUG | Class recall: [0.844  0.911  0.671  0.62   0.789  0.6075 0.868  0.796  0.909  0.893 ]
2025-02-26T22:58:44.732884+0300 | INFO | Training epoch #106 on client #0
2025-02-26T22:58:44.735876+0300 | DEBUG | Saving model to flat file storage. Save #106
2025-02-26T22:58:44.931567+0300 | INFO | [106,     0] loss: 0.016
2025-02-26T22:58:55.659457+0300 | INFO | [106,   100] loss: 1.500
2025-02-26T22:59:06.780802+0300 | INFO | [106,   200] loss: 1.504
2025-02-26T22:59:18.741196+0300 | INFO | [106,   300] loss: 1.488
2025-02-26T22:59:30.728768+0300 | INFO | [106,   400] loss: 1.497
2025-02-26T22:59:42.219080+0300 | INFO | [106,   500] loss: 1.502
2025-02-26T22:59:53.241101+0300 | INFO | [106,   600] loss: 1.486
2025-02-26T23:00:04.376210+0300 | INFO | [106,   700] loss: 1.495
2025-02-26T23:00:14.757357+0300 | INFO | [106,   800] loss: 1.496
2025-02-26T23:00:25.591454+0300 | INFO | [106,   900] loss: 1.496
2025-02-26T23:00:36.486904+0300 | INFO | [106,  1000] loss: 1.485
2025-02-26T23:00:46.820257+0300 | INFO | [106,  1100] loss: 1.506
2025-02-26T23:00:57.604902+0300 | INFO | [106,  1200] loss: 1.499
2025-02-26T23:01:08.621792+0300 | INFO | [106,  1300] loss: 1.497
2025-02-26T23:01:18.635207+0300 | INFO | [106,  1400] loss: 1.496
2025-02-26T23:01:29.889951+0300 | INFO | [106,  1500] loss: 1.493
2025-02-26T23:01:41.228406+0300 | INFO | [106,  1600] loss: 1.514
2025-02-26T23:01:51.392703+0300 | INFO | [106,  1700] loss: 1.506
2025-02-26T23:02:04.305068+0300 | INFO | [106,  1800] loss: 1.497
2025-02-26T23:02:15.598652+0300 | INFO | [106,  1900] loss: 1.500
2025-02-26T23:02:27.718074+0300 | INFO | [106,  2000] loss: 1.496
2025-02-26T23:02:38.104387+0300 | INFO | [106,  2100] loss: 1.495
2025-02-26T23:02:51.590326+0300 | INFO | [106,  2200] loss: 1.499
2025-02-26T23:03:02.229570+0300 | INFO | [106,  2300] loss: 1.492
2025-02-26T23:03:14.040176+0300 | INFO | [106,  2400] loss: 1.494
2025-02-26T23:03:24.460581+0300 | INFO | [106,  2500] loss: 1.484
2025-02-26T23:03:36.016191+0300 | INFO | [106,  2600] loss: 1.487
2025-02-26T23:03:46.905480+0300 | INFO | [106,  2700] loss: 1.501
2025-02-26T23:03:57.295986+0300 | INFO | [106,  2800] loss: 1.496
2025-02-26T23:04:08.416700+0300 | INFO | [106,  2900] loss: 1.495
2025-02-26T23:04:19.437597+0300 | INFO | [106,  3000] loss: 1.513
2025-02-26T23:04:29.920136+0300 | INFO | [106,  3100] loss: 1.497
2025-02-26T23:04:41.099442+0300 | INFO | [106,  3200] loss: 1.496
2025-02-26T23:04:51.860968+0300 | INFO | [106,  3300] loss: 1.497
2025-02-26T23:05:02.032851+0300 | INFO | [106,  3400] loss: 1.494
2025-02-26T23:05:12.797557+0300 | INFO | [106,  3500] loss: 1.498
2025-02-26T23:05:24.694652+0300 | INFO | [106,  3600] loss: 1.490
2025-02-26T23:05:34.910813+0300 | INFO | [106,  3700] loss: 1.498
2025-02-26T23:05:46.040634+0300 | INFO | [106,  3800] loss: 1.492
2025-02-26T23:06:03.655012+0300 | INFO | [106,  3900] loss: 1.499
2025-02-26T23:06:15.466475+0300 | INFO | [106,  4000] loss: 1.494
2025-02-26T23:06:27.829088+0300 | INFO | [106,  4100] loss: 1.500
2025-02-26T23:06:38.723052+0300 | INFO | [106,  4200] loss: 1.509
2025-02-26T23:06:50.652144+0300 | INFO | [106,  4300] loss: 1.493
2025-02-26T23:07:02.512582+0300 | INFO | [106,  4400] loss: 1.484
2025-02-26T23:07:13.928850+0300 | INFO | [106,  4500] loss: 1.494
2025-02-26T23:07:25.610557+0300 | INFO | [106,  4600] loss: 1.501
2025-02-26T23:07:37.677447+0300 | INFO | [106,  4700] loss: 1.502
2025-02-26T23:07:49.636524+0300 | INFO | [106,  4800] loss: 1.499
2025-02-26T23:08:02.741004+0300 | INFO | [106,  4900] loss: 1.491
2025-02-26T23:08:14.669665+0300 | DEBUG | Saving model to flat file storage. Save #106
2025-02-26T23:08:14.695422+0300 | INFO | Averaging client parameters
2025-02-26T23:08:14.705349+0300 | INFO | Updating parameters on client #0
2025-02-26T23:08:31.273753+0300 | DEBUG | Test set: Accuracy: 7934/10000 (79%)
2025-02-26T23:08:31.274758+0300 | DEBUG | Test set: Loss: 1.6675302982330322
2025-02-26T23:08:31.381989+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.65      0.62      0.63      1200
           4       0.81      0.77      0.79      1000
           5       0.54      0.58      0.56       800
           6       0.84      0.86      0.85      1000
           7       0.88      0.82      0.85      1000
           8       0.87      0.92      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T23:08:31.385991+0300 | DEBUG | Confusion Matrix:
[[846  19  39  10  10   5   4   7  40  20]
 [  7 934   1   2   0   1   5   1  16  33]
 [ 56   6 719  45  54  42  46  15  12   5]
 [ 22   6  56 739  40 236  40  22  23  16]
 [ 15   5  49  53 771  35  39  23   7   3]
 [ 10   3  43 203  26 463  10  34   6   2]
 [  7   4  35  42  11  20 864   5  11   1]
 [ 18   3  23  34  44  46   4 816   4   8]
 [ 28  13   7   8   0   2   5   2 921  14]
 [ 31  59   6   6   1   4   8   5  19 861]]
2025-02-26T23:08:31.387983+0300 | DEBUG | Class precision: [0.81346154 0.8878327  0.73517382 0.64711033 0.80564263 0.54215457
 0.84292683 0.87741935 0.86968839 0.894081  ]
2025-02-26T23:08:31.388983+0300 | DEBUG | Class recall: [0.846      0.934      0.719      0.61583333 0.771      0.57875
 0.864      0.816      0.921      0.861     ]
2025-02-26T23:08:31.444065+0300 | INFO | Training epoch #107 on client #0
2025-02-26T23:08:31.447060+0300 | DEBUG | Saving model to flat file storage. Save #107
2025-02-26T23:08:31.670556+0300 | INFO | [107,     0] loss: 0.015
2025-02-26T23:08:43.992445+0300 | INFO | [107,   100] loss: 1.491
2025-02-26T23:08:56.766268+0300 | INFO | [107,   200] loss: 1.495
2025-02-26T23:09:10.125300+0300 | INFO | [107,   300] loss: 1.492
2025-02-26T23:09:21.333943+0300 | INFO | [107,   400] loss: 1.493
2025-02-26T23:09:34.203064+0300 | INFO | [107,   500] loss: 1.499
2025-02-26T23:09:45.504186+0300 | INFO | [107,   600] loss: 1.501
2025-02-26T23:09:56.639591+0300 | INFO | [107,   700] loss: 1.494
2025-02-26T23:10:06.888162+0300 | INFO | [107,   800] loss: 1.494
2025-02-26T23:10:17.889427+0300 | INFO | [107,   900] loss: 1.487
2025-02-26T23:10:29.114953+0300 | INFO | [107,  1000] loss: 1.502
2025-02-26T23:10:38.997837+0300 | INFO | [107,  1100] loss: 1.503
2025-02-26T23:10:50.140645+0300 | INFO | [107,  1200] loss: 1.497
2025-02-26T23:11:03.017752+0300 | INFO | [107,  1300] loss: 1.500
2025-02-26T23:11:13.180910+0300 | INFO | [107,  1400] loss: 1.500
2025-02-26T23:11:24.581203+0300 | INFO | [107,  1500] loss: 1.492
2025-02-26T23:11:35.715193+0300 | INFO | [107,  1600] loss: 1.490
2025-02-26T23:11:46.141239+0300 | INFO | [107,  1700] loss: 1.498
2025-02-26T23:11:56.993654+0300 | INFO | [107,  1800] loss: 1.496
2025-02-26T23:12:08.692179+0300 | INFO | [107,  1900] loss: 1.501
2025-02-26T23:12:19.634438+0300 | INFO | [107,  2000] loss: 1.497
2025-02-26T23:12:30.332423+0300 | INFO | [107,  2100] loss: 1.496
2025-02-26T23:12:41.607510+0300 | INFO | [107,  2200] loss: 1.492
2025-02-26T23:12:53.041754+0300 | INFO | [107,  2300] loss: 1.487
2025-02-26T23:13:03.629541+0300 | INFO | [107,  2400] loss: 1.489
2025-02-26T23:13:14.864573+0300 | INFO | [107,  2500] loss: 1.498
2025-02-26T23:13:26.039278+0300 | INFO | [107,  2600] loss: 1.496
2025-02-26T23:13:36.475028+0300 | INFO | [107,  2700] loss: 1.494
2025-02-26T23:13:47.831326+0300 | INFO | [107,  2800] loss: 1.499
2025-02-26T23:13:58.895636+0300 | INFO | [107,  2900] loss: 1.496
2025-02-26T23:14:09.636989+0300 | INFO | [107,  3000] loss: 1.504
2025-02-26T23:14:20.288875+0300 | INFO | [107,  3100] loss: 1.498
2025-02-26T23:14:31.520429+0300 | INFO | [107,  3200] loss: 1.496
2025-02-26T23:14:44.165084+0300 | INFO | [107,  3300] loss: 1.503
2025-02-26T23:14:54.425043+0300 | INFO | [107,  3400] loss: 1.497
2025-02-26T23:15:07.673046+0300 | INFO | [107,  3500] loss: 1.504
2025-02-26T23:15:23.492276+0300 | INFO | [107,  3600] loss: 1.495
2025-02-26T23:15:35.349547+0300 | INFO | [107,  3700] loss: 1.486
2025-02-26T23:15:45.693701+0300 | INFO | [107,  3800] loss: 1.490
2025-02-26T23:15:56.568332+0300 | INFO | [107,  3900] loss: 1.494
2025-02-26T23:16:07.632556+0300 | INFO | [107,  4000] loss: 1.499
2025-02-26T23:16:19.011575+0300 | INFO | [107,  4100] loss: 1.497
2025-02-26T23:16:29.735478+0300 | INFO | [107,  4200] loss: 1.508
2025-02-26T23:16:40.604320+0300 | INFO | [107,  4300] loss: 1.492
2025-02-26T23:16:51.370755+0300 | INFO | [107,  4400] loss: 1.487
2025-02-26T23:17:01.946853+0300 | INFO | [107,  4500] loss: 1.494
2025-02-26T23:17:14.320016+0300 | INFO | [107,  4600] loss: 1.495
2025-02-26T23:17:25.329682+0300 | INFO | [107,  4700] loss: 1.500
2025-02-26T23:17:35.665658+0300 | INFO | [107,  4800] loss: 1.500
2025-02-26T23:17:47.278472+0300 | INFO | [107,  4900] loss: 1.505
2025-02-26T23:17:59.654618+0300 | DEBUG | Saving model to flat file storage. Save #107
2025-02-26T23:17:59.679135+0300 | INFO | Averaging client parameters
2025-02-26T23:17:59.686485+0300 | INFO | Updating parameters on client #0
2025-02-26T23:18:17.477897+0300 | DEBUG | Test set: Accuracy: 7937/10000 (79%)
2025-02-26T23:18:17.478901+0300 | DEBUG | Test set: Loss: 1.6664267778396606
2025-02-26T23:18:17.583914+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.81      0.82      1000
           1       0.89      0.94      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.68      0.59      0.63      1200
           4       0.80      0.78      0.79      1000
           5       0.53      0.61      0.57       800
           6       0.82      0.87      0.85      1000
           7       0.85      0.84      0.84      1000
           8       0.88      0.91      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T23:18:17.587441+0300 | DEBUG | Confusion Matrix:
[[812  20  50   9  14   6   6  11  42  30]
 [  4 939   1   1   0   1   4   1  14  35]
 [ 49   5 705  40  52  51  53  29  11   5]
 [ 16   7  42 707  46 264  47  35  19  17]
 [ 11   6  48  44 780  33  41  27   7   3]
 [ 11   4  33 174  24 490  18  37   6   3]
 [  7   3  30  35  12  26 871   5   9   2]
 [ 10   3  14  24  39  51   6 843   1   9]
 [ 25  19  10   6   1   3   5   3 913  15]
 [ 25  55   5   7   1   2   9   5  14 877]]
2025-02-26T23:18:17.589633+0300 | DEBUG | Class precision: [0.8371134  0.88501414 0.75159915 0.67526266 0.80495356 0.52858684
 0.82169811 0.84638554 0.88127413 0.88052209]
2025-02-26T23:18:17.591164+0300 | DEBUG | Class recall: [0.812      0.939      0.705      0.58916667 0.78       0.6125
 0.871      0.843      0.913      0.877     ]
2025-02-26T23:18:17.639289+0300 | INFO | Training epoch #108 on client #0
2025-02-26T23:18:17.639289+0300 | DEBUG | Saving model to flat file storage. Save #108
2025-02-26T23:18:17.831211+0300 | INFO | [108,     0] loss: 0.015
2025-02-26T23:18:30.416489+0300 | INFO | [108,   100] loss: 1.497
2025-02-26T23:18:41.129077+0300 | INFO | [108,   200] loss: 1.492
2025-02-26T23:18:52.881265+0300 | INFO | [108,   300] loss: 1.493
2025-02-26T23:19:03.988860+0300 | INFO | [108,   400] loss: 1.495
2025-02-26T23:19:15.183417+0300 | INFO | [108,   500] loss: 1.498
2025-02-26T23:19:26.205570+0300 | INFO | [108,   600] loss: 1.509
2025-02-26T23:19:38.290813+0300 | INFO | [108,   700] loss: 1.491
2025-02-26T23:19:49.652500+0300 | INFO | [108,   800] loss: 1.497
2025-02-26T23:20:00.083414+0300 | INFO | [108,   900] loss: 1.504
2025-02-26T23:20:11.005013+0300 | INFO | [108,  1000] loss: 1.485
2025-02-26T23:20:22.318406+0300 | INFO | [108,  1100] loss: 1.488
2025-02-26T23:20:32.770628+0300 | INFO | [108,  1200] loss: 1.501
2025-02-26T23:20:43.883125+0300 | INFO | [108,  1300] loss: 1.492
2025-02-26T23:20:55.104276+0300 | INFO | [108,  1400] loss: 1.488
2025-02-26T23:21:05.561117+0300 | INFO | [108,  1500] loss: 1.490
2025-02-26T23:21:16.570224+0300 | INFO | [108,  1600] loss: 1.491
2025-02-26T23:21:27.676450+0300 | INFO | [108,  1700] loss: 1.487
2025-02-26T23:21:39.500834+0300 | INFO | [108,  1800] loss: 1.498
2025-02-26T23:21:49.781259+0300 | INFO | [108,  1900] loss: 1.493
2025-02-26T23:22:01.135799+0300 | INFO | [108,  2000] loss: 1.498
2025-02-26T23:22:13.718286+0300 | INFO | [108,  2100] loss: 1.504
2025-02-26T23:22:23.756842+0300 | INFO | [108,  2200] loss: 1.504
2025-02-26T23:22:35.044552+0300 | INFO | [108,  2300] loss: 1.500
2025-02-26T23:22:46.064410+0300 | INFO | [108,  2400] loss: 1.498
2025-02-26T23:22:56.700240+0300 | INFO | [108,  2500] loss: 1.503
2025-02-26T23:23:08.562197+0300 | INFO | [108,  2600] loss: 1.494
2025-02-26T23:23:19.815969+0300 | INFO | [108,  2700] loss: 1.499
2025-02-26T23:23:30.449761+0300 | INFO | [108,  2800] loss: 1.494
2025-02-26T23:23:43.398044+0300 | INFO | [108,  2900] loss: 1.491
2025-02-26T23:23:54.384925+0300 | INFO | [108,  3000] loss: 1.501
2025-02-26T23:24:05.381430+0300 | INFO | [108,  3100] loss: 1.497
2025-02-26T23:24:21.421834+0300 | INFO | [108,  3200] loss: 1.494
2025-02-26T23:24:32.805176+0300 | INFO | [108,  3300] loss: 1.493
2025-02-26T23:24:44.813351+0300 | INFO | [108,  3400] loss: 1.509
2025-02-26T23:24:56.281190+0300 | INFO | [108,  3500] loss: 1.491
2025-02-26T23:25:06.810169+0300 | INFO | [108,  3600] loss: 1.495
2025-02-26T23:25:17.625098+0300 | INFO | [108,  3700] loss: 1.507
2025-02-26T23:25:29.938466+0300 | INFO | [108,  3800] loss: 1.499
2025-02-26T23:25:41.476543+0300 | INFO | [108,  3900] loss: 1.492
2025-02-26T23:25:51.851319+0300 | INFO | [108,  4000] loss: 1.485
2025-02-26T23:26:03.324821+0300 | INFO | [108,  4100] loss: 1.495
2025-02-26T23:26:14.139925+0300 | INFO | [108,  4200] loss: 1.501
2025-02-26T23:26:24.320634+0300 | INFO | [108,  4300] loss: 1.495
2025-02-26T23:26:35.462504+0300 | INFO | [108,  4400] loss: 1.498
2025-02-26T23:26:46.703678+0300 | INFO | [108,  4500] loss: 1.492
2025-02-26T23:26:57.265971+0300 | INFO | [108,  4600] loss: 1.494
2025-02-26T23:27:08.132008+0300 | INFO | [108,  4700] loss: 1.491
2025-02-26T23:27:19.710112+0300 | INFO | [108,  4800] loss: 1.500
2025-02-26T23:27:29.883797+0300 | INFO | [108,  4900] loss: 1.498
2025-02-26T23:27:40.580549+0300 | DEBUG | Saving model to flat file storage. Save #108
2025-02-26T23:27:40.597103+0300 | INFO | Averaging client parameters
2025-02-26T23:27:40.606588+0300 | INFO | Updating parameters on client #0
2025-02-26T23:27:56.915993+0300 | DEBUG | Test set: Accuracy: 7923/10000 (79%)
2025-02-26T23:27:56.915993+0300 | DEBUG | Test set: Loss: 1.668733835220337
2025-02-26T23:27:57.005968+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.82      0.83      1000
           1       0.88      0.94      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.78      0.81      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.86      0.85      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.91      0.84      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T23:27:57.007979+0300 | DEBUG | Confusion Matrix:
[[825  16  50   8  16   9   5  11  42  18]
 [  6 941   1   1   1   2   3   3  22  20]
 [ 50   3 705  43  67  54  36  28  10   4]
 [ 16   7  44 688  52 289  37  32  19  16]
 [  8   7  43  42 808  29  24  31   6   2]
 [ 11   5  31 155  29 510  16  32   8   3]
 [  8   2  37  39  18  29 850   6   9   2]
 [ 12   3  15  19  44  52   6 838   3   8]
 [ 26  17  11   6   2   3   4   5 915  11]
 [ 31  74   5   8   1   3   9   6  20 843]]
2025-02-26T23:27:57.008977+0300 | DEBUG | Class precision: [0.83081571 0.87534884 0.74840764 0.68186323 0.77842004 0.52040816
 0.85858586 0.84475806 0.86812144 0.90938511]
2025-02-26T23:27:57.008977+0300 | DEBUG | Class recall: [0.825      0.941      0.705      0.57333333 0.808      0.6375
 0.85       0.838      0.915      0.843     ]
2025-02-26T23:27:57.060862+0300 | INFO | Training epoch #109 on client #0
2025-02-26T23:27:57.062867+0300 | DEBUG | Saving model to flat file storage. Save #109
2025-02-26T23:27:57.292528+0300 | INFO | [109,     0] loss: 0.016
2025-02-26T23:28:08.358223+0300 | INFO | [109,   100] loss: 1.498
2025-02-26T23:28:19.031319+0300 | INFO | [109,   200] loss: 1.499
2025-02-26T23:28:29.524482+0300 | INFO | [109,   300] loss: 1.480
2025-02-26T23:28:40.684576+0300 | INFO | [109,   400] loss: 1.496
2025-02-26T23:28:51.643061+0300 | INFO | [109,   500] loss: 1.494
2025-02-26T23:29:03.424611+0300 | INFO | [109,   600] loss: 1.486
2025-02-26T23:29:14.279953+0300 | INFO | [109,   700] loss: 1.487
2025-02-26T23:29:25.138845+0300 | INFO | [109,   800] loss: 1.491
2025-02-26T23:29:35.556740+0300 | INFO | [109,   900] loss: 1.495
2025-02-26T23:29:46.901527+0300 | INFO | [109,  1000] loss: 1.499
2025-02-26T23:29:58.296235+0300 | INFO | [109,  1100] loss: 1.498
2025-02-26T23:30:08.719289+0300 | INFO | [109,  1200] loss: 1.496
2025-02-26T23:30:19.922620+0300 | INFO | [109,  1300] loss: 1.491
2025-02-26T23:30:32.516420+0300 | INFO | [109,  1400] loss: 1.491
2025-02-26T23:30:43.027653+0300 | INFO | [109,  1500] loss: 1.503
2025-02-26T23:30:53.546597+0300 | INFO | [109,  1600] loss: 1.504
2025-02-26T23:31:05.698066+0300 | INFO | [109,  1700] loss: 1.501
2025-02-26T23:31:16.560461+0300 | INFO | [109,  1800] loss: 1.506
2025-02-26T23:31:27.274697+0300 | INFO | [109,  1900] loss: 1.495
2025-02-26T23:31:38.624018+0300 | INFO | [109,  2000] loss: 1.495
2025-02-26T23:31:49.821624+0300 | INFO | [109,  2100] loss: 1.496
2025-02-26T23:32:00.536119+0300 | INFO | [109,  2200] loss: 1.504
2025-02-26T23:32:11.569390+0300 | INFO | [109,  2300] loss: 1.495
2025-02-26T23:32:22.781906+0300 | INFO | [109,  2400] loss: 1.498
2025-02-26T23:32:35.518654+0300 | INFO | [109,  2500] loss: 1.492
2025-02-26T23:32:46.130720+0300 | INFO | [109,  2600] loss: 1.482
2025-02-26T23:32:57.139322+0300 | INFO | [109,  2700] loss: 1.489
2025-02-26T23:33:13.212907+0300 | INFO | [109,  2800] loss: 1.497
2025-02-26T23:33:24.393848+0300 | INFO | [109,  2900] loss: 1.482
2025-02-26T23:33:34.806273+0300 | INFO | [109,  3000] loss: 1.492
2025-02-26T23:33:45.930137+0300 | INFO | [109,  3100] loss: 1.496
2025-02-26T23:33:57.447045+0300 | INFO | [109,  3200] loss: 1.487
2025-02-26T23:34:07.506196+0300 | INFO | [109,  3300] loss: 1.502
2025-02-26T23:34:19.873103+0300 | INFO | [109,  3400] loss: 1.502
2025-02-26T23:34:30.922584+0300 | INFO | [109,  3500] loss: 1.496
2025-02-26T23:34:41.008642+0300 | INFO | [109,  3600] loss: 1.512
2025-02-26T23:34:52.526757+0300 | INFO | [109,  3700] loss: 1.491
2025-02-26T23:35:03.966306+0300 | INFO | [109,  3800] loss: 1.493
2025-02-26T23:35:14.307484+0300 | INFO | [109,  3900] loss: 1.501
2025-02-26T23:35:24.954166+0300 | INFO | [109,  4000] loss: 1.497
2025-02-26T23:35:36.358364+0300 | INFO | [109,  4100] loss: 1.497
2025-02-26T23:35:47.380042+0300 | INFO | [109,  4200] loss: 1.497
2025-02-26T23:35:59.739567+0300 | INFO | [109,  4300] loss: 1.504
2025-02-26T23:36:12.545274+0300 | INFO | [109,  4400] loss: 1.500
2025-02-26T23:36:23.917073+0300 | INFO | [109,  4500] loss: 1.496
2025-02-26T23:36:35.294112+0300 | INFO | [109,  4600] loss: 1.492
2025-02-26T23:36:47.290495+0300 | INFO | [109,  4700] loss: 1.496
2025-02-26T23:36:59.400076+0300 | INFO | [109,  4800] loss: 1.503
2025-02-26T23:37:10.367209+0300 | INFO | [109,  4900] loss: 1.500
2025-02-26T23:37:21.378007+0300 | DEBUG | Saving model to flat file storage. Save #109
2025-02-26T23:37:21.407007+0300 | INFO | Averaging client parameters
2025-02-26T23:37:21.417025+0300 | INFO | Updating parameters on client #0
2025-02-26T23:37:38.140431+0300 | DEBUG | Test set: Accuracy: 7893/10000 (79%)
2025-02-26T23:37:38.144431+0300 | DEBUG | Test set: Loss: 1.67069673538208
2025-02-26T23:37:38.262372+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.91      0.92      0.91      1000
           2       0.76      0.67      0.71      1000
           3       0.69      0.54      0.61      1200
           4       0.76      0.80      0.78      1000
           5       0.52      0.65      0.58       800
           6       0.84      0.86      0.85      1000
           7       0.84      0.85      0.84      1000
           8       0.86      0.92      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T23:37:38.263376+0300 | DEBUG | Confusion Matrix:
[[818  14  40   7  19   9   5  11  50  27]
 [  7 919   1   1   0   2   3   3  23  41]
 [ 59   4 670  41  70  60  51  28  12   5]
 [ 21   6  39 653  59 299  49  33  20  21]
 [  9   4  37  42 802  31  32  33   7   3]
 [ 14   2  36 135  34 520  12  35   8   4]
 [ 11   1  30  35  21  27 859   4  10   2]
 [ 12   3  13  19  43  46   4 847   3  10]
 [ 28  12   7   6   1   3   5   3 922  13]
 [ 28  46   4   6   1   1   7   8  16 883]]
2025-02-26T23:37:38.267380+0300 | DEBUG | Class precision: [0.8123138  0.90900099 0.76396807 0.69100529 0.76380952 0.52104208
 0.83641675 0.84278607 0.86087768 0.87512389]
2025-02-26T23:37:38.268394+0300 | DEBUG | Class recall: [0.818      0.919      0.67       0.54416667 0.802      0.65
 0.859      0.847      0.922      0.883     ]
2025-02-26T23:37:38.270352+0300 | INFO | Training epoch #110 on client #0
2025-02-26T23:37:38.270352+0300 | DEBUG | Saving model to flat file storage. Save #110
2025-02-26T23:37:38.518415+0300 | INFO | [110,     0] loss: 0.016
2025-02-26T23:37:49.236775+0300 | INFO | [110,   100] loss: 1.500
2025-02-26T23:38:01.000871+0300 | INFO | [110,   200] loss: 1.502
2025-02-26T23:38:12.832328+0300 | INFO | [110,   300] loss: 1.490
2025-02-26T23:38:23.654224+0300 | INFO | [110,   400] loss: 1.494
2025-02-26T23:38:35.328233+0300 | INFO | [110,   500] loss: 1.494
2025-02-26T23:38:47.005390+0300 | INFO | [110,   600] loss: 1.506
2025-02-26T23:38:57.264737+0300 | INFO | [110,   700] loss: 1.493
2025-02-26T23:39:08.488750+0300 | INFO | [110,   800] loss: 1.491
2025-02-26T23:39:19.812591+0300 | INFO | [110,   900] loss: 1.489
2025-02-26T23:39:33.734753+0300 | INFO | [110,  1000] loss: 1.489
2025-02-26T23:39:43.963044+0300 | INFO | [110,  1100] loss: 1.498
2025-02-26T23:39:55.256243+0300 | INFO | [110,  1200] loss: 1.488
2025-02-26T23:40:06.390623+0300 | INFO | [110,  1300] loss: 1.492
2025-02-26T23:40:16.450166+0300 | INFO | [110,  1400] loss: 1.502
2025-02-26T23:40:27.492569+0300 | INFO | [110,  1500] loss: 1.491
2025-02-26T23:40:39.186864+0300 | INFO | [110,  1600] loss: 1.491
2025-02-26T23:40:49.645754+0300 | INFO | [110,  1700] loss: 1.495
2025-02-26T23:41:00.707548+0300 | INFO | [110,  1800] loss: 1.504
2025-02-26T23:41:11.501448+0300 | INFO | [110,  1900] loss: 1.502
2025-02-26T23:41:22.333981+0300 | INFO | [110,  2000] loss: 1.490
2025-02-26T23:41:33.111994+0300 | INFO | [110,  2100] loss: 1.490
2025-02-26T23:41:44.322489+0300 | INFO | [110,  2200] loss: 1.482
2025-02-26T23:41:55.295435+0300 | INFO | [110,  2300] loss: 1.499
2025-02-26T23:42:11.350639+0300 | INFO | [110,  2400] loss: 1.487
2025-02-26T23:42:21.728427+0300 | INFO | [110,  2500] loss: 1.494
2025-02-26T23:42:33.096174+0300 | INFO | [110,  2600] loss: 1.491
2025-02-26T23:42:44.168450+0300 | INFO | [110,  2700] loss: 1.505
2025-02-26T23:42:54.375954+0300 | INFO | [110,  2800] loss: 1.500
2025-02-26T23:43:05.554566+0300 | INFO | [110,  2900] loss: 1.489
2025-02-26T23:43:16.946796+0300 | INFO | [110,  3000] loss: 1.500
2025-02-26T23:43:27.065772+0300 | INFO | [110,  3100] loss: 1.497
2025-02-26T23:43:38.622561+0300 | INFO | [110,  3200] loss: 1.495
2025-02-26T23:43:50.348611+0300 | INFO | [110,  3300] loss: 1.501
2025-02-26T23:44:01.435852+0300 | INFO | [110,  3400] loss: 1.498
2025-02-26T23:44:12.412912+0300 | INFO | [110,  3500] loss: 1.489
2025-02-26T23:44:23.447482+0300 | INFO | [110,  3600] loss: 1.509
2025-02-26T23:44:34.011067+0300 | INFO | [110,  3700] loss: 1.496
2025-02-26T23:44:45.031255+0300 | INFO | [110,  3800] loss: 1.501
2025-02-26T23:44:57.361186+0300 | INFO | [110,  3900] loss: 1.498
2025-02-26T23:45:08.188816+0300 | INFO | [110,  4000] loss: 1.494
2025-02-26T23:45:18.476067+0300 | INFO | [110,  4100] loss: 1.506
2025-02-26T23:45:29.791880+0300 | INFO | [110,  4200] loss: 1.497
2025-02-26T23:45:40.931405+0300 | INFO | [110,  4300] loss: 1.499
2025-02-26T23:45:50.984493+0300 | INFO | [110,  4400] loss: 1.492
2025-02-26T23:46:02.180741+0300 | INFO | [110,  4500] loss: 1.506
2025-02-26T23:46:14.562869+0300 | INFO | [110,  4600] loss: 1.499
2025-02-26T23:46:24.819543+0300 | INFO | [110,  4700] loss: 1.497
2025-02-26T23:46:37.462739+0300 | INFO | [110,  4800] loss: 1.487
2025-02-26T23:46:48.476719+0300 | INFO | [110,  4900] loss: 1.504
2025-02-26T23:47:00.194342+0300 | DEBUG | Saving model to flat file storage. Save #110
2025-02-26T23:47:00.217357+0300 | INFO | Averaging client parameters
2025-02-26T23:47:00.227500+0300 | INFO | Updating parameters on client #0
2025-02-26T23:47:15.819841+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-26T23:47:15.820844+0300 | DEBUG | Test set: Loss: 1.6730393171310425
2025-02-26T23:47:15.937818+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.87      0.95      0.91      1000
           2       0.75      0.69      0.72      1000
           3       0.71      0.50      0.59      1200
           4       0.79      0.79      0.79      1000
           5       0.50      0.67      0.57       800
           6       0.81      0.88      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.87      0.91      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.78     10000

2025-02-26T23:47:15.940819+0300 | DEBUG | Confusion Matrix:
[[817  16  43   6  19   7   7  10  48  27]
 [  6 948   1   0   0   1   2   0  12  30]
 [ 61   6 691  34  62  54  54  20  10   8]
 [ 20   8  48 604  43 347  56  35  18  21]
 [  9   7  42  35 789  38  47  22   7   4]
 [ 14   4  38 114  30 537  17  35   7   4]
 [ 10   4  26  30  14  28 875   4   7   2]
 [ 13   3  15  20  46  54   5 828   5  11]
 [ 28  23   7   5   1   3   4   2 911  16]
 [ 25  70   6   3   1   2   7   6  17 863]]
2025-02-26T23:47:15.942815+0300 | DEBUG | Class precision: [0.81455633 0.87052342 0.75354417 0.70975323 0.78507463 0.50140056
 0.81471136 0.86070686 0.87428023 0.87525355]
2025-02-26T23:47:15.943816+0300 | DEBUG | Class recall: [0.817      0.948      0.691      0.50333333 0.789      0.67125
 0.875      0.828      0.911      0.863     ]
2025-02-26T23:47:15.994642+0300 | INFO | Training epoch #111 on client #0
2025-02-26T23:47:15.997632+0300 | DEBUG | Saving model to flat file storage. Save #111
2025-02-26T23:47:16.216895+0300 | INFO | [111,     0] loss: 0.015
2025-02-26T23:47:26.478562+0300 | INFO | [111,   100] loss: 1.493
2025-02-26T23:47:37.594440+0300 | INFO | [111,   200] loss: 1.490
2025-02-26T23:47:48.621103+0300 | INFO | [111,   300] loss: 1.489
2025-02-26T23:47:58.862262+0300 | INFO | [111,   400] loss: 1.495
2025-02-26T23:48:10.768648+0300 | INFO | [111,   500] loss: 1.498
2025-02-26T23:48:21.904345+0300 | INFO | [111,   600] loss: 1.492
2025-02-26T23:48:32.666658+0300 | INFO | [111,   700] loss: 1.492
2025-02-26T23:48:43.513871+0300 | INFO | [111,   800] loss: 1.504
2025-02-26T23:48:54.632501+0300 | INFO | [111,   900] loss: 1.483
2025-02-26T23:49:04.742200+0300 | INFO | [111,  1000] loss: 1.502
2025-02-26T23:49:15.613983+0300 | INFO | [111,  1100] loss: 1.492
2025-02-26T23:49:27.109204+0300 | INFO | [111,  1200] loss: 1.490
2025-02-26T23:49:37.534973+0300 | INFO | [111,  1300] loss: 1.497
2025-02-26T23:49:49.406524+0300 | INFO | [111,  1400] loss: 1.496
2025-02-26T23:50:01.032383+0300 | INFO | [111,  1500] loss: 1.496
2025-02-26T23:50:12.189422+0300 | INFO | [111,  1600] loss: 1.497
2025-02-26T23:50:22.217963+0300 | INFO | [111,  1700] loss: 1.480
2025-02-26T23:50:33.420461+0300 | INFO | [111,  1800] loss: 1.492
2025-02-26T23:50:44.607273+0300 | INFO | [111,  1900] loss: 1.505
2025-02-26T23:51:00.343310+0300 | INFO | [111,  2000] loss: 1.495
2025-02-26T23:51:10.587033+0300 | INFO | [111,  2100] loss: 1.490
2025-02-26T23:51:21.544726+0300 | INFO | [111,  2200] loss: 1.494
2025-02-26T23:51:32.949429+0300 | INFO | [111,  2300] loss: 1.497
2025-02-26T23:51:42.962596+0300 | INFO | [111,  2400] loss: 1.494
2025-02-26T23:51:54.087821+0300 | INFO | [111,  2500] loss: 1.490
2025-02-26T23:52:05.190768+0300 | INFO | [111,  2600] loss: 1.505
2025-02-26T23:52:15.503373+0300 | INFO | [111,  2700] loss: 1.503
2025-02-26T23:52:26.697204+0300 | INFO | [111,  2800] loss: 1.489
2025-02-26T23:52:37.752446+0300 | INFO | [111,  2900] loss: 1.496
2025-02-26T23:52:48.101811+0300 | INFO | [111,  3000] loss: 1.496
2025-02-26T23:52:59.101264+0300 | INFO | [111,  3100] loss: 1.489
2025-02-26T23:53:10.962381+0300 | INFO | [111,  3200] loss: 1.491
2025-02-26T23:53:21.141139+0300 | INFO | [111,  3300] loss: 1.491
2025-02-26T23:53:32.646113+0300 | INFO | [111,  3400] loss: 1.502
2025-02-26T23:53:43.452532+0300 | INFO | [111,  3500] loss: 1.500
2025-02-26T23:53:56.190228+0300 | INFO | [111,  3600] loss: 1.498
2025-02-26T23:54:06.615648+0300 | INFO | [111,  3700] loss: 1.494
2025-02-26T23:54:17.590054+0300 | INFO | [111,  3800] loss: 1.507
2025-02-26T23:54:29.188344+0300 | INFO | [111,  3900] loss: 1.489
2025-02-26T23:54:39.985940+0300 | INFO | [111,  4000] loss: 1.491
2025-02-26T23:54:51.296198+0300 | INFO | [111,  4100] loss: 1.498
2025-02-26T23:55:02.330670+0300 | INFO | [111,  4200] loss: 1.492
2025-02-26T23:55:12.200650+0300 | INFO | [111,  4300] loss: 1.488
2025-02-26T23:55:23.410589+0300 | INFO | [111,  4400] loss: 1.500
2025-02-26T23:55:34.828819+0300 | INFO | [111,  4500] loss: 1.502
2025-02-26T23:55:44.808350+0300 | INFO | [111,  4600] loss: 1.499
2025-02-26T23:55:55.827644+0300 | INFO | [111,  4700] loss: 1.489
2025-02-26T23:56:06.818595+0300 | INFO | [111,  4800] loss: 1.500
2025-02-26T23:56:17.927316+0300 | INFO | [111,  4900] loss: 1.501
2025-02-26T23:56:29.113333+0300 | DEBUG | Saving model to flat file storage. Save #111
2025-02-26T23:56:29.137337+0300 | INFO | Averaging client parameters
2025-02-26T23:56:29.150702+0300 | INFO | Updating parameters on client #0
2025-02-26T23:56:45.209861+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-26T23:56:45.211864+0300 | DEBUG | Test set: Loss: 1.6716384887695312
2025-02-26T23:56:45.334280+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.89      0.94      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.68      0.53      0.59      1200
           4       0.77      0.80      0.79      1000
           5       0.51      0.66      0.58       800
           6       0.85      0.86      0.86      1000
           7       0.87      0.81      0.84      1000
           8       0.85      0.93      0.89      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-26T23:56:45.335273+0300 | DEBUG | Confusion Matrix:
[[818  17  35  10  12   8   5   9  60  26]
 [  6 937   1   0   0   2   2   1  17  34]
 [ 61   6 698  42  66  53  36  16  14   8]
 [ 19   5  54 634  62 315  41  29  19  22]
 [ 13   6  44  38 801  31  33  23   8   3]
 [ 10   4  39 134  32 527  11  31   8   4]
 [  9   3  35  37  13  25 860   5  11   2]
 [ 14   3  13  29  49  60   6 809   4  13]
 [ 24  14   9   8   1   3   6   2 925   8]
 [ 20  63   5   7   2   3   8   4  19 869]]
2025-02-26T23:56:45.338787+0300 | DEBUG | Class precision: [0.82293763 0.88563327 0.74812433 0.67518637 0.7716763  0.51314508
 0.8531746  0.87082885 0.85253456 0.87866532]
2025-02-26T23:56:45.338787+0300 | DEBUG | Class recall: [0.818      0.937      0.698      0.52833333 0.801      0.65875
 0.86       0.809      0.925      0.869     ]
2025-02-26T23:56:45.399336+0300 | INFO | Training epoch #112 on client #0
2025-02-26T23:56:45.400331+0300 | DEBUG | Saving model to flat file storage. Save #112
2025-02-26T23:56:45.636055+0300 | INFO | [112,     0] loss: 0.017
2025-02-26T23:56:56.678646+0300 | INFO | [112,   100] loss: 1.490
2025-02-26T23:57:07.620726+0300 | INFO | [112,   200] loss: 1.504
2025-02-26T23:57:17.895788+0300 | INFO | [112,   300] loss: 1.488
2025-02-26T23:57:29.678781+0300 | INFO | [112,   400] loss: 1.493
2025-02-26T23:57:40.264658+0300 | INFO | [112,   500] loss: 1.497
2025-02-26T23:57:50.875335+0300 | INFO | [112,   600] loss: 1.501
2025-02-26T23:58:02.441612+0300 | INFO | [112,   700] loss: 1.490
2025-02-26T23:58:15.518245+0300 | INFO | [112,   800] loss: 1.502
2025-02-26T23:58:25.752578+0300 | INFO | [112,   900] loss: 1.493
2025-02-26T23:58:37.118270+0300 | INFO | [112,  1000] loss: 1.491
2025-02-26T23:58:48.129359+0300 | INFO | [112,  1100] loss: 1.502
2025-02-26T23:58:59.325139+0300 | INFO | [112,  1200] loss: 1.507
2025-02-26T23:59:09.926929+0300 | INFO | [112,  1300] loss: 1.484
2025-02-26T23:59:20.937673+0300 | INFO | [112,  1400] loss: 1.507
2025-02-26T23:59:39.944054+0300 | INFO | [112,  1500] loss: 1.488
2025-02-26T23:59:51.293397+0300 | INFO | [112,  1600] loss: 1.495
2025-02-27T00:00:03.280999+0300 | INFO | [112,  1700] loss: 1.500
2025-02-27T00:00:14.592441+0300 | INFO | [112,  1800] loss: 1.496
2025-02-27T00:00:29.248482+0300 | INFO | [112,  1900] loss: 1.490
2025-02-27T00:00:41.504164+0300 | INFO | [112,  2000] loss: 1.496
2025-02-27T00:00:53.668542+0300 | INFO | [112,  2100] loss: 1.498
2025-02-27T00:01:05.696194+0300 | INFO | [112,  2200] loss: 1.495
2025-02-27T00:01:18.027792+0300 | INFO | [112,  2300] loss: 1.501
2025-02-27T00:01:30.778007+0300 | INFO | [112,  2400] loss: 1.507
2025-02-27T00:01:43.751202+0300 | INFO | [112,  2500] loss: 1.497
2025-02-27T00:01:56.035352+0300 | INFO | [112,  2600] loss: 1.494
2025-02-27T00:02:06.013120+0300 | INFO | [112,  2700] loss: 1.498
2025-02-27T00:02:16.875937+0300 | INFO | [112,  2800] loss: 1.494
2025-02-27T00:02:28.623481+0300 | INFO | [112,  2900] loss: 1.497
2025-02-27T00:02:39.191821+0300 | INFO | [112,  3000] loss: 1.499
2025-02-27T00:02:50.692784+0300 | INFO | [112,  3100] loss: 1.493
2025-02-27T00:03:02.311964+0300 | INFO | [112,  3200] loss: 1.496
2025-02-27T00:03:12.448048+0300 | INFO | [112,  3300] loss: 1.490
2025-02-27T00:03:23.570421+0300 | INFO | [112,  3400] loss: 1.492
2025-02-27T00:03:34.873163+0300 | INFO | [112,  3500] loss: 1.489
2025-02-27T00:03:44.919059+0300 | INFO | [112,  3600] loss: 1.491
2025-02-27T00:03:56.594726+0300 | INFO | [112,  3700] loss: 1.497
2025-02-27T00:04:08.110891+0300 | INFO | [112,  3800] loss: 1.499
2025-02-27T00:04:18.868747+0300 | INFO | [112,  3900] loss: 1.508
2025-02-27T00:04:29.435802+0300 | INFO | [112,  4000] loss: 1.496
2025-02-27T00:04:40.841314+0300 | INFO | [112,  4100] loss: 1.498
2025-02-27T00:04:52.083669+0300 | INFO | [112,  4200] loss: 1.492
2025-02-27T00:05:02.215758+0300 | INFO | [112,  4300] loss: 1.494
2025-02-27T00:05:12.914806+0300 | INFO | [112,  4400] loss: 1.496
2025-02-27T00:05:23.829746+0300 | INFO | [112,  4500] loss: 1.488
2025-02-27T00:05:34.475451+0300 | INFO | [112,  4600] loss: 1.493
2025-02-27T00:05:45.659997+0300 | INFO | [112,  4700] loss: 1.488
2025-02-27T00:05:57.807465+0300 | INFO | [112,  4800] loss: 1.485
2025-02-27T00:06:08.843182+0300 | INFO | [112,  4900] loss: 1.507
2025-02-27T00:06:20.438674+0300 | DEBUG | Saving model to flat file storage. Save #112
2025-02-27T00:06:20.468875+0300 | INFO | Averaging client parameters
2025-02-27T00:06:20.484885+0300 | INFO | Updating parameters on client #0
2025-02-27T00:06:37.231124+0300 | DEBUG | Test set: Accuracy: 7911/10000 (79%)
2025-02-27T00:06:37.232118+0300 | DEBUG | Test set: Loss: 1.668588638305664
2025-02-27T00:06:37.332393+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.88      0.94      0.91      1000
           2       0.76      0.71      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.78      0.78      0.78      1000
           5       0.53      0.64      0.58       800
           6       0.82      0.87      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T00:06:37.334590+0300 | DEBUG | Confusion Matrix:
[[823  22  34   9  16   7   6  11  48  24]
 [  8 936   1   0   0   1   4   2  11  37]
 [ 53   5 710  35  61  49  48  23  10   6]
 [ 19   5  51 674  51 278  50  43  15  14]
 [ 10   5  41  43 777  40  43  30   7   4]
 [ 13   4  39 143  27 511  14  39   7   3]
 [  9   2  36  34  11  23 871   5   7   2]
 [ 14   2  15  22  45  45   5 842   3   7]
 [ 34  16   7   8   2   4   6   2 903  18]
 [ 29  66   5   7   1   2   9   6  11 864]]
2025-02-27T00:06:37.337586+0300 | DEBUG | Class precision: [0.81324111 0.88052681 0.75612354 0.69128205 0.78405651 0.53229167
 0.82481061 0.83948156 0.88356164 0.8825332 ]
2025-02-27T00:06:37.338961+0300 | DEBUG | Class recall: [0.823      0.936      0.71       0.56166667 0.777      0.63875
 0.871      0.842      0.903      0.864     ]
2025-02-27T00:06:37.390264+0300 | INFO | Training epoch #113 on client #0
2025-02-27T00:06:37.393619+0300 | DEBUG | Saving model to flat file storage. Save #113
2025-02-27T00:06:37.621816+0300 | INFO | [113,     0] loss: 0.015
2025-02-27T00:06:51.345815+0300 | INFO | [113,   100] loss: 1.492
2025-02-27T00:07:03.089392+0300 | INFO | [113,   200] loss: 1.504
2025-02-27T00:07:13.770654+0300 | INFO | [113,   300] loss: 1.485
2025-02-27T00:07:25.294079+0300 | INFO | [113,   400] loss: 1.504
2025-02-27T00:07:38.156527+0300 | INFO | [113,   500] loss: 1.499
2025-02-27T00:07:50.589620+0300 | INFO | [113,   600] loss: 1.492
2025-02-27T00:08:02.845469+0300 | INFO | [113,   700] loss: 1.496
2025-02-27T00:08:15.012333+0300 | INFO | [113,   800] loss: 1.500
2025-02-27T00:08:27.196823+0300 | INFO | [113,   900] loss: 1.492
2025-02-27T00:08:39.009663+0300 | INFO | [113,  1000] loss: 1.492
2025-02-27T00:08:52.065256+0300 | INFO | [113,  1100] loss: 1.492
2025-02-27T00:09:08.133130+0300 | INFO | [113,  1200] loss: 1.496
2025-02-27T00:09:20.831739+0300 | INFO | [113,  1300] loss: 1.488
2025-02-27T00:09:34.654445+0300 | INFO | [113,  1400] loss: 1.503
2025-02-27T00:09:46.973968+0300 | INFO | [113,  1500] loss: 1.495
2025-02-27T00:09:59.372847+0300 | INFO | [113,  1600] loss: 1.507
2025-02-27T00:10:11.758907+0300 | INFO | [113,  1700] loss: 1.492
2025-02-27T00:10:23.174876+0300 | INFO | [113,  1800] loss: 1.496
2025-02-27T00:10:36.012792+0300 | INFO | [113,  1900] loss: 1.492
2025-02-27T00:10:48.654831+0300 | INFO | [113,  2000] loss: 1.499
2025-02-27T00:11:01.622412+0300 | INFO | [113,  2100] loss: 1.498
2025-02-27T00:11:13.516931+0300 | INFO | [113,  2200] loss: 1.497
2025-02-27T00:11:25.434472+0300 | INFO | [113,  2300] loss: 1.501
2025-02-27T00:11:38.040449+0300 | INFO | [113,  2400] loss: 1.503
2025-02-27T00:11:51.902594+0300 | INFO | [113,  2500] loss: 1.493
2025-02-27T00:12:04.421602+0300 | INFO | [113,  2600] loss: 1.485
2025-02-27T00:12:15.072122+0300 | INFO | [113,  2700] loss: 1.488
2025-02-27T00:12:26.882113+0300 | INFO | [113,  2800] loss: 1.495
2025-02-27T00:12:39.252879+0300 | INFO | [113,  2900] loss: 1.500
2025-02-27T00:12:52.988201+0300 | INFO | [113,  3000] loss: 1.488
2025-02-27T00:13:06.905664+0300 | INFO | [113,  3100] loss: 1.501
2025-02-27T00:13:19.918759+0300 | INFO | [113,  3200] loss: 1.496
2025-02-27T00:13:30.724588+0300 | INFO | [113,  3300] loss: 1.501
2025-02-27T00:13:41.853911+0300 | INFO | [113,  3400] loss: 1.495
2025-02-27T00:13:52.025178+0300 | INFO | [113,  3500] loss: 1.498
2025-02-27T00:14:02.955320+0300 | INFO | [113,  3600] loss: 1.497
2025-02-27T00:14:13.477947+0300 | INFO | [113,  3700] loss: 1.503
2025-02-27T00:14:23.416728+0300 | INFO | [113,  3800] loss: 1.489
2025-02-27T00:14:34.715874+0300 | INFO | [113,  3900] loss: 1.485
2025-02-27T00:14:47.456446+0300 | INFO | [113,  4000] loss: 1.493
2025-02-27T00:14:58.315089+0300 | INFO | [113,  4100] loss: 1.493
2025-02-27T00:15:10.400593+0300 | INFO | [113,  4200] loss: 1.494
2025-02-27T00:15:23.128005+0300 | INFO | [113,  4300] loss: 1.494
2025-02-27T00:15:36.615956+0300 | INFO | [113,  4400] loss: 1.500
2025-02-27T00:15:49.151700+0300 | INFO | [113,  4500] loss: 1.491
2025-02-27T00:16:00.487906+0300 | INFO | [113,  4600] loss: 1.494
2025-02-27T00:16:12.877116+0300 | INFO | [113,  4700] loss: 1.490
2025-02-27T00:16:24.163056+0300 | INFO | [113,  4800] loss: 1.495
2025-02-27T00:16:35.612203+0300 | INFO | [113,  4900] loss: 1.492
2025-02-27T00:16:47.980042+0300 | DEBUG | Saving model to flat file storage. Save #113
2025-02-27T00:16:48.013465+0300 | INFO | Averaging client parameters
2025-02-27T00:16:48.023923+0300 | INFO | Updating parameters on client #0
2025-02-27T00:17:04.752622+0300 | DEBUG | Test set: Accuracy: 7926/10000 (79%)
2025-02-27T00:17:04.753624+0300 | DEBUG | Test set: Loss: 1.667842149734497
2025-02-27T00:17:04.852155+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.87      0.94      0.90      1000
           2       0.76      0.70      0.73      1000
           3       0.68      0.59      0.63      1200
           4       0.80      0.79      0.79      1000
           5       0.54      0.61      0.57       800
           6       0.84      0.85      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T00:17:04.854591+0300 | DEBUG | Confusion Matrix:
[[841  18  26   7  12   8   4   9  45  30]
 [  6 937   0   0   0   0   1   1  14  41]
 [ 57   8 700  48  54  47  47  16  14   9]
 [ 25  11  51 703  47 252  42  34  18  17]
 [ 13   6  47  40 790  34  32  26   9   3]
 [ 16   8  38 161  24 490  16  34   8   5]
 [ 12   9  37  36  12  24 848   5  14   3]
 [ 15   3  15  30  49  49   5 821   3  10]
 [ 28  16   4   6   1   2   4   2 921  16]
 [ 25  63   5   6   1   1   5   5  14 875]]
2025-02-27T00:17:04.855825+0300 | DEBUG | Class precision: [0.81021195 0.86839666 0.75839653 0.67791707 0.7979798  0.54024256
 0.84462151 0.86149003 0.86886792 0.86719524]
2025-02-27T00:17:04.856840+0300 | DEBUG | Class recall: [0.841      0.937      0.7        0.58583333 0.79       0.6125
 0.848      0.821      0.921      0.875     ]
2025-02-27T00:17:04.918801+0300 | INFO | Training epoch #114 on client #0
2025-02-27T00:17:04.925151+0300 | DEBUG | Saving model to flat file storage. Save #114
2025-02-27T00:17:05.153421+0300 | INFO | [114,     0] loss: 0.015
2025-02-27T00:17:17.110140+0300 | INFO | [114,   100] loss: 1.496
2025-02-27T00:17:29.350933+0300 | INFO | [114,   200] loss: 1.492
2025-02-27T00:17:41.069948+0300 | INFO | [114,   300] loss: 1.497
2025-02-27T00:17:52.513783+0300 | INFO | [114,   400] loss: 1.500
2025-02-27T00:18:04.204427+0300 | INFO | [114,   500] loss: 1.486
2025-02-27T00:18:15.460288+0300 | INFO | [114,   600] loss: 1.501
2025-02-27T00:18:26.547036+0300 | INFO | [114,   700] loss: 1.491
2025-02-27T00:18:45.592822+0300 | INFO | [114,   800] loss: 1.490
2025-02-27T00:18:57.674847+0300 | INFO | [114,   900] loss: 1.491
2025-02-27T00:19:09.568841+0300 | INFO | [114,  1000] loss: 1.498
2025-02-27T00:19:21.072510+0300 | INFO | [114,  1100] loss: 1.509
2025-02-27T00:19:33.009489+0300 | INFO | [114,  1200] loss: 1.491
2025-02-27T00:19:45.764026+0300 | INFO | [114,  1300] loss: 1.499
2025-02-27T00:19:58.523220+0300 | INFO | [114,  1400] loss: 1.491
2025-02-27T00:20:10.854618+0300 | INFO | [114,  1500] loss: 1.496
2025-02-27T00:20:23.210624+0300 | INFO | [114,  1600] loss: 1.492
2025-02-27T00:20:34.821649+0300 | INFO | [114,  1700] loss: 1.489
2025-02-27T00:20:45.070096+0300 | INFO | [114,  1800] loss: 1.499
2025-02-27T00:20:56.082082+0300 | INFO | [114,  1900] loss: 1.486
2025-02-27T00:21:06.327050+0300 | INFO | [114,  2000] loss: 1.493
2025-02-27T00:21:16.654064+0300 | INFO | [114,  2100] loss: 1.494
2025-02-27T00:21:27.672667+0300 | INFO | [114,  2200] loss: 1.494
2025-02-27T00:21:39.083740+0300 | INFO | [114,  2300] loss: 1.494
2025-02-27T00:21:49.229717+0300 | INFO | [114,  2400] loss: 1.503
2025-02-27T00:22:00.193931+0300 | INFO | [114,  2500] loss: 1.487
2025-02-27T00:22:11.030089+0300 | INFO | [114,  2600] loss: 1.497
2025-02-27T00:22:21.224588+0300 | INFO | [114,  2700] loss: 1.503
2025-02-27T00:22:32.562937+0300 | INFO | [114,  2800] loss: 1.492
2025-02-27T00:22:43.877941+0300 | INFO | [114,  2900] loss: 1.498
2025-02-27T00:22:54.914642+0300 | INFO | [114,  3000] loss: 1.491
2025-02-27T00:23:05.830412+0300 | INFO | [114,  3100] loss: 1.498
2025-02-27T00:23:16.723366+0300 | INFO | [114,  3200] loss: 1.490
2025-02-27T00:23:27.023294+0300 | INFO | [114,  3300] loss: 1.497
2025-02-27T00:23:38.269755+0300 | INFO | [114,  3400] loss: 1.495
2025-02-27T00:23:49.321064+0300 | INFO | [114,  3500] loss: 1.493
2025-02-27T00:23:59.289275+0300 | INFO | [114,  3600] loss: 1.495
2025-02-27T00:24:09.872192+0300 | INFO | [114,  3700] loss: 1.494
2025-02-27T00:24:20.427955+0300 | INFO | [114,  3800] loss: 1.500
2025-02-27T00:24:31.948371+0300 | INFO | [114,  3900] loss: 1.492
2025-02-27T00:24:45.746581+0300 | INFO | [114,  4000] loss: 1.505
2025-02-27T00:24:57.061232+0300 | INFO | [114,  4100] loss: 1.502
2025-02-27T00:25:07.900489+0300 | INFO | [114,  4200] loss: 1.495
2025-02-27T00:25:17.967964+0300 | INFO | [114,  4300] loss: 1.492
2025-02-27T00:25:28.967277+0300 | INFO | [114,  4400] loss: 1.499
2025-02-27T00:25:40.609804+0300 | INFO | [114,  4500] loss: 1.497
2025-02-27T00:25:50.931374+0300 | INFO | [114,  4600] loss: 1.492
2025-02-27T00:26:02.333085+0300 | INFO | [114,  4700] loss: 1.486
2025-02-27T00:26:13.094120+0300 | INFO | [114,  4800] loss: 1.493
2025-02-27T00:26:22.895888+0300 | INFO | [114,  4900] loss: 1.494
2025-02-27T00:26:33.945333+0300 | DEBUG | Saving model to flat file storage. Save #114
2025-02-27T00:26:33.968329+0300 | INFO | Averaging client parameters
2025-02-27T00:26:33.975648+0300 | INFO | Updating parameters on client #0
2025-02-27T00:26:49.213158+0300 | DEBUG | Test set: Accuracy: 7912/10000 (79%)
2025-02-27T00:26:49.214164+0300 | DEBUG | Test set: Loss: 1.6692687273025513
2025-02-27T00:26:49.304938+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.88      0.94      0.91      1000
           2       0.73      0.72      0.72      1000
           3       0.69      0.55      0.61      1200
           4       0.76      0.81      0.79      1000
           5       0.53      0.64      0.58       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.83      0.85      1000
           8       0.88      0.91      0.89      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T00:26:49.306938+0300 | DEBUG | Confusion Matrix:
[[817  17  53   8  17   6   5   9  44  24]
 [  9 935   2   0   1   0   3   1  13  36]
 [ 47   4 717  41  73  44  46  15   8   5]
 [ 18   4  46 658  65 293  45  36  20  15]
 [  7   4  48  37 814  33  25  22   9   1]
 [ 12   3  47 142  26 510  16  37   5   2]
 [ 10   4  35  29  19  27 861   5   9   1]
 [ 11   2  17  24  51  45   6 831   4   9]
 [ 34  20   8   6   1   3   7   1 909  11]
 [ 28  66   6   6   1   3   9   6  15 860]]
2025-02-27T00:26:49.310992+0300 | DEBUG | Class precision: [0.82275932 0.8829084  0.73237998 0.69190326 0.76217228 0.52904564
 0.84164223 0.86292835 0.87741313 0.89211618]
2025-02-27T00:26:49.312363+0300 | DEBUG | Class recall: [0.817      0.935      0.717      0.54833333 0.814      0.6375
 0.861      0.831      0.909      0.86      ]
2025-02-27T00:26:49.360699+0300 | INFO | Training epoch #115 on client #0
2025-02-27T00:26:49.361687+0300 | DEBUG | Saving model to flat file storage. Save #115
2025-02-27T00:26:49.555302+0300 | INFO | [115,     0] loss: 0.015
2025-02-27T00:27:00.541042+0300 | INFO | [115,   100] loss: 1.491
2025-02-27T00:27:15.330342+0300 | INFO | [115,   200] loss: 1.498
2025-02-27T00:27:26.688351+0300 | INFO | [115,   300] loss: 1.491
2025-02-27T00:27:38.121351+0300 | INFO | [115,   400] loss: 1.504
2025-02-27T00:27:49.023461+0300 | INFO | [115,   500] loss: 1.492
2025-02-27T00:27:59.028889+0300 | INFO | [115,   600] loss: 1.505
2025-02-27T00:28:09.714519+0300 | INFO | [115,   700] loss: 1.494
2025-02-27T00:28:20.598007+0300 | INFO | [115,   800] loss: 1.498
2025-02-27T00:28:31.102998+0300 | INFO | [115,   900] loss: 1.488
2025-02-27T00:28:42.094202+0300 | INFO | [115,  1000] loss: 1.494
2025-02-27T00:28:52.996538+0300 | INFO | [115,  1100] loss: 1.503
2025-02-27T00:29:03.142590+0300 | INFO | [115,  1200] loss: 1.499
2025-02-27T00:29:16.701352+0300 | INFO | [115,  1300] loss: 1.495
2025-02-27T00:29:27.643907+0300 | INFO | [115,  1400] loss: 1.490
2025-02-27T00:29:38.188564+0300 | INFO | [115,  1500] loss: 1.494
2025-02-27T00:29:48.639804+0300 | INFO | [115,  1600] loss: 1.503
2025-02-27T00:29:59.618219+0300 | INFO | [115,  1700] loss: 1.495
2025-02-27T00:30:09.725372+0300 | INFO | [115,  1800] loss: 1.498
2025-02-27T00:30:20.626301+0300 | INFO | [115,  1900] loss: 1.506
2025-02-27T00:30:31.678852+0300 | INFO | [115,  2000] loss: 1.491
2025-02-27T00:30:42.158487+0300 | INFO | [115,  2100] loss: 1.493
2025-02-27T00:30:53.176200+0300 | INFO | [115,  2200] loss: 1.486
2025-02-27T00:31:04.082793+0300 | INFO | [115,  2300] loss: 1.494
2025-02-27T00:31:14.382302+0300 | INFO | [115,  2400] loss: 1.493
2025-02-27T00:31:24.959909+0300 | INFO | [115,  2500] loss: 1.493
2025-02-27T00:31:37.920544+0300 | INFO | [115,  2600] loss: 1.497
2025-02-27T00:31:48.580415+0300 | INFO | [115,  2700] loss: 1.500
2025-02-27T00:31:58.730877+0300 | INFO | [115,  2800] loss: 1.492
2025-02-27T00:32:09.462773+0300 | INFO | [115,  2900] loss: 1.496
2025-02-27T00:32:20.890259+0300 | INFO | [115,  3000] loss: 1.490
2025-02-27T00:32:31.265029+0300 | INFO | [115,  3100] loss: 1.485
2025-02-27T00:32:42.270527+0300 | INFO | [115,  3200] loss: 1.499
2025-02-27T00:32:54.577995+0300 | INFO | [115,  3300] loss: 1.497
2025-02-27T00:33:04.528187+0300 | INFO | [115,  3400] loss: 1.502
2025-02-27T00:33:15.620768+0300 | INFO | [115,  3500] loss: 1.493
2025-02-27T00:33:26.399036+0300 | INFO | [115,  3600] loss: 1.493
2025-02-27T00:33:36.758027+0300 | INFO | [115,  3700] loss: 1.496
2025-02-27T00:33:47.636251+0300 | INFO | [115,  3800] loss: 1.497
2025-02-27T00:33:58.735366+0300 | INFO | [115,  3900] loss: 1.477
2025-02-27T00:34:10.635104+0300 | INFO | [115,  4000] loss: 1.495
2025-02-27T00:34:23.099593+0300 | INFO | [115,  4100] loss: 1.488
2025-02-27T00:34:33.923829+0300 | INFO | [115,  4200] loss: 1.494
2025-02-27T00:34:45.080274+0300 | INFO | [115,  4300] loss: 1.495
2025-02-27T00:34:55.370008+0300 | INFO | [115,  4400] loss: 1.492
2025-02-27T00:35:06.340156+0300 | INFO | [115,  4500] loss: 1.501
2025-02-27T00:35:17.634217+0300 | INFO | [115,  4600] loss: 1.499
2025-02-27T00:35:28.246257+0300 | INFO | [115,  4700] loss: 1.492
2025-02-27T00:35:39.284544+0300 | INFO | [115,  4800] loss: 1.485
2025-02-27T00:35:52.167071+0300 | INFO | [115,  4900] loss: 1.496
2025-02-27T00:36:06.812887+0300 | DEBUG | Saving model to flat file storage. Save #115
2025-02-27T00:36:06.839379+0300 | INFO | Averaging client parameters
2025-02-27T00:36:06.846503+0300 | INFO | Updating parameters on client #0
2025-02-27T00:36:21.916789+0300 | DEBUG | Test set: Accuracy: 7882/10000 (79%)
2025-02-27T00:36:21.918789+0300 | DEBUG | Test set: Loss: 1.671231985092163
2025-02-27T00:36:22.022082+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.67      0.72      1000
           3       0.67      0.55      0.60      1200
           4       0.75      0.82      0.78      1000
           5       0.52      0.63      0.57       800
           6       0.82      0.86      0.84      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.91      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T00:36:22.025080+0300 | DEBUG | Confusion Matrix:
[[843  15  33   8  11   7   8  10  39  26]
 [ 14 920   2   0   1   0   6   2  13  42]
 [ 49   3 666  47  88  61  53  18   9   6]
 [ 22   4  46 656  63 290  52  36  19  12]
 [  9   3  31  37 820  34  29  27   7   3]
 [ 14   2  31 153  31 504  20  36   7   2]
 [  8   1  26  34  22  31 864   7   6   1]
 [ 14   3  15  25  55  43   4 827   5   9]
 [ 34  18   4   5   2   4   8   1 914  10]
 [ 28  52   6   8   1   2   8   7  20 868]]
2025-02-27T00:36:22.026554+0300 | DEBUG | Class precision: [0.81449275 0.90107738 0.7744186  0.67420349 0.74954296 0.51639344
 0.82129278 0.85169928 0.87969201 0.886619  ]
2025-02-27T00:36:22.028568+0300 | DEBUG | Class recall: [0.843      0.92       0.666      0.54666667 0.82       0.63
 0.864      0.827      0.914      0.868     ]
2025-02-27T00:36:22.076796+0300 | INFO | Training epoch #116 on client #0
2025-02-27T00:36:22.078803+0300 | DEBUG | Saving model to flat file storage. Save #116
2025-02-27T00:36:22.294497+0300 | INFO | [116,     0] loss: 0.015
2025-02-27T00:36:32.832513+0300 | INFO | [116,   100] loss: 1.493
2025-02-27T00:36:45.184431+0300 | INFO | [116,   200] loss: 1.491
2025-02-27T00:36:57.357331+0300 | INFO | [116,   300] loss: 1.505
2025-02-27T00:37:08.010826+0300 | INFO | [116,   400] loss: 1.487
2025-02-27T00:37:18.137923+0300 | INFO | [116,   500] loss: 1.498
2025-02-27T00:37:29.002388+0300 | INFO | [116,   600] loss: 1.504
2025-02-27T00:37:40.025187+0300 | INFO | [116,   700] loss: 1.488
2025-02-27T00:37:50.284412+0300 | INFO | [116,   800] loss: 1.496
2025-02-27T00:38:01.942014+0300 | INFO | [116,   900] loss: 1.500
2025-02-27T00:38:13.783991+0300 | INFO | [116,  1000] loss: 1.498
2025-02-27T00:38:24.327690+0300 | INFO | [116,  1100] loss: 1.488
2025-02-27T00:38:36.816093+0300 | INFO | [116,  1200] loss: 1.499
2025-02-27T00:38:48.257306+0300 | INFO | [116,  1300] loss: 1.493
2025-02-27T00:38:59.395218+0300 | INFO | [116,  1400] loss: 1.489
2025-02-27T00:39:09.353916+0300 | INFO | [116,  1500] loss: 1.489
2025-02-27T00:39:20.406647+0300 | INFO | [116,  1600] loss: 1.499
2025-02-27T00:39:32.518998+0300 | INFO | [116,  1700] loss: 1.493
2025-02-27T00:39:42.654507+0300 | INFO | [116,  1800] loss: 1.506
2025-02-27T00:39:53.742139+0300 | INFO | [116,  1900] loss: 1.511
2025-02-27T00:40:04.651749+0300 | INFO | [116,  2000] loss: 1.494
2025-02-27T00:40:15.308998+0300 | INFO | [116,  2100] loss: 1.495
2025-02-27T00:40:26.178772+0300 | INFO | [116,  2200] loss: 1.499
2025-02-27T00:40:37.480981+0300 | INFO | [116,  2300] loss: 1.495
2025-02-27T00:40:47.636556+0300 | INFO | [116,  2400] loss: 1.499
2025-02-27T00:40:58.805066+0300 | INFO | [116,  2500] loss: 1.484
2025-02-27T00:41:09.704405+0300 | INFO | [116,  2600] loss: 1.485
2025-02-27T00:41:20.112518+0300 | INFO | [116,  2700] loss: 1.501
2025-02-27T00:41:31.137379+0300 | INFO | [116,  2800] loss: 1.499
2025-02-27T00:41:43.371142+0300 | INFO | [116,  2900] loss: 1.492
2025-02-27T00:41:53.554459+0300 | INFO | [116,  3000] loss: 1.490
2025-02-27T00:42:04.433610+0300 | INFO | [116,  3100] loss: 1.500
2025-02-27T00:42:15.486839+0300 | INFO | [116,  3200] loss: 1.486
2025-02-27T00:42:25.433604+0300 | INFO | [116,  3300] loss: 1.500
2025-02-27T00:42:36.829502+0300 | INFO | [116,  3400] loss: 1.492
2025-02-27T00:42:48.209967+0300 | INFO | [116,  3500] loss: 1.490
2025-02-27T00:42:59.266361+0300 | INFO | [116,  3600] loss: 1.496
2025-02-27T00:43:09.647114+0300 | INFO | [116,  3700] loss: 1.490
2025-02-27T00:43:20.469997+0300 | INFO | [116,  3800] loss: 1.493
2025-02-27T00:43:31.405170+0300 | INFO | [116,  3900] loss: 1.491
2025-02-27T00:43:41.813161+0300 | INFO | [116,  4000] loss: 1.504
2025-02-27T00:43:52.753334+0300 | INFO | [116,  4100] loss: 1.506
2025-02-27T00:44:04.514384+0300 | INFO | [116,  4200] loss: 1.485
2025-02-27T00:44:15.356120+0300 | INFO | [116,  4300] loss: 1.497
2025-02-27T00:44:26.053893+0300 | INFO | [116,  4400] loss: 1.496
2025-02-27T00:44:41.811974+0300 | INFO | [116,  4500] loss: 1.496
2025-02-27T00:44:53.334692+0300 | INFO | [116,  4600] loss: 1.489
2025-02-27T00:45:03.808945+0300 | INFO | [116,  4700] loss: 1.486
2025-02-27T00:45:14.305861+0300 | INFO | [116,  4800] loss: 1.500
2025-02-27T00:45:25.117260+0300 | INFO | [116,  4900] loss: 1.488
2025-02-27T00:45:35.188885+0300 | DEBUG | Saving model to flat file storage. Save #116
2025-02-27T00:45:35.211267+0300 | INFO | Averaging client parameters
2025-02-27T00:45:35.219772+0300 | INFO | Updating parameters on client #0
2025-02-27T00:45:50.767192+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-27T00:45:50.768268+0300 | DEBUG | Test set: Loss: 1.6721543073654175
2025-02-27T00:45:50.869474+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.81      0.82      1000
           1       0.89      0.92      0.90      1000
           2       0.77      0.69      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.50      0.65      0.56       800
           6       0.84      0.87      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.87      0.91      0.89      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T00:45:50.873470+0300 | DEBUG | Confusion Matrix:
[[808  18  41   7  16  13   7  10  46  34]
 [  8 915   2   0   0   1   4   3  16  51]
 [ 44   6 688  40  71  68  45  17  12   9]
 [ 13   7  41 679  53 297  41  33  20  16]
 [  8   4  37  46 795  40  35  25   8   2]
 [ 12   3  35 148  24 516  13  36   6   7]
 [  8   5  23  38  12  33 866   3  10   2]
 [ 14   3  15  26  44  58   4 823   4   9]
 [ 29  18   5   7   3   3   5   2 914  14]
 [ 22  50   7   7   1   4   8   4  18 879]]
2025-02-27T00:45:50.874958+0300 | DEBUG | Class precision: [0.83643892 0.88921283 0.76957494 0.68036072 0.78017664 0.49951597
 0.84241245 0.86087866 0.86717268 0.85923754]
2025-02-27T00:45:50.878210+0300 | DEBUG | Class recall: [0.808      0.915      0.688      0.56583333 0.795      0.645
 0.866      0.823      0.914      0.879     ]
2025-02-27T00:45:50.926758+0300 | INFO | Training epoch #117 on client #0
2025-02-27T00:45:50.928243+0300 | DEBUG | Saving model to flat file storage. Save #117
2025-02-27T00:45:51.135109+0300 | INFO | [117,     0] loss: 0.015
2025-02-27T00:46:03.539278+0300 | INFO | [117,   100] loss: 1.496
2025-02-27T00:46:14.435474+0300 | INFO | [117,   200] loss: 1.496
2025-02-27T00:46:24.445670+0300 | INFO | [117,   300] loss: 1.486
2025-02-27T00:46:35.558850+0300 | INFO | [117,   400] loss: 1.492
2025-02-27T00:46:46.522821+0300 | INFO | [117,   500] loss: 1.505
2025-02-27T00:46:56.661066+0300 | INFO | [117,   600] loss: 1.487
2025-02-27T00:47:07.379416+0300 | INFO | [117,   700] loss: 1.509
2025-02-27T00:47:18.209766+0300 | INFO | [117,   800] loss: 1.512
2025-02-27T00:47:29.672025+0300 | INFO | [117,   900] loss: 1.485
2025-02-27T00:47:40.650284+0300 | INFO | [117,  1000] loss: 1.489
2025-02-27T00:47:51.999427+0300 | INFO | [117,  1100] loss: 1.494
2025-02-27T00:48:03.629184+0300 | INFO | [117,  1200] loss: 1.497
2025-02-27T00:48:13.878998+0300 | INFO | [117,  1300] loss: 1.494
2025-02-27T00:48:24.867351+0300 | INFO | [117,  1400] loss: 1.505
2025-02-27T00:48:35.969765+0300 | INFO | [117,  1500] loss: 1.485
2025-02-27T00:48:46.092743+0300 | INFO | [117,  1600] loss: 1.489
2025-02-27T00:48:57.508759+0300 | INFO | [117,  1700] loss: 1.506
2025-02-27T00:49:08.563060+0300 | INFO | [117,  1800] loss: 1.489
2025-02-27T00:49:18.640203+0300 | INFO | [117,  1900] loss: 1.502
2025-02-27T00:49:29.281716+0300 | INFO | [117,  2000] loss: 1.485
2025-02-27T00:49:40.317308+0300 | INFO | [117,  2100] loss: 1.494
2025-02-27T00:49:50.421475+0300 | INFO | [117,  2200] loss: 1.493
2025-02-27T00:50:02.893702+0300 | INFO | [117,  2300] loss: 1.491
2025-02-27T00:50:13.999760+0300 | INFO | [117,  2400] loss: 1.496
2025-02-27T00:50:23.891063+0300 | INFO | [117,  2500] loss: 1.502
2025-02-27T00:50:35.288113+0300 | INFO | [117,  2600] loss: 1.490
2025-02-27T00:50:46.438413+0300 | INFO | [117,  2700] loss: 1.497
2025-02-27T00:50:57.167664+0300 | INFO | [117,  2800] loss: 1.491
2025-02-27T00:51:08.972459+0300 | INFO | [117,  2900] loss: 1.495
2025-02-27T00:51:19.729307+0300 | INFO | [117,  3000] loss: 1.500
2025-02-27T00:51:29.904540+0300 | INFO | [117,  3100] loss: 1.480
2025-02-27T00:51:41.255939+0300 | INFO | [117,  3200] loss: 1.485
2025-02-27T00:51:52.323112+0300 | INFO | [117,  3300] loss: 1.500
2025-02-27T00:52:03.093101+0300 | INFO | [117,  3400] loss: 1.495
2025-02-27T00:52:13.125582+0300 | INFO | [117,  3500] loss: 1.498
2025-02-27T00:52:24.025421+0300 | INFO | [117,  3600] loss: 1.494
2025-02-27T00:52:35.300931+0300 | INFO | [117,  3700] loss: 1.496
2025-02-27T00:52:45.897554+0300 | INFO | [117,  3800] loss: 1.494
2025-02-27T00:52:57.381906+0300 | INFO | [117,  3900] loss: 1.497
2025-02-27T00:53:10.622166+0300 | INFO | [117,  4000] loss: 1.487
2025-02-27T00:53:24.789602+0300 | INFO | [117,  4100] loss: 1.496
2025-02-27T00:53:35.400130+0300 | INFO | [117,  4200] loss: 1.488
2025-02-27T00:53:46.406315+0300 | INFO | [117,  4300] loss: 1.497
2025-02-27T00:53:58.658247+0300 | INFO | [117,  4400] loss: 1.491
2025-02-27T00:54:08.413295+0300 | INFO | [117,  4500] loss: 1.490
2025-02-27T00:54:22.124943+0300 | INFO | [117,  4600] loss: 1.498
2025-02-27T00:54:33.119264+0300 | INFO | [117,  4700] loss: 1.497
2025-02-27T00:54:45.040312+0300 | INFO | [117,  4800] loss: 1.506
2025-02-27T00:54:55.498376+0300 | INFO | [117,  4900] loss: 1.489
2025-02-27T00:55:06.297128+0300 | DEBUG | Saving model to flat file storage. Save #117
2025-02-27T00:55:06.323125+0300 | INFO | Averaging client parameters
2025-02-27T00:55:06.333330+0300 | INFO | Updating parameters on client #0
2025-02-27T00:55:21.241640+0300 | DEBUG | Test set: Accuracy: 7901/10000 (79%)
2025-02-27T00:55:21.244633+0300 | DEBUG | Test set: Loss: 1.6699707508087158
2025-02-27T00:55:21.338755+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.86      0.94      0.90      1000
           2       0.74      0.72      0.73      1000
           3       0.65      0.58      0.61      1200
           4       0.79      0.79      0.79      1000
           5       0.52      0.61      0.56       800
           6       0.85      0.86      0.85      1000
           7       0.87      0.82      0.85      1000
           8       0.88      0.91      0.89      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T00:55:21.340755+0300 | DEBUG | Confusion Matrix:
[[816  28  42   9  13   7   6   8  43  28]
 [  6 938   3   0   0   0   2   0  13  38]
 [ 43  10 719  44  61  50  41  15  10   7]
 [ 16  11  51 691  50 274  43  32  19  13]
 [  8   6  46  50 790  34  31  25   7   3]
 [ 11   5  37 178  22 487  14  33   7   6]
 [  8   5  37  34  14  27 856   6  10   3]
 [ 16   3  17  35  40  50   3 824   4   8]
 [ 26  23   9   7   3   3   4   1 912  12]
 [ 23  66   8   7   1   3   7   3  14 868]]
2025-02-27T00:55:21.343755+0300 | DEBUG | Class precision: [0.83864337 0.856621   0.74200206 0.6549763  0.79476861 0.52085561
 0.85004965 0.87011616 0.87776708 0.88032454]
2025-02-27T00:55:21.346749+0300 | DEBUG | Class recall: [0.816      0.938      0.719      0.57583333 0.79       0.60875
 0.856      0.824      0.912      0.868     ]
2025-02-27T00:55:21.397153+0300 | INFO | Training epoch #118 on client #0
2025-02-27T00:55:21.399147+0300 | DEBUG | Saving model to flat file storage. Save #118
2025-02-27T00:55:21.605181+0300 | INFO | [118,     0] loss: 0.016
2025-02-27T00:55:32.824919+0300 | INFO | [118,   100] loss: 1.495
2025-02-27T00:55:42.987994+0300 | INFO | [118,   200] loss: 1.493
2025-02-27T00:55:55.411071+0300 | INFO | [118,   300] loss: 1.490
2025-02-27T00:56:06.286830+0300 | INFO | [118,   400] loss: 1.488
2025-02-27T00:56:16.514365+0300 | INFO | [118,   500] loss: 1.495
2025-02-27T00:56:27.583589+0300 | INFO | [118,   600] loss: 1.495
2025-02-27T00:56:40.908661+0300 | INFO | [118,   700] loss: 1.495
2025-02-27T00:56:52.012568+0300 | INFO | [118,   800] loss: 1.489
2025-02-27T00:57:02.421432+0300 | INFO | [118,   900] loss: 1.492
2025-02-27T00:57:13.605983+0300 | INFO | [118,  1000] loss: 1.500
2025-02-27T00:57:25.298604+0300 | INFO | [118,  1100] loss: 1.495
2025-02-27T00:57:35.663137+0300 | INFO | [118,  1200] loss: 1.494
2025-02-27T00:57:46.676949+0300 | INFO | [118,  1300] loss: 1.494
2025-02-27T00:57:57.777480+0300 | INFO | [118,  1400] loss: 1.483
2025-02-27T00:58:07.767472+0300 | INFO | [118,  1500] loss: 1.503
2025-02-27T00:58:20.401070+0300 | INFO | [118,  1600] loss: 1.498
2025-02-27T00:58:30.878104+0300 | INFO | [118,  1700] loss: 1.487
2025-02-27T00:58:41.937643+0300 | INFO | [118,  1800] loss: 1.496
2025-02-27T00:58:52.775335+0300 | INFO | [118,  1900] loss: 1.503
2025-02-27T00:59:04.394572+0300 | INFO | [118,  2000] loss: 1.500
2025-02-27T00:59:15.403183+0300 | INFO | [118,  2100] loss: 1.487
2025-02-27T00:59:25.518890+0300 | INFO | [118,  2200] loss: 1.494
2025-02-27T00:59:36.597265+0300 | INFO | [118,  2300] loss: 1.499
2025-02-27T00:59:47.395438+0300 | INFO | [118,  2400] loss: 1.500
2025-02-27T00:59:57.806455+0300 | INFO | [118,  2500] loss: 1.497
2025-02-27T01:00:08.862623+0300 | INFO | [118,  2600] loss: 1.496
2025-02-27T01:00:19.680290+0300 | INFO | [118,  2700] loss: 1.493
2025-02-27T01:00:30.494896+0300 | INFO | [118,  2800] loss: 1.498
2025-02-27T01:00:41.574548+0300 | INFO | [118,  2900] loss: 1.490
2025-02-27T01:00:52.764641+0300 | INFO | [118,  3000] loss: 1.486
2025-02-27T01:01:03.321659+0300 | INFO | [118,  3100] loss: 1.493
2025-02-27T01:01:14.027637+0300 | INFO | [118,  3200] loss: 1.503
2025-02-27T01:01:24.892023+0300 | INFO | [118,  3300] loss: 1.494
2025-02-27T01:01:35.225262+0300 | INFO | [118,  3400] loss: 1.494
2025-02-27T01:01:46.268459+0300 | INFO | [118,  3500] loss: 1.489
2025-02-27T01:01:57.274851+0300 | INFO | [118,  3600] loss: 1.491
2025-02-27T01:02:11.558146+0300 | INFO | [118,  3700] loss: 1.497
2025-02-27T01:02:23.037990+0300 | INFO | [118,  3800] loss: 1.499
2025-02-27T01:02:34.092650+0300 | INFO | [118,  3900] loss: 1.493
2025-02-27T01:02:45.330231+0300 | INFO | [118,  4000] loss: 1.493
2025-02-27T01:02:55.589825+0300 | INFO | [118,  4100] loss: 1.497
2025-02-27T01:03:06.767256+0300 | INFO | [118,  4200] loss: 1.496
2025-02-27T01:03:18.019273+0300 | INFO | [118,  4300] loss: 1.487
2025-02-27T01:03:28.230657+0300 | INFO | [118,  4400] loss: 1.508
2025-02-27T01:03:40.563877+0300 | INFO | [118,  4500] loss: 1.492
2025-02-27T01:03:53.365571+0300 | INFO | [118,  4600] loss: 1.491
2025-02-27T01:04:03.978760+0300 | INFO | [118,  4700] loss: 1.494
2025-02-27T01:04:14.407059+0300 | INFO | [118,  4800] loss: 1.493
2025-02-27T01:04:27.341534+0300 | INFO | [118,  4900] loss: 1.488
2025-02-27T01:04:37.706781+0300 | DEBUG | Saving model to flat file storage. Save #118
2025-02-27T01:04:37.727634+0300 | INFO | Averaging client parameters
2025-02-27T01:04:37.738778+0300 | INFO | Updating parameters on client #0
2025-02-27T01:04:54.031653+0300 | DEBUG | Test set: Accuracy: 7922/10000 (79%)
2025-02-27T01:04:54.035652+0300 | DEBUG | Test set: Loss: 1.6672149896621704
2025-02-27T01:04:54.141830+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.90      0.91      0.90      1000
           2       0.76      0.70      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.54      0.61      0.57       800
           6       0.83      0.87      0.85      1000
           7       0.83      0.85      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T01:04:54.144828+0300 | DEBUG | Confusion Matrix:
[[841  14  33  10  13   9   6  10  39  25]
 [ 13 908   2   0   0   0   5   3  18  51]
 [ 58   6 698  41  64  48  45  22  10   8]
 [ 18   9  45 682  53 264  51  40  19  19]
 [ 10   6  43  38 786  28  33  45   8   3]
 [ 12   3  37 161  24 486  18  46   7   6]
 [ 12   3  31  31  14  17 873   6  10   3]
 [ 14   1  14  23  37  39   4 855   4   9]
 [ 34  12  10   7   1   2   6   1 916  11]
 [ 27  47   7   6   1   1   7   8  19 877]]
2025-02-27T01:04:54.144828+0300 | DEBUG | Class precision: [0.80943215 0.89990089 0.75869565 0.68268268 0.79154079 0.54362416
 0.83301527 0.82528958 0.87238095 0.86660079]
2025-02-27T01:04:54.146828+0300 | DEBUG | Class recall: [0.841      0.908      0.698      0.56833333 0.786      0.6075
 0.873      0.855      0.916      0.877     ]
2025-02-27T01:04:54.204883+0300 | INFO | Training epoch #119 on client #0
2025-02-27T01:04:54.206881+0300 | DEBUG | Saving model to flat file storage. Save #119
2025-02-27T01:04:54.419289+0300 | INFO | [119,     0] loss: 0.015
2025-02-27T01:05:06.613310+0300 | INFO | [119,   100] loss: 1.487
2025-02-27T01:05:18.543015+0300 | INFO | [119,   200] loss: 1.505
2025-02-27T01:05:30.797063+0300 | INFO | [119,   300] loss: 1.500
2025-02-27T01:05:43.089471+0300 | INFO | [119,   400] loss: 1.502
2025-02-27T01:05:54.487365+0300 | INFO | [119,   500] loss: 1.492
2025-02-27T01:06:06.400715+0300 | INFO | [119,   600] loss: 1.484
2025-02-27T01:06:18.383198+0300 | INFO | [119,   700] loss: 1.495
2025-02-27T01:06:30.338925+0300 | INFO | [119,   800] loss: 1.491
2025-02-27T01:06:43.351068+0300 | INFO | [119,   900] loss: 1.494
2025-02-27T01:06:55.120390+0300 | INFO | [119,  1000] loss: 1.499
2025-02-27T01:07:08.457310+0300 | INFO | [119,  1100] loss: 1.496
2025-02-27T01:07:20.639570+0300 | INFO | [119,  1200] loss: 1.492
2025-02-27T01:07:33.035842+0300 | INFO | [119,  1300] loss: 1.490
2025-02-27T01:07:44.927584+0300 | INFO | [119,  1400] loss: 1.496
2025-02-27T01:07:57.888208+0300 | INFO | [119,  1500] loss: 1.497
2025-02-27T01:08:11.143874+0300 | INFO | [119,  1600] loss: 1.493
2025-02-27T01:08:24.509105+0300 | INFO | [119,  1700] loss: 1.492
2025-02-27T01:08:39.435957+0300 | INFO | [119,  1800] loss: 1.493
2025-02-27T01:08:52.323262+0300 | INFO | [119,  1900] loss: 1.494
2025-02-27T01:09:04.670237+0300 | INFO | [119,  2000] loss: 1.495
2025-02-27T01:09:17.794124+0300 | INFO | [119,  2100] loss: 1.493
2025-02-27T01:09:31.789765+0300 | INFO | [119,  2200] loss: 1.503
2025-02-27T01:09:44.607086+0300 | INFO | [119,  2300] loss: 1.506
2025-02-27T01:09:57.815278+0300 | INFO | [119,  2400] loss: 1.488
2025-02-27T01:10:09.740775+0300 | INFO | [119,  2500] loss: 1.503
2025-02-27T01:10:22.533665+0300 | INFO | [119,  2600] loss: 1.486
2025-02-27T01:10:35.459476+0300 | INFO | [119,  2700] loss: 1.489
2025-02-27T01:10:49.019816+0300 | INFO | [119,  2800] loss: 1.488
2025-02-27T01:11:01.417606+0300 | INFO | [119,  2900] loss: 1.491
2025-02-27T01:11:12.764645+0300 | INFO | [119,  3000] loss: 1.492
2025-02-27T01:11:24.796474+0300 | INFO | [119,  3100] loss: 1.493
2025-02-27T01:11:40.962978+0300 | INFO | [119,  3200] loss: 1.492
2025-02-27T01:11:57.229519+0300 | INFO | [119,  3300] loss: 1.496
2025-02-27T01:12:08.909155+0300 | INFO | [119,  3400] loss: 1.486
2025-02-27T01:12:22.367172+0300 | INFO | [119,  3500] loss: 1.495
2025-02-27T01:12:34.702232+0300 | INFO | [119,  3600] loss: 1.496
2025-02-27T01:12:46.348917+0300 | INFO | [119,  3700] loss: 1.495
2025-02-27T01:12:59.072838+0300 | INFO | [119,  3800] loss: 1.486
2025-02-27T01:13:10.820735+0300 | INFO | [119,  3900] loss: 1.493
2025-02-27T01:13:22.399337+0300 | INFO | [119,  4000] loss: 1.495
2025-02-27T01:13:35.209173+0300 | INFO | [119,  4100] loss: 1.501
2025-02-27T01:13:48.488203+0300 | INFO | [119,  4200] loss: 1.498
2025-02-27T01:14:02.196384+0300 | INFO | [119,  4300] loss: 1.494
2025-02-27T01:14:15.131701+0300 | INFO | [119,  4400] loss: 1.494
2025-02-27T01:14:28.235369+0300 | INFO | [119,  4500] loss: 1.491
2025-02-27T01:14:39.881278+0300 | INFO | [119,  4600] loss: 1.487
2025-02-27T01:14:52.424259+0300 | INFO | [119,  4700] loss: 1.501
2025-02-27T01:15:04.980026+0300 | INFO | [119,  4800] loss: 1.497
2025-02-27T01:15:17.574189+0300 | INFO | [119,  4900] loss: 1.493
2025-02-27T01:15:29.891257+0300 | DEBUG | Saving model to flat file storage. Save #119
2025-02-27T01:15:29.923740+0300 | INFO | Averaging client parameters
2025-02-27T01:15:29.944950+0300 | INFO | Updating parameters on client #0
2025-02-27T01:15:48.086666+0300 | DEBUG | Test set: Accuracy: 7934/10000 (79%)
2025-02-27T01:15:48.086666+0300 | DEBUG | Test set: Loss: 1.6673097610473633
2025-02-27T01:15:48.209487+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.79      0.70      0.74      1000
           3       0.66      0.59      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.83      0.88      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T01:15:48.212758+0300 | DEBUG | Confusion Matrix:
[[852  15  29  11  12  10   7   8  28  28]
 [ 12 921   3   1   1   1   6   2  15  38]
 [ 51   2 698  48  61  57  51  16   7   9]
 [ 14   6  39 708  52 276  48  31  14  12]
 [ 10   5  36  44 793  37  35  30   7   3]
 [ 11   2  36 165  26 505  14  34   2   5]
 [  7   3  22  40  15  23 880   5   3   2]
 [ 16   2  13  36  42  56   7 816   2  10]
 [ 53  16   7   9   1   4   8   1 887  14]
 [ 27  51   6   8   1   3   7   6  17 874]]
2025-02-27T01:15:48.214795+0300 | DEBUG | Class precision: [0.80911681 0.90029326 0.78515186 0.66168224 0.78984064 0.51954733
 0.82784572 0.85985248 0.90325866 0.87839196]
2025-02-27T01:15:48.217313+0300 | DEBUG | Class recall: [0.852   0.921   0.698   0.59    0.793   0.63125 0.88    0.816   0.887
 0.874  ]
2025-02-27T01:15:48.272392+0300 | INFO | Training epoch #120 on client #0
2025-02-27T01:15:48.274384+0300 | DEBUG | Saving model to flat file storage. Save #120
2025-02-27T01:15:48.515474+0300 | INFO | [120,     0] loss: 0.015
2025-02-27T01:16:00.622234+0300 | INFO | [120,   100] loss: 1.494
2025-02-27T01:16:12.934703+0300 | INFO | [120,   200] loss: 1.495
2025-02-27T01:16:26.813043+0300 | INFO | [120,   300] loss: 1.498
2025-02-27T01:16:39.514592+0300 | INFO | [120,   400] loss: 1.497
2025-02-27T01:16:51.127743+0300 | INFO | [120,   500] loss: 1.493
2025-02-27T01:17:02.960243+0300 | INFO | [120,   600] loss: 1.490
2025-02-27T01:17:17.343399+0300 | INFO | [120,   700] loss: 1.492
2025-02-27T01:17:29.394638+0300 | INFO | [120,   800] loss: 1.499
2025-02-27T01:17:41.150194+0300 | INFO | [120,   900] loss: 1.489
2025-02-27T01:17:51.636957+0300 | INFO | [120,  1000] loss: 1.502
2025-02-27T01:18:03.812377+0300 | INFO | [120,  1100] loss: 1.489
2025-02-27T01:18:15.688409+0300 | INFO | [120,  1200] loss: 1.493
2025-02-27T01:18:27.671377+0300 | INFO | [120,  1300] loss: 1.489
2025-02-27T01:18:38.866838+0300 | INFO | [120,  1400] loss: 1.488
2025-02-27T01:18:50.941198+0300 | INFO | [120,  1500] loss: 1.484
2025-02-27T01:19:02.612372+0300 | INFO | [120,  1600] loss: 1.489
2025-02-27T01:19:16.133351+0300 | INFO | [120,  1700] loss: 1.495
2025-02-27T01:19:27.533984+0300 | INFO | [120,  1800] loss: 1.494
2025-02-27T01:19:39.992297+0300 | INFO | [120,  1900] loss: 1.490
2025-02-27T01:19:53.028365+0300 | INFO | [120,  2000] loss: 1.483
2025-02-27T01:20:06.386687+0300 | INFO | [120,  2100] loss: 1.502
2025-02-27T01:20:16.919580+0300 | INFO | [120,  2200] loss: 1.495
2025-02-27T01:20:29.039077+0300 | INFO | [120,  2300] loss: 1.488
2025-02-27T01:20:40.487249+0300 | INFO | [120,  2400] loss: 1.501
2025-02-27T01:20:51.901539+0300 | INFO | [120,  2500] loss: 1.500
2025-02-27T01:21:03.111345+0300 | INFO | [120,  2600] loss: 1.490
2025-02-27T01:21:15.462480+0300 | INFO | [120,  2700] loss: 1.497
2025-02-27T01:21:29.687183+0300 | INFO | [120,  2800] loss: 1.502
2025-02-27T01:21:45.499014+0300 | INFO | [120,  2900] loss: 1.499
2025-02-27T01:21:57.418711+0300 | INFO | [120,  3000] loss: 1.492
2025-02-27T01:22:08.029620+0300 | INFO | [120,  3100] loss: 1.496
2025-02-27T01:22:19.752709+0300 | INFO | [120,  3200] loss: 1.497
2025-02-27T01:22:31.154092+0300 | INFO | [120,  3300] loss: 1.495
2025-02-27T01:22:43.165922+0300 | INFO | [120,  3400] loss: 1.500
2025-02-27T01:22:54.269782+0300 | INFO | [120,  3500] loss: 1.490
2025-02-27T01:23:06.214738+0300 | INFO | [120,  3600] loss: 1.495
2025-02-27T01:23:17.969917+0300 | INFO | [120,  3700] loss: 1.492
2025-02-27T01:23:28.848575+0300 | INFO | [120,  3800] loss: 1.493
2025-02-27T01:23:40.456362+0300 | INFO | [120,  3900] loss: 1.501
2025-02-27T01:23:52.228983+0300 | INFO | [120,  4000] loss: 1.496
2025-02-27T01:24:04.146798+0300 | INFO | [120,  4100] loss: 1.489
2025-02-27T01:24:15.170178+0300 | INFO | [120,  4200] loss: 1.492
2025-02-27T01:24:27.203148+0300 | INFO | [120,  4300] loss: 1.504
2025-02-27T01:24:41.941997+0300 | INFO | [120,  4400] loss: 1.498
2025-02-27T01:24:53.645591+0300 | INFO | [120,  4500] loss: 1.496
2025-02-27T01:25:08.613256+0300 | INFO | [120,  4600] loss: 1.495
2025-02-27T01:25:19.577275+0300 | INFO | [120,  4700] loss: 1.492
2025-02-27T01:25:31.518036+0300 | INFO | [120,  4800] loss: 1.495
2025-02-27T01:25:43.594317+0300 | INFO | [120,  4900] loss: 1.489
2025-02-27T01:25:55.275039+0300 | DEBUG | Saving model to flat file storage. Save #120
2025-02-27T01:25:55.311196+0300 | INFO | Averaging client parameters
2025-02-27T01:25:55.321703+0300 | INFO | Updating parameters on client #0
2025-02-27T01:26:12.375093+0300 | DEBUG | Test set: Accuracy: 7912/10000 (79%)
2025-02-27T01:26:12.377100+0300 | DEBUG | Test set: Loss: 1.6695277690887451
2025-02-27T01:26:12.473002+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.85      0.95      0.90      1000
           2       0.75      0.71      0.73      1000
           3       0.70      0.56      0.62      1200
           4       0.75      0.82      0.78      1000
           5       0.54      0.62      0.58       800
           6       0.86      0.85      0.85      1000
           7       0.84      0.82      0.83      1000
           8       0.91      0.88      0.89      1000
           9       0.90      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T01:26:12.476498+0300 | DEBUG | Confusion Matrix:
[[848  24  35   9  15   6   6   7  29  21]
 [  7 950   1   0   0   0   2   1  10  29]
 [ 59   6 715  35  76  43  38  18   5   5]
 [ 21  12  45 668  70 273  43  40  13  15]
 [  8   7  42  31 819  30  25  28   7   3]
 [ 14   4  43 149  30 500  13  40   3   4]
 [ 11   9  41  32  23  22 848   6   5   3]
 [ 17   3  15  22  57  44   4 825   3  10]
 [ 51  31   9   9   0   5   4   2 879  10]
 [ 24  72   9   3   2   2   5  10  13 860]]
2025-02-27T01:26:12.479012+0300 | DEBUG | Class precision: [0.8        0.84973166 0.7486911  0.69728601 0.75       0.54054054
 0.8582996  0.8444217  0.9089969  0.89583333]
2025-02-27T01:26:12.481377+0300 | DEBUG | Class recall: [0.848      0.95       0.715      0.55666667 0.819      0.625
 0.848      0.825      0.879      0.86      ]
2025-02-27T01:26:12.534333+0300 | INFO | Training epoch #121 on client #0
2025-02-27T01:26:12.536849+0300 | DEBUG | Saving model to flat file storage. Save #121
2025-02-27T01:26:12.757815+0300 | INFO | [121,     0] loss: 0.015
2025-02-27T01:26:24.840560+0300 | INFO | [121,   100] loss: 1.503
2025-02-27T01:26:36.859352+0300 | INFO | [121,   200] loss: 1.491
2025-02-27T01:26:48.925931+0300 | INFO | [121,   300] loss: 1.491
2025-02-27T01:27:01.008663+0300 | INFO | [121,   400] loss: 1.492
2025-02-27T01:27:12.373098+0300 | INFO | [121,   500] loss: 1.499
2025-02-27T01:27:23.920964+0300 | INFO | [121,   600] loss: 1.495
2025-02-27T01:27:35.550724+0300 | INFO | [121,   700] loss: 1.493
2025-02-27T01:27:47.306527+0300 | INFO | [121,   800] loss: 1.489
2025-02-27T01:27:58.328807+0300 | INFO | [121,   900] loss: 1.498
2025-02-27T01:28:10.622350+0300 | INFO | [121,  1000] loss: 1.489
2025-02-27T01:28:22.316679+0300 | INFO | [121,  1100] loss: 1.492
2025-02-27T01:28:32.979900+0300 | INFO | [121,  1200] loss: 1.494
2025-02-27T01:28:44.871004+0300 | INFO | [121,  1300] loss: 1.485
2025-02-27T01:28:56.665594+0300 | INFO | [121,  1400] loss: 1.497
2025-02-27T01:29:09.788952+0300 | INFO | [121,  1500] loss: 1.486
2025-02-27T01:29:25.560881+0300 | INFO | [121,  1600] loss: 1.487
2025-02-27T01:29:38.121510+0300 | INFO | [121,  1700] loss: 1.496
2025-02-27T01:29:51.868986+0300 | INFO | [121,  1800] loss: 1.495
2025-02-27T01:30:04.247541+0300 | INFO | [121,  1900] loss: 1.491
2025-02-27T01:30:16.611924+0300 | INFO | [121,  2000] loss: 1.508
2025-02-27T01:30:29.592052+0300 | INFO | [121,  2100] loss: 1.493
2025-02-27T01:30:41.101235+0300 | INFO | [121,  2200] loss: 1.492
2025-02-27T01:30:56.374537+0300 | INFO | [121,  2300] loss: 1.491
2025-02-27T01:31:11.558091+0300 | INFO | [121,  2400] loss: 1.492
2025-02-27T01:31:23.952614+0300 | INFO | [121,  2500] loss: 1.493
2025-02-27T01:31:37.086134+0300 | INFO | [121,  2600] loss: 1.499
2025-02-27T01:31:49.175706+0300 | INFO | [121,  2700] loss: 1.494
2025-02-27T01:31:59.697995+0300 | INFO | [121,  2800] loss: 1.491
2025-02-27T01:32:11.453367+0300 | INFO | [121,  2900] loss: 1.482
2025-02-27T01:32:26.792316+0300 | INFO | [121,  3000] loss: 1.494
2025-02-27T01:32:37.754373+0300 | INFO | [121,  3100] loss: 1.495
2025-02-27T01:32:48.216272+0300 | INFO | [121,  3200] loss: 1.487
2025-02-27T01:32:59.376593+0300 | INFO | [121,  3300] loss: 1.491
2025-02-27T01:33:11.263672+0300 | INFO | [121,  3400] loss: 1.493
2025-02-27T01:33:21.500675+0300 | INFO | [121,  3500] loss: 1.496
2025-02-27T01:33:32.250266+0300 | INFO | [121,  3600] loss: 1.493
2025-02-27T01:33:43.444992+0300 | INFO | [121,  3700] loss: 1.493
2025-02-27T01:33:54.161040+0300 | INFO | [121,  3800] loss: 1.489
2025-02-27T01:34:05.209462+0300 | INFO | [121,  3900] loss: 1.501
2025-02-27T01:34:16.190041+0300 | INFO | [121,  4000] loss: 1.497
2025-02-27T01:34:27.725977+0300 | INFO | [121,  4100] loss: 1.498
2025-02-27T01:34:37.787794+0300 | INFO | [121,  4200] loss: 1.504
2025-02-27T01:34:49.192331+0300 | INFO | [121,  4300] loss: 1.492
2025-02-27T01:35:01.543548+0300 | INFO | [121,  4400] loss: 1.491
2025-02-27T01:35:11.766793+0300 | INFO | [121,  4500] loss: 1.492
2025-02-27T01:35:22.842277+0300 | INFO | [121,  4600] loss: 1.499
2025-02-27T01:35:33.786556+0300 | INFO | [121,  4700] loss: 1.493
2025-02-27T01:35:44.186753+0300 | INFO | [121,  4800] loss: 1.487
2025-02-27T01:35:55.121062+0300 | INFO | [121,  4900] loss: 1.501
2025-02-27T01:36:06.105663+0300 | DEBUG | Saving model to flat file storage. Save #121
2025-02-27T01:36:06.130716+0300 | INFO | Averaging client parameters
2025-02-27T01:36:06.139141+0300 | INFO | Updating parameters on client #0
2025-02-27T01:36:21.628181+0300 | DEBUG | Test set: Accuracy: 7916/10000 (79%)
2025-02-27T01:36:21.631186+0300 | DEBUG | Test set: Loss: 1.6689578294754028
2025-02-27T01:36:21.733983+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.78      0.86      0.82      1000
           1       0.92      0.90      0.91      1000
           2       0.78      0.69      0.73      1000
           3       0.68      0.56      0.62      1200
           4       0.78      0.79      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.86      0.85      0.85      1000
           7       0.82      0.85      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T01:36:21.736983+0300 | DEBUG | Confusion Matrix:
[[861  12  27   9  10   6   4  11  39  21]
 [ 16 898   1   1   0   1   2   6  22  53]
 [ 69   5 686  38  74  48  40  26   8   6]
 [ 25   3  43 676  53 280  38  46  18  18]
 [ 13   5  37  41 792  32  32  37   7   4]
 [ 18   1  35 159  29 494  12  42   5   5]
 [ 12   6  30  38  17  29 851   6   9   2]
 [ 19   3  13  22  38  38   4 853   2   8]
 [ 37  11   6   9   1   3   5   2 917   9]
 [ 30  35   4   5   1   3   5  10  19 888]]
2025-02-27T01:36:21.737976+0300 | DEBUG | Class precision: [0.78272727 0.91726251 0.77777778 0.67735471 0.78029557 0.52890792
 0.85699899 0.82098171 0.87667304 0.87573964]
2025-02-27T01:36:21.737976+0300 | DEBUG | Class recall: [0.861      0.898      0.686      0.56333333 0.792      0.6175
 0.851      0.853      0.917      0.888     ]
2025-02-27T01:36:21.788130+0300 | INFO | Training epoch #122 on client #0
2025-02-27T01:36:21.789135+0300 | DEBUG | Saving model to flat file storage. Save #122
2025-02-27T01:36:21.992758+0300 | INFO | [122,     0] loss: 0.015
2025-02-27T01:36:32.056697+0300 | INFO | [122,   100] loss: 1.486
2025-02-27T01:36:43.765084+0300 | INFO | [122,   200] loss: 1.493
2025-02-27T01:36:56.356898+0300 | INFO | [122,   300] loss: 1.502
2025-02-27T01:37:07.735611+0300 | INFO | [122,   400] loss: 1.484
2025-02-27T01:37:17.944554+0300 | INFO | [122,   500] loss: 1.501
2025-02-27T01:37:28.714195+0300 | INFO | [122,   600] loss: 1.493
2025-02-27T01:37:39.409761+0300 | INFO | [122,   700] loss: 1.496
2025-02-27T01:37:50.582098+0300 | INFO | [122,   800] loss: 1.491
2025-02-27T01:38:02.740815+0300 | INFO | [122,   900] loss: 1.500
2025-02-27T01:38:14.703296+0300 | INFO | [122,  1000] loss: 1.496
2025-02-27T01:38:25.940329+0300 | INFO | [122,  1100] loss: 1.502
2025-02-27T01:38:38.838683+0300 | INFO | [122,  1200] loss: 1.495
2025-02-27T01:38:49.951170+0300 | INFO | [122,  1300] loss: 1.499
2025-02-27T01:39:01.560864+0300 | INFO | [122,  1400] loss: 1.493
2025-02-27T01:39:12.082209+0300 | INFO | [122,  1500] loss: 1.489
2025-02-27T01:39:22.978481+0300 | INFO | [122,  1600] loss: 1.485
2025-02-27T01:39:34.735647+0300 | INFO | [122,  1700] loss: 1.488
2025-02-27T01:39:47.435200+0300 | INFO | [122,  1800] loss: 1.498
2025-02-27T01:39:59.036642+0300 | INFO | [122,  1900] loss: 1.493
2025-02-27T01:40:13.933478+0300 | INFO | [122,  2000] loss: 1.488
2025-02-27T01:40:24.554728+0300 | INFO | [122,  2100] loss: 1.501
2025-02-27T01:40:35.382166+0300 | INFO | [122,  2200] loss: 1.488
2025-02-27T01:40:45.683410+0300 | INFO | [122,  2300] loss: 1.490
2025-02-27T01:40:56.737747+0300 | INFO | [122,  2400] loss: 1.501
2025-02-27T01:41:07.564578+0300 | INFO | [122,  2500] loss: 1.502
2025-02-27T01:41:17.738175+0300 | INFO | [122,  2600] loss: 1.493
2025-02-27T01:41:29.288470+0300 | INFO | [122,  2700] loss: 1.499
2025-02-27T01:41:40.062789+0300 | INFO | [122,  2800] loss: 1.504
2025-02-27T01:41:50.425143+0300 | INFO | [122,  2900] loss: 1.498
2025-02-27T01:42:01.531050+0300 | INFO | [122,  3000] loss: 1.481
2025-02-27T01:42:12.236895+0300 | INFO | [122,  3100] loss: 1.486
2025-02-27T01:42:22.078493+0300 | INFO | [122,  3200] loss: 1.493
2025-02-27T01:42:32.912855+0300 | INFO | [122,  3300] loss: 1.497
2025-02-27T01:42:44.026684+0300 | INFO | [122,  3400] loss: 1.496
2025-02-27T01:42:54.021431+0300 | INFO | [122,  3500] loss: 1.485
2025-02-27T01:43:05.274095+0300 | INFO | [122,  3600] loss: 1.499
2025-02-27T01:43:16.292730+0300 | INFO | [122,  3700] loss: 1.494
2025-02-27T01:43:27.626264+0300 | INFO | [122,  3800] loss: 1.494
2025-02-27T01:43:39.115139+0300 | INFO | [122,  3900] loss: 1.487
2025-02-27T01:43:50.145365+0300 | INFO | [122,  4000] loss: 1.493
2025-02-27T01:44:00.535418+0300 | INFO | [122,  4100] loss: 1.486
2025-02-27T01:44:11.621899+0300 | INFO | [122,  4200] loss: 1.490
2025-02-27T01:44:22.425532+0300 | INFO | [122,  4300] loss: 1.500
2025-02-27T01:44:33.069328+0300 | INFO | [122,  4400] loss: 1.495
2025-02-27T01:44:44.371919+0300 | INFO | [122,  4500] loss: 1.495
2025-02-27T01:44:55.270725+0300 | INFO | [122,  4600] loss: 1.489
2025-02-27T01:45:06.072628+0300 | INFO | [122,  4700] loss: 1.506
2025-02-27T01:45:16.606270+0300 | INFO | [122,  4800] loss: 1.489
2025-02-27T01:45:27.817592+0300 | INFO | [122,  4900] loss: 1.495
2025-02-27T01:45:38.242962+0300 | DEBUG | Saving model to flat file storage. Save #122
2025-02-27T01:45:38.294512+0300 | INFO | Averaging client parameters
2025-02-27T01:45:38.311517+0300 | INFO | Updating parameters on client #0
2025-02-27T01:45:54.044155+0300 | DEBUG | Test set: Accuracy: 7885/10000 (79%)
2025-02-27T01:45:54.048178+0300 | DEBUG | Test set: Loss: 1.6721183061599731
2025-02-27T01:45:54.175592+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.69      0.54      0.61      1200
           4       0.76      0.80      0.78      1000
           5       0.53      0.62      0.57       800
           6       0.85      0.86      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.85      0.93      0.88      1000
           9       0.90      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T01:45:54.206467+0300 | DEBUG | Confusion Matrix:
[[826  13  37   6  15   8   6   7  58  24]
 [  9 925   2   1   0   1   3   4  24  31]
 [ 57   5 723  35  69  38  38  20  11   4]
 [ 24   5  54 647  62 293  42  39  21  13]
 [  9   6  46  39 801  28  34  25   8   4]
 [ 14   2  43 140  32 499  15  43   8   4]
 [ 12   5  40  35  15  21 859   5   8   0]
 [ 17   3  19  21  55  43   4 826   3   9]
 [ 30  10   9   7   0   3   4   0 928   9]
 [ 24  65   8   2   1   5   7   8  29 851]]
2025-02-27T01:45:54.207469+0300 | DEBUG | Class precision: [0.80821918 0.89027911 0.73700306 0.69346195 0.76285714 0.5314164
 0.84881423 0.84544524 0.84517304 0.8967334 ]
2025-02-27T01:45:54.208476+0300 | DEBUG | Class recall: [0.826      0.925      0.723      0.53916667 0.801      0.62375
 0.859      0.826      0.928      0.851     ]
2025-02-27T01:45:54.211476+0300 | INFO | Training epoch #123 on client #0
2025-02-27T01:45:54.211476+0300 | DEBUG | Saving model to flat file storage. Save #123
2025-02-27T01:45:54.512182+0300 | INFO | [123,     0] loss: 0.015
2025-02-27T01:46:05.122626+0300 | INFO | [123,   100] loss: 1.498
2025-02-27T01:46:15.778296+0300 | INFO | [123,   200] loss: 1.483
2025-02-27T01:46:25.947351+0300 | INFO | [123,   300] loss: 1.493
2025-02-27T01:46:36.584551+0300 | INFO | [123,   400] loss: 1.513
2025-02-27T01:46:47.523410+0300 | INFO | [123,   500] loss: 1.499
2025-02-27T01:46:58.211361+0300 | INFO | [123,   600] loss: 1.488
2025-02-27T01:47:09.414967+0300 | INFO | [123,   700] loss: 1.500
2025-02-27T01:47:20.527535+0300 | INFO | [123,   800] loss: 1.495
2025-02-27T01:47:31.924076+0300 | INFO | [123,   900] loss: 1.498
2025-02-27T01:47:42.299032+0300 | INFO | [123,  1000] loss: 1.499
2025-02-27T01:47:53.323945+0300 | INFO | [123,  1100] loss: 1.502
2025-02-27T01:48:04.310505+0300 | INFO | [123,  1200] loss: 1.490
2025-02-27T01:48:14.371941+0300 | INFO | [123,  1300] loss: 1.495
2025-02-27T01:48:28.282165+0300 | INFO | [123,  1400] loss: 1.493
2025-02-27T01:48:41.492131+0300 | INFO | [123,  1500] loss: 1.489
2025-02-27T01:48:52.725448+0300 | INFO | [123,  1600] loss: 1.498
2025-02-27T01:49:03.476066+0300 | INFO | [123,  1700] loss: 1.494
2025-02-27T01:49:14.484849+0300 | INFO | [123,  1800] loss: 1.485
2025-02-27T01:49:25.464916+0300 | INFO | [123,  1900] loss: 1.488
2025-02-27T01:49:35.457920+0300 | INFO | [123,  2000] loss: 1.486
2025-02-27T01:49:46.711848+0300 | INFO | [123,  2100] loss: 1.495
2025-02-27T01:49:57.781669+0300 | INFO | [123,  2200] loss: 1.489
2025-02-27T01:50:08.000644+0300 | INFO | [123,  2300] loss: 1.499
2025-02-27T01:50:19.012420+0300 | INFO | [123,  2400] loss: 1.504
2025-02-27T01:50:29.593161+0300 | INFO | [123,  2500] loss: 1.486
2025-02-27T01:50:40.744269+0300 | INFO | [123,  2600] loss: 1.501
2025-02-27T01:50:51.747026+0300 | INFO | [123,  2700] loss: 1.488
2025-02-27T01:51:04.645906+0300 | INFO | [123,  2800] loss: 1.498
2025-02-27T01:51:15.385870+0300 | INFO | [123,  2900] loss: 1.488
2025-02-27T01:51:26.309848+0300 | INFO | [123,  3000] loss: 1.494
2025-02-27T01:51:38.025706+0300 | INFO | [123,  3100] loss: 1.500
2025-02-27T01:51:49.567702+0300 | INFO | [123,  3200] loss: 1.495
2025-02-27T01:51:59.761833+0300 | INFO | [123,  3300] loss: 1.499
2025-02-27T01:52:10.677860+0300 | INFO | [123,  3400] loss: 1.491
2025-02-27T01:52:21.546565+0300 | INFO | [123,  3500] loss: 1.506
2025-02-27T01:52:31.517941+0300 | INFO | [123,  3600] loss: 1.497
2025-02-27T01:52:42.464396+0300 | INFO | [123,  3700] loss: 1.491
2025-02-27T01:52:53.602463+0300 | INFO | [123,  3800] loss: 1.493
2025-02-27T01:53:03.946503+0300 | INFO | [123,  3900] loss: 1.492
2025-02-27T01:53:14.873906+0300 | INFO | [123,  4000] loss: 1.495
2025-02-27T01:53:25.827855+0300 | INFO | [123,  4100] loss: 1.498
2025-02-27T01:53:35.670709+0300 | INFO | [123,  4200] loss: 1.487
2025-02-27T01:53:47.546495+0300 | INFO | [123,  4300] loss: 1.494
2025-02-27T01:54:00.290695+0300 | INFO | [123,  4400] loss: 1.492
2025-02-27T01:54:10.684246+0300 | INFO | [123,  4500] loss: 1.499
2025-02-27T01:54:21.170997+0300 | INFO | [123,  4600] loss: 1.485
2025-02-27T01:54:32.615095+0300 | INFO | [123,  4700] loss: 1.495
2025-02-27T01:54:43.755702+0300 | INFO | [123,  4800] loss: 1.499
2025-02-27T01:54:53.963682+0300 | INFO | [123,  4900] loss: 1.494
2025-02-27T01:55:05.343722+0300 | DEBUG | Saving model to flat file storage. Save #123
2025-02-27T01:55:05.365729+0300 | INFO | Averaging client parameters
2025-02-27T01:55:05.373178+0300 | INFO | Updating parameters on client #0
2025-02-27T01:55:21.116018+0300 | DEBUG | Test set: Accuracy: 7864/10000 (79%)
2025-02-27T01:55:21.118033+0300 | DEBUG | Test set: Loss: 1.673317790031433
2025-02-27T01:55:21.226255+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.88      0.93      0.91      1000
           2       0.78      0.68      0.73      1000
           3       0.68      0.55      0.61      1200
           4       0.77      0.79      0.78      1000
           5       0.51      0.64      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.80      0.83      1000
           8       0.85      0.92      0.88      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T01:55:21.229695+0300 | DEBUG | Confusion Matrix:
[[838  17  33   6  13   7   4   5  54  23]
 [  8 933   3   1   0   1   1   1  17  35]
 [ 63   5 684  41  74  54  46  15  12   6]
 [ 28   7  35 663  53 295  46  31  25  17]
 [ 13   6  35  43 790  40  34  27   8   4]
 [ 18   2  36 146  27 510  13  37   7   4]
 [  9   7  26  39  17  27 856   6  13   0]
 [ 19   3  13  31  49  64   3 804   4  10]
 [ 31  17   7   5   0   2   4   1 921  12]
 [ 25  62   5   3   1   3   7   8  21 865]]
2025-02-27T01:55:21.231067+0300 | DEBUG | Class precision: [0.79657795 0.88101983 0.77993158 0.67791411 0.77148438 0.50847458
 0.84418146 0.85989305 0.85120148 0.88627049]
2025-02-27T01:55:21.231067+0300 | DEBUG | Class recall: [0.838  0.933  0.684  0.5525 0.79   0.6375 0.856  0.804  0.921  0.865 ]
2025-02-27T01:55:21.282795+0300 | INFO | Training epoch #124 on client #0
2025-02-27T01:55:21.284792+0300 | DEBUG | Saving model to flat file storage. Save #124
2025-02-27T01:55:21.512239+0300 | INFO | [124,     0] loss: 0.015
2025-02-27T01:55:32.568610+0300 | INFO | [124,   100] loss: 1.486
2025-02-27T01:55:42.956790+0300 | INFO | [124,   200] loss: 1.493
2025-02-27T01:55:54.214900+0300 | INFO | [124,   300] loss: 1.497
2025-02-27T01:56:05.171839+0300 | INFO | [124,   400] loss: 1.498
2025-02-27T01:56:15.520915+0300 | INFO | [124,   500] loss: 1.491
2025-02-27T01:56:26.255509+0300 | INFO | [124,   600] loss: 1.506
2025-02-27T01:56:37.896611+0300 | INFO | [124,   700] loss: 1.491
2025-02-27T01:56:50.204074+0300 | INFO | [124,   800] loss: 1.496
2025-02-27T01:57:02.058927+0300 | INFO | [124,   900] loss: 1.489
2025-02-27T01:57:15.091381+0300 | INFO | [124,  1000] loss: 1.495
2025-02-27T01:57:29.499396+0300 | INFO | [124,  1100] loss: 1.481
2025-02-27T01:57:40.363879+0300 | INFO | [124,  1200] loss: 1.497
2025-02-27T01:57:50.711827+0300 | INFO | [124,  1300] loss: 1.500
2025-02-27T01:58:01.776199+0300 | INFO | [124,  1400] loss: 1.488
2025-02-27T01:58:12.570157+0300 | INFO | [124,  1500] loss: 1.492
2025-02-27T01:58:22.523077+0300 | INFO | [124,  1600] loss: 1.501
2025-02-27T01:58:33.283227+0300 | INFO | [124,  1700] loss: 1.486
2025-02-27T01:58:44.069498+0300 | INFO | [124,  1800] loss: 1.492
2025-02-27T01:58:54.291279+0300 | INFO | [124,  1900] loss: 1.492
2025-02-27T01:59:05.657340+0300 | INFO | [124,  2000] loss: 1.497
2025-02-27T01:59:16.638430+0300 | INFO | [124,  2100] loss: 1.497
2025-02-27T01:59:26.701241+0300 | INFO | [124,  2200] loss: 1.491
2025-02-27T01:59:37.571980+0300 | INFO | [124,  2300] loss: 1.492
2025-02-27T01:59:48.282312+0300 | INFO | [124,  2400] loss: 1.500
2025-02-27T01:59:58.543482+0300 | INFO | [124,  2500] loss: 1.497
2025-02-27T02:00:10.515832+0300 | INFO | [124,  2600] loss: 1.490
2025-02-27T02:00:21.363404+0300 | INFO | [124,  2700] loss: 1.492
2025-02-27T02:00:31.374204+0300 | INFO | [124,  2800] loss: 1.494
2025-02-27T02:00:42.147750+0300 | INFO | [124,  2900] loss: 1.490
2025-02-27T02:00:53.399468+0300 | INFO | [124,  3000] loss: 1.501
2025-02-27T02:01:03.585484+0300 | INFO | [124,  3100] loss: 1.498
2025-02-27T02:01:14.333450+0300 | INFO | [124,  3200] loss: 1.496
2025-02-27T02:01:25.057542+0300 | INFO | [124,  3300] loss: 1.488
2025-02-27T02:01:34.864914+0300 | INFO | [124,  3400] loss: 1.495
2025-02-27T02:01:45.862700+0300 | INFO | [124,  3500] loss: 1.495
2025-02-27T02:01:56.995565+0300 | INFO | [124,  3600] loss: 1.493
2025-02-27T02:02:07.243692+0300 | INFO | [124,  3700] loss: 1.493
2025-02-27T02:02:17.965275+0300 | INFO | [124,  3800] loss: 1.489
2025-02-27T02:02:29.150255+0300 | INFO | [124,  3900] loss: 1.489
2025-02-27T02:02:39.161163+0300 | INFO | [124,  4000] loss: 1.488
2025-02-27T02:02:50.823017+0300 | INFO | [124,  4100] loss: 1.505
2025-02-27T02:03:02.313592+0300 | INFO | [124,  4200] loss: 1.497
2025-02-27T02:03:13.085010+0300 | INFO | [124,  4300] loss: 1.499
2025-02-27T02:03:24.177884+0300 | INFO | [124,  4400] loss: 1.495
2025-02-27T02:03:35.571802+0300 | INFO | [124,  4500] loss: 1.493
2025-02-27T02:03:46.197003+0300 | INFO | [124,  4600] loss: 1.498
2025-02-27T02:03:56.942982+0300 | INFO | [124,  4700] loss: 1.497
2025-02-27T02:04:08.241132+0300 | INFO | [124,  4800] loss: 1.493
2025-02-27T02:04:19.130059+0300 | INFO | [124,  4900] loss: 1.494
2025-02-27T02:04:29.327101+0300 | DEBUG | Saving model to flat file storage. Save #124
2025-02-27T02:04:29.354947+0300 | INFO | Averaging client parameters
2025-02-27T02:04:29.364504+0300 | INFO | Updating parameters on client #0
2025-02-27T02:04:44.818992+0300 | DEBUG | Test set: Accuracy: 7921/10000 (79%)
2025-02-27T02:04:44.820984+0300 | DEBUG | Test set: Loss: 1.6685791015625
2025-02-27T02:04:44.953734+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.83      1000
           1       0.88      0.93      0.91      1000
           2       0.79      0.67      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.76      0.81      0.79      1000
           5       0.52      0.62      0.57       800
           6       0.85      0.86      0.86      1000
           7       0.84      0.84      0.84      1000
           8       0.89      0.90      0.90      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T02:04:44.954739+0300 | DEBUG | Confusion Matrix:
[[855  16  30   7  10  10   5  12  33  22]
 [ 11 933   1   1   1   2   5   3  14  29]
 [ 67   5 671  46  72  57  46  22   8   6]
 [ 20   6  35 679  60 289  43  40  15  13]
 [ 12   5  32  42 808  38  28  25   7   3]
 [ 16   2  36 153  33 500  11  40   5   4]
 [  9   4  22  33  23  28 864   7   9   1]
 [ 17   3  11  30  47  39   3 841   2   7]
 [ 38  21   9   7   2   2   6   2 903  10]
 [ 25  63   2   6   1   4   8   8  16 867]]
2025-02-27T02:04:44.956739+0300 | DEBUG | Class precision: [0.79906542 0.88185255 0.79034158 0.67629482 0.76442763 0.51599587
 0.84789009 0.841      0.89229249 0.9012474 ]
2025-02-27T02:04:44.957953+0300 | DEBUG | Class recall: [0.855      0.933      0.671      0.56583333 0.808      0.625
 0.864      0.841      0.903      0.867     ]
2025-02-27T02:04:45.019162+0300 | INFO | Training epoch #125 on client #0
2025-02-27T02:04:45.021160+0300 | DEBUG | Saving model to flat file storage. Save #125
2025-02-27T02:04:45.270097+0300 | INFO | [125,     0] loss: 0.017
2025-02-27T02:04:56.460345+0300 | INFO | [125,   100] loss: 1.491
2025-02-27T02:05:07.670964+0300 | INFO | [125,   200] loss: 1.491
2025-02-27T02:05:17.751763+0300 | INFO | [125,   300] loss: 1.488
2025-02-27T02:05:31.640737+0300 | INFO | [125,   400] loss: 1.501
2025-02-27T02:05:44.580011+0300 | INFO | [125,   500] loss: 1.497
2025-02-27T02:05:55.935344+0300 | INFO | [125,   600] loss: 1.489
2025-02-27T02:06:06.418893+0300 | INFO | [125,   700] loss: 1.497
2025-02-27T02:06:17.181941+0300 | INFO | [125,   800] loss: 1.492
2025-02-27T02:06:28.820005+0300 | INFO | [125,   900] loss: 1.486
2025-02-27T02:06:38.914911+0300 | INFO | [125,  1000] loss: 1.496
2025-02-27T02:06:51.080150+0300 | INFO | [125,  1100] loss: 1.497
2025-02-27T02:07:02.215518+0300 | INFO | [125,  1200] loss: 1.483
2025-02-27T02:07:12.418467+0300 | INFO | [125,  1300] loss: 1.503
2025-02-27T02:07:23.219323+0300 | INFO | [125,  1400] loss: 1.489
2025-02-27T02:07:34.118036+0300 | INFO | [125,  1500] loss: 1.490
2025-02-27T02:07:44.497548+0300 | INFO | [125,  1600] loss: 1.489
2025-02-27T02:07:56.342601+0300 | INFO | [125,  1700] loss: 1.492
2025-02-27T02:08:07.917959+0300 | INFO | [125,  1800] loss: 1.482
2025-02-27T02:08:18.771900+0300 | INFO | [125,  1900] loss: 1.497
2025-02-27T02:08:29.665321+0300 | INFO | [125,  2000] loss: 1.495
2025-02-27T02:08:40.905442+0300 | INFO | [125,  2100] loss: 1.493
2025-02-27T02:08:52.087640+0300 | INFO | [125,  2200] loss: 1.492
2025-02-27T02:09:02.734566+0300 | INFO | [125,  2300] loss: 1.498
2025-02-27T02:09:14.055791+0300 | INFO | [125,  2400] loss: 1.494
2025-02-27T02:09:25.714563+0300 | INFO | [125,  2500] loss: 1.489
2025-02-27T02:09:37.422513+0300 | INFO | [125,  2600] loss: 1.489
2025-02-27T02:09:48.587737+0300 | INFO | [125,  2700] loss: 1.504
2025-02-27T02:09:59.707681+0300 | INFO | [125,  2800] loss: 1.503
2025-02-27T02:10:10.259195+0300 | INFO | [125,  2900] loss: 1.494
2025-02-27T02:10:22.713654+0300 | INFO | [125,  3000] loss: 1.498
2025-02-27T02:10:33.419193+0300 | INFO | [125,  3100] loss: 1.499
2025-02-27T02:10:44.425559+0300 | INFO | [125,  3200] loss: 1.500
2025-02-27T02:10:54.635639+0300 | INFO | [125,  3300] loss: 1.496
2025-02-27T02:11:05.912189+0300 | INFO | [125,  3400] loss: 1.503
2025-02-27T02:11:16.865410+0300 | INFO | [125,  3500] loss: 1.487
2025-02-27T02:11:27.169533+0300 | INFO | [125,  3600] loss: 1.494
2025-02-27T02:11:38.114598+0300 | INFO | [125,  3700] loss: 1.498
2025-02-27T02:11:49.504924+0300 | INFO | [125,  3800] loss: 1.486
2025-02-27T02:11:59.969662+0300 | INFO | [125,  3900] loss: 1.493
2025-02-27T02:12:11.399308+0300 | INFO | [125,  4000] loss: 1.496
2025-02-27T02:12:22.565308+0300 | INFO | [125,  4100] loss: 1.503
2025-02-27T02:12:33.448369+0300 | INFO | [125,  4200] loss: 1.494
2025-02-27T02:12:45.998177+0300 | INFO | [125,  4300] loss: 1.491
2025-02-27T02:12:57.176604+0300 | INFO | [125,  4400] loss: 1.495
2025-02-27T02:13:07.947432+0300 | INFO | [125,  4500] loss: 1.493
2025-02-27T02:13:18.352727+0300 | INFO | [125,  4600] loss: 1.491
2025-02-27T02:13:29.476516+0300 | INFO | [125,  4700] loss: 1.486
2025-02-27T02:13:40.790585+0300 | INFO | [125,  4800] loss: 1.485
2025-02-27T02:13:50.867463+0300 | INFO | [125,  4900] loss: 1.495
2025-02-27T02:14:06.089358+0300 | DEBUG | Saving model to flat file storage. Save #125
2025-02-27T02:14:06.118430+0300 | INFO | Averaging client parameters
2025-02-27T02:14:06.126957+0300 | INFO | Updating parameters on client #0
2025-02-27T02:14:22.767952+0300 | DEBUG | Test set: Accuracy: 7913/10000 (79%)
2025-02-27T02:14:22.769421+0300 | DEBUG | Test set: Loss: 1.66939377784729
2025-02-27T02:14:22.862799+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.83      1000
           1       0.91      0.92      0.91      1000
           2       0.78      0.67      0.72      1000
           3       0.68      0.58      0.63      1200
           4       0.76      0.80      0.78      1000
           5       0.52      0.64      0.57       800
           6       0.85      0.85      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.91      0.90      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T02:14:22.866797+0300 | DEBUG | Confusion Matrix:
[[826  15  31   9  14  10   4  13  42  36]
 [  8 920   2   1   0   1   4   2  16  46]
 [ 54   5 673  44  79  56  51  20   9   9]
 [ 17   3  39 701  57 276  38  35  16  18]
 [ 12   5  32  40 799  41  33  27   7   4]
 [ 14   3  35 157  31 508   9  36   2   5]
 [  7   7  29  39  17  34 846   6  11   4]
 [ 13   3  13  26  46  49   4 832   1  13]
 [ 33  16   5   5   2   4   6   2 911  16]
 [ 18  39   7   6   1   3   6   6  17 897]]
2025-02-27T02:14:22.870789+0300 | DEBUG | Class precision: [0.8243513  0.90551181 0.77713626 0.68190661 0.76386233 0.51731161
 0.84515485 0.84984678 0.88275194 0.85591603]
2025-02-27T02:14:22.870789+0300 | DEBUG | Class recall: [0.826      0.92       0.673      0.58416667 0.799      0.635
 0.846      0.832      0.911      0.897     ]
2025-02-27T02:14:22.921364+0300 | INFO | Training epoch #126 on client #0
2025-02-27T02:14:22.922380+0300 | DEBUG | Saving model to flat file storage. Save #126
2025-02-27T02:14:23.136527+0300 | INFO | [126,     0] loss: 0.016
2025-02-27T02:14:34.430272+0300 | INFO | [126,   100] loss: 1.494
2025-02-27T02:14:45.337494+0300 | INFO | [126,   200] loss: 1.490
2025-02-27T02:14:55.904587+0300 | INFO | [126,   300] loss: 1.490
2025-02-27T02:15:07.488821+0300 | INFO | [126,   400] loss: 1.488
2025-02-27T02:15:19.702364+0300 | INFO | [126,   500] loss: 1.498
2025-02-27T02:15:30.901606+0300 | INFO | [126,   600] loss: 1.505
2025-02-27T02:15:41.257585+0300 | INFO | [126,   700] loss: 1.497
2025-02-27T02:15:52.177325+0300 | INFO | [126,   800] loss: 1.493
2025-02-27T02:16:03.904579+0300 | INFO | [126,   900] loss: 1.495
2025-02-27T02:16:15.836420+0300 | INFO | [126,  1000] loss: 1.494
2025-02-27T02:16:26.676291+0300 | INFO | [126,  1100] loss: 1.494
2025-02-27T02:16:37.717142+0300 | INFO | [126,  1200] loss: 1.493
2025-02-27T02:16:48.040546+0300 | INFO | [126,  1300] loss: 1.483
2025-02-27T02:16:59.196213+0300 | INFO | [126,  1400] loss: 1.497
2025-02-27T02:17:11.604803+0300 | INFO | [126,  1500] loss: 1.490
2025-02-27T02:17:23.231914+0300 | INFO | [126,  1600] loss: 1.494
2025-02-27T02:17:34.402021+0300 | INFO | [126,  1700] loss: 1.492
2025-02-27T02:17:46.715373+0300 | INFO | [126,  1800] loss: 1.492
2025-02-27T02:17:59.479180+0300 | INFO | [126,  1900] loss: 1.488
2025-02-27T02:18:11.130878+0300 | INFO | [126,  2000] loss: 1.503
2025-02-27T02:18:22.155283+0300 | INFO | [126,  2100] loss: 1.502
2025-02-27T02:18:34.806774+0300 | INFO | [126,  2200] loss: 1.486
2025-02-27T02:18:47.648468+0300 | INFO | [126,  2300] loss: 1.503
2025-02-27T02:18:59.561990+0300 | INFO | [126,  2400] loss: 1.494
2025-02-27T02:19:10.769778+0300 | INFO | [126,  2500] loss: 1.491
2025-02-27T02:19:23.067998+0300 | INFO | [126,  2600] loss: 1.496
2025-02-27T02:19:34.642032+0300 | INFO | [126,  2700] loss: 1.497
2025-02-27T02:19:45.716493+0300 | INFO | [126,  2800] loss: 1.494
2025-02-27T02:19:57.737736+0300 | INFO | [126,  2900] loss: 1.496
2025-02-27T02:20:09.754444+0300 | INFO | [126,  3000] loss: 1.502
2025-02-27T02:20:21.397303+0300 | INFO | [126,  3100] loss: 1.500
2025-02-27T02:20:32.573604+0300 | INFO | [126,  3200] loss: 1.496
2025-02-27T02:20:44.827354+0300 | INFO | [126,  3300] loss: 1.481
2025-02-27T02:20:55.743959+0300 | INFO | [126,  3400] loss: 1.484
2025-02-27T02:21:06.912752+0300 | INFO | [126,  3500] loss: 1.494
2025-02-27T02:21:17.343750+0300 | INFO | [126,  3600] loss: 1.489
2025-02-27T02:21:28.528181+0300 | INFO | [126,  3700] loss: 1.487
2025-02-27T02:21:39.229849+0300 | INFO | [126,  3800] loss: 1.488
2025-02-27T02:21:50.185926+0300 | INFO | [126,  3900] loss: 1.505
2025-02-27T02:22:01.245612+0300 | INFO | [126,  4000] loss: 1.484
2025-02-27T02:22:12.148620+0300 | INFO | [126,  4100] loss: 1.498
2025-02-27T02:22:22.196347+0300 | INFO | [126,  4200] loss: 1.493
2025-02-27T02:22:33.788456+0300 | INFO | [126,  4300] loss: 1.490
2025-02-27T02:22:44.724314+0300 | INFO | [126,  4400] loss: 1.496
2025-02-27T02:22:54.924693+0300 | INFO | [126,  4500] loss: 1.501
2025-02-27T02:23:07.323276+0300 | INFO | [126,  4600] loss: 1.499
2025-02-27T02:23:21.894878+0300 | INFO | [126,  4700] loss: 1.493
2025-02-27T02:23:32.891849+0300 | INFO | [126,  4800] loss: 1.488
2025-02-27T02:23:43.223608+0300 | INFO | [126,  4900] loss: 1.493
2025-02-27T02:23:54.178585+0300 | DEBUG | Saving model to flat file storage. Save #126
2025-02-27T02:23:54.206249+0300 | INFO | Averaging client parameters
2025-02-27T02:23:54.212677+0300 | INFO | Updating parameters on client #0
2025-02-27T02:24:10.260652+0300 | DEBUG | Test set: Accuracy: 7872/10000 (79%)
2025-02-27T02:24:10.262930+0300 | DEBUG | Test set: Loss: 1.6727511882781982
2025-02-27T02:24:10.357512+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.92      0.89      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.68      0.55      0.61      1200
           4       0.79      0.80      0.79      1000
           5       0.48      0.66      0.56       800
           6       0.83      0.87      0.85      1000
           7       0.85      0.82      0.84      1000
           8       0.90      0.90      0.90      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T02:24:10.359510+0300 | DEBUG | Confusion Matrix:
[[831  13  34  11  11  14   6  12  34  34]
 [ 12 889   3   3   0   2   7   3  20  61]
 [ 61   2 679  31  66  71  54  20   9   7]
 [ 11   3  46 664  51 326  42  32  11  14]
 [ 10   3  31  36 796  49  39  26   6   4]
 [ 12   3  34 142  28 527  12  36   2   4]
 [  8   1  25  36  15  36 869   6   3   1]
 [ 15   2  12  32  43  62   4 820   1   9]
 [ 42  13   7  11   2   4   8   1 901  11]
 [ 23  34   8   6   2   4   7   5  15 896]]
2025-02-27T02:24:10.361528+0300 | DEBUG | Class precision: [0.81073171 0.9231568  0.77246871 0.68312757 0.78500986 0.48127854
 0.82919847 0.85327784 0.8992016  0.86071085]
2025-02-27T02:24:10.364520+0300 | DEBUG | Class recall: [0.831      0.889      0.679      0.55333333 0.796      0.65875
 0.869      0.82       0.901      0.896     ]
2025-02-27T02:24:10.412329+0300 | INFO | Training epoch #127 on client #0
2025-02-27T02:24:10.416334+0300 | DEBUG | Saving model to flat file storage. Save #127
2025-02-27T02:24:10.635412+0300 | INFO | [127,     0] loss: 0.015
2025-02-27T02:24:21.777079+0300 | INFO | [127,   100] loss: 1.502
2025-02-27T02:24:32.835620+0300 | INFO | [127,   200] loss: 1.487
2025-02-27T02:24:44.017138+0300 | INFO | [127,   300] loss: 1.498
2025-02-27T02:24:55.542609+0300 | INFO | [127,   400] loss: 1.486
2025-02-27T02:25:07.018663+0300 | INFO | [127,   500] loss: 1.498
2025-02-27T02:25:17.457545+0300 | INFO | [127,   600] loss: 1.499
2025-02-27T02:25:28.158643+0300 | INFO | [127,   700] loss: 1.491
2025-02-27T02:25:41.030371+0300 | INFO | [127,   800] loss: 1.498
2025-02-27T02:25:53.921716+0300 | INFO | [127,   900] loss: 1.497
2025-02-27T02:26:05.389989+0300 | INFO | [127,  1000] loss: 1.487
2025-02-27T02:26:16.565045+0300 | INFO | [127,  1100] loss: 1.493
2025-02-27T02:26:27.334917+0300 | INFO | [127,  1200] loss: 1.484
2025-02-27T02:26:37.764736+0300 | INFO | [127,  1300] loss: 1.488
2025-02-27T02:26:49.102879+0300 | INFO | [127,  1400] loss: 1.487
2025-02-27T02:27:00.344357+0300 | INFO | [127,  1500] loss: 1.493
2025-02-27T02:27:10.654616+0300 | INFO | [127,  1600] loss: 1.482
2025-02-27T02:27:21.686496+0300 | INFO | [127,  1700] loss: 1.492
2025-02-27T02:27:32.679760+0300 | INFO | [127,  1800] loss: 1.496
2025-02-27T02:27:42.737708+0300 | INFO | [127,  1900] loss: 1.492
2025-02-27T02:27:54.056748+0300 | INFO | [127,  2000] loss: 1.489
2025-02-27T02:28:05.471282+0300 | INFO | [127,  2100] loss: 1.503
2025-02-27T02:28:15.454539+0300 | INFO | [127,  2200] loss: 1.486
2025-02-27T02:28:26.588136+0300 | INFO | [127,  2300] loss: 1.504
2025-02-27T02:28:37.683269+0300 | INFO | [127,  2400] loss: 1.492
2025-02-27T02:28:48.405465+0300 | INFO | [127,  2500] loss: 1.489
2025-02-27T02:29:02.402520+0300 | INFO | [127,  2600] loss: 1.492
2025-02-27T02:29:14.759984+0300 | INFO | [127,  2700] loss: 1.493
2025-02-27T02:29:25.820883+0300 | INFO | [127,  2800] loss: 1.492
2025-02-27T02:29:35.788353+0300 | INFO | [127,  2900] loss: 1.487
2025-02-27T02:29:46.470376+0300 | INFO | [127,  3000] loss: 1.494
2025-02-27T02:29:57.458794+0300 | INFO | [127,  3100] loss: 1.491
2025-02-27T02:30:08.297262+0300 | INFO | [127,  3200] loss: 1.495
2025-02-27T02:30:19.058756+0300 | INFO | [127,  3300] loss: 1.492
2025-02-27T02:30:29.982034+0300 | INFO | [127,  3400] loss: 1.495
2025-02-27T02:30:39.917521+0300 | INFO | [127,  3500] loss: 1.493
2025-02-27T02:30:51.705173+0300 | INFO | [127,  3600] loss: 1.491
2025-02-27T02:31:02.908535+0300 | INFO | [127,  3700] loss: 1.496
2025-02-27T02:31:13.271899+0300 | INFO | [127,  3800] loss: 1.492
2025-02-27T02:31:24.081501+0300 | INFO | [127,  3900] loss: 1.488
2025-02-27T02:31:34.994075+0300 | INFO | [127,  4000] loss: 1.492
2025-02-27T02:31:46.705418+0300 | INFO | [127,  4100] loss: 1.491
2025-02-27T02:32:01.228912+0300 | INFO | [127,  4200] loss: 1.503
2025-02-27T02:32:12.937796+0300 | INFO | [127,  4300] loss: 1.490
2025-02-27T02:32:25.928739+0300 | INFO | [127,  4400] loss: 1.490
2025-02-27T02:32:36.134898+0300 | INFO | [127,  4500] loss: 1.501
2025-02-27T02:32:46.072354+0300 | INFO | [127,  4600] loss: 1.490
2025-02-27T02:32:57.390416+0300 | INFO | [127,  4700] loss: 1.497
2025-02-27T02:33:08.816082+0300 | INFO | [127,  4800] loss: 1.502
2025-02-27T02:33:18.761291+0300 | INFO | [127,  4900] loss: 1.509
2025-02-27T02:33:29.976485+0300 | DEBUG | Saving model to flat file storage. Save #127
2025-02-27T02:33:30.004483+0300 | INFO | Averaging client parameters
2025-02-27T02:33:30.013180+0300 | INFO | Updating parameters on client #0
2025-02-27T02:33:45.399705+0300 | DEBUG | Test set: Accuracy: 7891/10000 (79%)
2025-02-27T02:33:45.400720+0300 | DEBUG | Test set: Loss: 1.670648455619812
2025-02-27T02:33:45.563490+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.71      0.73      1000
           3       0.69      0.55      0.61      1200
           4       0.80      0.78      0.79      1000
           5       0.50      0.66      0.57       800
           6       0.88      0.84      0.86      1000
           7       0.82      0.85      0.83      1000
           8       0.90      0.89      0.89      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T02:33:45.568479+0300 | DEBUG | Confusion Matrix:
[[844  16  40   7   7   9   4  14  31  28]
 [ 11 926   2   0   0   2   3   2  15  39]
 [ 51   4 710  36  62  64  37  21   8   7]
 [ 21   6  49 654  49 310  32  45  15  19]
 [ 15   6  43  40 776  47  20  43   6   4]
 [ 12   3  39 138  23 528   8  41   2   6]
 [  9   4  40  39  17  35 838   8   6   4]
 [ 18   3  16  21  31  50   3 846   3   9]
 [ 46  21   8   9   0   2   6   2 888  18]
 [ 31  49   9   3   1   4   3   7  12 881]]
2025-02-27T02:33:45.569481+0300 | DEBUG | Class precision: [0.79773157 0.89210019 0.74267782 0.6906019  0.80331263 0.50237869
 0.87840671 0.82215743 0.90060852 0.8679803 ]
2025-02-27T02:33:45.573493+0300 | DEBUG | Class recall: [0.844 0.926 0.71  0.545 0.776 0.66  0.838 0.846 0.888 0.881]
2025-02-27T02:33:45.634977+0300 | INFO | Training epoch #128 on client #0
2025-02-27T02:33:45.637975+0300 | DEBUG | Saving model to flat file storage. Save #128
2025-02-27T02:33:45.840691+0300 | INFO | [128,     0] loss: 0.015
2025-02-27T02:33:58.095991+0300 | INFO | [128,   100] loss: 1.496
2025-02-27T02:34:09.365661+0300 | INFO | [128,   200] loss: 1.489
2025-02-27T02:34:20.320203+0300 | INFO | [128,   300] loss: 1.502
2025-02-27T02:34:31.227716+0300 | INFO | [128,   400] loss: 1.487
2025-02-27T02:34:41.149849+0300 | INFO | [128,   500] loss: 1.494
2025-02-27T02:34:52.212804+0300 | INFO | [128,   600] loss: 1.488
2025-02-27T02:35:03.513527+0300 | INFO | [128,   700] loss: 1.490
2025-02-27T02:35:14.148451+0300 | INFO | [128,   800] loss: 1.496
2025-02-27T02:35:25.462423+0300 | INFO | [128,   900] loss: 1.489
2025-02-27T02:35:36.190185+0300 | INFO | [128,  1000] loss: 1.492
2025-02-27T02:35:46.603915+0300 | INFO | [128,  1100] loss: 1.494
2025-02-27T02:35:57.325128+0300 | INFO | [128,  1200] loss: 1.491
2025-02-27T02:36:08.548608+0300 | INFO | [128,  1300] loss: 1.493
2025-02-27T02:36:18.924519+0300 | INFO | [128,  1400] loss: 1.489
2025-02-27T02:36:29.043419+0300 | INFO | [128,  1500] loss: 1.496
2025-02-27T02:36:39.917376+0300 | INFO | [128,  1600] loss: 1.492
2025-02-27T02:36:52.932225+0300 | INFO | [128,  1700] loss: 1.492
2025-02-27T02:37:03.403734+0300 | INFO | [128,  1800] loss: 1.491
2025-02-27T02:37:15.879698+0300 | INFO | [128,  1900] loss: 1.494
2025-02-27T02:37:26.447935+0300 | INFO | [128,  2000] loss: 1.487
2025-02-27T02:37:37.152371+0300 | INFO | [128,  2100] loss: 1.498
2025-02-27T02:37:49.349163+0300 | INFO | [128,  2200] loss: 1.498
2025-02-27T02:38:01.201735+0300 | INFO | [128,  2300] loss: 1.506
2025-02-27T02:38:14.148216+0300 | INFO | [128,  2400] loss: 1.493
2025-02-27T02:38:25.461237+0300 | INFO | [128,  2500] loss: 1.485
2025-02-27T02:38:37.223835+0300 | INFO | [128,  2600] loss: 1.498
2025-02-27T02:38:48.742162+0300 | INFO | [128,  2700] loss: 1.507
2025-02-27T02:39:00.277562+0300 | INFO | [128,  2800] loss: 1.490
2025-02-27T02:39:11.745295+0300 | INFO | [128,  2900] loss: 1.492
2025-02-27T02:39:22.380093+0300 | INFO | [128,  3000] loss: 1.490
2025-02-27T02:39:34.314837+0300 | INFO | [128,  3100] loss: 1.496
2025-02-27T02:39:44.145228+0300 | INFO | [128,  3200] loss: 1.498
2025-02-27T02:39:55.227004+0300 | INFO | [128,  3300] loss: 1.489
2025-02-27T02:40:06.565775+0300 | INFO | [128,  3400] loss: 1.494
2025-02-27T02:40:16.674305+0300 | INFO | [128,  3500] loss: 1.499
2025-02-27T02:40:27.377100+0300 | INFO | [128,  3600] loss: 1.487
2025-02-27T02:40:38.101123+0300 | INFO | [128,  3700] loss: 1.495
2025-02-27T02:40:54.124494+0300 | INFO | [128,  3800] loss: 1.503
2025-02-27T02:41:04.585637+0300 | INFO | [128,  3900] loss: 1.501
2025-02-27T02:41:15.470011+0300 | INFO | [128,  4000] loss: 1.502
2025-02-27T02:41:26.737952+0300 | INFO | [128,  4100] loss: 1.497
2025-02-27T02:41:37.928524+0300 | INFO | [128,  4200] loss: 1.485
2025-02-27T02:41:48.734070+0300 | INFO | [128,  4300] loss: 1.499
2025-02-27T02:41:59.869876+0300 | INFO | [128,  4400] loss: 1.490
2025-02-27T02:42:12.038248+0300 | INFO | [128,  4500] loss: 1.487
2025-02-27T02:42:22.818391+0300 | INFO | [128,  4600] loss: 1.489
2025-02-27T02:42:33.586339+0300 | INFO | [128,  4700] loss: 1.489
2025-02-27T02:42:44.877063+0300 | INFO | [128,  4800] loss: 1.494
2025-02-27T02:42:55.194873+0300 | INFO | [128,  4900] loss: 1.496
2025-02-27T02:43:06.125913+0300 | DEBUG | Saving model to flat file storage. Save #128
2025-02-27T02:43:06.150135+0300 | INFO | Averaging client parameters
2025-02-27T02:43:06.155989+0300 | INFO | Updating parameters on client #0
2025-02-27T02:43:21.315855+0300 | DEBUG | Test set: Accuracy: 7923/10000 (79%)
2025-02-27T02:43:21.316858+0300 | DEBUG | Test set: Loss: 1.6676150560379028
2025-02-27T02:43:21.412173+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.78      0.69      0.73      1000
           3       0.68      0.56      0.62      1200
           4       0.78      0.81      0.79      1000
           5       0.51      0.63      0.56       800
           6       0.84      0.86      0.85      1000
           7       0.83      0.85      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T02:43:21.414174+0300 | DEBUG | Confusion Matrix:
[[825  18  35   9  13   7   6  11  43  33]
 [  8 930   3   1   0   1   6   1  10  40]
 [ 58   3 689  37  70  58  45  25   7   8]
 [ 22   6  41 672  57 292  42  36  14  18]
 [  8   6  28  33 805  46  27  37   6   4]
 [ 12   4  34 154  27 502  14  44   5   4]
 [  5   3  30  38  16  32 860   7   6   3]
 [ 15   4  11  26  38  42   5 847   3   9]
 [ 33  19   6   9   0   2   8   0 905  18]
 [ 23  46   4   5   1   5   8   7  13 888]]
2025-02-27T02:43:21.416173+0300 | DEBUG | Class precision: [0.81764123 0.89509143 0.78206583 0.68292683 0.78383642 0.50861196
 0.84231146 0.83448276 0.89426877 0.86634146]
2025-02-27T02:43:21.418172+0300 | DEBUG | Class recall: [0.825  0.93   0.689  0.56   0.805  0.6275 0.86   0.847  0.905  0.888 ]
2025-02-27T02:43:21.474140+0300 | INFO | Training epoch #129 on client #0
2025-02-27T02:43:21.475142+0300 | DEBUG | Saving model to flat file storage. Save #129
2025-02-27T02:43:21.683180+0300 | INFO | [129,     0] loss: 0.015
2025-02-27T02:43:32.550354+0300 | INFO | [129,   100] loss: 1.498
2025-02-27T02:43:42.578120+0300 | INFO | [129,   200] loss: 1.502
2025-02-27T02:43:53.721506+0300 | INFO | [129,   300] loss: 1.495
2025-02-27T02:44:04.806568+0300 | INFO | [129,   400] loss: 1.500
2025-02-27T02:44:14.803859+0300 | INFO | [129,   500] loss: 1.495
2025-02-27T02:44:25.500607+0300 | INFO | [129,   600] loss: 1.484
2025-02-27T02:44:36.239811+0300 | INFO | [129,   700] loss: 1.488
2025-02-27T02:44:46.985868+0300 | INFO | [129,   800] loss: 1.496
2025-02-27T02:44:58.109584+0300 | INFO | [129,   900] loss: 1.493
2025-02-27T02:45:09.265881+0300 | INFO | [129,  1000] loss: 1.488
2025-02-27T02:45:19.695973+0300 | INFO | [129,  1100] loss: 1.499
2025-02-27T02:45:30.369840+0300 | INFO | [129,  1200] loss: 1.490
2025-02-27T02:45:41.442386+0300 | INFO | [129,  1300] loss: 1.487
2025-02-27T02:45:51.915793+0300 | INFO | [129,  1400] loss: 1.490
2025-02-27T02:46:03.073346+0300 | INFO | [129,  1500] loss: 1.492
2025-02-27T02:46:13.941640+0300 | INFO | [129,  1600] loss: 1.491
2025-02-27T02:46:24.576639+0300 | INFO | [129,  1700] loss: 1.489
2025-02-27T02:46:35.391432+0300 | INFO | [129,  1800] loss: 1.488
2025-02-27T02:46:46.247557+0300 | INFO | [129,  1900] loss: 1.503
2025-02-27T02:46:56.505040+0300 | INFO | [129,  2000] loss: 1.491
2025-02-27T02:47:07.885305+0300 | INFO | [129,  2100] loss: 1.492
2025-02-27T02:47:19.240196+0300 | INFO | [129,  2200] loss: 1.491
2025-02-27T02:47:29.219434+0300 | INFO | [129,  2300] loss: 1.498
2025-02-27T02:47:40.124971+0300 | INFO | [129,  2400] loss: 1.499
2025-02-27T02:47:52.390286+0300 | INFO | [129,  2500] loss: 1.506
2025-02-27T02:48:03.370320+0300 | INFO | [129,  2600] loss: 1.492
2025-02-27T02:48:13.944476+0300 | INFO | [129,  2700] loss: 1.493
2025-02-27T02:48:24.691559+0300 | INFO | [129,  2800] loss: 1.484
2025-02-27T02:48:35.597675+0300 | INFO | [129,  2900] loss: 1.498
2025-02-27T02:48:45.816640+0300 | INFO | [129,  3000] loss: 1.494
2025-02-27T02:48:57.210744+0300 | INFO | [129,  3100] loss: 1.495
2025-02-27T02:49:08.700579+0300 | INFO | [129,  3200] loss: 1.493
2025-02-27T02:49:22.171042+0300 | INFO | [129,  3300] loss: 1.484
2025-02-27T02:49:35.266121+0300 | INFO | [129,  3400] loss: 1.501
2025-02-27T02:49:46.520881+0300 | INFO | [129,  3500] loss: 1.504
2025-02-27T02:49:57.643633+0300 | INFO | [129,  3600] loss: 1.493
2025-02-27T02:50:07.933658+0300 | INFO | [129,  3700] loss: 1.491
2025-02-27T02:50:21.078966+0300 | INFO | [129,  3800] loss: 1.499
2025-02-27T02:50:31.891512+0300 | INFO | [129,  3900] loss: 1.488
2025-02-27T02:50:42.517183+0300 | INFO | [129,  4000] loss: 1.493
2025-02-27T02:50:53.500365+0300 | INFO | [129,  4100] loss: 1.496
2025-02-27T02:51:05.714970+0300 | INFO | [129,  4200] loss: 1.492
2025-02-27T02:51:16.671036+0300 | INFO | [129,  4300] loss: 1.492
2025-02-27T02:51:26.715580+0300 | INFO | [129,  4400] loss: 1.489
2025-02-27T02:51:38.109717+0300 | INFO | [129,  4500] loss: 1.487
2025-02-27T02:51:48.976611+0300 | INFO | [129,  4600] loss: 1.496
2025-02-27T02:51:59.300853+0300 | INFO | [129,  4700] loss: 1.486
2025-02-27T02:52:10.363805+0300 | INFO | [129,  4800] loss: 1.494
2025-02-27T02:52:21.391222+0300 | INFO | [129,  4900] loss: 1.503
2025-02-27T02:52:31.604753+0300 | DEBUG | Saving model to flat file storage. Save #129
2025-02-27T02:52:31.625751+0300 | INFO | Averaging client parameters
2025-02-27T02:52:31.635233+0300 | INFO | Updating parameters on client #0
2025-02-27T02:52:47.403550+0300 | DEBUG | Test set: Accuracy: 7935/10000 (79%)
2025-02-27T02:52:47.405556+0300 | DEBUG | Test set: Loss: 1.6668505668640137
2025-02-27T02:52:47.503293+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.83      0.80      1000
           5       0.54      0.62      0.58       800
           6       0.85      0.86      0.85      1000
           7       0.86      0.83      0.84      1000
           8       0.88      0.91      0.89      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T02:52:47.505441+0300 | DEBUG | Confusion Matrix:
[[830  13  41   9   8   6   6  10  45  32]
 [ 10 920   3   1   0   3   5   1  16  41]
 [ 58   2 709  37  71  47  40  19   9   8]
 [ 22   5  49 672  68 265  47  35  17  20]
 [  7   6  37  34 829  29  24  25   5   4]
 [ 14   4  41 155  27 498  15  37   4   5]
 [  6   4  36  31  20  25 860   6  10   2]
 [ 16   3  17  26  48  45   5 827   3  10]
 [ 37  16   7   9   3   2   6   1 907  12]
 [ 28  47   6   5   2   3   6   5  15 883]]
2025-02-27T02:52:47.506441+0300 | DEBUG | Class precision: [0.807393   0.90196078 0.74947146 0.68641471 0.7704461  0.53954496
 0.84812623 0.85610766 0.87972842 0.86823992]
2025-02-27T02:52:47.510445+0300 | DEBUG | Class recall: [0.83   0.92   0.709  0.56   0.829  0.6225 0.86   0.827  0.907  0.883 ]
2025-02-27T02:52:47.559764+0300 | INFO | Training epoch #130 on client #0
2025-02-27T02:52:47.561772+0300 | DEBUG | Saving model to flat file storage. Save #130
2025-02-27T02:52:47.843480+0300 | INFO | [130,     0] loss: 0.015
2025-02-27T02:52:59.348241+0300 | INFO | [130,   100] loss: 1.496
2025-02-27T02:53:11.192547+0300 | INFO | [130,   200] loss: 1.506
2025-02-27T02:53:21.105813+0300 | INFO | [130,   300] loss: 1.496
2025-02-27T02:53:34.309635+0300 | INFO | [130,   400] loss: 1.492
2025-02-27T02:53:46.590047+0300 | INFO | [130,   500] loss: 1.493
2025-02-27T02:53:57.609300+0300 | INFO | [130,   600] loss: 1.495
2025-02-27T02:54:07.809157+0300 | INFO | [130,   700] loss: 1.494
2025-02-27T02:54:20.477608+0300 | INFO | [130,   800] loss: 1.491
2025-02-27T02:54:31.743049+0300 | INFO | [130,   900] loss: 1.495
2025-02-27T02:54:42.245022+0300 | INFO | [130,  1000] loss: 1.490
2025-02-27T02:54:52.852422+0300 | INFO | [130,  1100] loss: 1.499
2025-02-27T02:55:04.451244+0300 | INFO | [130,  1200] loss: 1.488
2025-02-27T02:55:15.419499+0300 | INFO | [130,  1300] loss: 1.495
2025-02-27T02:55:26.931765+0300 | INFO | [130,  1400] loss: 1.493
2025-02-27T02:55:37.439298+0300 | INFO | [130,  1500] loss: 1.488
2025-02-27T02:55:48.462716+0300 | INFO | [130,  1600] loss: 1.492
2025-02-27T02:55:58.868911+0300 | INFO | [130,  1700] loss: 1.489
2025-02-27T02:56:09.996215+0300 | INFO | [130,  1800] loss: 1.489
2025-02-27T02:56:20.745191+0300 | INFO | [130,  1900] loss: 1.492
2025-02-27T02:56:31.253963+0300 | INFO | [130,  2000] loss: 1.494
2025-02-27T02:56:42.148997+0300 | INFO | [130,  2100] loss: 1.496
2025-02-27T02:56:53.661410+0300 | INFO | [130,  2200] loss: 1.503
2025-02-27T02:57:04.028850+0300 | INFO | [130,  2300] loss: 1.494
2025-02-27T02:57:14.978407+0300 | INFO | [130,  2400] loss: 1.499
2025-02-27T02:57:26.522876+0300 | INFO | [130,  2500] loss: 1.491
2025-02-27T02:57:36.302038+0300 | INFO | [130,  2600] loss: 1.488
2025-02-27T02:57:47.566507+0300 | INFO | [130,  2700] loss: 1.505
2025-02-27T02:57:59.039919+0300 | INFO | [130,  2800] loss: 1.497
2025-02-27T02:58:09.507354+0300 | INFO | [130,  2900] loss: 1.497
2025-02-27T02:58:22.569518+0300 | INFO | [130,  3000] loss: 1.479
2025-02-27T02:58:36.320515+0300 | INFO | [130,  3100] loss: 1.489
2025-02-27T02:58:47.121601+0300 | INFO | [130,  3200] loss: 1.497
2025-02-27T02:58:57.407498+0300 | INFO | [130,  3300] loss: 1.505
2025-02-27T02:59:08.525572+0300 | INFO | [130,  3400] loss: 1.494
2025-02-27T02:59:19.580854+0300 | INFO | [130,  3500] loss: 1.493
2025-02-27T02:59:29.749641+0300 | INFO | [130,  3600] loss: 1.482
2025-02-27T02:59:40.604556+0300 | INFO | [130,  3700] loss: 1.487
2025-02-27T02:59:51.651324+0300 | INFO | [130,  3800] loss: 1.492
2025-02-27T03:00:02.650171+0300 | INFO | [130,  3900] loss: 1.492
2025-02-27T03:00:13.487014+0300 | INFO | [130,  4000] loss: 1.491
2025-02-27T03:00:24.296701+0300 | INFO | [130,  4100] loss: 1.488
2025-02-27T03:00:36.030816+0300 | INFO | [130,  4200] loss: 1.489
2025-02-27T03:00:46.311874+0300 | INFO | [130,  4300] loss: 1.494
2025-02-27T03:00:57.335572+0300 | INFO | [130,  4400] loss: 1.500
2025-02-27T03:01:08.186518+0300 | INFO | [130,  4500] loss: 1.490
2025-02-27T03:01:18.460310+0300 | INFO | [130,  4600] loss: 1.505
2025-02-27T03:01:29.392605+0300 | INFO | [130,  4700] loss: 1.490
2025-02-27T03:01:40.425421+0300 | INFO | [130,  4800] loss: 1.488
2025-02-27T03:01:50.496186+0300 | INFO | [130,  4900] loss: 1.494
2025-02-27T03:02:01.912436+0300 | DEBUG | Saving model to flat file storage. Save #130
2025-02-27T03:02:01.938445+0300 | INFO | Averaging client parameters
2025-02-27T03:02:01.949446+0300 | INFO | Updating parameters on client #0
2025-02-27T03:02:17.398424+0300 | DEBUG | Test set: Accuracy: 7891/10000 (79%)
2025-02-27T03:02:17.399423+0300 | DEBUG | Test set: Loss: 1.671048879623413
2025-02-27T03:02:17.491594+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.89      0.92      0.90      1000
           2       0.73      0.71      0.72      1000
           3       0.69      0.56      0.62      1200
           4       0.80      0.78      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.84      0.85      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.90      0.89      1000
           9       0.85      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:02:17.495594+0300 | DEBUG | Confusion Matrix:
[[822  20  36   9   9   8   6  11  40  39]
 [  6 920   2   1   0   1   4   0  16  50]
 [ 56   7 712  36  60  54  42  16   9   8]
 [ 20   7  62 669  47 289  42  32  14  18]
 [ 13   6  43  40 782  43  32  31   6   4]
 [ 14   4  42 148  22 509  14  38   4   5]
 [  7   5  44  31  15  23 855   7   9   4]
 [ 13   4  20  23  43  53   5 828   3   8]
 [ 37  17   7  10   1   2   6   2 901  17]
 [ 21  47   5   4   1   2   6   8  13 893]]
2025-02-27T03:02:17.497600+0300 | DEBUG | Class precision: [0.81466799 0.88717454 0.73175745 0.68898043 0.79795918 0.51727642
 0.84486166 0.85097636 0.88768473 0.85372849]
2025-02-27T03:02:17.498595+0300 | DEBUG | Class recall: [0.822   0.92    0.712   0.5575  0.782   0.63625 0.855   0.828   0.901
 0.893  ]
2025-02-27T03:02:17.549912+0300 | INFO | Training epoch #131 on client #0
2025-02-27T03:02:17.551914+0300 | DEBUG | Saving model to flat file storage. Save #131
2025-02-27T03:02:17.768503+0300 | INFO | [131,     0] loss: 0.015
2025-02-27T03:02:28.605493+0300 | INFO | [131,   100] loss: 1.495
2025-02-27T03:02:38.930386+0300 | INFO | [131,   200] loss: 1.493
2025-02-27T03:02:49.966421+0300 | INFO | [131,   300] loss: 1.494
2025-02-27T03:03:01.244478+0300 | INFO | [131,   400] loss: 1.499
2025-02-27T03:03:11.540307+0300 | INFO | [131,   500] loss: 1.495
2025-02-27T03:03:23.180364+0300 | INFO | [131,   600] loss: 1.486
2025-02-27T03:03:34.225839+0300 | INFO | [131,   700] loss: 1.487
2025-02-27T03:03:45.219352+0300 | INFO | [131,   800] loss: 1.496
2025-02-27T03:03:56.995186+0300 | INFO | [131,   900] loss: 1.494
2025-02-27T03:04:08.173872+0300 | INFO | [131,  1000] loss: 1.484
2025-02-27T03:04:19.644764+0300 | INFO | [131,  1100] loss: 1.501
2025-02-27T03:04:29.640329+0300 | INFO | [131,  1200] loss: 1.485
2025-02-27T03:04:40.386010+0300 | INFO | [131,  1300] loss: 1.500
2025-02-27T03:04:51.697190+0300 | INFO | [131,  1400] loss: 1.486
2025-02-27T03:05:03.721986+0300 | INFO | [131,  1500] loss: 1.496
2025-02-27T03:05:14.795026+0300 | INFO | [131,  1600] loss: 1.490
2025-02-27T03:05:26.404404+0300 | INFO | [131,  1700] loss: 1.488
2025-02-27T03:05:36.770857+0300 | INFO | [131,  1800] loss: 1.497
2025-02-27T03:05:48.001034+0300 | INFO | [131,  1900] loss: 1.499
2025-02-27T03:05:59.368985+0300 | INFO | [131,  2000] loss: 1.489
2025-02-27T03:06:10.152670+0300 | INFO | [131,  2100] loss: 1.493
2025-02-27T03:06:20.945915+0300 | INFO | [131,  2200] loss: 1.486
2025-02-27T03:06:32.400935+0300 | INFO | [131,  2300] loss: 1.498
2025-02-27T03:06:44.304168+0300 | INFO | [131,  2400] loss: 1.491
2025-02-27T03:06:55.820628+0300 | INFO | [131,  2500] loss: 1.495
2025-02-27T03:07:11.202728+0300 | INFO | [131,  2600] loss: 1.496
2025-02-27T03:07:22.655624+0300 | INFO | [131,  2700] loss: 1.489
2025-02-27T03:07:33.581085+0300 | INFO | [131,  2800] loss: 1.496
2025-02-27T03:07:43.998483+0300 | INFO | [131,  2900] loss: 1.495
2025-02-27T03:07:55.371066+0300 | INFO | [131,  3000] loss: 1.489
2025-02-27T03:08:07.623802+0300 | INFO | [131,  3100] loss: 1.495
2025-02-27T03:08:18.412006+0300 | INFO | [131,  3200] loss: 1.487
2025-02-27T03:08:29.548399+0300 | INFO | [131,  3300] loss: 1.495
2025-02-27T03:08:40.744022+0300 | INFO | [131,  3400] loss: 1.504
2025-02-27T03:08:51.885868+0300 | INFO | [131,  3500] loss: 1.501
2025-02-27T03:09:02.542519+0300 | INFO | [131,  3600] loss: 1.488
2025-02-27T03:09:15.033639+0300 | INFO | [131,  3700] loss: 1.492
2025-02-27T03:09:26.710866+0300 | INFO | [131,  3800] loss: 1.503
2025-02-27T03:09:37.598600+0300 | INFO | [131,  3900] loss: 1.499
2025-02-27T03:09:48.721059+0300 | INFO | [131,  4000] loss: 1.492
2025-02-27T03:09:59.864446+0300 | INFO | [131,  4100] loss: 1.496
2025-02-27T03:10:11.636896+0300 | INFO | [131,  4200] loss: 1.489
2025-02-27T03:10:21.911645+0300 | INFO | [131,  4300] loss: 1.486
2025-02-27T03:10:33.401022+0300 | INFO | [131,  4400] loss: 1.490
2025-02-27T03:10:45.305399+0300 | INFO | [131,  4500] loss: 1.490
2025-02-27T03:10:55.959413+0300 | INFO | [131,  4600] loss: 1.496
2025-02-27T03:11:07.045831+0300 | INFO | [131,  4700] loss: 1.508
2025-02-27T03:11:18.076952+0300 | INFO | [131,  4800] loss: 1.491
2025-02-27T03:11:27.988811+0300 | INFO | [131,  4900] loss: 1.501
2025-02-27T03:11:38.923343+0300 | DEBUG | Saving model to flat file storage. Save #131
2025-02-27T03:11:38.947846+0300 | INFO | Averaging client parameters
2025-02-27T03:11:38.959347+0300 | INFO | Updating parameters on client #0
2025-02-27T03:11:55.122889+0300 | DEBUG | Test set: Accuracy: 7895/10000 (79%)
2025-02-27T03:11:55.124889+0300 | DEBUG | Test set: Loss: 1.671030879020691
2025-02-27T03:11:55.218503+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.89      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.69      0.55      0.61      1200
           4       0.77      0.81      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.87      0.83      0.85      1000
           7       0.84      0.83      0.83      1000
           8       0.87      0.91      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:11:55.222500+0300 | DEBUG | Confusion Matrix:
[[839  17  38   8  10   6   4  11  39  28]
 [ 11 923   3   0   1   1   3   1  19  38]
 [ 59   8 710  39  66  50  33  17  11   7]
 [ 19   6  52 659  57 292  37  39  21  18]
 [ 13   5  39  34 806  42  21  30   6   4]
 [ 12   3  37 145  28 514  12  40   6   3]
 [ 10   1  44  38  25  31 831   7  11   2]
 [ 12   4  16  25  44  52   5 829   4   9]
 [ 42  13   4   8   3   1   6   2 909  12]
 [ 23  55   6   4   1   4   3  10  19 875]]
2025-02-27T03:11:55.226502+0300 | DEBUG | Class precision: [0.80673077 0.89178744 0.74815595 0.68645833 0.77425552 0.51762336
 0.87015707 0.84077079 0.86985646 0.87851406]
2025-02-27T03:11:55.227826+0300 | DEBUG | Class recall: [0.839      0.923      0.71       0.54916667 0.806      0.6425
 0.831      0.829      0.909      0.875     ]
2025-02-27T03:11:55.283052+0300 | INFO | Training epoch #132 on client #0
2025-02-27T03:11:55.285046+0300 | DEBUG | Saving model to flat file storage. Save #132
2025-02-27T03:11:55.517889+0300 | INFO | [132,     0] loss: 0.015
2025-02-27T03:12:06.598388+0300 | INFO | [132,   100] loss: 1.498
2025-02-27T03:12:16.814545+0300 | INFO | [132,   200] loss: 1.486
2025-02-27T03:12:27.699454+0300 | INFO | [132,   300] loss: 1.498
2025-02-27T03:12:38.870776+0300 | INFO | [132,   400] loss: 1.500
2025-02-27T03:12:49.498997+0300 | INFO | [132,   500] loss: 1.489
2025-02-27T03:13:03.488434+0300 | INFO | [132,   600] loss: 1.497
2025-02-27T03:13:14.915537+0300 | INFO | [132,   700] loss: 1.501
2025-02-27T03:13:26.589083+0300 | INFO | [132,   800] loss: 1.498
2025-02-27T03:13:36.886181+0300 | INFO | [132,   900] loss: 1.494
2025-02-27T03:13:48.147017+0300 | INFO | [132,  1000] loss: 1.487
2025-02-27T03:13:59.580160+0300 | INFO | [132,  1100] loss: 1.483
2025-02-27T03:14:09.777706+0300 | INFO | [132,  1200] loss: 1.490
2025-02-27T03:14:22.688182+0300 | INFO | [132,  1300] loss: 1.497
2025-02-27T03:14:33.019575+0300 | INFO | [132,  1400] loss: 1.491
2025-02-27T03:14:44.113398+0300 | INFO | [132,  1500] loss: 1.492
2025-02-27T03:14:56.778840+0300 | INFO | [132,  1600] loss: 1.493
2025-02-27T03:15:07.522424+0300 | INFO | [132,  1700] loss: 1.503
2025-02-27T03:15:18.640055+0300 | INFO | [132,  1800] loss: 1.501
2025-02-27T03:15:29.418085+0300 | INFO | [132,  1900] loss: 1.492
2025-02-27T03:15:40.082008+0300 | INFO | [132,  2000] loss: 1.489
2025-02-27T03:15:51.125088+0300 | INFO | [132,  2100] loss: 1.493
2025-02-27T03:16:01.727416+0300 | INFO | [132,  2200] loss: 1.487
2025-02-27T03:16:17.761526+0300 | INFO | [132,  2300] loss: 1.488
2025-02-27T03:16:28.469337+0300 | INFO | [132,  2400] loss: 1.493
2025-02-27T03:16:40.035511+0300 | INFO | [132,  2500] loss: 1.498
2025-02-27T03:16:50.605163+0300 | INFO | [132,  2600] loss: 1.491
2025-02-27T03:17:01.629971+0300 | INFO | [132,  2700] loss: 1.489
2025-02-27T03:17:12.544861+0300 | INFO | [132,  2800] loss: 1.492
2025-02-27T03:17:23.663982+0300 | INFO | [132,  2900] loss: 1.496
2025-02-27T03:17:33.706503+0300 | INFO | [132,  3000] loss: 1.490
2025-02-27T03:17:44.649947+0300 | INFO | [132,  3100] loss: 1.496
2025-02-27T03:17:56.402291+0300 | INFO | [132,  3200] loss: 1.493
2025-02-27T03:18:07.070866+0300 | INFO | [132,  3300] loss: 1.491
2025-02-27T03:18:20.176426+0300 | INFO | [132,  3400] loss: 1.498
2025-02-27T03:18:30.809495+0300 | INFO | [132,  3500] loss: 1.493
2025-02-27T03:18:41.361169+0300 | INFO | [132,  3600] loss: 1.490
2025-02-27T03:18:52.741184+0300 | INFO | [132,  3700] loss: 1.502
2025-02-27T03:19:04.231915+0300 | INFO | [132,  3800] loss: 1.493
2025-02-27T03:19:16.005990+0300 | INFO | [132,  3900] loss: 1.500
2025-02-27T03:19:26.022254+0300 | INFO | [132,  4000] loss: 1.488
2025-02-27T03:19:36.775506+0300 | INFO | [132,  4100] loss: 1.497
2025-02-27T03:19:48.583428+0300 | INFO | [132,  4200] loss: 1.493
2025-02-27T03:19:58.905976+0300 | INFO | [132,  4300] loss: 1.484
2025-02-27T03:20:09.954565+0300 | INFO | [132,  4400] loss: 1.487
2025-02-27T03:20:21.234902+0300 | INFO | [132,  4500] loss: 1.499
2025-02-27T03:20:31.748313+0300 | INFO | [132,  4600] loss: 1.490
2025-02-27T03:20:42.840585+0300 | INFO | [132,  4700] loss: 1.483
2025-02-27T03:20:55.930854+0300 | INFO | [132,  4800] loss: 1.497
2025-02-27T03:21:07.622942+0300 | INFO | [132,  4900] loss: 1.498
2025-02-27T03:21:18.950100+0300 | DEBUG | Saving model to flat file storage. Save #132
2025-02-27T03:21:18.970350+0300 | INFO | Averaging client parameters
2025-02-27T03:21:18.986948+0300 | INFO | Updating parameters on client #0
2025-02-27T03:21:35.501906+0300 | DEBUG | Test set: Accuracy: 7883/10000 (79%)
2025-02-27T03:21:35.502913+0300 | DEBUG | Test set: Loss: 1.6713224649429321
2025-02-27T03:21:35.581505+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.76      0.70      0.72      1000
           3       0.68      0.57      0.62      1200
           4       0.81      0.77      0.79      1000
           5       0.49      0.66      0.56       800
           6       0.85      0.85      0.85      1000
           7       0.84      0.85      0.84      1000
           8       0.88      0.91      0.89      1000
           9       0.91      0.85      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:21:35.582501+0300 | DEBUG | Confusion Matrix:
[[823  18  41  12   8  12   5  13  46  22]
 [ 12 919   3   1   0   3   4   5  21  32]
 [ 56   2 696  44  58  68  41  20  10   5]
 [ 13   4  38 680  44 316  41  37  15  12]
 [ 10   2  44  42 774  51  33  35   6   3]
 [ 14   3  32 146  22 527  13  40   2   1]
 [  6   1  39  43  11  37 851   5   7   0]
 [ 16   1  13  24  32  54   4 849   2   5]
 [ 38  14   8   9   2   4   4   1 913   7]
 [ 26  62   7   5   1   7  11  11  19 851]]
2025-02-27T03:21:35.584499+0300 | DEBUG | Class precision: [0.81163708 0.8957115  0.75570033 0.67594433 0.81302521 0.4884152
 0.84508441 0.83562992 0.87704131 0.90724947]
2025-02-27T03:21:35.585508+0300 | DEBUG | Class recall: [0.823      0.919      0.696      0.56666667 0.774      0.65875
 0.851      0.849      0.913      0.851     ]
2025-02-27T03:21:35.671469+0300 | INFO | Training epoch #133 on client #0
2025-02-27T03:21:35.671469+0300 | DEBUG | Saving model to flat file storage. Save #133
2025-02-27T03:21:35.936318+0300 | INFO | [133,     0] loss: 0.015
2025-02-27T03:21:49.087064+0300 | INFO | [133,   100] loss: 1.489
2025-02-27T03:22:01.165389+0300 | INFO | [133,   200] loss: 1.493
2025-02-27T03:22:13.137037+0300 | INFO | [133,   300] loss: 1.483
2025-02-27T03:22:24.070984+0300 | INFO | [133,   400] loss: 1.495
2025-02-27T03:22:35.761199+0300 | INFO | [133,   500] loss: 1.492
2025-02-27T03:22:47.835601+0300 | INFO | [133,   600] loss: 1.482
2025-02-27T03:22:59.700443+0300 | INFO | [133,   700] loss: 1.499
2025-02-27T03:23:11.654816+0300 | INFO | [133,   800] loss: 1.494
2025-02-27T03:23:23.466305+0300 | INFO | [133,   900] loss: 1.502
2025-02-27T03:23:35.291120+0300 | INFO | [133,  1000] loss: 1.478
2025-02-27T03:23:47.119094+0300 | INFO | [133,  1100] loss: 1.497
2025-02-27T03:23:58.436802+0300 | INFO | [133,  1200] loss: 1.490
2025-02-27T03:24:10.423563+0300 | INFO | [133,  1300] loss: 1.497
2025-02-27T03:24:22.571109+0300 | INFO | [133,  1400] loss: 1.499
2025-02-27T03:24:33.298780+0300 | INFO | [133,  1500] loss: 1.495
2025-02-27T03:24:44.570587+0300 | INFO | [133,  1600] loss: 1.500
2025-02-27T03:24:55.316731+0300 | INFO | [133,  1700] loss: 1.490
2025-02-27T03:25:09.993395+0300 | INFO | [133,  1800] loss: 1.495
2025-02-27T03:25:22.893658+0300 | INFO | [133,  1900] loss: 1.486
2025-02-27T03:25:33.338948+0300 | INFO | [133,  2000] loss: 1.494
2025-02-27T03:25:44.390356+0300 | INFO | [133,  2100] loss: 1.489
2025-02-27T03:25:56.742565+0300 | INFO | [133,  2200] loss: 1.493
2025-02-27T03:26:07.254629+0300 | INFO | [133,  2300] loss: 1.497
2025-02-27T03:26:18.387542+0300 | INFO | [133,  2400] loss: 1.492
2025-02-27T03:26:29.477575+0300 | INFO | [133,  2500] loss: 1.496
2025-02-27T03:26:39.041289+0300 | INFO | [133,  2600] loss: 1.494
2025-02-27T03:26:50.147644+0300 | INFO | [133,  2700] loss: 1.484
2025-02-27T03:27:01.758240+0300 | INFO | [133,  2800] loss: 1.498
2025-02-27T03:27:12.163777+0300 | INFO | [133,  2900] loss: 1.491
2025-02-27T03:27:22.928163+0300 | INFO | [133,  3000] loss: 1.494
2025-02-27T03:27:33.897293+0300 | INFO | [133,  3100] loss: 1.496
2025-02-27T03:27:44.282672+0300 | INFO | [133,  3200] loss: 1.488
2025-02-27T03:27:55.540456+0300 | INFO | [133,  3300] loss: 1.501
2025-02-27T03:28:06.653676+0300 | INFO | [133,  3400] loss: 1.483
2025-02-27T03:28:16.717395+0300 | INFO | [133,  3500] loss: 1.491
2025-02-27T03:28:27.680140+0300 | INFO | [133,  3600] loss: 1.502
2025-02-27T03:28:38.727501+0300 | INFO | [133,  3700] loss: 1.485
2025-02-27T03:28:48.877203+0300 | INFO | [133,  3800] loss: 1.491
2025-02-27T03:28:59.969036+0300 | INFO | [133,  3900] loss: 1.491
2025-02-27T03:29:12.695412+0300 | INFO | [133,  4000] loss: 1.496
2025-02-27T03:29:23.581082+0300 | INFO | [133,  4100] loss: 1.500
2025-02-27T03:29:34.920865+0300 | INFO | [133,  4200] loss: 1.497
2025-02-27T03:29:45.766083+0300 | INFO | [133,  4300] loss: 1.500
2025-02-27T03:29:57.130441+0300 | INFO | [133,  4400] loss: 1.502
2025-02-27T03:30:07.327054+0300 | INFO | [133,  4500] loss: 1.493
2025-02-27T03:30:18.510656+0300 | INFO | [133,  4600] loss: 1.491
2025-02-27T03:30:29.236277+0300 | INFO | [133,  4700] loss: 1.490
2025-02-27T03:30:39.215218+0300 | INFO | [133,  4800] loss: 1.497
2025-02-27T03:30:50.255465+0300 | INFO | [133,  4900] loss: 1.486
2025-02-27T03:31:01.272915+0300 | DEBUG | Saving model to flat file storage. Save #133
2025-02-27T03:31:01.295433+0300 | INFO | Averaging client parameters
2025-02-27T03:31:01.308442+0300 | INFO | Updating parameters on client #0
2025-02-27T03:31:17.514153+0300 | DEBUG | Test set: Accuracy: 7878/10000 (79%)
2025-02-27T03:31:17.515166+0300 | DEBUG | Test set: Loss: 1.6712480783462524
2025-02-27T03:31:17.610427+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.80      0.82      1000
           1       0.89      0.92      0.90      1000
           2       0.73      0.73      0.73      1000
           3       0.67      0.56      0.61      1200
           4       0.78      0.80      0.79      1000
           5       0.53      0.59      0.56       800
           6       0.83      0.87      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.87      0.91      0.89      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:31:17.613427+0300 | DEBUG | Confusion Matrix:
[[804  19  45   9  12  10   4  13  53  31]
 [  7 917   2   1   0   1   6   3  19  44]
 [ 45   4 730  38  67  39  45  15   6  11]
 [ 14   5  62 666  62 258  57  38  15  23]
 [ 11   4  44  35 797  39  33  27   7   3]
 [ 15   3  47 171  31 469  17  40   4   3]
 [  8   3  43  31  12  15 871   7   7   3]
 [ 16   3  16  26  43  44   4 835   3  10]
 [ 30  20   7   7   2   4   4   1 913  12]
 [ 19  55   7   3   1   3   6   9  21 876]]
2025-02-27T03:31:17.615416+0300 | DEBUG | Class precision: [0.82972136 0.88770571 0.72781655 0.67477204 0.77604674 0.53174603
 0.83190067 0.8451417  0.87118321 0.86220472]
2025-02-27T03:31:17.616427+0300 | DEBUG | Class recall: [0.804   0.917   0.73    0.555   0.797   0.58625 0.871   0.835   0.913
 0.876  ]
2025-02-27T03:31:17.672116+0300 | INFO | Training epoch #134 on client #0
2025-02-27T03:31:17.674125+0300 | DEBUG | Saving model to flat file storage. Save #134
2025-02-27T03:31:17.899977+0300 | INFO | [134,     0] loss: 0.015
2025-02-27T03:31:28.030993+0300 | INFO | [134,   100] loss: 1.508
2025-02-27T03:31:40.656868+0300 | INFO | [134,   200] loss: 1.486
2025-02-27T03:31:51.294021+0300 | INFO | [134,   300] loss: 1.490
2025-02-27T03:32:02.159875+0300 | INFO | [134,   400] loss: 1.494
2025-02-27T03:32:12.808011+0300 | INFO | [134,   500] loss: 1.498
2025-02-27T03:32:23.523756+0300 | INFO | [134,   600] loss: 1.495
2025-02-27T03:32:33.660573+0300 | INFO | [134,   700] loss: 1.486
2025-02-27T03:32:45.457164+0300 | INFO | [134,   800] loss: 1.503
2025-02-27T03:32:56.685533+0300 | INFO | [134,   900] loss: 1.493
2025-02-27T03:33:08.543793+0300 | INFO | [134,  1000] loss: 1.492
2025-02-27T03:33:19.217850+0300 | INFO | [134,  1100] loss: 1.490
2025-02-27T03:33:30.120751+0300 | INFO | [134,  1200] loss: 1.490
2025-02-27T03:33:42.473478+0300 | INFO | [134,  1300] loss: 1.489
2025-02-27T03:33:57.600895+0300 | INFO | [134,  1400] loss: 1.482
2025-02-27T03:34:07.924583+0300 | INFO | [134,  1500] loss: 1.493
2025-02-27T03:34:18.760338+0300 | INFO | [134,  1600] loss: 1.495
2025-02-27T03:34:29.557510+0300 | INFO | [134,  1700] loss: 1.497
2025-02-27T03:34:41.400165+0300 | INFO | [134,  1800] loss: 1.490
2025-02-27T03:34:51.616215+0300 | INFO | [134,  1900] loss: 1.487
2025-02-27T03:35:02.889555+0300 | INFO | [134,  2000] loss: 1.494
2025-02-27T03:35:13.134284+0300 | INFO | [134,  2100] loss: 1.488
2025-02-27T03:35:24.299076+0300 | INFO | [134,  2200] loss: 1.489
2025-02-27T03:35:35.270254+0300 | INFO | [134,  2300] loss: 1.496
2025-02-27T03:35:46.113710+0300 | INFO | [134,  2400] loss: 1.493
2025-02-27T03:35:57.188507+0300 | INFO | [134,  2500] loss: 1.496
2025-02-27T03:36:08.390398+0300 | INFO | [134,  2600] loss: 1.493
2025-02-27T03:36:19.035323+0300 | INFO | [134,  2700] loss: 1.494
2025-02-27T03:36:29.402462+0300 | INFO | [134,  2800] loss: 1.491
2025-02-27T03:36:40.274762+0300 | INFO | [134,  2900] loss: 1.496
2025-02-27T03:36:52.764342+0300 | INFO | [134,  3000] loss: 1.489
2025-02-27T03:37:03.638375+0300 | INFO | [134,  3100] loss: 1.496
2025-02-27T03:37:14.572530+0300 | INFO | [134,  3200] loss: 1.492
2025-02-27T03:37:25.389525+0300 | INFO | [134,  3300] loss: 1.497
2025-02-27T03:37:35.544092+0300 | INFO | [134,  3400] loss: 1.491
2025-02-27T03:37:48.335097+0300 | INFO | [134,  3500] loss: 1.502
2025-02-27T03:38:00.473682+0300 | INFO | [134,  3600] loss: 1.489
2025-02-27T03:38:12.330259+0300 | INFO | [134,  3700] loss: 1.493
2025-02-27T03:38:24.576539+0300 | INFO | [134,  3800] loss: 1.493
2025-02-27T03:38:35.351131+0300 | INFO | [134,  3900] loss: 1.494
2025-02-27T03:38:47.156736+0300 | INFO | [134,  4000] loss: 1.494
2025-02-27T03:38:58.774071+0300 | INFO | [134,  4100] loss: 1.501
2025-02-27T03:39:09.661152+0300 | INFO | [134,  4200] loss: 1.492
2025-02-27T03:39:20.994503+0300 | INFO | [134,  4300] loss: 1.491
2025-02-27T03:39:33.073633+0300 | INFO | [134,  4400] loss: 1.497
2025-02-27T03:39:44.036445+0300 | INFO | [134,  4500] loss: 1.495
2025-02-27T03:39:55.580125+0300 | INFO | [134,  4600] loss: 1.492
2025-02-27T03:40:06.600368+0300 | INFO | [134,  4700] loss: 1.501
2025-02-27T03:40:16.733882+0300 | INFO | [134,  4800] loss: 1.482
2025-02-27T03:40:27.818168+0300 | INFO | [134,  4900] loss: 1.494
2025-02-27T03:40:38.569676+0300 | DEBUG | Saving model to flat file storage. Save #134
2025-02-27T03:40:38.593315+0300 | INFO | Averaging client parameters
2025-02-27T03:40:38.601179+0300 | INFO | Updating parameters on client #0
2025-02-27T03:40:54.401392+0300 | DEBUG | Test set: Accuracy: 7863/10000 (79%)
2025-02-27T03:40:54.404389+0300 | DEBUG | Test set: Loss: 1.6728246212005615
2025-02-27T03:40:54.511789+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.81      1000
           1       0.90      0.91      0.91      1000
           2       0.74      0.71      0.72      1000
           3       0.66      0.57      0.61      1200
           4       0.76      0.81      0.78      1000
           5       0.53      0.59      0.56       800
           6       0.84      0.85      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:40:54.513795+0300 | DEBUG | Confusion Matrix:
[[818  18  40  11  16  10   5  15  35  32]
 [ 10 913   2   1   1   3   6   3   9  52]
 [ 55   3 710  43  66  43  44  21   7   8]
 [ 17   3  52 680  62 272  46  41  12  15]
 [ 10   3  41  35 811  35  29  27   6   3]
 [ 14   1  43 177  34 472  12  40   2   5]
 [  9   3  43  39  22  22 849   6   4   3]
 [ 18   1  16  27  53  35   3 835   2  10]
 [ 43  23   7  12   3   2   4   1 893  12]
 [ 17  48   7   8   1   4   8   9  16 882]]
2025-02-27T03:40:54.516804+0300 | DEBUG | Class precision: [0.8090999  0.89862205 0.73881374 0.65827686 0.75865295 0.52561247
 0.84393638 0.83667335 0.90567951 0.8630137 ]
2025-02-27T03:40:54.518796+0300 | DEBUG | Class recall: [0.818      0.913      0.71       0.56666667 0.811      0.59
 0.849      0.835      0.893      0.882     ]
2025-02-27T03:40:54.572413+0300 | INFO | Training epoch #135 on client #0
2025-02-27T03:40:54.575429+0300 | DEBUG | Saving model to flat file storage. Save #135
2025-02-27T03:40:54.839145+0300 | INFO | [135,     0] loss: 0.015
2025-02-27T03:41:04.847447+0300 | INFO | [135,   100] loss: 1.488
2025-02-27T03:41:16.102568+0300 | INFO | [135,   200] loss: 1.485
2025-02-27T03:41:27.057957+0300 | INFO | [135,   300] loss: 1.502
2025-02-27T03:41:38.805817+0300 | INFO | [135,   400] loss: 1.492
2025-02-27T03:41:48.896833+0300 | INFO | [135,   500] loss: 1.494
2025-02-27T03:42:01.310286+0300 | INFO | [135,   600] loss: 1.507
2025-02-27T03:42:12.382575+0300 | INFO | [135,   700] loss: 1.485
2025-02-27T03:42:22.363681+0300 | INFO | [135,   800] loss: 1.495
2025-02-27T03:42:34.400644+0300 | INFO | [135,   900] loss: 1.492
2025-02-27T03:42:49.265737+0300 | INFO | [135,  1000] loss: 1.500
2025-02-27T03:43:00.493350+0300 | INFO | [135,  1100] loss: 1.492
2025-02-27T03:43:10.766330+0300 | INFO | [135,  1200] loss: 1.496
2025-02-27T03:43:21.834419+0300 | INFO | [135,  1300] loss: 1.490
2025-02-27T03:43:32.741960+0300 | INFO | [135,  1400] loss: 1.489
2025-02-27T03:43:42.873739+0300 | INFO | [135,  1500] loss: 1.505
2025-02-27T03:43:53.763303+0300 | INFO | [135,  1600] loss: 1.509
2025-02-27T03:44:05.035204+0300 | INFO | [135,  1700] loss: 1.499
2025-02-27T03:44:15.118176+0300 | INFO | [135,  1800] loss: 1.496
2025-02-27T03:44:26.002026+0300 | INFO | [135,  1900] loss: 1.507
2025-02-27T03:44:36.522428+0300 | INFO | [135,  2000] loss: 1.493
2025-02-27T03:44:46.614024+0300 | INFO | [135,  2100] loss: 1.498
2025-02-27T03:44:58.780365+0300 | INFO | [135,  2200] loss: 1.487
2025-02-27T03:45:09.596816+0300 | INFO | [135,  2300] loss: 1.485
2025-02-27T03:45:19.774650+0300 | INFO | [135,  2400] loss: 1.491
2025-02-27T03:45:30.801523+0300 | INFO | [135,  2500] loss: 1.483
2025-02-27T03:45:41.568503+0300 | INFO | [135,  2600] loss: 1.497
2025-02-27T03:45:51.945699+0300 | INFO | [135,  2700] loss: 1.493
2025-02-27T03:46:03.081399+0300 | INFO | [135,  2800] loss: 1.492
2025-02-27T03:46:14.241476+0300 | INFO | [135,  2900] loss: 1.501
2025-02-27T03:46:24.431561+0300 | INFO | [135,  3000] loss: 1.487
2025-02-27T03:46:35.452860+0300 | INFO | [135,  3100] loss: 1.489
2025-02-27T03:46:46.406948+0300 | INFO | [135,  3200] loss: 1.493
2025-02-27T03:46:56.932929+0300 | INFO | [135,  3300] loss: 1.492
2025-02-27T03:47:08.395571+0300 | INFO | [135,  3400] loss: 1.487
2025-02-27T03:47:19.311945+0300 | INFO | [135,  3500] loss: 1.488
2025-02-27T03:47:29.439959+0300 | INFO | [135,  3600] loss: 1.496
2025-02-27T03:47:42.195177+0300 | INFO | [135,  3700] loss: 1.488
2025-02-27T03:47:52.553762+0300 | INFO | [135,  3800] loss: 1.486
2025-02-27T03:48:04.664470+0300 | INFO | [135,  3900] loss: 1.492
2025-02-27T03:48:16.176169+0300 | INFO | [135,  4000] loss: 1.484
2025-02-27T03:48:26.184359+0300 | INFO | [135,  4100] loss: 1.490
2025-02-27T03:48:37.747977+0300 | INFO | [135,  4200] loss: 1.488
2025-02-27T03:48:48.597508+0300 | INFO | [135,  4300] loss: 1.496
2025-02-27T03:49:00.801226+0300 | INFO | [135,  4400] loss: 1.497
2025-02-27T03:49:11.600774+0300 | INFO | [135,  4500] loss: 1.487
2025-02-27T03:49:21.786471+0300 | INFO | [135,  4600] loss: 1.495
2025-02-27T03:49:32.814947+0300 | INFO | [135,  4700] loss: 1.494
2025-02-27T03:49:43.740018+0300 | INFO | [135,  4800] loss: 1.504
2025-02-27T03:49:53.568651+0300 | INFO | [135,  4900] loss: 1.493
2025-02-27T03:50:04.901080+0300 | DEBUG | Saving model to flat file storage. Save #135
2025-02-27T03:50:04.925079+0300 | INFO | Averaging client parameters
2025-02-27T03:50:04.933422+0300 | INFO | Updating parameters on client #0
2025-02-27T03:50:20.434263+0300 | DEBUG | Test set: Accuracy: 7882/10000 (79%)
2025-02-27T03:50:20.435275+0300 | DEBUG | Test set: Loss: 1.6719141006469727
2025-02-27T03:50:20.537698+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.78      0.67      0.72      1000
           3       0.67      0.55      0.61      1200
           4       0.74      0.82      0.78      1000
           5       0.51      0.63      0.56       800
           6       0.87      0.83      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:50:20.541693+0300 | DEBUG | Confusion Matrix:
[[835  17  29   8  18   9   4  10  40  30]
 [  7 931   3   1   1   0   3   2  15  37]
 [ 62   4 669  49  77  59  43  19   8  10]
 [ 21   6  39 663  67 295  32  41  17  19]
 [ 11   5  28  36 825  39  15  32   6   3]
 [ 16   3  33 158  30 505  11  37   4   3]
 [ 11   5  34  37  34  31 834   6   6   2]
 [ 15   3   9  26  52  46   2 835   3   9]
 [ 35  17   7   7   3   4   5   2 909  11]
 [ 20  53   5   5   2   7   6   9  17 876]]
2025-02-27T03:50:20.543697+0300 | DEBUG | Class precision: [0.80832527 0.89176245 0.78154206 0.66969697 0.74391344 0.50753769
 0.87329843 0.8408862  0.88682927 0.876     ]
2025-02-27T03:50:20.545699+0300 | DEBUG | Class recall: [0.835   0.931   0.669   0.5525  0.825   0.63125 0.834   0.835   0.909
 0.876  ]
2025-02-27T03:50:20.605894+0300 | INFO | Training epoch #136 on client #0
2025-02-27T03:50:20.608895+0300 | DEBUG | Saving model to flat file storage. Save #136
2025-02-27T03:50:20.861655+0300 | INFO | [136,     0] loss: 0.015
2025-02-27T03:50:31.850360+0300 | INFO | [136,   100] loss: 1.496
2025-02-27T03:50:41.932248+0300 | INFO | [136,   200] loss: 1.491
2025-02-27T03:50:52.417041+0300 | INFO | [136,   300] loss: 1.504
2025-02-27T03:51:06.067671+0300 | INFO | [136,   400] loss: 1.491
2025-02-27T03:51:20.963593+0300 | INFO | [136,   500] loss: 1.498
2025-02-27T03:51:32.090586+0300 | INFO | [136,   600] loss: 1.499
2025-02-27T03:51:42.194343+0300 | INFO | [136,   700] loss: 1.493
2025-02-27T03:51:52.963522+0300 | INFO | [136,   800] loss: 1.501
2025-02-27T03:52:04.373346+0300 | INFO | [136,   900] loss: 1.491
2025-02-27T03:52:14.739506+0300 | INFO | [136,  1000] loss: 1.488
2025-02-27T03:52:25.691395+0300 | INFO | [136,  1100] loss: 1.490
2025-02-27T03:52:37.088405+0300 | INFO | [136,  1200] loss: 1.491
2025-02-27T03:52:47.081025+0300 | INFO | [136,  1300] loss: 1.489
2025-02-27T03:52:58.347578+0300 | INFO | [136,  1400] loss: 1.504
2025-02-27T03:53:09.297993+0300 | INFO | [136,  1500] loss: 1.490
2025-02-27T03:53:19.539134+0300 | INFO | [136,  1600] loss: 1.485
2025-02-27T03:53:30.384372+0300 | INFO | [136,  1700] loss: 1.487
2025-02-27T03:53:41.072046+0300 | INFO | [136,  1800] loss: 1.493
2025-02-27T03:53:51.381736+0300 | INFO | [136,  1900] loss: 1.491
2025-02-27T03:54:02.830636+0300 | INFO | [136,  2000] loss: 1.486
2025-02-27T03:54:14.580204+0300 | INFO | [136,  2100] loss: 1.492
2025-02-27T03:54:24.539829+0300 | INFO | [136,  2200] loss: 1.497
2025-02-27T03:54:35.694756+0300 | INFO | [136,  2300] loss: 1.497
2025-02-27T03:54:46.961607+0300 | INFO | [136,  2400] loss: 1.485
2025-02-27T03:54:57.151391+0300 | INFO | [136,  2500] loss: 1.490
2025-02-27T03:55:07.993133+0300 | INFO | [136,  2600] loss: 1.493
2025-02-27T03:55:19.004572+0300 | INFO | [136,  2700] loss: 1.481
2025-02-27T03:55:29.277276+0300 | INFO | [136,  2800] loss: 1.492
2025-02-27T03:55:39.916812+0300 | INFO | [136,  2900] loss: 1.497
2025-02-27T03:55:50.761189+0300 | INFO | [136,  3000] loss: 1.489
2025-02-27T03:56:01.264966+0300 | INFO | [136,  3100] loss: 1.488
2025-02-27T03:56:12.209008+0300 | INFO | [136,  3200] loss: 1.498
2025-02-27T03:56:22.941451+0300 | INFO | [136,  3300] loss: 1.496
2025-02-27T03:56:33.053363+0300 | INFO | [136,  3400] loss: 1.490
2025-02-27T03:56:43.867986+0300 | INFO | [136,  3500] loss: 1.489
2025-02-27T03:56:54.847936+0300 | INFO | [136,  3600] loss: 1.484
2025-02-27T03:57:06.469407+0300 | INFO | [136,  3700] loss: 1.490
2025-02-27T03:57:17.678988+0300 | INFO | [136,  3800] loss: 1.492
2025-02-27T03:57:28.580079+0300 | INFO | [136,  3900] loss: 1.498
2025-02-27T03:57:39.462375+0300 | INFO | [136,  4000] loss: 1.487
2025-02-27T03:57:49.624137+0300 | INFO | [136,  4100] loss: 1.492
2025-02-27T03:58:00.895108+0300 | INFO | [136,  4200] loss: 1.488
2025-02-27T03:58:12.024326+0300 | INFO | [136,  4300] loss: 1.495
2025-02-27T03:58:22.268951+0300 | INFO | [136,  4400] loss: 1.492
2025-02-27T03:58:32.858886+0300 | INFO | [136,  4500] loss: 1.495
2025-02-27T03:58:43.762235+0300 | INFO | [136,  4600] loss: 1.504
2025-02-27T03:58:53.642526+0300 | INFO | [136,  4700] loss: 1.497
2025-02-27T03:59:04.794789+0300 | INFO | [136,  4800] loss: 1.492
2025-02-27T03:59:15.797843+0300 | INFO | [136,  4900] loss: 1.502
2025-02-27T03:59:27.682522+0300 | DEBUG | Saving model to flat file storage. Save #136
2025-02-27T03:59:27.698521+0300 | INFO | Averaging client parameters
2025-02-27T03:59:27.708515+0300 | INFO | Updating parameters on client #0
2025-02-27T03:59:47.280744+0300 | DEBUG | Test set: Accuracy: 7876/10000 (79%)
2025-02-27T03:59:47.286740+0300 | DEBUG | Test set: Loss: 1.6730116605758667
2025-02-27T03:59:47.421894+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82      1000
           1       0.91      0.91      0.91      1000
           2       0.77      0.70      0.73      1000
           3       0.64      0.59      0.62      1200
           4       0.75      0.82      0.78      1000
           5       0.52      0.59      0.55       800
           6       0.83      0.86      0.84      1000
           7       0.85      0.82      0.84      1000
           8       0.91      0.89      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T03:59:47.423898+0300 | DEBUG | Confusion Matrix:
[[823  16  43  14  20  11   6   9  33  25]
 [ 14 907   2   1   0   4   6   2  15  49]
 [ 51   4 702  52  72  45  50  18   1   5]
 [ 10   3  45 712  64 264  47  34  10  11]
 [  8   2  30  43 816  35  31  25   6   4]
 [ 12   0  37 188  34 470  17  36   3   3]
 [  8   2  32  47  21  17 863   6   3   1]
 [ 18   3  12  31  56  51   3 819   1   6]
 [ 45  18   7  12   4   5   6   2 888  13]
 [ 24  41   5   6   2   6  14  10  16 876]]
2025-02-27T03:59:47.424887+0300 | DEBUG | Class precision: [0.8124383  0.91064257 0.76721311 0.6437613  0.74931129 0.51762115
 0.8274209  0.85223725 0.90983607 0.88217523]
2025-02-27T03:59:47.426889+0300 | DEBUG | Class recall: [0.823      0.907      0.702      0.59333333 0.816      0.5875
 0.863      0.819      0.888      0.876     ]
2025-02-27T03:59:47.428895+0300 | INFO | Training epoch #137 on client #0
2025-02-27T03:59:47.429904+0300 | DEBUG | Saving model to flat file storage. Save #137
2025-02-27T03:59:47.602084+0300 | INFO | [137,     0] loss: 0.017
2025-02-27T03:59:58.136996+0300 | INFO | [137,   100] loss: 1.496
2025-02-27T04:00:09.465591+0300 | INFO | [137,   200] loss: 1.492
2025-02-27T04:00:24.034483+0300 | INFO | [137,   300] loss: 1.493
2025-02-27T04:00:33.669726+0300 | INFO | [137,   400] loss: 1.500
2025-02-27T04:00:44.563038+0300 | INFO | [137,   500] loss: 1.493
2025-02-27T04:00:55.175516+0300 | INFO | [137,   600] loss: 1.487
2025-02-27T04:01:05.591378+0300 | INFO | [137,   700] loss: 1.486
2025-02-27T04:01:16.501119+0300 | INFO | [137,   800] loss: 1.497
2025-02-27T04:01:27.155971+0300 | INFO | [137,   900] loss: 1.501
2025-02-27T04:01:37.464549+0300 | INFO | [137,  1000] loss: 1.485
2025-02-27T04:01:48.854843+0300 | INFO | [137,  1100] loss: 1.492
2025-02-27T04:02:01.297585+0300 | INFO | [137,  1200] loss: 1.495
2025-02-27T04:02:12.656568+0300 | INFO | [137,  1300] loss: 1.488
2025-02-27T04:02:22.966467+0300 | INFO | [137,  1400] loss: 1.487
2025-02-27T04:02:34.271610+0300 | INFO | [137,  1500] loss: 1.493
2025-02-27T04:02:45.164216+0300 | INFO | [137,  1600] loss: 1.492
2025-02-27T04:02:55.061928+0300 | INFO | [137,  1700] loss: 1.495
2025-02-27T04:03:06.353437+0300 | INFO | [137,  1800] loss: 1.488
2025-02-27T04:03:19.860977+0300 | INFO | [137,  1900] loss: 1.494
2025-02-27T04:03:30.630813+0300 | INFO | [137,  2000] loss: 1.494
2025-02-27T04:03:41.066809+0300 | INFO | [137,  2100] loss: 1.490
2025-02-27T04:03:52.548640+0300 | INFO | [137,  2200] loss: 1.498
2025-02-27T04:04:03.966227+0300 | INFO | [137,  2300] loss: 1.490
2025-02-27T04:04:14.071148+0300 | INFO | [137,  2400] loss: 1.493
2025-02-27T04:04:25.051080+0300 | INFO | [137,  2500] loss: 1.499
2025-02-27T04:04:35.901366+0300 | INFO | [137,  2600] loss: 1.495
2025-02-27T04:04:46.420992+0300 | INFO | [137,  2700] loss: 1.508
2025-02-27T04:04:57.222106+0300 | INFO | [137,  2800] loss: 1.490
2025-02-27T04:05:08.445911+0300 | INFO | [137,  2900] loss: 1.490
2025-02-27T04:05:18.908126+0300 | INFO | [137,  3000] loss: 1.492
2025-02-27T04:05:30.964101+0300 | INFO | [137,  3100] loss: 1.493
2025-02-27T04:05:42.334040+0300 | INFO | [137,  3200] loss: 1.499
2025-02-27T04:05:52.638485+0300 | INFO | [137,  3300] loss: 1.491
2025-02-27T04:06:05.162637+0300 | INFO | [137,  3400] loss: 1.489
2025-02-27T04:06:17.093319+0300 | INFO | [137,  3500] loss: 1.492
2025-02-27T04:06:29.868031+0300 | INFO | [137,  3600] loss: 1.488
2025-02-27T04:06:41.778661+0300 | INFO | [137,  3700] loss: 1.489
2025-02-27T04:06:53.850345+0300 | INFO | [137,  3800] loss: 1.494
2025-02-27T04:07:06.324468+0300 | INFO | [137,  3900] loss: 1.492
2025-02-27T04:07:18.177163+0300 | INFO | [137,  4000] loss: 1.494
2025-02-27T04:07:29.036127+0300 | INFO | [137,  4100] loss: 1.494
2025-02-27T04:07:40.820095+0300 | INFO | [137,  4200] loss: 1.497
2025-02-27T04:07:52.668611+0300 | INFO | [137,  4300] loss: 1.495
2025-02-27T04:08:05.281971+0300 | INFO | [137,  4400] loss: 1.501
2025-02-27T04:08:16.741351+0300 | INFO | [137,  4500] loss: 1.491
2025-02-27T04:08:33.316709+0300 | INFO | [137,  4600] loss: 1.488
2025-02-27T04:08:47.375073+0300 | INFO | [137,  4700] loss: 1.497
2025-02-27T04:08:59.276922+0300 | INFO | [137,  4800] loss: 1.495
2025-02-27T04:09:11.731739+0300 | INFO | [137,  4900] loss: 1.495
2025-02-27T04:09:23.742844+0300 | DEBUG | Saving model to flat file storage. Save #137
2025-02-27T04:09:23.774772+0300 | INFO | Averaging client parameters
2025-02-27T04:09:23.789924+0300 | INFO | Updating parameters on client #0
2025-02-27T04:09:41.044501+0300 | DEBUG | Test set: Accuracy: 7875/10000 (79%)
2025-02-27T04:09:41.046878+0300 | DEBUG | Test set: Loss: 1.6732077598571777
2025-02-27T04:09:41.149143+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.80      0.66      0.72      1000
           3       0.66      0.58      0.61      1200
           4       0.80      0.77      0.79      1000
           5       0.49      0.65      0.55       800
           6       0.83      0.87      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.90      0.91      0.90      1000
           9       0.84      0.90      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T04:09:41.152180+0300 | DEBUG | Confusion Matrix:
[[819  15  32  11   9  11   4  10  44  45]
 [  7 924   1   0   0   3   5   0  10  50]
 [ 63   5 659  52  56  73  60  15   8   9]
 [ 17   6  35 692  49 295  43  27  13  23]
 [ 13   6  30  47 772  56  36  29   6   5]
 [ 14   4  29 158  23 516  13  33   4   6]
 [  7   3  20  45  12  30 874   4   3   2]
 [ 15   5  10  32  40  68   5 813   1  11]
 [ 28  19   6   9   3   4   5   1 909  16]
 [ 16  43   5   6   1   6   7   5  14 897]]
2025-02-27T04:09:41.153707+0300 | DEBUG | Class precision: [0.81981982 0.89708738 0.79685611 0.65779468 0.8        0.48587571
 0.83079848 0.86766275 0.89822134 0.84304511]
2025-02-27T04:09:41.155708+0300 | DEBUG | Class recall: [0.819      0.924      0.659      0.57666667 0.772      0.645
 0.874      0.813      0.909      0.897     ]
2025-02-27T04:09:41.203979+0300 | INFO | Training epoch #138 on client #0
2025-02-27T04:09:41.206068+0300 | DEBUG | Saving model to flat file storage. Save #138
2025-02-27T04:09:41.411202+0300 | INFO | [138,     0] loss: 0.015
2025-02-27T04:09:53.018970+0300 | INFO | [138,   100] loss: 1.493
2025-02-27T04:10:05.277145+0300 | INFO | [138,   200] loss: 1.492
2025-02-27T04:10:17.090290+0300 | INFO | [138,   300] loss: 1.487
2025-02-27T04:10:28.874348+0300 | INFO | [138,   400] loss: 1.492
2025-02-27T04:10:39.515303+0300 | INFO | [138,   500] loss: 1.494
2025-02-27T04:10:51.575408+0300 | INFO | [138,   600] loss: 1.485
2025-02-27T04:11:03.704588+0300 | INFO | [138,   700] loss: 1.492
2025-02-27T04:11:13.682878+0300 | INFO | [138,   800] loss: 1.484
2025-02-27T04:11:24.786868+0300 | INFO | [138,   900] loss: 1.494
2025-02-27T04:11:35.870173+0300 | INFO | [138,  1000] loss: 1.483
2025-02-27T04:11:46.248369+0300 | INFO | [138,  1100] loss: 1.495
2025-02-27T04:11:57.112840+0300 | INFO | [138,  1200] loss: 1.496
2025-02-27T04:12:08.413289+0300 | INFO | [138,  1300] loss: 1.492
2025-02-27T04:12:19.764355+0300 | INFO | [138,  1400] loss: 1.488
2025-02-27T04:12:29.892698+0300 | INFO | [138,  1500] loss: 1.490
2025-02-27T04:12:40.925594+0300 | INFO | [138,  1600] loss: 1.492
2025-02-27T04:12:52.256225+0300 | INFO | [138,  1700] loss: 1.493
2025-02-27T04:13:03.705707+0300 | INFO | [138,  1800] loss: 1.487
2025-02-27T04:13:15.498992+0300 | INFO | [138,  1900] loss: 1.486
2025-02-27T04:13:26.739433+0300 | INFO | [138,  2000] loss: 1.492
2025-02-27T04:13:37.101002+0300 | INFO | [138,  2100] loss: 1.496
2025-02-27T04:13:48.320865+0300 | INFO | [138,  2200] loss: 1.488
2025-02-27T04:13:59.325356+0300 | INFO | [138,  2300] loss: 1.495
2025-02-27T04:14:10.005531+0300 | INFO | [138,  2400] loss: 1.489
2025-02-27T04:14:20.980965+0300 | INFO | [138,  2500] loss: 1.490
2025-02-27T04:14:32.281633+0300 | INFO | [138,  2600] loss: 1.493
2025-02-27T04:14:43.219910+0300 | INFO | [138,  2700] loss: 1.496
2025-02-27T04:14:53.733692+0300 | INFO | [138,  2800] loss: 1.492
2025-02-27T04:15:05.832524+0300 | INFO | [138,  2900] loss: 1.492
2025-02-27T04:15:16.695548+0300 | INFO | [138,  3000] loss: 1.499
2025-02-27T04:15:28.020647+0300 | INFO | [138,  3100] loss: 1.489
2025-02-27T04:15:40.612898+0300 | INFO | [138,  3200] loss: 1.487
2025-02-27T04:15:51.750725+0300 | INFO | [138,  3300] loss: 1.501
2025-02-27T04:16:03.679163+0300 | INFO | [138,  3400] loss: 1.501
2025-02-27T04:16:13.850868+0300 | INFO | [138,  3500] loss: 1.491
2025-02-27T04:16:24.779169+0300 | INFO | [138,  3600] loss: 1.499
2025-02-27T04:16:35.752925+0300 | INFO | [138,  3700] loss: 1.490
2025-02-27T04:16:45.707614+0300 | INFO | [138,  3800] loss: 1.495
2025-02-27T04:16:58.345652+0300 | INFO | [138,  3900] loss: 1.495
2025-02-27T04:17:09.094076+0300 | INFO | [138,  4000] loss: 1.497
2025-02-27T04:17:19.707500+0300 | INFO | [138,  4100] loss: 1.500
2025-02-27T04:17:35.595736+0300 | INFO | [138,  4200] loss: 1.487
2025-02-27T04:17:46.959647+0300 | INFO | [138,  4300] loss: 1.496
2025-02-27T04:17:58.607507+0300 | INFO | [138,  4400] loss: 1.496
2025-02-27T04:18:08.689435+0300 | INFO | [138,  4500] loss: 1.493
2025-02-27T04:18:19.598479+0300 | INFO | [138,  4600] loss: 1.494
2025-02-27T04:18:30.398296+0300 | INFO | [138,  4700] loss: 1.494
2025-02-27T04:18:41.038019+0300 | INFO | [138,  4800] loss: 1.494
2025-02-27T04:18:52.114431+0300 | INFO | [138,  4900] loss: 1.491
2025-02-27T04:19:03.841461+0300 | DEBUG | Saving model to flat file storage. Save #138
2025-02-27T04:19:03.866455+0300 | INFO | Averaging client parameters
2025-02-27T04:19:03.873462+0300 | INFO | Updating parameters on client #0
2025-02-27T04:19:19.435262+0300 | DEBUG | Test set: Accuracy: 7915/10000 (79%)
2025-02-27T04:19:19.436259+0300 | DEBUG | Test set: Loss: 1.6689667701721191
2025-02-27T04:19:19.534129+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.74      0.71      0.73      1000
           3       0.70      0.54      0.61      1200
           4       0.77      0.80      0.79      1000
           5       0.55      0.61      0.58       800
           6       0.84      0.87      0.86      1000
           7       0.83      0.85      0.84      1000
           8       0.89      0.88      0.89      1000
           9       0.86      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T04:19:19.536548+0300 | DEBUG | Confusion Matrix:
[[841  15  35   7  11   9   4  12  36  30]
 [  8 919   2   0   0   0   4   2  14  51]
 [ 61   4 714  31  67  38  50  21   6   8]
 [ 20   8  60 653  65 262  48  47  18  19]
 [ 12   5  45  33 801  33  24  36   6   5]
 [ 14   4  44 147  34 487  16  44   6   4]
 [  8   1  37  29  16  20 874   7   6   2]
 [ 16   3  17  17  40  36   6 855   2   8]
 [ 48  24   6   7   4   3   5   2 884  17]
 [ 24  37   8   5   2   3  11   9  14 887]]
2025-02-27T04:19:19.537548+0300 | DEBUG | Class precision: [0.79942966 0.90098039 0.73760331 0.70290635 0.77019231 0.54657688
 0.83877159 0.82608696 0.89112903 0.86032978]
2025-02-27T04:19:19.539552+0300 | DEBUG | Class recall: [0.841      0.919      0.714      0.54416667 0.801      0.60875
 0.874      0.855      0.884      0.887     ]
2025-02-27T04:19:19.585901+0300 | INFO | Training epoch #139 on client #0
2025-02-27T04:19:19.586901+0300 | DEBUG | Saving model to flat file storage. Save #139
2025-02-27T04:19:19.793715+0300 | INFO | [139,     0] loss: 0.016
2025-02-27T04:19:31.723088+0300 | INFO | [139,   100] loss: 1.493
2025-02-27T04:19:41.861941+0300 | INFO | [139,   200] loss: 1.489
2025-02-27T04:19:53.215588+0300 | INFO | [139,   300] loss: 1.493
2025-02-27T04:20:06.990042+0300 | INFO | [139,   400] loss: 1.491
2025-02-27T04:20:16.695997+0300 | INFO | [139,   500] loss: 1.493
2025-02-27T04:20:28.500875+0300 | INFO | [139,   600] loss: 1.495
2025-02-27T04:20:39.600614+0300 | INFO | [139,   700] loss: 1.484
2025-02-27T04:20:49.766581+0300 | INFO | [139,   800] loss: 1.495
2025-02-27T04:21:00.882501+0300 | INFO | [139,   900] loss: 1.494
2025-02-27T04:21:11.945590+0300 | INFO | [139,  1000] loss: 1.492
2025-02-27T04:21:23.038411+0300 | INFO | [139,  1100] loss: 1.505
2025-02-27T04:21:33.483358+0300 | INFO | [139,  1200] loss: 1.486
2025-02-27T04:21:44.603192+0300 | INFO | [139,  1300] loss: 1.487
2025-02-27T04:21:56.107130+0300 | INFO | [139,  1400] loss: 1.496
2025-02-27T04:22:06.963822+0300 | INFO | [139,  1500] loss: 1.500
2025-02-27T04:22:19.520838+0300 | INFO | [139,  1600] loss: 1.491
2025-02-27T04:22:30.457814+0300 | INFO | [139,  1700] loss: 1.493
2025-02-27T04:22:40.730339+0300 | INFO | [139,  1800] loss: 1.490
2025-02-27T04:22:52.156743+0300 | INFO | [139,  1900] loss: 1.494
2025-02-27T04:23:03.441945+0300 | INFO | [139,  2000] loss: 1.500
2025-02-27T04:23:13.625401+0300 | INFO | [139,  2100] loss: 1.494
2025-02-27T04:23:24.926371+0300 | INFO | [139,  2200] loss: 1.478
2025-02-27T04:23:36.944847+0300 | INFO | [139,  2300] loss: 1.496
2025-02-27T04:23:47.480248+0300 | INFO | [139,  2400] loss: 1.487
2025-02-27T04:23:57.653455+0300 | INFO | [139,  2500] loss: 1.491
2025-02-27T04:24:09.149286+0300 | INFO | [139,  2600] loss: 1.497
2025-02-27T04:24:20.761416+0300 | INFO | [139,  2700] loss: 1.494
2025-02-27T04:24:32.730097+0300 | INFO | [139,  2800] loss: 1.494
2025-02-27T04:24:44.504919+0300 | INFO | [139,  2900] loss: 1.492
2025-02-27T04:24:56.206102+0300 | INFO | [139,  3000] loss: 1.496
2025-02-27T04:25:08.424032+0300 | INFO | [139,  3100] loss: 1.492
2025-02-27T04:25:20.138158+0300 | INFO | [139,  3200] loss: 1.496
2025-02-27T04:25:32.495930+0300 | INFO | [139,  3300] loss: 1.486
2025-02-27T04:25:45.220879+0300 | INFO | [139,  3400] loss: 1.495
2025-02-27T04:25:57.391727+0300 | INFO | [139,  3500] loss: 1.492
2025-02-27T04:26:09.004118+0300 | INFO | [139,  3600] loss: 1.495
2025-02-27T04:26:20.866400+0300 | INFO | [139,  3700] loss: 1.494
2025-02-27T04:26:36.067475+0300 | INFO | [139,  3800] loss: 1.490
2025-02-27T04:26:52.141059+0300 | INFO | [139,  3900] loss: 1.498
2025-02-27T04:27:04.172818+0300 | INFO | [139,  4000] loss: 1.498
2025-02-27T04:27:16.403691+0300 | INFO | [139,  4100] loss: 1.487
2025-02-27T04:27:27.602996+0300 | INFO | [139,  4200] loss: 1.496
2025-02-27T04:27:39.553767+0300 | INFO | [139,  4300] loss: 1.488
2025-02-27T04:27:51.189891+0300 | INFO | [139,  4400] loss: 1.493
2025-02-27T04:28:02.986883+0300 | INFO | [139,  4500] loss: 1.483
2025-02-27T04:28:13.486740+0300 | INFO | [139,  4600] loss: 1.498
2025-02-27T04:28:24.942089+0300 | INFO | [139,  4700] loss: 1.491
2025-02-27T04:28:36.471226+0300 | INFO | [139,  4800] loss: 1.486
2025-02-27T04:28:46.561410+0300 | INFO | [139,  4900] loss: 1.498
2025-02-27T04:28:57.548679+0300 | DEBUG | Saving model to flat file storage. Save #139
2025-02-27T04:28:57.567512+0300 | INFO | Averaging client parameters
2025-02-27T04:28:57.577076+0300 | INFO | Updating parameters on client #0
2025-02-27T04:29:13.422617+0300 | DEBUG | Test set: Accuracy: 7880/10000 (79%)
2025-02-27T04:29:13.423612+0300 | DEBUG | Test set: Loss: 1.672650933265686
2025-02-27T04:29:13.523676+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.88      0.93      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.68      0.52      0.59      1200
           4       0.79      0.79      0.79      1000
           5       0.50      0.63      0.56       800
           6       0.84      0.86      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T04:29:13.525685+0300 | DEBUG | Confusion Matrix:
[[848  17  27   9   9   9   4  10  38  29]
 [  9 934   3   0   0   2   2   3   9  38]
 [ 62   5 711  37  54  46  49  20   9   7]
 [ 25  10  52 626  52 314  46  42  14  19]
 [ 14   5  45  31 789  48  30  29   5   4]
 [ 17   4  41 148  28 504  12  38   4   4]
 [ 10   5  37  30  14  29 860   6   6   3]
 [ 20   3  16  21  45  50   4 833   1   7]
 [ 40  27   7   8   1   4   4   2 894  13]
 [ 19  52   6   4   1   3   9   9  16 881]]
2025-02-27T04:29:13.526690+0300 | DEBUG | Class precision: [0.79699248 0.87947269 0.75238095 0.68490153 0.79456193 0.49950446
 0.84313725 0.83971774 0.89759036 0.87661692]
2025-02-27T04:29:13.527689+0300 | DEBUG | Class recall: [0.848      0.934      0.711      0.52166667 0.789      0.63
 0.86       0.833      0.894      0.881     ]
2025-02-27T04:29:13.569402+0300 | INFO | Training epoch #140 on client #0
2025-02-27T04:29:13.570874+0300 | DEBUG | Saving model to flat file storage. Save #140
2025-02-27T04:29:13.800933+0300 | INFO | [140,     0] loss: 0.015
2025-02-27T04:29:25.128363+0300 | INFO | [140,   100] loss: 1.497
2025-02-27T04:29:35.471453+0300 | INFO | [140,   200] loss: 1.497
2025-02-27T04:29:46.385204+0300 | INFO | [140,   300] loss: 1.496
2025-02-27T04:29:58.139216+0300 | INFO | [140,   400] loss: 1.486
2025-02-27T04:30:10.797557+0300 | INFO | [140,   500] loss: 1.495
2025-02-27T04:30:21.426025+0300 | INFO | [140,   600] loss: 1.485
2025-02-27T04:30:32.398915+0300 | INFO | [140,   700] loss: 1.499
2025-02-27T04:30:43.322855+0300 | INFO | [140,   800] loss: 1.498
2025-02-27T04:30:53.351108+0300 | INFO | [140,   900] loss: 1.490
2025-02-27T04:31:04.765657+0300 | INFO | [140,  1000] loss: 1.492
2025-02-27T04:31:15.911006+0300 | INFO | [140,  1100] loss: 1.496
2025-02-27T04:31:26.322917+0300 | INFO | [140,  1200] loss: 1.497
2025-02-27T04:31:37.715117+0300 | INFO | [140,  1300] loss: 1.485
2025-02-27T04:31:49.483326+0300 | INFO | [140,  1400] loss: 1.497
2025-02-27T04:32:01.604554+0300 | INFO | [140,  1500] loss: 1.490
2025-02-27T04:32:12.894414+0300 | INFO | [140,  1600] loss: 1.495
2025-02-27T04:32:23.779875+0300 | INFO | [140,  1700] loss: 1.492
2025-02-27T04:32:34.226432+0300 | INFO | [140,  1800] loss: 1.492
2025-02-27T04:32:44.897030+0300 | INFO | [140,  1900] loss: 1.489
2025-02-27T04:32:56.215995+0300 | INFO | [140,  2000] loss: 1.495
2025-02-27T04:33:07.325045+0300 | INFO | [140,  2100] loss: 1.499
2025-02-27T04:33:17.787258+0300 | INFO | [140,  2200] loss: 1.494
2025-02-27T04:33:28.818219+0300 | INFO | [140,  2300] loss: 1.484
2025-02-27T04:33:39.681315+0300 | INFO | [140,  2400] loss: 1.490
2025-02-27T04:33:51.095233+0300 | INFO | [140,  2500] loss: 1.488
2025-02-27T04:34:02.310784+0300 | INFO | [140,  2600] loss: 1.499
2025-02-27T04:34:13.412631+0300 | INFO | [140,  2700] loss: 1.494
2025-02-27T04:34:23.337130+0300 | INFO | [140,  2800] loss: 1.481
2025-02-27T04:34:34.071012+0300 | INFO | [140,  2900] loss: 1.492
2025-02-27T04:34:45.693916+0300 | INFO | [140,  3000] loss: 1.488
2025-02-27T04:34:55.709247+0300 | INFO | [140,  3100] loss: 1.489
2025-02-27T04:35:06.899069+0300 | INFO | [140,  3200] loss: 1.490
2025-02-27T04:35:17.956857+0300 | INFO | [140,  3300] loss: 1.487
2025-02-27T04:35:28.231615+0300 | INFO | [140,  3400] loss: 1.491
2025-02-27T04:35:41.353206+0300 | INFO | [140,  3500] loss: 1.500
2025-02-27T04:35:54.583114+0300 | INFO | [140,  3600] loss: 1.493
2025-02-27T04:36:05.781840+0300 | INFO | [140,  3700] loss: 1.485
2025-02-27T04:36:16.024044+0300 | INFO | [140,  3800] loss: 1.488
2025-02-27T04:36:27.208599+0300 | INFO | [140,  3900] loss: 1.491
2025-02-27T04:36:37.872286+0300 | INFO | [140,  4000] loss: 1.503
2025-02-27T04:36:50.209978+0300 | INFO | [140,  4100] loss: 1.494
2025-02-27T04:37:01.959385+0300 | INFO | [140,  4200] loss: 1.482
2025-02-27T04:37:12.993333+0300 | INFO | [140,  4300] loss: 1.494
2025-02-27T04:37:23.797007+0300 | INFO | [140,  4400] loss: 1.497
2025-02-27T04:37:34.083359+0300 | INFO | [140,  4500] loss: 1.488
2025-02-27T04:37:45.033071+0300 | INFO | [140,  4600] loss: 1.499
2025-02-27T04:37:59.159637+0300 | INFO | [140,  4700] loss: 1.494
2025-02-27T04:38:10.651612+0300 | INFO | [140,  4800] loss: 1.481
2025-02-27T04:38:21.741268+0300 | INFO | [140,  4900] loss: 1.496
2025-02-27T04:38:33.026804+0300 | DEBUG | Saving model to flat file storage. Save #140
2025-02-27T04:38:33.050993+0300 | INFO | Averaging client parameters
2025-02-27T04:38:33.061355+0300 | INFO | Updating parameters on client #0
2025-02-27T04:38:49.029889+0300 | DEBUG | Test set: Accuracy: 7894/10000 (79%)
2025-02-27T04:38:49.031882+0300 | DEBUG | Test set: Loss: 1.6711655855178833
2025-02-27T04:38:49.136432+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.88      0.94      0.91      1000
           2       0.81      0.65      0.72      1000
           3       0.68      0.56      0.61      1200
           4       0.79      0.79      0.79      1000
           5       0.51      0.65      0.57       800
           6       0.82      0.88      0.85      1000
           7       0.83      0.85      0.84      1000
           8       0.90      0.89      0.90      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T04:38:49.138430+0300 | DEBUG | Confusion Matrix:
[[843  20  23  10   9  12   6  11  36  30]
 [ 10 935   1   0   1   1   3   2   9  38]
 [ 69   4 650  47  66  65  60  24   7   8]
 [ 17   8  33 673  50 298  52  41  14  14]
 [  9   7  30  47 787  42  38  33   5   2]
 [ 16   3  29 146  27 518  12  42   4   3]
 [  7   5  21  36  16  24 877   6   6   2]
 [ 14   3   8  22  40  50   6 847   2   8]
 [ 43  21   5   9   2   3   4   3 894  16]
 [ 22  57   5   5   1   4  12  10  14 870]]
2025-02-27T04:38:49.140432+0300 | DEBUG | Class precision: [0.80285714 0.87958608 0.80745342 0.67638191 0.78778779 0.5093412
 0.81962617 0.83120707 0.90211907 0.87790111]
2025-02-27T04:38:49.141438+0300 | DEBUG | Class recall: [0.843      0.935      0.65       0.56083333 0.787      0.6475
 0.877      0.847      0.894      0.87      ]
2025-02-27T04:38:49.194932+0300 | INFO | Training epoch #141 on client #0
2025-02-27T04:38:49.196934+0300 | DEBUG | Saving model to flat file storage. Save #141
2025-02-27T04:38:49.399017+0300 | INFO | [141,     0] loss: 0.016
2025-02-27T04:39:00.669513+0300 | INFO | [141,   100] loss: 1.491
2025-02-27T04:39:10.834505+0300 | INFO | [141,   200] loss: 1.499
2025-02-27T04:39:23.310724+0300 | INFO | [141,   300] loss: 1.499
2025-02-27T04:39:35.041228+0300 | INFO | [141,   400] loss: 1.486
2025-02-27T04:39:45.014284+0300 | INFO | [141,   500] loss: 1.482
2025-02-27T04:39:56.164077+0300 | INFO | [141,   600] loss: 1.499
2025-02-27T04:40:07.262969+0300 | INFO | [141,   700] loss: 1.485
2025-02-27T04:40:17.488512+0300 | INFO | [141,   800] loss: 1.493
2025-02-27T04:40:28.739438+0300 | INFO | [141,   900] loss: 1.491
2025-02-27T04:40:39.603835+0300 | INFO | [141,  1000] loss: 1.490
2025-02-27T04:40:49.595608+0300 | INFO | [141,  1100] loss: 1.496
2025-02-27T04:41:01.762156+0300 | INFO | [141,  1200] loss: 1.488
2025-02-27T04:41:12.741639+0300 | INFO | [141,  1300] loss: 1.489
2025-02-27T04:41:24.015674+0300 | INFO | [141,  1400] loss: 1.497
2025-02-27T04:41:34.347177+0300 | INFO | [141,  1500] loss: 1.484
2025-02-27T04:41:45.053818+0300 | INFO | [141,  1600] loss: 1.481
2025-02-27T04:41:56.291487+0300 | INFO | [141,  1700] loss: 1.495
2025-02-27T04:42:06.919225+0300 | INFO | [141,  1800] loss: 1.502
2025-02-27T04:42:18.551098+0300 | INFO | [141,  1900] loss: 1.497
2025-02-27T04:42:29.917500+0300 | INFO | [141,  2000] loss: 1.496
2025-02-27T04:42:39.974463+0300 | INFO | [141,  2100] loss: 1.492
2025-02-27T04:42:51.456090+0300 | INFO | [141,  2200] loss: 1.488
2025-02-27T04:43:02.761989+0300 | INFO | [141,  2300] loss: 1.504
2025-02-27T04:43:13.107288+0300 | INFO | [141,  2400] loss: 1.491
2025-02-27T04:43:23.926061+0300 | INFO | [141,  2500] loss: 1.493
2025-02-27T04:43:35.179399+0300 | INFO | [141,  2600] loss: 1.502
2025-02-27T04:43:45.424303+0300 | INFO | [141,  2700] loss: 1.488
2025-02-27T04:43:56.878109+0300 | INFO | [141,  2800] loss: 1.498
2025-02-27T04:44:08.808722+0300 | INFO | [141,  2900] loss: 1.503
2025-02-27T04:44:23.924921+0300 | INFO | [141,  3000] loss: 1.498
2025-02-27T04:44:36.327220+0300 | INFO | [141,  3100] loss: 1.483
2025-02-27T04:44:46.625856+0300 | INFO | [141,  3200] loss: 1.490
2025-02-27T04:44:57.698423+0300 | INFO | [141,  3300] loss: 1.489
2025-02-27T04:45:09.608750+0300 | INFO | [141,  3400] loss: 1.484
2025-02-27T04:45:19.925697+0300 | INFO | [141,  3500] loss: 1.485
2025-02-27T04:45:31.314915+0300 | INFO | [141,  3600] loss: 1.488
2025-02-27T04:45:42.273604+0300 | INFO | [141,  3700] loss: 1.487
2025-02-27T04:45:52.817181+0300 | INFO | [141,  3800] loss: 1.499
2025-02-27T04:46:04.131382+0300 | INFO | [141,  3900] loss: 1.494
2025-02-27T04:46:15.198551+0300 | INFO | [141,  4000] loss: 1.491
2025-02-27T04:46:25.294022+0300 | INFO | [141,  4100] loss: 1.502
2025-02-27T04:46:36.258387+0300 | INFO | [141,  4200] loss: 1.504
2025-02-27T04:46:46.990248+0300 | INFO | [141,  4300] loss: 1.490
2025-02-27T04:46:57.081360+0300 | INFO | [141,  4400] loss: 1.496
2025-02-27T04:47:10.314947+0300 | INFO | [141,  4500] loss: 1.491
2025-02-27T04:47:21.499764+0300 | INFO | [141,  4600] loss: 1.495
2025-02-27T04:47:32.573179+0300 | INFO | [141,  4700] loss: 1.485
2025-02-27T04:47:42.568443+0300 | INFO | [141,  4800] loss: 1.495
2025-02-27T04:47:54.684501+0300 | INFO | [141,  4900] loss: 1.489
2025-02-27T04:48:05.870418+0300 | DEBUG | Saving model to flat file storage. Save #141
2025-02-27T04:48:05.899726+0300 | INFO | Averaging client parameters
2025-02-27T04:48:05.908736+0300 | INFO | Updating parameters on client #0
2025-02-27T04:48:21.561836+0300 | DEBUG | Test set: Accuracy: 7860/10000 (79%)
2025-02-27T04:48:21.563846+0300 | DEBUG | Test set: Loss: 1.6731517314910889
2025-02-27T04:48:21.666558+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.89      0.92      0.90      1000
           2       0.74      0.70      0.72      1000
           3       0.66      0.59      0.62      1200
           4       0.80      0.77      0.78      1000
           5       0.51      0.61      0.55       800
           6       0.86      0.85      0.85      1000
           7       0.88      0.79      0.83      1000
           8       0.87      0.92      0.89      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.78     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T04:48:21.669564+0300 | DEBUG | Confusion Matrix:
[[852  14  31  10   8  11   3   4  44  23]
 [ 11 919   3   0   0   2   3   0  21  41]
 [ 67   6 704  43  57  49  43  12  12   7]
 [ 26  10  51 704  44 266  38  21  20  20]
 [ 14   6  48  56 772  43  29  24   5   3]
 [ 18   3  39 175  25 485  13  31   7   4]
 [  9   5  40  41  16  26 849   3   9   2]
 [ 20   5  19  33  48  64   3 789   4  15]
 [ 39  13   6   7   0   2   4   1 917  11]
 [ 28  56   7   3   1   3   7   8  18 869]]
2025-02-27T04:48:21.673573+0300 | DEBUG | Class precision: [0.78597786 0.88621022 0.74261603 0.65671642 0.79505664 0.50998948
 0.85584677 0.88353863 0.86754967 0.87336683]
2025-02-27T04:48:21.676570+0300 | DEBUG | Class recall: [0.852      0.919      0.704      0.58666667 0.772      0.60625
 0.849      0.789      0.917      0.869     ]
2025-02-27T04:48:21.723892+0300 | INFO | Training epoch #142 on client #0
2025-02-27T04:48:21.725893+0300 | DEBUG | Saving model to flat file storage. Save #142
2025-02-27T04:48:21.940862+0300 | INFO | [142,     0] loss: 0.015
2025-02-27T04:48:32.554324+0300 | INFO | [142,   100] loss: 1.495
2025-02-27T04:48:43.420410+0300 | INFO | [142,   200] loss: 1.500
2025-02-27T04:48:54.316665+0300 | INFO | [142,   300] loss: 1.500
2025-02-27T04:49:05.778567+0300 | INFO | [142,   400] loss: 1.495
2025-02-27T04:49:16.724140+0300 | INFO | [142,   500] loss: 1.490
2025-02-27T04:49:27.519844+0300 | INFO | [142,   600] loss: 1.495
2025-02-27T04:49:37.578126+0300 | INFO | [142,   700] loss: 1.486
2025-02-27T04:49:48.636321+0300 | INFO | [142,   800] loss: 1.492
2025-02-27T04:49:59.209263+0300 | INFO | [142,   900] loss: 1.496
2025-02-27T04:50:10.179817+0300 | INFO | [142,  1000] loss: 1.494
2025-02-27T04:50:22.133848+0300 | INFO | [142,  1100] loss: 1.487
2025-02-27T04:50:33.157225+0300 | INFO | [142,  1200] loss: 1.493
2025-02-27T04:50:44.159222+0300 | INFO | [142,  1300] loss: 1.487
2025-02-27T04:50:54.714877+0300 | INFO | [142,  1400] loss: 1.494
2025-02-27T04:51:06.197523+0300 | INFO | [142,  1500] loss: 1.506
2025-02-27T04:51:17.498757+0300 | INFO | [142,  1600] loss: 1.493
2025-02-27T04:51:27.537994+0300 | INFO | [142,  1700] loss: 1.489
2025-02-27T04:51:38.466114+0300 | INFO | [142,  1800] loss: 1.491
2025-02-27T04:51:49.224719+0300 | INFO | [142,  1900] loss: 1.499
2025-02-27T04:51:59.241591+0300 | INFO | [142,  2000] loss: 1.494
2025-02-27T04:52:10.717342+0300 | INFO | [142,  2100] loss: 1.495
2025-02-27T04:52:21.790315+0300 | INFO | [142,  2200] loss: 1.479
2025-02-27T04:52:32.000087+0300 | INFO | [142,  2300] loss: 1.490
2025-02-27T04:52:43.002871+0300 | INFO | [142,  2400] loss: 1.496
2025-02-27T04:52:54.224582+0300 | INFO | [142,  2500] loss: 1.493
2025-02-27T04:53:10.527973+0300 | INFO | [142,  2600] loss: 1.485
2025-02-27T04:53:21.476990+0300 | INFO | [142,  2700] loss: 1.486
2025-02-27T04:53:32.603515+0300 | INFO | [142,  2800] loss: 1.485
2025-02-27T04:53:43.253156+0300 | INFO | [142,  2900] loss: 1.491
2025-02-27T04:53:53.322532+0300 | INFO | [142,  3000] loss: 1.490
2025-02-27T04:54:05.731415+0300 | INFO | [142,  3100] loss: 1.488
2025-02-27T04:54:16.822437+0300 | INFO | [142,  3200] loss: 1.495
2025-02-27T04:54:27.883311+0300 | INFO | [142,  3300] loss: 1.486
2025-02-27T04:54:38.880497+0300 | INFO | [142,  3400] loss: 1.492
2025-02-27T04:54:49.775083+0300 | INFO | [142,  3500] loss: 1.497
2025-02-27T04:55:00.832765+0300 | INFO | [142,  3600] loss: 1.500
2025-02-27T04:55:11.159799+0300 | INFO | [142,  3700] loss: 1.496
2025-02-27T04:55:22.101032+0300 | INFO | [142,  3800] loss: 1.483
2025-02-27T04:55:34.476483+0300 | INFO | [142,  3900] loss: 1.494
2025-02-27T04:55:44.926322+0300 | INFO | [142,  4000] loss: 1.501
2025-02-27T04:55:56.170314+0300 | INFO | [142,  4100] loss: 1.489
2025-02-27T04:56:07.394602+0300 | INFO | [142,  4200] loss: 1.493
2025-02-27T04:56:18.983710+0300 | INFO | [142,  4300] loss: 1.493
2025-02-27T04:56:29.163476+0300 | INFO | [142,  4400] loss: 1.479
2025-02-27T04:56:40.079846+0300 | INFO | [142,  4500] loss: 1.501
2025-02-27T04:56:50.873875+0300 | INFO | [142,  4600] loss: 1.500
2025-02-27T04:57:01.108990+0300 | INFO | [142,  4700] loss: 1.500
2025-02-27T04:57:12.279344+0300 | INFO | [142,  4800] loss: 1.490
2025-02-27T04:57:23.356215+0300 | INFO | [142,  4900] loss: 1.493
2025-02-27T04:57:33.485860+0300 | DEBUG | Saving model to flat file storage. Save #142
2025-02-27T04:57:33.506857+0300 | INFO | Averaging client parameters
2025-02-27T04:57:33.514884+0300 | INFO | Updating parameters on client #0
2025-02-27T04:57:48.667727+0300 | DEBUG | Test set: Accuracy: 7925/10000 (79%)
2025-02-27T04:57:48.668727+0300 | DEBUG | Test set: Loss: 1.6685870885849
2025-02-27T04:57:48.757434+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.83      1000
           1       0.88      0.93      0.90      1000
           2       0.74      0.70      0.72      1000
           3       0.69      0.58      0.63      1200
           4       0.77      0.81      0.79      1000
           5       0.53      0.64      0.58       800
           6       0.86      0.84      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.90      0.85      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T04:57:48.758439+0300 | DEBUG | Confusion Matrix:
[[849  15  37   7  13   7   3  10  38  21]
 [ 13 926   4   0   0   2   3   2  16  34]
 [ 61   7 701  42  73  47  38  17   8   6]
 [ 16   8  54 691  53 281  39  33  13  12]
 [  8   6  37  37 808  41  27  28   5   3]
 [ 15   3  37 150  28 513  13  36   3   2]
 [  9   4  45  38  22  26 845   7   4   0]
 [ 15   3  13  25  44  53   2 835   2   8]
 [ 40  14   7   7   4   3   5   2 906  12]
 [ 32  61   7   7   1   4  10   9  18 851]]
2025-02-27T04:57:48.761443+0300 | DEBUG | Class precision: [0.80245747 0.88443171 0.74416136 0.68824701 0.77246654 0.52507677
 0.85786802 0.85291113 0.89437315 0.8967334 ]
2025-02-27T04:57:48.762440+0300 | DEBUG | Class recall: [0.849      0.926      0.701      0.57583333 0.808      0.64125
 0.845      0.835      0.906      0.851     ]
2025-02-27T04:57:48.808962+0300 | INFO | Training epoch #143 on client #0
2025-02-27T04:57:48.811964+0300 | DEBUG | Saving model to flat file storage. Save #143
2025-02-27T04:57:49.028921+0300 | INFO | [143,     0] loss: 0.015
2025-02-27T04:58:00.176623+0300 | INFO | [143,   100] loss: 1.495
2025-02-27T04:58:11.585893+0300 | INFO | [143,   200] loss: 1.503
2025-02-27T04:58:22.915628+0300 | INFO | [143,   300] loss: 1.496
2025-02-27T04:58:34.253310+0300 | INFO | [143,   400] loss: 1.497
2025-02-27T04:58:44.948885+0300 | INFO | [143,   500] loss: 1.488
2025-02-27T04:58:55.434437+0300 | INFO | [143,   600] loss: 1.491
2025-02-27T04:59:06.829928+0300 | INFO | [143,   700] loss: 1.494
2025-02-27T04:59:17.949813+0300 | INFO | [143,   800] loss: 1.489
2025-02-27T04:59:29.518390+0300 | INFO | [143,   900] loss: 1.497
2025-02-27T04:59:40.177477+0300 | INFO | [143,  1000] loss: 1.485
2025-02-27T04:59:50.913933+0300 | INFO | [143,  1100] loss: 1.497
2025-02-27T05:00:03.803444+0300 | INFO | [143,  1200] loss: 1.492
2025-02-27T05:00:14.099829+0300 | INFO | [143,  1300] loss: 1.492
2025-02-27T05:00:25.162937+0300 | INFO | [143,  1400] loss: 1.492
2025-02-27T05:00:36.173465+0300 | INFO | [143,  1500] loss: 1.492
2025-02-27T05:00:46.220109+0300 | INFO | [143,  1600] loss: 1.485
2025-02-27T05:00:57.262661+0300 | INFO | [143,  1700] loss: 1.494
2025-02-27T05:01:08.386158+0300 | INFO | [143,  1800] loss: 1.485
2025-02-27T05:01:18.450420+0300 | INFO | [143,  1900] loss: 1.494
2025-02-27T05:01:29.214576+0300 | INFO | [143,  2000] loss: 1.490
2025-02-27T05:01:40.047582+0300 | INFO | [143,  2100] loss: 1.502
2025-02-27T05:01:53.106623+0300 | INFO | [143,  2200] loss: 1.490
2025-02-27T05:02:06.082816+0300 | INFO | [143,  2300] loss: 1.492
2025-02-27T05:02:16.978627+0300 | INFO | [143,  2400] loss: 1.481
2025-02-27T05:02:28.430083+0300 | INFO | [143,  2500] loss: 1.507
2025-02-27T05:02:38.400314+0300 | INFO | [143,  2600] loss: 1.495
2025-02-27T05:02:49.534232+0300 | INFO | [143,  2700] loss: 1.486
2025-02-27T05:03:00.802389+0300 | INFO | [143,  2800] loss: 1.482
2025-02-27T05:03:11.190365+0300 | INFO | [143,  2900] loss: 1.493
2025-02-27T05:03:23.985507+0300 | INFO | [143,  3000] loss: 1.502
2025-02-27T05:03:35.144536+0300 | INFO | [143,  3100] loss: 1.490
2025-02-27T05:03:45.415134+0300 | INFO | [143,  3200] loss: 1.487
2025-02-27T05:03:59.030212+0300 | INFO | [143,  3300] loss: 1.494
2025-02-27T05:04:10.618644+0300 | INFO | [143,  3400] loss: 1.491
2025-02-27T05:04:21.669488+0300 | INFO | [143,  3500] loss: 1.494
2025-02-27T05:04:31.900255+0300 | INFO | [143,  3600] loss: 1.494
2025-02-27T05:04:42.896205+0300 | INFO | [143,  3700] loss: 1.493
2025-02-27T05:04:54.039518+0300 | INFO | [143,  3800] loss: 1.492
2025-02-27T05:05:04.289407+0300 | INFO | [143,  3900] loss: 1.494
2025-02-27T05:05:15.170503+0300 | INFO | [143,  4000] loss: 1.498
2025-02-27T05:05:27.314067+0300 | INFO | [143,  4100] loss: 1.503
2025-02-27T05:05:38.979173+0300 | INFO | [143,  4200] loss: 1.495
2025-02-27T05:05:49.241149+0300 | INFO | [143,  4300] loss: 1.482
2025-02-27T05:06:00.776757+0300 | INFO | [143,  4400] loss: 1.492
2025-02-27T05:06:12.431212+0300 | INFO | [143,  4500] loss: 1.498
2025-02-27T05:06:22.691743+0300 | INFO | [143,  4600] loss: 1.495
2025-02-27T05:06:33.989166+0300 | INFO | [143,  4700] loss: 1.490
2025-02-27T05:06:45.120560+0300 | INFO | [143,  4800] loss: 1.487
2025-02-27T05:06:55.344534+0300 | INFO | [143,  4900] loss: 1.485
2025-02-27T05:07:06.435062+0300 | DEBUG | Saving model to flat file storage. Save #143
2025-02-27T05:07:06.459245+0300 | INFO | Averaging client parameters
2025-02-27T05:07:06.466388+0300 | INFO | Updating parameters on client #0
2025-02-27T05:07:22.759924+0300 | DEBUG | Test set: Accuracy: 7877/10000 (79%)
2025-02-27T05:07:22.761923+0300 | DEBUG | Test set: Loss: 1.6723142862319946
2025-02-27T05:07:22.862287+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.82      0.81      1000
           1       0.89      0.91      0.90      1000
           2       0.76      0.69      0.72      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.80      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.83      0.85      0.84      1000
           8       0.88      0.90      0.89      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.78      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T05:07:22.863294+0300 | DEBUG | Confusion Matrix:
[[818  15  39   8  19   7   6  12  43  33]
 [ 10 914   2   0   0   1   3   0  18  52]
 [ 52   7 695  37  73  50  48  23   9   6]
 [ 20   7  47 670  51 281  44  45  14  21]
 [ 11   6  31  41 800  34  31  39   4   3]
 [ 14   4  38 153  29 493  11  47   6   5]
 [ 10   4  37  35  25  17 857   7   5   3]
 [ 14   4  13  21  37  42   3 854   4   8]
 [ 44  19   8   5   2   2   5   1 899  15]
 [ 22  51   8   4   1   2   8   7  20 877]]
2025-02-27T05:07:22.865291+0300 | DEBUG | Class precision: [0.80591133 0.88651794 0.75708061 0.68788501 0.77145612 0.53067815
 0.84350394 0.82512077 0.87964775 0.8572825 ]
2025-02-27T05:07:22.866287+0300 | DEBUG | Class recall: [0.818      0.914      0.695      0.55833333 0.8        0.61625
 0.857      0.854      0.899      0.877     ]
2025-02-27T05:07:22.922431+0300 | INFO | Training epoch #144 on client #0
2025-02-27T05:07:22.923427+0300 | DEBUG | Saving model to flat file storage. Save #144
2025-02-27T05:07:23.141192+0300 | INFO | [144,     0] loss: 0.015
2025-02-27T05:07:34.244829+0300 | INFO | [144,   100] loss: 1.485
2025-02-27T05:07:44.603137+0300 | INFO | [144,   200] loss: 1.490
2025-02-27T05:07:56.335152+0300 | INFO | [144,   300] loss: 1.489
2025-02-27T05:08:08.251041+0300 | INFO | [144,   400] loss: 1.502
2025-02-27T05:08:19.405272+0300 | INFO | [144,   500] loss: 1.486
2025-02-27T05:08:30.120294+0300 | INFO | [144,   600] loss: 1.484
2025-02-27T05:08:42.063206+0300 | INFO | [144,   700] loss: 1.500
2025-02-27T05:08:53.540380+0300 | INFO | [144,   800] loss: 1.503
2025-02-27T05:09:04.185416+0300 | INFO | [144,   900] loss: 1.499
2025-02-27T05:09:15.223035+0300 | INFO | [144,  1000] loss: 1.497
2025-02-27T05:09:27.098406+0300 | INFO | [144,  1100] loss: 1.496
2025-02-27T05:09:37.690443+0300 | INFO | [144,  1200] loss: 1.488
2025-02-27T05:09:48.592761+0300 | INFO | [144,  1300] loss: 1.491
2025-02-27T05:09:59.777887+0300 | INFO | [144,  1400] loss: 1.499
2025-02-27T05:10:10.443722+0300 | INFO | [144,  1500] loss: 1.489
2025-02-27T05:10:21.161604+0300 | INFO | [144,  1600] loss: 1.489
2025-02-27T05:10:32.386871+0300 | INFO | [144,  1700] loss: 1.493
2025-02-27T05:10:48.481554+0300 | INFO | [144,  1800] loss: 1.496
2025-02-27T05:11:00.232865+0300 | INFO | [144,  1900] loss: 1.488
2025-02-27T05:11:10.537636+0300 | INFO | [144,  2000] loss: 1.497
2025-02-27T05:11:21.647727+0300 | INFO | [144,  2100] loss: 1.495
2025-02-27T05:11:33.111423+0300 | INFO | [144,  2200] loss: 1.490
2025-02-27T05:11:43.291337+0300 | INFO | [144,  2300] loss: 1.493
2025-02-27T05:11:55.088624+0300 | INFO | [144,  2400] loss: 1.485
2025-02-27T05:12:07.091831+0300 | INFO | [144,  2500] loss: 1.492
2025-02-27T05:12:17.944768+0300 | INFO | [144,  2600] loss: 1.493
2025-02-27T05:12:28.865151+0300 | INFO | [144,  2700] loss: 1.492
2025-02-27T05:12:40.180540+0300 | INFO | [144,  2800] loss: 1.488
2025-02-27T05:12:50.716431+0300 | INFO | [144,  2900] loss: 1.495
2025-02-27T05:13:01.981164+0300 | INFO | [144,  3000] loss: 1.504
2025-02-27T05:13:13.304495+0300 | INFO | [144,  3100] loss: 1.497
2025-02-27T05:13:24.238462+0300 | INFO | [144,  3200] loss: 1.492
2025-02-27T05:13:34.702975+0300 | INFO | [144,  3300] loss: 1.487
2025-02-27T05:13:45.791097+0300 | INFO | [144,  3400] loss: 1.493
2025-02-27T05:13:57.041446+0300 | INFO | [144,  3500] loss: 1.493
2025-02-27T05:14:07.355812+0300 | INFO | [144,  3600] loss: 1.488
2025-02-27T05:14:18.487435+0300 | INFO | [144,  3700] loss: 1.497
2025-02-27T05:14:29.500499+0300 | INFO | [144,  3800] loss: 1.493
2025-02-27T05:14:39.850658+0300 | INFO | [144,  3900] loss: 1.502
2025-02-27T05:14:51.547163+0300 | INFO | [144,  4000] loss: 1.483
2025-02-27T05:15:02.882443+0300 | INFO | [144,  4100] loss: 1.493
2025-02-27T05:15:13.158911+0300 | INFO | [144,  4200] loss: 1.488
2025-02-27T05:15:24.089584+0300 | INFO | [144,  4300] loss: 1.500
2025-02-27T05:15:35.907337+0300 | INFO | [144,  4400] loss: 1.488
2025-02-27T05:15:46.268970+0300 | INFO | [144,  4500] loss: 1.495
2025-02-27T05:15:57.510449+0300 | INFO | [144,  4600] loss: 1.484
2025-02-27T05:16:08.511136+0300 | INFO | [144,  4700] loss: 1.489
2025-02-27T05:16:20.018635+0300 | INFO | [144,  4800] loss: 1.491
2025-02-27T05:16:30.337812+0300 | INFO | [144,  4900] loss: 1.496
2025-02-27T05:16:41.244815+0300 | DEBUG | Saving model to flat file storage. Save #144
2025-02-27T05:16:41.269261+0300 | INFO | Averaging client parameters
2025-02-27T05:16:41.278927+0300 | INFO | Updating parameters on client #0
2025-02-27T05:16:57.462728+0300 | DEBUG | Test set: Accuracy: 7930/10000 (79%)
2025-02-27T05:16:57.465630+0300 | DEBUG | Test set: Loss: 1.6671648025512695
2025-02-27T05:16:57.569892+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.67      0.58      0.63      1200
           4       0.81      0.76      0.79      1000
           5       0.54      0.62      0.58       800
           6       0.83      0.87      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T05:16:57.572282+0300 | DEBUG | Confusion Matrix:
[[830  19  41   8  10   6   6   8  40  32]
 [  4 930   2   0   1   1   4   0  15  43]
 [ 53   6 725  43  48  45  47  18  11   4]
 [ 23   5  61 700  41 259  47  34  12  18]
 [ 14   4  45  52 761  40  41  35   5   3]
 [ 18   3  40 158  24 497  15  40   2   3]
 [  7   3  34  37  18  14 874   6   4   3]
 [ 14   4  20  28  33  55   4 829   4   9]
 [ 33  22   9   7   0   2   6   1 908  12]
 [ 20  51   9   6   1   2  12   5  18 876]]
2025-02-27T05:16:57.572282+0300 | DEBUG | Class precision: [0.81692913 0.88825215 0.73529412 0.67372474 0.81216649 0.53963084
 0.82765152 0.84938525 0.89106968 0.87337986]
2025-02-27T05:16:57.574625+0300 | DEBUG | Class recall: [0.83       0.93       0.725      0.58333333 0.761      0.62125
 0.874      0.829      0.908      0.876     ]
2025-02-27T05:16:57.624462+0300 | INFO | Training epoch #145 on client #0
2025-02-27T05:16:57.626460+0300 | DEBUG | Saving model to flat file storage. Save #145
2025-02-27T05:16:57.855640+0300 | INFO | [145,     0] loss: 0.015
2025-02-27T05:17:08.922920+0300 | INFO | [145,   100] loss: 1.497
2025-02-27T05:17:19.292263+0300 | INFO | [145,   200] loss: 1.488
2025-02-27T05:17:30.320164+0300 | INFO | [145,   300] loss: 1.499
2025-02-27T05:17:41.420458+0300 | INFO | [145,   400] loss: 1.491
2025-02-27T05:17:51.731081+0300 | INFO | [145,   500] loss: 1.497
2025-02-27T05:18:04.061997+0300 | INFO | [145,   600] loss: 1.491
2025-02-27T05:18:15.531372+0300 | INFO | [145,   700] loss: 1.496
2025-02-27T05:18:26.090237+0300 | INFO | [145,   800] loss: 1.491
2025-02-27T05:18:36.874871+0300 | INFO | [145,   900] loss: 1.490
2025-02-27T05:18:47.837885+0300 | INFO | [145,  1000] loss: 1.493
2025-02-27T05:18:58.732970+0300 | INFO | [145,  1100] loss: 1.483
2025-02-27T05:19:11.465694+0300 | INFO | [145,  1200] loss: 1.494
2025-02-27T05:19:26.257567+0300 | INFO | [145,  1300] loss: 1.498
2025-02-27T05:19:37.757789+0300 | INFO | [145,  1400] loss: 1.495
2025-02-27T05:19:48.834097+0300 | INFO | [145,  1500] loss: 1.490
2025-02-27T05:19:58.818223+0300 | INFO | [145,  1600] loss: 1.499
2025-02-27T05:20:10.329386+0300 | INFO | [145,  1700] loss: 1.496
2025-02-27T05:20:21.473486+0300 | INFO | [145,  1800] loss: 1.489
2025-02-27T05:20:31.653369+0300 | INFO | [145,  1900] loss: 1.493
2025-02-27T05:20:45.031486+0300 | INFO | [145,  2000] loss: 1.492
2025-02-27T05:20:55.534727+0300 | INFO | [145,  2100] loss: 1.488
2025-02-27T05:21:07.352142+0300 | INFO | [145,  2200] loss: 1.493
2025-02-27T05:21:17.701736+0300 | INFO | [145,  2300] loss: 1.486
2025-02-27T05:21:28.590437+0300 | INFO | [145,  2400] loss: 1.490
2025-02-27T05:21:39.490689+0300 | INFO | [145,  2500] loss: 1.494
2025-02-27T05:21:50.184321+0300 | INFO | [145,  2600] loss: 1.500
2025-02-27T05:22:01.632393+0300 | INFO | [145,  2700] loss: 1.501
2025-02-27T05:22:13.070256+0300 | INFO | [145,  2800] loss: 1.486
2025-02-27T05:22:24.913102+0300 | INFO | [145,  2900] loss: 1.490
2025-02-27T05:22:36.050386+0300 | INFO | [145,  3000] loss: 1.491
2025-02-27T05:22:47.191180+0300 | INFO | [145,  3100] loss: 1.493
2025-02-27T05:22:57.520967+0300 | INFO | [145,  3200] loss: 1.501
2025-02-27T05:23:09.544184+0300 | INFO | [145,  3300] loss: 1.499
2025-02-27T05:23:20.472316+0300 | INFO | [145,  3400] loss: 1.492
2025-02-27T05:23:31.637943+0300 | INFO | [145,  3500] loss: 1.485
2025-02-27T05:23:41.789699+0300 | INFO | [145,  3600] loss: 1.486
2025-02-27T05:23:52.810459+0300 | INFO | [145,  3700] loss: 1.495
2025-02-27T05:24:03.772646+0300 | INFO | [145,  3800] loss: 1.492
2025-02-27T05:24:14.881115+0300 | INFO | [145,  3900] loss: 1.496
2025-02-27T05:24:26.198770+0300 | INFO | [145,  4000] loss: 1.497
2025-02-27T05:24:37.826404+0300 | INFO | [145,  4100] loss: 1.493
2025-02-27T05:24:47.936263+0300 | INFO | [145,  4200] loss: 1.490
2025-02-27T05:24:58.839573+0300 | INFO | [145,  4300] loss: 1.484
2025-02-27T05:25:10.084070+0300 | INFO | [145,  4400] loss: 1.495
2025-02-27T05:25:21.882494+0300 | INFO | [145,  4500] loss: 1.495
2025-02-27T05:25:33.090923+0300 | INFO | [145,  4600] loss: 1.488
2025-02-27T05:25:43.952423+0300 | INFO | [145,  4700] loss: 1.492
2025-02-27T05:25:54.567732+0300 | INFO | [145,  4800] loss: 1.482
2025-02-27T05:26:05.786796+0300 | INFO | [145,  4900] loss: 1.495
2025-02-27T05:26:16.803602+0300 | DEBUG | Saving model to flat file storage. Save #145
2025-02-27T05:26:16.833372+0300 | INFO | Averaging client parameters
2025-02-27T05:26:16.844383+0300 | INFO | Updating parameters on client #0
2025-02-27T05:26:32.521999+0300 | DEBUG | Test set: Accuracy: 7924/10000 (79%)
2025-02-27T05:26:32.525007+0300 | DEBUG | Test set: Loss: 1.6680412292480469
2025-02-27T05:26:32.636984+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1000
           1       0.88      0.93      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.70      0.55      0.62      1200
           4       0.80      0.78      0.79      1000
           5       0.52      0.65      0.58       800
           6       0.83      0.88      0.86      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.84      0.89      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T05:26:32.638987+0300 | DEBUG | Confusion Matrix:
[[837  18  30   7  10   6   4   8  40  40]
 [  4 932   1   0   1   1   3   1  11  46]
 [ 55   9 694  35  63  49  55  18  11  11]
 [ 23  12  46 663  40 295  47  35  15  24]
 [  9   7  43  38 784  45  39  26   5   4]
 [ 16   4  32 143  24 519  16  34   6   6]
 [  9   4  28  31  15  16 884   6   4   3]
 [ 17   5  19  21  41  59   4 816   4  14]
 [ 32  20   8   8   0   2   6   2 907  15]
 [ 20  48   6   4   1   2   8   7  16 888]]
2025-02-27T05:26:32.640988+0300 | DEBUG | Class precision: [0.81898239 0.88007554 0.76515987 0.69789474 0.80081716 0.5221328
 0.82926829 0.85624344 0.89008832 0.84490961]
2025-02-27T05:26:32.642988+0300 | DEBUG | Class recall: [0.837   0.932   0.694   0.5525  0.784   0.64875 0.884   0.816   0.907
 0.888  ]
2025-02-27T05:26:32.703938+0300 | INFO | Training epoch #146 on client #0
2025-02-27T05:26:32.705950+0300 | DEBUG | Saving model to flat file storage. Save #146
2025-02-27T05:26:32.977448+0300 | INFO | [146,     0] loss: 0.015
2025-02-27T05:26:44.100577+0300 | INFO | [146,   100] loss: 1.498
2025-02-27T05:26:54.335932+0300 | INFO | [146,   200] loss: 1.488
2025-02-27T05:27:05.778713+0300 | INFO | [146,   300] loss: 1.498
2025-02-27T05:27:17.962167+0300 | INFO | [146,   400] loss: 1.487
2025-02-27T05:27:28.033072+0300 | INFO | [146,   500] loss: 1.487
2025-02-27T05:27:38.758290+0300 | INFO | [146,   600] loss: 1.490
2025-02-27T05:27:49.496676+0300 | INFO | [146,   700] loss: 1.489
2025-02-27T05:28:05.586995+0300 | INFO | [146,   800] loss: 1.491
2025-02-27T05:28:16.901688+0300 | INFO | [146,   900] loss: 1.499
2025-02-27T05:28:28.851141+0300 | INFO | [146,  1000] loss: 1.479
2025-02-27T05:28:40.674363+0300 | INFO | [146,  1100] loss: 1.491
2025-02-27T05:28:52.335292+0300 | INFO | [146,  1200] loss: 1.490
2025-02-27T05:29:03.908528+0300 | INFO | [146,  1300] loss: 1.497
2025-02-27T05:29:16.161232+0300 | INFO | [146,  1400] loss: 1.493
2025-02-27T05:29:28.180277+0300 | INFO | [146,  1500] loss: 1.493
2025-02-27T05:29:40.021759+0300 | INFO | [146,  1600] loss: 1.502
2025-02-27T05:29:50.770283+0300 | INFO | [146,  1700] loss: 1.497
2025-02-27T05:30:02.545552+0300 | INFO | [146,  1800] loss: 1.481
2025-02-27T05:30:14.565405+0300 | INFO | [146,  1900] loss: 1.490
2025-02-27T05:30:25.700699+0300 | INFO | [146,  2000] loss: 1.498
2025-02-27T05:30:38.514911+0300 | INFO | [146,  2100] loss: 1.485
2025-02-27T05:30:50.578906+0300 | INFO | [146,  2200] loss: 1.495
2025-02-27T05:31:02.514375+0300 | INFO | [146,  2300] loss: 1.494
2025-02-27T05:31:14.670544+0300 | INFO | [146,  2400] loss: 1.498
2025-02-27T05:31:25.970662+0300 | INFO | [146,  2500] loss: 1.490
2025-02-27T05:31:37.461031+0300 | INFO | [146,  2600] loss: 1.497
2025-02-27T05:31:48.629264+0300 | INFO | [146,  2700] loss: 1.487
2025-02-27T05:31:59.102324+0300 | INFO | [146,  2800] loss: 1.493
2025-02-27T05:32:10.472825+0300 | INFO | [146,  2900] loss: 1.490
2025-02-27T05:32:21.848526+0300 | INFO | [146,  3000] loss: 1.492
2025-02-27T05:32:31.875962+0300 | INFO | [146,  3100] loss: 1.500
2025-02-27T05:32:42.801980+0300 | INFO | [146,  3200] loss: 1.492
2025-02-27T05:32:53.705581+0300 | INFO | [146,  3300] loss: 1.490
2025-02-27T05:33:04.372343+0300 | INFO | [146,  3400] loss: 1.492
2025-02-27T05:33:15.605276+0300 | INFO | [146,  3500] loss: 1.493
2025-02-27T05:33:26.766978+0300 | INFO | [146,  3600] loss: 1.491
2025-02-27T05:33:37.664783+0300 | INFO | [146,  3700] loss: 1.492
2025-02-27T05:33:48.536885+0300 | INFO | [146,  3800] loss: 1.497
2025-02-27T05:33:59.710921+0300 | INFO | [146,  3900] loss: 1.492
2025-02-27T05:34:10.322784+0300 | INFO | [146,  4000] loss: 1.501
2025-02-27T05:34:21.096589+0300 | INFO | [146,  4100] loss: 1.496
2025-02-27T05:34:31.933840+0300 | INFO | [146,  4200] loss: 1.484
2025-02-27T05:34:42.171699+0300 | INFO | [146,  4300] loss: 1.480
2025-02-27T05:34:52.911120+0300 | INFO | [146,  4400] loss: 1.489
2025-02-27T05:35:04.145550+0300 | INFO | [146,  4500] loss: 1.497
2025-02-27T05:35:15.274524+0300 | INFO | [146,  4600] loss: 1.486
2025-02-27T05:35:25.674809+0300 | INFO | [146,  4700] loss: 1.504
2025-02-27T05:35:36.727113+0300 | INFO | [146,  4800] loss: 1.488
2025-02-27T05:35:47.360993+0300 | INFO | [146,  4900] loss: 1.497
2025-02-27T05:35:57.282088+0300 | DEBUG | Saving model to flat file storage. Save #146
2025-02-27T05:35:57.303215+0300 | INFO | Averaging client parameters
2025-02-27T05:35:57.312389+0300 | INFO | Updating parameters on client #0
2025-02-27T05:36:13.011165+0300 | DEBUG | Test set: Accuracy: 7945/10000 (79%)
2025-02-27T05:36:13.012160+0300 | DEBUG | Test set: Loss: 1.6670855283737183
2025-02-27T05:36:13.116846+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.82      0.84      1000
           1       0.89      0.92      0.91      1000
           2       0.78      0.69      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.52      0.67      0.58       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.83      0.84      1000
           8       0.91      0.91      0.91      1000
           9       0.85      0.90      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.80      0.80      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T05:36:13.118852+0300 | DEBUG | Confusion Matrix:
[[824  18  32  10  16   8   6  10  41  35]
 [  3 922   1   0   1   2   4   0  12  55]
 [ 49   5 689  52  67  57  48  20   3  10]
 [ 14   7  41 689  42 300  45  33   9  20]
 [  9   5  35  47 787  49  32  28   5   3]
 [ 10   3  24 142  23 539  19  32   3   5]
 [  4   3  30  40  22  25 863   6   2   5]
 [ 15   4  13  25  39  58   4 829   2  11]
 [ 27  20  10   8   2   3   4   3 907  16]
 [ 16  45   7   6   1   2   8   7  12 896]]
2025-02-27T05:36:13.119855+0300 | DEBUG | Class precision: [0.84860968 0.89341085 0.78117914 0.67615309 0.787      0.51677852
 0.83543078 0.85640496 0.91064257 0.84848485]
2025-02-27T05:36:13.120850+0300 | DEBUG | Class recall: [0.824      0.922      0.689      0.57416667 0.787      0.67375
 0.863      0.829      0.907      0.896     ]
2025-02-27T05:36:13.170632+0300 | INFO | Training epoch #147 on client #0
2025-02-27T05:36:13.172634+0300 | DEBUG | Saving model to flat file storage. Save #147
2025-02-27T05:36:13.377954+0300 | INFO | [147,     0] loss: 0.016
2025-02-27T05:36:26.010589+0300 | INFO | [147,   100] loss: 1.490
2025-02-27T05:36:40.973613+0300 | INFO | [147,   200] loss: 1.503
2025-02-27T05:36:54.696947+0300 | INFO | [147,   300] loss: 1.494
2025-02-27T05:37:05.586962+0300 | INFO | [147,   400] loss: 1.494
2025-02-27T05:37:16.715653+0300 | INFO | [147,   500] loss: 1.503
2025-02-27T05:37:27.544772+0300 | INFO | [147,   600] loss: 1.489
2025-02-27T05:37:38.306632+0300 | INFO | [147,   700] loss: 1.484
2025-02-27T05:37:49.267660+0300 | INFO | [147,   800] loss: 1.488
2025-02-27T05:38:01.143537+0300 | INFO | [147,   900] loss: 1.487
2025-02-27T05:38:13.010221+0300 | INFO | [147,  1000] loss: 1.493
2025-02-27T05:38:23.758128+0300 | INFO | [147,  1100] loss: 1.492
2025-02-27T05:38:35.412731+0300 | INFO | [147,  1200] loss: 1.487
2025-02-27T05:38:46.677937+0300 | INFO | [147,  1300] loss: 1.489
2025-02-27T05:38:57.068735+0300 | INFO | [147,  1400] loss: 1.493
2025-02-27T05:39:08.411209+0300 | INFO | [147,  1500] loss: 1.495
2025-02-27T05:39:19.507926+0300 | INFO | [147,  1600] loss: 1.496
2025-02-27T05:39:31.274572+0300 | INFO | [147,  1700] loss: 1.499
2025-02-27T05:39:41.542524+0300 | INFO | [147,  1800] loss: 1.494
2025-02-27T05:39:53.371430+0300 | INFO | [147,  1900] loss: 1.488
2025-02-27T05:40:04.374495+0300 | INFO | [147,  2000] loss: 1.496
2025-02-27T05:40:14.662509+0300 | INFO | [147,  2100] loss: 1.496
2025-02-27T05:40:26.147749+0300 | INFO | [147,  2200] loss: 1.496
2025-02-27T05:40:37.745144+0300 | INFO | [147,  2300] loss: 1.486
2025-02-27T05:40:47.824106+0300 | INFO | [147,  2400] loss: 1.493
2025-02-27T05:40:58.983403+0300 | INFO | [147,  2500] loss: 1.501
2025-02-27T05:41:10.316364+0300 | INFO | [147,  2600] loss: 1.486
2025-02-27T05:41:23.103089+0300 | INFO | [147,  2700] loss: 1.500
2025-02-27T05:41:33.482023+0300 | INFO | [147,  2800] loss: 1.500
2025-02-27T05:41:44.589366+0300 | INFO | [147,  2900] loss: 1.499
2025-02-27T05:41:55.472862+0300 | INFO | [147,  3000] loss: 1.495
2025-02-27T05:42:06.543369+0300 | INFO | [147,  3100] loss: 1.495
2025-02-27T05:42:17.997207+0300 | INFO | [147,  3200] loss: 1.485
2025-02-27T05:42:28.679695+0300 | INFO | [147,  3300] loss: 1.490
2025-02-27T05:42:40.152278+0300 | INFO | [147,  3400] loss: 1.495
2025-02-27T05:42:51.955650+0300 | INFO | [147,  3500] loss: 1.495
2025-02-27T05:43:04.269362+0300 | INFO | [147,  3600] loss: 1.484
2025-02-27T05:43:15.112683+0300 | INFO | [147,  3700] loss: 1.491
2025-02-27T05:43:25.412633+0300 | INFO | [147,  3800] loss: 1.505
2025-02-27T05:43:36.409202+0300 | INFO | [147,  3900] loss: 1.486
2025-02-27T05:43:46.680282+0300 | INFO | [147,  4000] loss: 1.490
2025-02-27T05:43:57.493141+0300 | INFO | [147,  4100] loss: 1.502
2025-02-27T05:44:08.709390+0300 | INFO | [147,  4200] loss: 1.478
2025-02-27T05:44:20.271825+0300 | INFO | [147,  4300] loss: 1.487
2025-02-27T05:44:30.457895+0300 | INFO | [147,  4400] loss: 1.495
2025-02-27T05:44:41.542630+0300 | INFO | [147,  4500] loss: 1.485
2025-02-27T05:44:52.371486+0300 | INFO | [147,  4600] loss: 1.494
2025-02-27T05:45:03.954064+0300 | INFO | [147,  4700] loss: 1.484
2025-02-27T05:45:18.683654+0300 | INFO | [147,  4800] loss: 1.484
2025-02-27T05:45:29.929170+0300 | INFO | [147,  4900] loss: 1.499
2025-02-27T05:45:41.276136+0300 | DEBUG | Saving model to flat file storage. Save #147
2025-02-27T05:45:41.300924+0300 | INFO | Averaging client parameters
2025-02-27T05:45:41.308952+0300 | INFO | Updating parameters on client #0
2025-02-27T05:45:56.922664+0300 | DEBUG | Test set: Accuracy: 7891/10000 (79%)
2025-02-27T05:45:56.923672+0300 | DEBUG | Test set: Loss: 1.6713687181472778
2025-02-27T05:45:57.041867+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.82      0.83      1000
           1       0.87      0.94      0.90      1000
           2       0.74      0.72      0.73      1000
           3       0.68      0.55      0.61      1200
           4       0.80      0.77      0.78      1000
           5       0.50      0.64      0.56       800
           6       0.85      0.86      0.86      1000
           7       0.84      0.83      0.83      1000
           8       0.90      0.91      0.91      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T05:45:57.042942+0300 | DEBUG | Confusion Matrix:
[[820  21  37  11  12  10   5  11  43  30]
 [  4 936   3   0   1   1   3   1  12  39]
 [ 52   6 720  36  63  53  42  20   3   5]
 [ 20   9  59 664  39 308  33  33  16  19]
 [  8   6  41  45 770  49  34  39   5   3]
 [ 14   3  39 147  25 513  12  39   3   5]
 [  8   3  41  33  14  31 858   7   4   1]
 [ 16   4  13  28  38  55   4 829   3  10]
 [ 25  21   7   6   3   4   4   2 914  14]
 [ 18  64   8   4   1   8  10   5  15 867]]
2025-02-27T05:45:57.046319+0300 | DEBUG | Class precision: [0.83248731 0.8723206  0.74380165 0.68172485 0.79710145 0.49709302
 0.85373134 0.84077079 0.8978389  0.87311178]
2025-02-27T05:45:57.048686+0300 | DEBUG | Class recall: [0.82       0.936      0.72       0.55333333 0.77       0.64125
 0.858      0.829      0.914      0.867     ]
2025-02-27T05:45:57.105775+0300 | INFO | Training epoch #148 on client #0
2025-02-27T05:45:57.106779+0300 | DEBUG | Saving model to flat file storage. Save #148
2025-02-27T05:45:57.348582+0300 | INFO | [148,     0] loss: 0.015
2025-02-27T05:46:08.814605+0300 | INFO | [148,   100] loss: 1.488
2025-02-27T05:46:20.436626+0300 | INFO | [148,   200] loss: 1.501
2025-02-27T05:46:32.013995+0300 | INFO | [148,   300] loss: 1.481
2025-02-27T05:46:43.554671+0300 | INFO | [148,   400] loss: 1.498
2025-02-27T05:46:53.589073+0300 | INFO | [148,   500] loss: 1.493
2025-02-27T05:47:04.875637+0300 | INFO | [148,   600] loss: 1.482
2025-02-27T05:47:15.911556+0300 | INFO | [148,   700] loss: 1.497
2025-02-27T05:47:26.222137+0300 | INFO | [148,   800] loss: 1.484
2025-02-27T05:47:37.192301+0300 | INFO | [148,   900] loss: 1.495
2025-02-27T05:47:47.963807+0300 | INFO | [148,  1000] loss: 1.494
2025-02-27T05:47:58.219850+0300 | INFO | [148,  1100] loss: 1.493
2025-02-27T05:48:09.396467+0300 | INFO | [148,  1200] loss: 1.493
2025-02-27T05:48:20.367601+0300 | INFO | [148,  1300] loss: 1.490
2025-02-27T05:48:30.510400+0300 | INFO | [148,  1400] loss: 1.492
2025-02-27T05:48:41.412453+0300 | INFO | [148,  1500] loss: 1.485
2025-02-27T05:48:52.202066+0300 | INFO | [148,  1600] loss: 1.486
2025-02-27T05:49:03.048732+0300 | INFO | [148,  1700] loss: 1.486
2025-02-27T05:49:15.131896+0300 | INFO | [148,  1800] loss: 1.490
2025-02-27T05:49:26.540983+0300 | INFO | [148,  1900] loss: 1.492
2025-02-27T05:49:36.524072+0300 | INFO | [148,  2000] loss: 1.499
2025-02-27T05:49:47.569284+0300 | INFO | [148,  2100] loss: 1.488
2025-02-27T05:49:58.675136+0300 | INFO | [148,  2200] loss: 1.494
2025-02-27T05:50:08.792415+0300 | INFO | [148,  2300] loss: 1.505
2025-02-27T05:50:19.654848+0300 | INFO | [148,  2400] loss: 1.492
2025-02-27T05:50:30.789749+0300 | INFO | [148,  2500] loss: 1.493
2025-02-27T05:50:41.031753+0300 | INFO | [148,  2600] loss: 1.493
2025-02-27T05:50:51.906588+0300 | INFO | [148,  2700] loss: 1.490
2025-02-27T05:51:03.004843+0300 | INFO | [148,  2800] loss: 1.486
2025-02-27T05:51:15.529352+0300 | INFO | [148,  2900] loss: 1.494
2025-02-27T05:51:26.692050+0300 | INFO | [148,  3000] loss: 1.501
2025-02-27T05:51:38.932649+0300 | INFO | [148,  3100] loss: 1.492
2025-02-27T05:51:49.534146+0300 | INFO | [148,  3200] loss: 1.499
2025-02-27T05:52:02.354093+0300 | INFO | [148,  3300] loss: 1.493
2025-02-27T05:52:13.781173+0300 | INFO | [148,  3400] loss: 1.488
2025-02-27T05:52:25.239988+0300 | INFO | [148,  3500] loss: 1.501
2025-02-27T05:52:36.258654+0300 | INFO | [148,  3600] loss: 1.485
2025-02-27T05:52:46.810774+0300 | INFO | [148,  3700] loss: 1.491
2025-02-27T05:52:57.798568+0300 | INFO | [148,  3800] loss: 1.492
2025-02-27T05:53:09.280320+0300 | INFO | [148,  3900] loss: 1.488
2025-02-27T05:53:19.453016+0300 | INFO | [148,  4000] loss: 1.490
2025-02-27T05:53:30.348560+0300 | INFO | [148,  4100] loss: 1.491
2025-02-27T05:53:41.201227+0300 | INFO | [148,  4200] loss: 1.499
2025-02-27T05:53:52.480471+0300 | INFO | [148,  4300] loss: 1.499
2025-02-27T05:54:07.472951+0300 | INFO | [148,  4400] loss: 1.489
2025-02-27T05:54:18.322084+0300 | INFO | [148,  4500] loss: 1.495
2025-02-27T05:54:31.282332+0300 | INFO | [148,  4600] loss: 1.498
2025-02-27T05:54:41.404563+0300 | INFO | [148,  4700] loss: 1.493
2025-02-27T05:54:52.442562+0300 | INFO | [148,  4800] loss: 1.495
2025-02-27T05:55:03.358917+0300 | INFO | [148,  4900] loss: 1.487
2025-02-27T05:55:13.667447+0300 | DEBUG | Saving model to flat file storage. Save #148
2025-02-27T05:55:13.701453+0300 | INFO | Averaging client parameters
2025-02-27T05:55:13.720991+0300 | INFO | Updating parameters on client #0
2025-02-27T05:55:29.225562+0300 | DEBUG | Test set: Accuracy: 7912/10000 (79%)
2025-02-27T05:55:29.226564+0300 | DEBUG | Test set: Loss: 1.670135498046875
2025-02-27T05:55:29.322617+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.81      0.82      1000
           1       0.88      0.94      0.91      1000
           2       0.74      0.71      0.73      1000
           3       0.68      0.58      0.63      1200
           4       0.74      0.80      0.77      1000
           5       0.56      0.58      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.81      0.84      0.83      1000
           8       0.89      0.92      0.90      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T05:55:29.323604+0300 | DEBUG | Confusion Matrix:
[[815  17  36   8  27   6   5  11  48  27]
 [  4 936   3   0   1   1   3   2  14  36]
 [ 49   5 710  37  81  29  40  27  13   9]
 [ 18   9  61 693  61 237  42  46  15  18]
 [  8   5  38  33 804  32  37  37   5   1]
 [ 17   5  40 172  31 463  14  49   5   4]
 [  9   3  42  34  25  15 860   7   3   2]
 [ 17   4  11  24  49  45   4 836   2   8]
 [ 26  15   8   7   3   2   3   2 923  11]
 [ 20  62   5   4   1   3  10   9  14 872]]
2025-02-27T05:55:29.325614+0300 | DEBUG | Class precision: [0.82909461 0.88218662 0.7442348  0.68478261 0.74238227 0.55582233
 0.84479371 0.81481481 0.88579655 0.88259109]
2025-02-27T05:55:29.326629+0300 | DEBUG | Class recall: [0.815   0.936   0.71    0.5775  0.804   0.57875 0.86    0.836   0.923
 0.872  ]
2025-02-27T05:55:29.389912+0300 | INFO | Training epoch #149 on client #0
2025-02-27T05:55:29.390911+0300 | DEBUG | Saving model to flat file storage. Save #149
2025-02-27T05:55:29.610821+0300 | INFO | [149,     0] loss: 0.015
2025-02-27T05:55:41.004636+0300 | INFO | [149,   100] loss: 1.492
2025-02-27T05:55:52.094601+0300 | INFO | [149,   200] loss: 1.490
2025-02-27T05:56:03.575887+0300 | INFO | [149,   300] loss: 1.490
2025-02-27T05:56:14.031570+0300 | INFO | [149,   400] loss: 1.491
2025-02-27T05:56:26.922069+0300 | INFO | [149,   500] loss: 1.490
2025-02-27T05:56:37.600225+0300 | INFO | [149,   600] loss: 1.494
2025-02-27T05:56:47.919631+0300 | INFO | [149,   700] loss: 1.493
2025-02-27T05:56:59.387301+0300 | INFO | [149,   800] loss: 1.497
2025-02-27T05:57:10.819085+0300 | INFO | [149,   900] loss: 1.495
2025-02-27T05:57:21.505602+0300 | INFO | [149,  1000] loss: 1.493
2025-02-27T05:57:32.446419+0300 | INFO | [149,  1100] loss: 1.492
2025-02-27T05:57:43.671401+0300 | INFO | [149,  1200] loss: 1.488
2025-02-27T05:57:54.021400+0300 | INFO | [149,  1300] loss: 1.486
2025-02-27T05:58:04.935711+0300 | INFO | [149,  1400] loss: 1.490
2025-02-27T05:58:16.105345+0300 | INFO | [149,  1500] loss: 1.494
2025-02-27T05:58:28.044987+0300 | INFO | [149,  1600] loss: 1.496
2025-02-27T05:58:38.053080+0300 | INFO | [149,  1700] loss: 1.495
2025-02-27T05:58:51.134182+0300 | INFO | [149,  1800] loss: 1.494
2025-02-27T05:59:01.546102+0300 | INFO | [149,  1900] loss: 1.492
2025-02-27T05:59:12.324813+0300 | INFO | [149,  2000] loss: 1.487
2025-02-27T05:59:23.168978+0300 | INFO | [149,  2100] loss: 1.494
2025-02-27T05:59:34.134293+0300 | INFO | [149,  2200] loss: 1.486
2025-02-27T05:59:44.115808+0300 | INFO | [149,  2300] loss: 1.504
2025-02-27T05:59:55.202014+0300 | INFO | [149,  2400] loss: 1.483
2025-02-27T06:00:06.602484+0300 | INFO | [149,  2500] loss: 1.481
2025-02-27T06:00:16.875094+0300 | INFO | [149,  2600] loss: 1.505
2025-02-27T06:00:27.947406+0300 | INFO | [149,  2700] loss: 1.496
2025-02-27T06:00:38.779103+0300 | INFO | [149,  2800] loss: 1.491
2025-02-27T06:00:52.086679+0300 | INFO | [149,  2900] loss: 1.486
2025-02-27T06:01:02.744480+0300 | INFO | [149,  3000] loss: 1.485
2025-02-27T06:01:14.621366+0300 | INFO | [149,  3100] loss: 1.493
2025-02-27T06:01:26.564509+0300 | INFO | [149,  3200] loss: 1.487
2025-02-27T06:01:38.092156+0300 | INFO | [149,  3300] loss: 1.498
2025-02-27T06:01:49.338338+0300 | INFO | [149,  3400] loss: 1.500
2025-02-27T06:02:00.906943+0300 | INFO | [149,  3500] loss: 1.488
2025-02-27T06:02:12.453451+0300 | INFO | [149,  3600] loss: 1.492
2025-02-27T06:02:23.355804+0300 | INFO | [149,  3700] loss: 1.494
2025-02-27T06:02:35.016027+0300 | INFO | [149,  3800] loss: 1.489
2025-02-27T06:02:49.978199+0300 | INFO | [149,  3900] loss: 1.487
2025-02-27T06:03:04.027944+0300 | INFO | [149,  4000] loss: 1.491
2025-02-27T06:03:15.833556+0300 | INFO | [149,  4100] loss: 1.496
2025-02-27T06:03:26.708185+0300 | INFO | [149,  4200] loss: 1.495
2025-02-27T06:03:38.298272+0300 | INFO | [149,  4300] loss: 1.483
2025-02-27T06:03:49.820882+0300 | INFO | [149,  4400] loss: 1.498
2025-02-27T06:04:00.864716+0300 | INFO | [149,  4500] loss: 1.497
2025-02-27T06:04:12.850784+0300 | INFO | [149,  4600] loss: 1.497
2025-02-27T06:04:25.155631+0300 | INFO | [149,  4700] loss: 1.495
2025-02-27T06:04:36.712319+0300 | INFO | [149,  4800] loss: 1.485
2025-02-27T06:04:48.316084+0300 | INFO | [149,  4900] loss: 1.493
2025-02-27T06:04:59.617249+0300 | DEBUG | Saving model to flat file storage. Save #149
2025-02-27T06:04:59.649021+0300 | INFO | Averaging client parameters
2025-02-27T06:04:59.663260+0300 | INFO | Updating parameters on client #0
2025-02-27T06:05:15.763739+0300 | DEBUG | Test set: Accuracy: 7911/10000 (79%)
2025-02-27T06:05:15.766739+0300 | DEBUG | Test set: Loss: 1.6699442863464355
2025-02-27T06:05:15.864379+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.76      0.71      0.73      1000
           3       0.67      0.58      0.62      1200
           4       0.79      0.80      0.79      1000
           5       0.53      0.63      0.58       800
           6       0.84      0.87      0.85      1000
           7       0.86      0.81      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T06:05:15.868384+0300 | DEBUG | Confusion Matrix:
[[847  19  33   9  14  10   5   7  32  24]
 [  8 931   3   0   1   1   4   2  12  38]
 [ 55   6 707  46  66  44  41  19   8   8]
 [ 23   9  49 692  43 276  49  28  13  18]
 [ 12   6  39  45 800  37  29  25   6   1]
 [ 16   1  32 164  27 506  16  29   4   5]
 [  9   4  38  32  19  18 866   6   6   2]
 [ 17   4  13  34  46  58   4 813   4   7]
 [ 48  19   8  10   2   3   6   2 890  12]
 [ 26  60   6   7   1   4  10   9  18 859]]
2025-02-27T06:05:15.871372+0300 | DEBUG | Class precision: [0.79830349 0.87913126 0.76185345 0.66602502 0.78508342 0.52873563
 0.8407767  0.86489362 0.89627392 0.88193018]
2025-02-27T06:05:15.872858+0300 | DEBUG | Class recall: [0.847      0.931      0.707      0.57666667 0.8        0.6325
 0.866      0.813      0.89       0.859     ]
2025-02-27T06:05:15.928028+0300 | INFO | Training epoch #150 on client #0
2025-02-27T06:05:15.929027+0300 | DEBUG | Saving model to flat file storage. Save #150
2025-02-27T06:05:16.139115+0300 | INFO | [150,     0] loss: 0.015
2025-02-27T06:05:27.999450+0300 | INFO | [150,   100] loss: 1.491
2025-02-27T06:05:39.442097+0300 | INFO | [150,   200] loss: 1.484
2025-02-27T06:05:50.144264+0300 | INFO | [150,   300] loss: 1.493
2025-02-27T06:06:02.024683+0300 | INFO | [150,   400] loss: 1.487
2025-02-27T06:06:13.979713+0300 | INFO | [150,   500] loss: 1.487
2025-02-27T06:06:24.826616+0300 | INFO | [150,   600] loss: 1.492
2025-02-27T06:06:36.423011+0300 | INFO | [150,   700] loss: 1.495
2025-02-27T06:06:48.214302+0300 | INFO | [150,   800] loss: 1.485
2025-02-27T06:06:59.690160+0300 | INFO | [150,   900] loss: 1.488
2025-02-27T06:07:10.773101+0300 | INFO | [150,  1000] loss: 1.493
2025-02-27T06:07:22.385134+0300 | INFO | [150,  1100] loss: 1.488
2025-02-27T06:07:33.973139+0300 | INFO | [150,  1200] loss: 1.493
2025-02-27T06:07:44.705010+0300 | INFO | [150,  1300] loss: 1.488
2025-02-27T06:07:56.478483+0300 | INFO | [150,  1400] loss: 1.499
2025-02-27T06:08:10.919571+0300 | INFO | [150,  1500] loss: 1.493
2025-02-27T06:08:23.175350+0300 | INFO | [150,  1600] loss: 1.490
2025-02-27T06:08:37.787801+0300 | INFO | [150,  1700] loss: 1.500
2025-02-27T06:08:50.917740+0300 | INFO | [150,  1800] loss: 1.491
2025-02-27T06:09:04.602040+0300 | INFO | [150,  1900] loss: 1.492
2025-02-27T06:09:19.530592+0300 | INFO | [150,  2000] loss: 1.499
2025-02-27T06:09:34.686026+0300 | INFO | [150,  2100] loss: 1.488
2025-02-27T06:09:52.321624+0300 | INFO | [150,  2200] loss: 1.493
2025-02-27T06:10:08.022911+0300 | INFO | [150,  2300] loss: 1.487
2025-02-27T06:10:23.089141+0300 | INFO | [150,  2400] loss: 1.490
2025-02-27T06:10:38.915276+0300 | INFO | [150,  2500] loss: 1.499
2025-02-27T06:10:55.565977+0300 | INFO | [150,  2600] loss: 1.496
2025-02-27T06:11:08.560981+0300 | INFO | [150,  2700] loss: 1.489
2025-02-27T06:11:22.236698+0300 | INFO | [150,  2800] loss: 1.501
2025-02-27T06:11:38.076369+0300 | INFO | [150,  2900] loss: 1.496
2025-02-27T06:11:55.283784+0300 | INFO | [150,  3000] loss: 1.488
2025-02-27T06:12:10.213752+0300 | INFO | [150,  3100] loss: 1.496
2025-02-27T06:12:27.447172+0300 | INFO | [150,  3200] loss: 1.489
2025-02-27T06:12:43.904770+0300 | INFO | [150,  3300] loss: 1.497
2025-02-27T06:12:58.544645+0300 | INFO | [150,  3400] loss: 1.485
2025-02-27T06:13:14.902820+0300 | INFO | [150,  3500] loss: 1.498
2025-02-27T06:13:28.763415+0300 | INFO | [150,  3600] loss: 1.487
2025-02-27T06:13:41.429855+0300 | INFO | [150,  3700] loss: 1.494
2025-02-27T06:13:52.816635+0300 | INFO | [150,  3800] loss: 1.489
2025-02-27T06:14:05.025985+0300 | INFO | [150,  3900] loss: 1.495
2025-02-27T06:14:16.522415+0300 | INFO | [150,  4000] loss: 1.495
2025-02-27T06:14:28.914093+0300 | INFO | [150,  4100] loss: 1.487
2025-02-27T06:14:39.389305+0300 | INFO | [150,  4200] loss: 1.493
2025-02-27T06:14:50.869279+0300 | INFO | [150,  4300] loss: 1.490
2025-02-27T06:15:02.883639+0300 | INFO | [150,  4400] loss: 1.496
2025-02-27T06:15:13.159274+0300 | INFO | [150,  4500] loss: 1.487
2025-02-27T06:15:24.273911+0300 | INFO | [150,  4600] loss: 1.487
2025-02-27T06:15:36.545937+0300 | INFO | [150,  4700] loss: 1.486
2025-02-27T06:15:47.717520+0300 | INFO | [150,  4800] loss: 1.498
2025-02-27T06:15:57.915505+0300 | INFO | [150,  4900] loss: 1.505
2025-02-27T06:16:08.904896+0300 | DEBUG | Updating LR for optimizer
2025-02-27T06:16:08.907908+0300 | DEBUG | New LR: 1.25e-05
2025-02-27T06:16:08.907908+0300 | DEBUG | Saving model to flat file storage. Save #150
2025-02-27T06:16:08.933198+0300 | INFO | Averaging client parameters
2025-02-27T06:16:08.944221+0300 | INFO | Updating parameters on client #0
2025-02-27T06:16:24.987067+0300 | DEBUG | Test set: Accuracy: 7898/10000 (79%)
2025-02-27T06:16:24.989084+0300 | DEBUG | Test set: Loss: 1.6696869134902954
2025-02-27T06:16:25.087060+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.69      0.53      0.60      1200
           4       0.76      0.80      0.78      1000
           5       0.53      0.65      0.58       800
           6       0.83      0.85      0.84      1000
           7       0.84      0.84      0.84      1000
           8       0.91      0.90      0.90      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T06:16:25.090063+0300 | DEBUG | Confusion Matrix:
[[821  16  44   7  23   8  10  10  32  29]
 [  7 924   2   0   1   1   4   1  12  48]
 [ 51   3 725  36  65  46  42  21   3   8]
 [ 17   6  65 640  62 290  49  39  10  22]
 [  9   3  37  37 801  39  34  34   5   1]
 [ 14   1  36 139  30 518  14  41   3   4]
 [  8   3  40  28  25  25 855   9   4   3]
 [ 14   4  19  21  43  47   3 839   1   9]
 [ 41  16  10  10   2   3   4   3 895  16]
 [ 23  48   8   4   1   3  10   7  16 880]]
2025-02-27T06:16:25.094057+0300 | DEBUG | Class precision: [0.81691542 0.90234375 0.73529412 0.69414317 0.76068376 0.52857143
 0.83414634 0.83565737 0.91233435 0.8627451 ]
2025-02-27T06:16:25.095061+0300 | DEBUG | Class recall: [0.821      0.924      0.725      0.53333333 0.801      0.6475
 0.855      0.839      0.895      0.88      ]
2025-02-27T06:16:25.148382+0300 | INFO | Training epoch #151 on client #0
2025-02-27T06:16:25.149381+0300 | DEBUG | Saving model to flat file storage. Save #151
2025-02-27T06:16:25.341961+0300 | INFO | [151,     0] loss: 0.015
2025-02-27T06:16:36.867976+0300 | INFO | [151,   100] loss: 1.499
2025-02-27T06:16:47.699784+0300 | INFO | [151,   200] loss: 1.494
2025-02-27T06:16:58.710469+0300 | INFO | [151,   300] loss: 1.492
2025-02-27T06:17:10.108328+0300 | INFO | [151,   400] loss: 1.482
2025-02-27T06:17:20.384398+0300 | INFO | [151,   500] loss: 1.490
2025-02-27T06:17:31.722866+0300 | INFO | [151,   600] loss: 1.506
2025-02-27T06:17:42.494997+0300 | INFO | [151,   700] loss: 1.479
2025-02-27T06:17:52.456434+0300 | INFO | [151,   800] loss: 1.494
2025-02-27T06:18:03.975985+0300 | INFO | [151,   900] loss: 1.487
2025-02-27T06:18:15.051407+0300 | INFO | [151,  1000] loss: 1.490
2025-02-27T06:18:25.234654+0300 | INFO | [151,  1100] loss: 1.496
2025-02-27T06:18:36.698205+0300 | INFO | [151,  1200] loss: 1.498
2025-02-27T06:18:48.387731+0300 | INFO | [151,  1300] loss: 1.502
2025-02-27T06:18:58.684655+0300 | INFO | [151,  1400] loss: 1.493
2025-02-27T06:19:10.478242+0300 | INFO | [151,  1500] loss: 1.483
2025-02-27T06:19:21.593546+0300 | INFO | [151,  1600] loss: 1.491
2025-02-27T06:19:32.826943+0300 | INFO | [151,  1700] loss: 1.489
2025-02-27T06:19:42.795944+0300 | INFO | [151,  1800] loss: 1.485
2025-02-27T06:19:53.790261+0300 | INFO | [151,  1900] loss: 1.484
2025-02-27T06:20:04.789628+0300 | INFO | [151,  2000] loss: 1.489
2025-02-27T06:20:14.964038+0300 | INFO | [151,  2100] loss: 1.484
2025-02-27T06:20:26.589027+0300 | INFO | [151,  2200] loss: 1.499
2025-02-27T06:20:37.480694+0300 | INFO | [151,  2300] loss: 1.497
2025-02-27T06:20:47.855552+0300 | INFO | [151,  2400] loss: 1.494
2025-02-27T06:20:59.089357+0300 | INFO | [151,  2500] loss: 1.501
2025-02-27T06:21:10.396761+0300 | INFO | [151,  2600] loss: 1.490
2025-02-27T06:21:22.522922+0300 | INFO | [151,  2700] loss: 1.485
2025-02-27T06:21:33.320496+0300 | INFO | [151,  2800] loss: 1.498
2025-02-27T06:21:45.040947+0300 | INFO | [151,  2900] loss: 1.498
2025-02-27T06:21:55.805865+0300 | INFO | [151,  3000] loss: 1.499
2025-02-27T06:22:12.094079+0300 | INFO | [151,  3100] loss: 1.486
2025-02-27T06:22:22.334805+0300 | INFO | [151,  3200] loss: 1.500
2025-02-27T06:22:33.360147+0300 | INFO | [151,  3300] loss: 1.502
2025-02-27T06:22:44.367891+0300 | INFO | [151,  3400] loss: 1.489
2025-02-27T06:22:54.764588+0300 | INFO | [151,  3500] loss: 1.490
2025-02-27T06:23:06.050986+0300 | INFO | [151,  3600] loss: 1.495
2025-02-27T06:23:19.037183+0300 | INFO | [151,  3700] loss: 1.492
2025-02-27T06:23:29.760629+0300 | INFO | [151,  3800] loss: 1.484
2025-02-27T06:23:40.752288+0300 | INFO | [151,  3900] loss: 1.493
2025-02-27T06:23:51.429058+0300 | INFO | [151,  4000] loss: 1.492
2025-02-27T06:24:02.126748+0300 | INFO | [151,  4100] loss: 1.488
2025-02-27T06:24:13.052559+0300 | INFO | [151,  4200] loss: 1.493
2025-02-27T06:24:24.072578+0300 | INFO | [151,  4300] loss: 1.501
2025-02-27T06:24:35.640260+0300 | INFO | [151,  4400] loss: 1.495
2025-02-27T06:24:46.722443+0300 | INFO | [151,  4500] loss: 1.482
2025-02-27T06:24:57.715188+0300 | INFO | [151,  4600] loss: 1.488
2025-02-27T06:25:08.622744+0300 | INFO | [151,  4700] loss: 1.483
2025-02-27T06:25:18.873769+0300 | INFO | [151,  4800] loss: 1.482
2025-02-27T06:25:29.952831+0300 | INFO | [151,  4900] loss: 1.493
2025-02-27T06:25:40.782720+0300 | DEBUG | Saving model to flat file storage. Save #151
2025-02-27T06:25:40.806851+0300 | INFO | Averaging client parameters
2025-02-27T06:25:40.811757+0300 | INFO | Updating parameters on client #0
2025-02-27T06:25:58.307588+0300 | DEBUG | Test set: Accuracy: 7926/10000 (79%)
2025-02-27T06:25:58.309590+0300 | DEBUG | Test set: Loss: 1.667380452156067
2025-02-27T06:25:58.419437+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.70      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.80      0.79      1000
           5       0.53      0.65      0.58       800
           6       0.85      0.85      0.85      1000
           7       0.83      0.85      0.84      1000
           8       0.91      0.90      0.90      1000
           9       0.84      0.90      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T06:25:58.423839+0300 | DEBUG | Confusion Matrix:
[[824  16  40   9  21   7   4   9  35  35]
 [  7 921   2   0   1   1   4   1   9  54]
 [ 51   7 697  41  73  51  43  23   5   9]
 [ 16   6  44 675  50 282  45  41  13  28]
 [ 10   5  30  43 797  41  27  38   6   3]
 [ 15   3  30 143  26 517  15  42   3   6]
 [  8   5  37  33  22  28 850  10   4   3]
 [ 15   4  14  22  36  45   3 848   2  11]
 [ 39  17   5  10   3   3   4   2 897  20]
 [ 18  41   6   4   1   2   7   8  13 900]]
2025-02-27T06:25:58.427838+0300 | DEBUG | Class precision: [0.82153539 0.89853659 0.77016575 0.68877551 0.77378641 0.52917093
 0.84830339 0.8297456  0.90881459 0.84190833]
2025-02-27T06:25:58.430179+0300 | DEBUG | Class recall: [0.824   0.921   0.697   0.5625  0.797   0.64625 0.85    0.848   0.897
 0.9    ]
2025-02-27T06:25:58.483553+0300 | INFO | Training epoch #152 on client #0
2025-02-27T06:25:58.486089+0300 | DEBUG | Saving model to flat file storage. Save #152
2025-02-27T06:25:58.727038+0300 | INFO | [152,     0] loss: 0.016
2025-02-27T06:26:09.481665+0300 | INFO | [152,   100] loss: 1.502
2025-02-27T06:26:20.707203+0300 | INFO | [152,   200] loss: 1.497
2025-02-27T06:26:32.024043+0300 | INFO | [152,   300] loss: 1.488
2025-02-27T06:26:42.314639+0300 | INFO | [152,   400] loss: 1.498
2025-02-27T06:26:53.162736+0300 | INFO | [152,   500] loss: 1.496
2025-02-27T06:27:04.449689+0300 | INFO | [152,   600] loss: 1.487
2025-02-27T06:27:15.525405+0300 | INFO | [152,   700] loss: 1.497
2025-02-27T06:27:25.892344+0300 | INFO | [152,   800] loss: 1.490
2025-02-27T06:27:36.849573+0300 | INFO | [152,   900] loss: 1.495
2025-02-27T06:27:47.864185+0300 | INFO | [152,  1000] loss: 1.492
2025-02-27T06:27:58.579828+0300 | INFO | [152,  1100] loss: 1.495
2025-02-27T06:28:09.814794+0300 | INFO | [152,  1200] loss: 1.486
2025-02-27T06:28:20.722531+0300 | INFO | [152,  1300] loss: 1.495
2025-02-27T06:28:31.429515+0300 | INFO | [152,  1400] loss: 1.488
2025-02-27T06:28:43.165283+0300 | INFO | [152,  1500] loss: 1.492
2025-02-27T06:28:54.669402+0300 | INFO | [152,  1600] loss: 1.486
2025-02-27T06:29:08.659424+0300 | INFO | [152,  1700] loss: 1.489
2025-02-27T06:29:19.179378+0300 | INFO | [152,  1800] loss: 1.498
2025-02-27T06:29:30.364938+0300 | INFO | [152,  1900] loss: 1.489
2025-02-27T06:29:41.298712+0300 | INFO | [152,  2000] loss: 1.485
2025-02-27T06:29:51.287109+0300 | INFO | [152,  2100] loss: 1.497
2025-02-27T06:30:02.148635+0300 | INFO | [152,  2200] loss: 1.487
2025-02-27T06:30:13.256058+0300 | INFO | [152,  2300] loss: 1.485
2025-02-27T06:30:23.796892+0300 | INFO | [152,  2400] loss: 1.489
2025-02-27T06:30:34.700311+0300 | INFO | [152,  2500] loss: 1.491
2025-02-27T06:30:49.718163+0300 | INFO | [152,  2600] loss: 1.493
2025-02-27T06:31:02.576202+0300 | INFO | [152,  2700] loss: 1.496
2025-02-27T06:31:13.962655+0300 | INFO | [152,  2800] loss: 1.489
2025-02-27T06:31:25.295076+0300 | INFO | [152,  2900] loss: 1.490
2025-02-27T06:31:36.091064+0300 | INFO | [152,  3000] loss: 1.489
2025-02-27T06:31:47.894835+0300 | INFO | [152,  3100] loss: 1.487
2025-02-27T06:31:58.703192+0300 | INFO | [152,  3200] loss: 1.486
2025-02-27T06:32:11.138508+0300 | INFO | [152,  3300] loss: 1.488
2025-02-27T06:32:24.754150+0300 | INFO | [152,  3400] loss: 1.490
2025-02-27T06:32:35.999678+0300 | INFO | [152,  3500] loss: 1.492
2025-02-27T06:32:46.880615+0300 | INFO | [152,  3600] loss: 1.493
2025-02-27T06:32:58.958885+0300 | INFO | [152,  3700] loss: 1.489
2025-02-27T06:33:11.174719+0300 | INFO | [152,  3800] loss: 1.486
2025-02-27T06:33:22.313497+0300 | INFO | [152,  3900] loss: 1.487
2025-02-27T06:33:34.061025+0300 | INFO | [152,  4000] loss: 1.500
2025-02-27T06:33:45.495340+0300 | INFO | [152,  4100] loss: 1.492
2025-02-27T06:33:57.156083+0300 | INFO | [152,  4200] loss: 1.498
2025-02-27T06:34:08.904549+0300 | INFO | [152,  4300] loss: 1.488
2025-02-27T06:34:21.769448+0300 | INFO | [152,  4400] loss: 1.487
2025-02-27T06:34:33.599371+0300 | INFO | [152,  4500] loss: 1.496
2025-02-27T06:34:45.517228+0300 | INFO | [152,  4600] loss: 1.494
2025-02-27T06:34:57.045761+0300 | INFO | [152,  4700] loss: 1.500
2025-02-27T06:35:08.620472+0300 | INFO | [152,  4800] loss: 1.485
2025-02-27T06:35:19.491080+0300 | INFO | [152,  4900] loss: 1.486
2025-02-27T06:35:30.392995+0300 | DEBUG | Saving model to flat file storage. Save #152
2025-02-27T06:35:30.424045+0300 | INFO | Averaging client parameters
2025-02-27T06:35:30.437206+0300 | INFO | Updating parameters on client #0
2025-02-27T06:35:46.367419+0300 | DEBUG | Test set: Accuracy: 7943/10000 (79%)
2025-02-27T06:35:46.374435+0300 | DEBUG | Test set: Loss: 1.66568124294281
2025-02-27T06:35:46.491541+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.91      0.91      0.91      1000
           2       0.76      0.71      0.74      1000
           3       0.67      0.58      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.83      0.84      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T06:35:46.492560+0300 | DEBUG | Confusion Matrix:
[[829  12  41  10  18   9   7   8  41  25]
 [  7 911   2   0   1   1   5   1  21  51]
 [ 46   6 713  45  71  40  41  22   8   8]
 [ 18   5  47 694  51 270  47  37  15  16]
 [ 10   4  31  50 798  39  26  35   6   1]
 [ 14   1  35 158  28 495  17  42   5   5]
 [  7   4  37  39  18  19 860   9   4   3]
 [ 13   3  16  25  41  49   3 839   2   9]
 [ 31  11   6  11   2   3   4   2 917  13]
 [ 21  39   7   5   1   5   8  10  17 887]]
2025-02-27T06:35:46.494561+0300 | DEBUG | Class precision: [0.83232932 0.91465863 0.76256684 0.66923819 0.7755102  0.53225806
 0.84479371 0.83482587 0.88513514 0.87131631]
2025-02-27T06:35:46.494561+0300 | DEBUG | Class recall: [0.829      0.911      0.713      0.57833333 0.798      0.61875
 0.86       0.839      0.917      0.887     ]
2025-02-27T06:35:46.498611+0300 | INFO | Training epoch #153 on client #0
2025-02-27T06:35:46.498611+0300 | DEBUG | Saving model to flat file storage. Save #153
2025-02-27T06:35:46.755128+0300 | INFO | [153,     0] loss: 0.016
2025-02-27T06:35:57.560363+0300 | INFO | [153,   100] loss: 1.496
2025-02-27T06:36:08.638160+0300 | INFO | [153,   200] loss: 1.493
2025-02-27T06:36:19.881307+0300 | INFO | [153,   300] loss: 1.488
2025-02-27T06:36:30.368184+0300 | INFO | [153,   400] loss: 1.497
2025-02-27T06:36:41.306922+0300 | INFO | [153,   500] loss: 1.502
2025-02-27T06:36:54.249640+0300 | INFO | [153,   600] loss: 1.499
2025-02-27T06:37:04.532907+0300 | INFO | [153,   700] loss: 1.486
2025-02-27T06:37:15.773301+0300 | INFO | [153,   800] loss: 1.491
2025-02-27T06:37:26.992014+0300 | INFO | [153,   900] loss: 1.497
2025-02-27T06:37:38.384883+0300 | INFO | [153,  1000] loss: 1.485
2025-02-27T06:37:49.012531+0300 | INFO | [153,  1100] loss: 1.484
2025-02-27T06:38:00.752923+0300 | INFO | [153,  1200] loss: 1.484
2025-02-27T06:38:12.496806+0300 | INFO | [153,  1300] loss: 1.486
2025-02-27T06:38:22.815379+0300 | INFO | [153,  1400] loss: 1.481
2025-02-27T06:38:34.478377+0300 | INFO | [153,  1500] loss: 1.495
2025-02-27T06:38:45.718640+0300 | INFO | [153,  1600] loss: 1.488
2025-02-27T06:38:56.228526+0300 | INFO | [153,  1700] loss: 1.488
2025-02-27T06:39:07.955368+0300 | INFO | [153,  1800] loss: 1.486
2025-02-27T06:39:18.892945+0300 | INFO | [153,  1900] loss: 1.497
2025-02-27T06:39:30.536974+0300 | INFO | [153,  2000] loss: 1.491
2025-02-27T06:39:43.271566+0300 | INFO | [153,  2100] loss: 1.495
2025-02-27T06:39:57.020274+0300 | INFO | [153,  2200] loss: 1.497
2025-02-27T06:40:08.049038+0300 | INFO | [153,  2300] loss: 1.490
2025-02-27T06:40:18.623619+0300 | INFO | [153,  2400] loss: 1.490
2025-02-27T06:40:29.204444+0300 | INFO | [153,  2500] loss: 1.490
2025-02-27T06:40:41.070012+0300 | INFO | [153,  2600] loss: 1.490
2025-02-27T06:40:52.048229+0300 | INFO | [153,  2700] loss: 1.488
2025-02-27T06:41:02.278453+0300 | INFO | [153,  2800] loss: 1.502
2025-02-27T06:41:13.669310+0300 | INFO | [153,  2900] loss: 1.486
2025-02-27T06:41:24.763515+0300 | INFO | [153,  3000] loss: 1.496
2025-02-27T06:41:34.669523+0300 | INFO | [153,  3100] loss: 1.499
2025-02-27T06:41:45.791857+0300 | INFO | [153,  3200] loss: 1.487
2025-02-27T06:41:58.409483+0300 | INFO | [153,  3300] loss: 1.493
2025-02-27T06:42:08.300842+0300 | INFO | [153,  3400] loss: 1.490
2025-02-27T06:42:19.591948+0300 | INFO | [153,  3500] loss: 1.490
2025-02-27T06:42:30.828470+0300 | INFO | [153,  3600] loss: 1.495
2025-02-27T06:42:41.063428+0300 | INFO | [153,  3700] loss: 1.494
2025-02-27T06:42:52.314947+0300 | INFO | [153,  3800] loss: 1.494
2025-02-27T06:43:04.534159+0300 | INFO | [153,  3900] loss: 1.494
2025-02-27T06:43:15.425252+0300 | INFO | [153,  4000] loss: 1.493
2025-02-27T06:43:25.715439+0300 | INFO | [153,  4100] loss: 1.485
2025-02-27T06:43:37.510143+0300 | INFO | [153,  4200] loss: 1.487
2025-02-27T06:43:48.421333+0300 | INFO | [153,  4300] loss: 1.493
2025-02-27T06:43:58.777403+0300 | INFO | [153,  4400] loss: 1.488
2025-02-27T06:44:10.089467+0300 | INFO | [153,  4500] loss: 1.487
2025-02-27T06:44:21.214885+0300 | INFO | [153,  4600] loss: 1.496
2025-02-27T06:44:31.645345+0300 | INFO | [153,  4700] loss: 1.487
2025-02-27T06:44:42.780412+0300 | INFO | [153,  4800] loss: 1.499
2025-02-27T06:44:53.590772+0300 | INFO | [153,  4900] loss: 1.488
2025-02-27T06:45:03.772842+0300 | DEBUG | Saving model to flat file storage. Save #153
2025-02-27T06:45:03.801833+0300 | INFO | Averaging client parameters
2025-02-27T06:45:03.810842+0300 | INFO | Updating parameters on client #0
2025-02-27T06:45:20.278086+0300 | DEBUG | Test set: Accuracy: 7938/10000 (79%)
2025-02-27T06:45:20.282088+0300 | DEBUG | Test set: Loss: 1.6666841506958008
2025-02-27T06:45:20.384501+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.82      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.78      0.70      0.73      1000
           3       0.68      0.58      0.63      1200
           4       0.78      0.80      0.79      1000
           5       0.52      0.62      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.83      0.84      1000
           8       0.89      0.92      0.91      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T06:45:20.386516+0300 | DEBUG | Confusion Matrix:
[[825  17  38   9  18   8   7   6  40  32]
 [  5 929   2   0   1   1   3   0  17  42]
 [ 51   7 697  42  68  52  47  18  10   8]
 [ 17   7  43 700  50 266  48  35  15  19]
 [ 12   6  30  46 802  41  29  27   5   2]
 [ 15   4  31 163  27 498  16  38   5   3]
 [  8   5  33  35  21  23 862   6   3   4]
 [ 16   4  14  29  42  54   3 826   2  10]
 [ 27  13   5   6   2   3   4   2 922  16]
 [ 22  48   6   7   1   4  11   7  17 877]]
2025-02-27T06:45:20.390517+0300 | DEBUG | Class precision: [0.82665331 0.89326923 0.7753059  0.67502411 0.77713178 0.52421053
 0.8368932  0.85595855 0.88996139 0.86574531]
2025-02-27T06:45:20.392764+0300 | DEBUG | Class recall: [0.825      0.929      0.697      0.58333333 0.802      0.6225
 0.862      0.826      0.922      0.877     ]
2025-02-27T06:45:20.448092+0300 | INFO | Training epoch #154 on client #0
2025-02-27T06:45:20.449226+0300 | DEBUG | Saving model to flat file storage. Save #154
2025-02-27T06:45:20.676525+0300 | INFO | [154,     0] loss: 0.016
2025-02-27T06:45:32.570674+0300 | INFO | [154,   100] loss: 1.495
2025-02-27T06:45:43.703947+0300 | INFO | [154,   200] loss: 1.494
2025-02-27T06:45:54.594061+0300 | INFO | [154,   300] loss: 1.485
2025-02-27T06:46:05.122152+0300 | INFO | [154,   400] loss: 1.484
2025-02-27T06:46:16.741790+0300 | INFO | [154,   500] loss: 1.483
2025-02-27T06:46:28.240444+0300 | INFO | [154,   600] loss: 1.490
2025-02-27T06:46:38.542147+0300 | INFO | [154,   700] loss: 1.489
2025-02-27T06:46:50.087597+0300 | INFO | [154,   800] loss: 1.499
2025-02-27T06:47:01.188157+0300 | INFO | [154,   900] loss: 1.498
2025-02-27T06:47:11.648847+0300 | INFO | [154,  1000] loss: 1.482
2025-02-27T06:47:22.852816+0300 | INFO | [154,  1100] loss: 1.497
2025-02-27T06:47:33.833069+0300 | INFO | [154,  1200] loss: 1.493
2025-02-27T06:47:44.040601+0300 | INFO | [154,  1300] loss: 1.497
2025-02-27T06:47:55.462715+0300 | INFO | [154,  1400] loss: 1.488
2025-02-27T06:48:06.553007+0300 | INFO | [154,  1500] loss: 1.488
2025-02-27T06:48:19.726154+0300 | INFO | [154,  1600] loss: 1.498
2025-02-27T06:48:33.190913+0300 | INFO | [154,  1700] loss: 1.498
2025-02-27T06:48:44.187463+0300 | INFO | [154,  1800] loss: 1.494
2025-02-27T06:48:55.391832+0300 | INFO | [154,  1900] loss: 1.491
2025-02-27T06:49:05.628589+0300 | INFO | [154,  2000] loss: 1.495
2025-02-27T06:49:17.291257+0300 | INFO | [154,  2100] loss: 1.482
2025-02-27T06:49:28.700478+0300 | INFO | [154,  2200] loss: 1.497
2025-02-27T06:49:39.442086+0300 | INFO | [154,  2300] loss: 1.486
2025-02-27T06:49:49.969401+0300 | INFO | [154,  2400] loss: 1.492
2025-02-27T06:50:01.251514+0300 | INFO | [154,  2500] loss: 1.486
2025-02-27T06:50:12.797526+0300 | INFO | [154,  2600] loss: 1.491
2025-02-27T06:50:23.063888+0300 | INFO | [154,  2700] loss: 1.495
2025-02-27T06:50:34.175480+0300 | INFO | [154,  2800] loss: 1.482
2025-02-27T06:50:45.313499+0300 | INFO | [154,  2900] loss: 1.496
2025-02-27T06:50:55.881499+0300 | INFO | [154,  3000] loss: 1.493
2025-02-27T06:51:06.647290+0300 | INFO | [154,  3100] loss: 1.496
2025-02-27T06:51:17.944200+0300 | INFO | [154,  3200] loss: 1.493
2025-02-27T06:51:28.413364+0300 | INFO | [154,  3300] loss: 1.497
2025-02-27T06:51:39.231654+0300 | INFO | [154,  3400] loss: 1.489
2025-02-27T06:51:50.377465+0300 | INFO | [154,  3500] loss: 1.486
2025-02-27T06:52:00.395187+0300 | INFO | [154,  3600] loss: 1.501
2025-02-27T06:52:11.244366+0300 | INFO | [154,  3700] loss: 1.488
2025-02-27T06:52:22.448211+0300 | INFO | [154,  3800] loss: 1.496
2025-02-27T06:52:33.145509+0300 | INFO | [154,  3900] loss: 1.486
2025-02-27T06:52:44.293215+0300 | INFO | [154,  4000] loss: 1.495
2025-02-27T06:52:56.109686+0300 | INFO | [154,  4100] loss: 1.492
2025-02-27T06:53:06.486579+0300 | INFO | [154,  4200] loss: 1.488
2025-02-27T06:53:17.199670+0300 | INFO | [154,  4300] loss: 1.489
2025-02-27T06:53:28.409659+0300 | INFO | [154,  4400] loss: 1.488
2025-02-27T06:53:39.480779+0300 | INFO | [154,  4500] loss: 1.488
2025-02-27T06:53:49.697236+0300 | INFO | [154,  4600] loss: 1.490
2025-02-27T06:54:00.889492+0300 | INFO | [154,  4700] loss: 1.490
2025-02-27T06:54:13.715100+0300 | INFO | [154,  4800] loss: 1.486
2025-02-27T06:54:24.129114+0300 | INFO | [154,  4900] loss: 1.488
2025-02-27T06:54:36.735511+0300 | DEBUG | Saving model to flat file storage. Save #154
2025-02-27T06:54:36.758944+0300 | INFO | Averaging client parameters
2025-02-27T06:54:36.765959+0300 | INFO | Updating parameters on client #0
2025-02-27T06:54:52.240646+0300 | DEBUG | Test set: Accuracy: 7943/10000 (79%)
2025-02-27T06:54:52.241650+0300 | DEBUG | Test set: Loss: 1.6656605005264282
2025-02-27T06:54:52.341966+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.90      0.93      0.91      1000
           2       0.78      0.68      0.73      1000
           3       0.69      0.58      0.63      1200
           4       0.74      0.82      0.78      1000
           5       0.55      0.62      0.59       800
           6       0.82      0.88      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T06:54:52.346459+0300 | DEBUG | Confusion Matrix:
[[846  14  28   9  19   6   7   6  39  26]
 [  5 927   3   0   2   1   3   0  18  41]
 [ 59   6 683  43  79  41  58  17   8   6]
 [ 21   8  46 691  68 250  54  32  15  15]
 [ 11   6  26  37 825  35  31  21   5   3]
 [ 12   1  32 160  34 498  19  35   5   4]
 [  8   3  30  32  23  12 877   7   5   3]
 [ 18   4  12  26  57  51   3 815   3  11]
 [ 37  11   7   6   2   3   4   2 913  15]
 [ 29  53   7   3   1   4  11   6  18 868]]
2025-02-27T06:54:52.347955+0300 | DEBUG | Class precision: [0.80879541 0.89738625 0.78146453 0.68619662 0.74324324 0.5527192
 0.82193065 0.86609989 0.88726919 0.875     ]
2025-02-27T06:54:52.349485+0300 | DEBUG | Class recall: [0.846      0.927      0.683      0.57583333 0.825      0.6225
 0.877      0.815      0.913      0.868     ]
2025-02-27T06:54:52.401312+0300 | INFO | Training epoch #155 on client #0
2025-02-27T06:54:52.403616+0300 | DEBUG | Saving model to flat file storage. Save #155
2025-02-27T06:54:52.609105+0300 | INFO | [155,     0] loss: 0.015
2025-02-27T06:55:03.897240+0300 | INFO | [155,   100] loss: 1.488
2025-02-27T06:55:14.281532+0300 | INFO | [155,   200] loss: 1.491
2025-02-27T06:55:24.750230+0300 | INFO | [155,   300] loss: 1.488
2025-02-27T06:55:35.857138+0300 | INFO | [155,   400] loss: 1.489
2025-02-27T06:55:46.252952+0300 | INFO | [155,   500] loss: 1.497
2025-02-27T06:55:57.385410+0300 | INFO | [155,   600] loss: 1.490
2025-02-27T06:56:08.786457+0300 | INFO | [155,   700] loss: 1.491
2025-02-27T06:56:19.986944+0300 | INFO | [155,   800] loss: 1.496
2025-02-27T06:56:30.868076+0300 | INFO | [155,   900] loss: 1.495
2025-02-27T06:56:41.950157+0300 | INFO | [155,  1000] loss: 1.477
2025-02-27T06:56:54.445107+0300 | INFO | [155,  1100] loss: 1.491
2025-02-27T06:57:09.846319+0300 | INFO | [155,  1200] loss: 1.496
2025-02-27T06:57:20.094715+0300 | INFO | [155,  1300] loss: 1.488
2025-02-27T06:57:31.282791+0300 | INFO | [155,  1400] loss: 1.493
2025-02-27T06:57:42.552873+0300 | INFO | [155,  1500] loss: 1.491
2025-02-27T06:57:52.864267+0300 | INFO | [155,  1600] loss: 1.495
2025-02-27T06:58:03.706063+0300 | INFO | [155,  1700] loss: 1.484
2025-02-27T06:58:14.879588+0300 | INFO | [155,  1800] loss: 1.485
2025-02-27T06:58:24.853791+0300 | INFO | [155,  1900] loss: 1.501
2025-02-27T06:58:36.084147+0300 | INFO | [155,  2000] loss: 1.486
2025-02-27T06:58:46.941824+0300 | INFO | [155,  2100] loss: 1.487
2025-02-27T06:58:57.027433+0300 | INFO | [155,  2200] loss: 1.492
2025-02-27T06:59:09.037914+0300 | INFO | [155,  2300] loss: 1.496
2025-02-27T06:59:20.145309+0300 | INFO | [155,  2400] loss: 1.488
2025-02-27T06:59:30.560251+0300 | INFO | [155,  2500] loss: 1.490
2025-02-27T06:59:41.155520+0300 | INFO | [155,  2600] loss: 1.491
2025-02-27T06:59:51.939546+0300 | INFO | [155,  2700] loss: 1.498
2025-02-27T07:00:03.230663+0300 | INFO | [155,  2800] loss: 1.494
2025-02-27T07:00:13.304380+0300 | INFO | [155,  2900] loss: 1.508
2025-02-27T07:00:24.348721+0300 | INFO | [155,  3000] loss: 1.488
2025-02-27T07:00:35.401547+0300 | INFO | [155,  3100] loss: 1.496
2025-02-27T07:00:45.513486+0300 | INFO | [155,  3200] loss: 1.484
2025-02-27T07:00:57.895404+0300 | INFO | [155,  3300] loss: 1.498
2025-02-27T07:01:08.838441+0300 | INFO | [155,  3400] loss: 1.496
2025-02-27T07:01:20.334781+0300 | INFO | [155,  3500] loss: 1.486
2025-02-27T07:01:31.118456+0300 | INFO | [155,  3600] loss: 1.490
2025-02-27T07:01:42.083849+0300 | INFO | [155,  3700] loss: 1.490
2025-02-27T07:01:52.172429+0300 | INFO | [155,  3800] loss: 1.497
2025-02-27T07:02:03.168054+0300 | INFO | [155,  3900] loss: 1.489
2025-02-27T07:02:15.111329+0300 | INFO | [155,  4000] loss: 1.485
2025-02-27T07:02:25.020943+0300 | INFO | [155,  4100] loss: 1.496
2025-02-27T07:02:36.579338+0300 | INFO | [155,  4200] loss: 1.486
2025-02-27T07:02:47.913294+0300 | INFO | [155,  4300] loss: 1.493
2025-02-27T07:02:59.112956+0300 | INFO | [155,  4400] loss: 1.486
2025-02-27T07:03:09.534082+0300 | INFO | [155,  4500] loss: 1.486
2025-02-27T07:03:20.656154+0300 | INFO | [155,  4600] loss: 1.494
2025-02-27T07:03:32.248741+0300 | INFO | [155,  4700] loss: 1.491
2025-02-27T07:03:42.574709+0300 | INFO | [155,  4800] loss: 1.489
2025-02-27T07:03:54.196777+0300 | INFO | [155,  4900] loss: 1.494
2025-02-27T07:04:05.331168+0300 | DEBUG | Saving model to flat file storage. Save #155
2025-02-27T07:04:05.355639+0300 | INFO | Averaging client parameters
2025-02-27T07:04:05.363438+0300 | INFO | Updating parameters on client #0
2025-02-27T07:04:21.285341+0300 | DEBUG | Test set: Accuracy: 7929/10000 (79%)
2025-02-27T07:04:21.287330+0300 | DEBUG | Test set: Loss: 1.6670539379119873
2025-02-27T07:04:21.379639+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.84      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.75      0.72      0.73      1000
           3       0.71      0.54      0.61      1200
           4       0.77      0.80      0.78      1000
           5       0.55      0.64      0.59       800
           6       0.82      0.88      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.91      0.90      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T07:04:21.384636+0300 | DEBUG | Confusion Matrix:
[[843  13  34   7  19   7   6   6  38  27]
 [  6 929   3   0   1   1   2   0  18  40]
 [ 56   6 718  33  64  34  52  20   9   8]
 [ 22   8  55 642  57 277  58  40  19  22]
 [ 11   6  36  38 796  35  43  27   5   3]
 [ 18   1  38 128  32 514  17  40   7   5]
 [ 10   4  41  23  13  17 876   7   6   3]
 [ 19   4  18  19  47  49   3 826   2  13]
 [ 37  11   9   5   2   2   4   2 914  14]
 [ 26  52   6   3   1   4  10   8  19 871]]
2025-02-27T07:04:21.386646+0300 | DEBUG | Class precision: [0.80438931 0.89845261 0.74947808 0.71492205 0.77131783 0.54680851
 0.81792717 0.84631148 0.88138862 0.86580517]
2025-02-27T07:04:21.387890+0300 | DEBUG | Class recall: [0.843  0.929  0.718  0.535  0.796  0.6425 0.876  0.826  0.914  0.871 ]
2025-02-27T07:04:21.439452+0300 | INFO | Training epoch #156 on client #0
2025-02-27T07:04:21.440454+0300 | DEBUG | Saving model to flat file storage. Save #156
2025-02-27T07:04:21.669616+0300 | INFO | [156,     0] loss: 0.015
2025-02-27T07:04:32.618996+0300 | INFO | [156,   100] loss: 1.486
2025-02-27T07:04:43.401862+0300 | INFO | [156,   200] loss: 1.493
2025-02-27T07:04:54.645458+0300 | INFO | [156,   300] loss: 1.493
2025-02-27T07:05:04.880760+0300 | INFO | [156,   400] loss: 1.487
2025-02-27T07:05:17.041690+0300 | INFO | [156,   500] loss: 1.488
2025-02-27T07:05:31.677785+0300 | INFO | [156,   600] loss: 1.500
2025-02-27T07:05:44.575100+0300 | INFO | [156,   700] loss: 1.489
2025-02-27T07:05:55.772185+0300 | INFO | [156,   800] loss: 1.484
2025-02-27T07:06:06.140769+0300 | INFO | [156,   900] loss: 1.489
2025-02-27T07:06:17.684483+0300 | INFO | [156,  1000] loss: 1.492
2025-02-27T07:06:28.963597+0300 | INFO | [156,  1100] loss: 1.484
2025-02-27T07:06:39.507120+0300 | INFO | [156,  1200] loss: 1.490
2025-02-27T07:06:50.743171+0300 | INFO | [156,  1300] loss: 1.494
2025-02-27T07:07:02.004905+0300 | INFO | [156,  1400] loss: 1.493
2025-02-27T07:07:12.168970+0300 | INFO | [156,  1500] loss: 1.493
2025-02-27T07:07:23.258647+0300 | INFO | [156,  1600] loss: 1.493
2025-02-27T07:07:34.843576+0300 | INFO | [156,  1700] loss: 1.487
2025-02-27T07:07:45.225975+0300 | INFO | [156,  1800] loss: 1.487
2025-02-27T07:07:56.964277+0300 | INFO | [156,  1900] loss: 1.485
2025-02-27T07:08:08.654563+0300 | INFO | [156,  2000] loss: 1.496
2025-02-27T07:08:20.345181+0300 | INFO | [156,  2100] loss: 1.501
2025-02-27T07:08:32.053662+0300 | INFO | [156,  2200] loss: 1.487
2025-02-27T07:08:43.442944+0300 | INFO | [156,  2300] loss: 1.496
2025-02-27T07:08:54.700970+0300 | INFO | [156,  2400] loss: 1.501
2025-02-27T07:09:05.761430+0300 | INFO | [156,  2500] loss: 1.492
2025-02-27T07:09:17.246824+0300 | INFO | [156,  2600] loss: 1.496
2025-02-27T07:09:29.117231+0300 | INFO | [156,  2700] loss: 1.492
2025-02-27T07:09:40.318084+0300 | INFO | [156,  2800] loss: 1.488
2025-02-27T07:09:50.604434+0300 | INFO | [156,  2900] loss: 1.487
2025-02-27T07:10:01.759916+0300 | INFO | [156,  3000] loss: 1.493
2025-02-27T07:10:12.873446+0300 | INFO | [156,  3100] loss: 1.486
2025-02-27T07:10:23.046740+0300 | INFO | [156,  3200] loss: 1.492
2025-02-27T07:10:34.548457+0300 | INFO | [156,  3300] loss: 1.491
2025-02-27T07:10:45.498964+0300 | INFO | [156,  3400] loss: 1.494
2025-02-27T07:10:56.285925+0300 | INFO | [156,  3500] loss: 1.495
2025-02-27T07:11:07.375881+0300 | INFO | [156,  3600] loss: 1.491
2025-02-27T07:11:18.577652+0300 | INFO | [156,  3700] loss: 1.485
2025-02-27T07:11:29.198517+0300 | INFO | [156,  3800] loss: 1.503
2025-02-27T07:11:40.426783+0300 | INFO | [156,  3900] loss: 1.489
2025-02-27T07:11:52.832638+0300 | INFO | [156,  4000] loss: 1.484
2025-02-27T07:12:04.657927+0300 | INFO | [156,  4100] loss: 1.492
2025-02-27T07:12:14.515865+0300 | INFO | [156,  4200] loss: 1.487
2025-02-27T07:12:25.554180+0300 | INFO | [156,  4300] loss: 1.488
2025-02-27T07:12:36.868180+0300 | INFO | [156,  4400] loss: 1.494
2025-02-27T07:12:47.201301+0300 | INFO | [156,  4500] loss: 1.491
2025-02-27T07:12:58.070648+0300 | INFO | [156,  4600] loss: 1.492
2025-02-27T07:13:09.333176+0300 | INFO | [156,  4700] loss: 1.486
2025-02-27T07:13:19.772275+0300 | INFO | [156,  4800] loss: 1.493
2025-02-27T07:13:30.796073+0300 | INFO | [156,  4900] loss: 1.494
2025-02-27T07:13:41.717868+0300 | DEBUG | Saving model to flat file storage. Save #156
2025-02-27T07:13:41.739550+0300 | INFO | Averaging client parameters
2025-02-27T07:13:41.746815+0300 | INFO | Updating parameters on client #0
2025-02-27T07:13:57.703269+0300 | DEBUG | Test set: Accuracy: 7971/10000 (80%)
2025-02-27T07:13:57.705285+0300 | DEBUG | Test set: Loss: 1.664169192314148
2025-02-27T07:13:57.805140+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.83      1000
           1       0.88      0.93      0.91      1000
           2       0.77      0.71      0.74      1000
           3       0.69      0.57      0.62      1200
           4       0.78      0.81      0.79      1000
           5       0.56      0.63      0.59       800
           6       0.86      0.85      0.86      1000
           7       0.83      0.84      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.80     10000

2025-02-27T07:13:57.806143+0300 | DEBUG | Confusion Matrix:
[[853  14  29   7  13   8   3   6  44  23]
 [  6 933   3   0   1   1   1   0  13  42]
 [ 61   8 710  38  69  39  39  21   9   6]
 [ 23  12  48 680  54 257  45  44  14  23]
 [ 12   6  35  42 808  33  23  32   6   3]
 [ 19   3  36 147  26 502  12  45   4   6]
 [ 13   5  39  38  25  14 849   9   5   3]
 [ 21   4  11  21  41  46   2 842   2  10]
 [ 32  14   6   6   2   2   3   2 920  13]
 [ 26  56   7   3   1   2   5   8  18 874]]
2025-02-27T07:13:57.809149+0300 | DEBUG | Class precision: [0.80018762 0.88436019 0.76839827 0.69246436 0.77692308 0.55530973
 0.86456212 0.83448959 0.88888889 0.87138584]
2025-02-27T07:13:57.810141+0300 | DEBUG | Class recall: [0.853      0.933      0.71       0.56666667 0.808      0.6275
 0.849      0.842      0.92       0.874     ]
2025-02-27T07:13:57.861289+0300 | INFO | Training epoch #157 on client #0
2025-02-27T07:13:57.862544+0300 | DEBUG | Saving model to flat file storage. Save #157
2025-02-27T07:13:58.079504+0300 | INFO | [157,     0] loss: 0.015
2025-02-27T07:14:12.819305+0300 | INFO | [157,   100] loss: 1.475
2025-02-27T07:14:25.114667+0300 | INFO | [157,   200] loss: 1.497
2025-02-27T07:14:36.156057+0300 | INFO | [157,   300] loss: 1.481
2025-02-27T07:14:47.925343+0300 | INFO | [157,   400] loss: 1.492
2025-02-27T07:14:58.717435+0300 | INFO | [157,   500] loss: 1.491
2025-02-27T07:15:09.493566+0300 | INFO | [157,   600] loss: 1.499
2025-02-27T07:15:20.796276+0300 | INFO | [157,   700] loss: 1.492
2025-02-27T07:15:32.419730+0300 | INFO | [157,   800] loss: 1.489
2025-02-27T07:15:42.601465+0300 | INFO | [157,   900] loss: 1.488
2025-02-27T07:15:53.521631+0300 | INFO | [157,  1000] loss: 1.499
2025-02-27T07:16:04.587083+0300 | INFO | [157,  1100] loss: 1.480
2025-02-27T07:16:15.072415+0300 | INFO | [157,  1200] loss: 1.490
2025-02-27T07:16:26.089343+0300 | INFO | [157,  1300] loss: 1.487
2025-02-27T07:16:37.283971+0300 | INFO | [157,  1400] loss: 1.487
2025-02-27T07:16:47.155624+0300 | INFO | [157,  1500] loss: 1.497
2025-02-27T07:16:58.192932+0300 | INFO | [157,  1600] loss: 1.494
2025-02-27T07:17:09.548882+0300 | INFO | [157,  1700] loss: 1.485
2025-02-27T07:17:19.643341+0300 | INFO | [157,  1800] loss: 1.489
2025-02-27T07:17:30.869583+0300 | INFO | [157,  1900] loss: 1.481
2025-02-27T07:17:43.048810+0300 | INFO | [157,  2000] loss: 1.490
2025-02-27T07:17:53.516407+0300 | INFO | [157,  2100] loss: 1.487
2025-02-27T07:18:04.933320+0300 | INFO | [157,  2200] loss: 1.492
2025-02-27T07:18:16.526677+0300 | INFO | [157,  2300] loss: 1.492
2025-02-27T07:18:27.235320+0300 | INFO | [157,  2400] loss: 1.500
2025-02-27T07:18:38.156528+0300 | INFO | [157,  2500] loss: 1.488
2025-02-27T07:18:49.170562+0300 | INFO | [157,  2600] loss: 1.493
2025-02-27T07:19:00.428043+0300 | INFO | [157,  2700] loss: 1.486
2025-02-27T07:19:11.453681+0300 | INFO | [157,  2800] loss: 1.498
2025-02-27T07:19:22.936380+0300 | INFO | [157,  2900] loss: 1.503
2025-02-27T07:19:33.923911+0300 | INFO | [157,  3000] loss: 1.485
2025-02-27T07:19:44.051714+0300 | INFO | [157,  3100] loss: 1.491
2025-02-27T07:19:55.054652+0300 | INFO | [157,  3200] loss: 1.483
2025-02-27T07:20:06.355349+0300 | INFO | [157,  3300] loss: 1.485
2025-02-27T07:20:16.508735+0300 | INFO | [157,  3400] loss: 1.490
2025-02-27T07:20:27.711852+0300 | INFO | [157,  3500] loss: 1.489
2025-02-27T07:20:39.008984+0300 | INFO | [157,  3600] loss: 1.490
2025-02-27T07:20:49.913230+0300 | INFO | [157,  3700] loss: 1.488
2025-02-27T07:21:01.232916+0300 | INFO | [157,  3800] loss: 1.504
2025-02-27T07:21:12.454770+0300 | INFO | [157,  3900] loss: 1.490
2025-02-27T07:21:23.335703+0300 | INFO | [157,  4000] loss: 1.489
2025-02-27T07:21:33.975500+0300 | INFO | [157,  4100] loss: 1.489
2025-02-27T07:21:44.834372+0300 | INFO | [157,  4200] loss: 1.489
2025-02-27T07:21:56.887135+0300 | INFO | [157,  4300] loss: 1.500
2025-02-27T07:22:07.158997+0300 | INFO | [157,  4400] loss: 1.488
2025-02-27T07:22:18.184867+0300 | INFO | [157,  4500] loss: 1.497
2025-02-27T07:22:30.557485+0300 | INFO | [157,  4600] loss: 1.495
2025-02-27T07:22:45.405971+0300 | INFO | [157,  4700] loss: 1.493
2025-02-27T07:22:55.694957+0300 | INFO | [157,  4800] loss: 1.493
2025-02-27T07:23:06.906185+0300 | INFO | [157,  4900] loss: 1.487
2025-02-27T07:23:17.915722+0300 | DEBUG | Saving model to flat file storage. Save #157
2025-02-27T07:23:17.941910+0300 | INFO | Averaging client parameters
2025-02-27T07:23:17.948906+0300 | INFO | Updating parameters on client #0
2025-02-27T07:23:34.115511+0300 | DEBUG | Test set: Accuracy: 7951/10000 (80%)
2025-02-27T07:23:34.116510+0300 | DEBUG | Test set: Loss: 1.6654468774795532
2025-02-27T07:23:34.210016+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.78      0.70      0.73      1000
           3       0.67      0.59      0.63      1200
           4       0.78      0.80      0.79      1000
           5       0.54      0.63      0.58       800
           6       0.86      0.85      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.79     10000

2025-02-27T07:23:34.212175+0300 | DEBUG | Confusion Matrix:
[[836  17  31  11  16   6   5   8  43  27]
 [  7 926   3   0   1   1   2   1  15  44]
 [ 54   7 696  53  70  49  36  21   7   7]
 [ 19   9  43 707  47 260  46  39  15  15]
 [  8   4  33  50 795  41  28  32   7   2]
 [ 17   1  34 156  26 507  12  39   3   5]
 [ 11   5  32  39  22  22 850   9   7   3]
 [ 17   4  12  27  40  52   4 833   2   9]
 [ 29  13   5  10   1   4   3   3 920  12]
 [ 20  51   7   4   2   3   6   7  19 881]]
2025-02-27T07:23:34.214175+0300 | DEBUG | Class precision: [0.82121807 0.89296046 0.77678571 0.66887417 0.77941176 0.53650794
 0.85685484 0.83971774 0.88631985 0.87661692]
2025-02-27T07:23:34.215178+0300 | DEBUG | Class recall: [0.836      0.926      0.696      0.58916667 0.795      0.63375
 0.85       0.833      0.92       0.881     ]
2025-02-27T07:23:34.265004+0300 | INFO | Training epoch #158 on client #0
2025-02-27T07:23:34.267217+0300 | DEBUG | Saving model to flat file storage. Save #158
2025-02-27T07:23:34.486666+0300 | INFO | [158,     0] loss: 0.016
2025-02-27T07:23:44.724147+0300 | INFO | [158,   100] loss: 1.500
2025-02-27T07:23:55.920557+0300 | INFO | [158,   200] loss: 1.499
2025-02-27T07:24:07.741826+0300 | INFO | [158,   300] loss: 1.493
2025-02-27T07:24:18.561552+0300 | INFO | [158,   400] loss: 1.484
2025-02-27T07:24:29.717618+0300 | INFO | [158,   500] loss: 1.484
2025-02-27T07:24:40.755897+0300 | INFO | [158,   600] loss: 1.487
2025-02-27T07:24:51.861500+0300 | INFO | [158,   700] loss: 1.490
2025-02-27T07:25:02.201189+0300 | INFO | [158,   800] loss: 1.496
2025-02-27T07:25:13.093151+0300 | INFO | [158,   900] loss: 1.495
2025-02-27T07:25:24.346342+0300 | INFO | [158,  1000] loss: 1.488
2025-02-27T07:25:34.609785+0300 | INFO | [158,  1100] loss: 1.492
2025-02-27T07:25:45.592832+0300 | INFO | [158,  1200] loss: 1.492
2025-02-27T07:25:56.685991+0300 | INFO | [158,  1300] loss: 1.492
2025-02-27T07:26:07.118717+0300 | INFO | [158,  1400] loss: 1.489
2025-02-27T07:26:18.214379+0300 | INFO | [158,  1500] loss: 1.494
2025-02-27T07:26:29.351335+0300 | INFO | [158,  1600] loss: 1.489
2025-02-27T07:26:40.261122+0300 | INFO | [158,  1700] loss: 1.489
2025-02-27T07:26:51.311298+0300 | INFO | [158,  1800] loss: 1.483
2025-02-27T07:27:03.427323+0300 | INFO | [158,  1900] loss: 1.484
2025-02-27T07:27:14.244566+0300 | INFO | [158,  2000] loss: 1.496
2025-02-27T07:27:25.197682+0300 | INFO | [158,  2100] loss: 1.489
2025-02-27T07:27:36.850526+0300 | INFO | [158,  2200] loss: 1.485
2025-02-27T07:27:47.912873+0300 | INFO | [158,  2300] loss: 1.496
2025-02-27T07:27:58.385065+0300 | INFO | [158,  2400] loss: 1.489
2025-02-27T07:28:09.484758+0300 | INFO | [158,  2500] loss: 1.492
2025-02-27T07:28:20.527449+0300 | INFO | [158,  2600] loss: 1.486
2025-02-27T07:28:31.212919+0300 | INFO | [158,  2700] loss: 1.500
2025-02-27T07:28:42.422773+0300 | INFO | [158,  2800] loss: 1.490
2025-02-27T07:28:53.387113+0300 | INFO | [158,  2900] loss: 1.498
2025-02-27T07:29:03.575083+0300 | INFO | [158,  3000] loss: 1.496
2025-02-27T07:29:14.877366+0300 | INFO | [158,  3100] loss: 1.486
2025-02-27T07:29:26.135054+0300 | INFO | [158,  3200] loss: 1.489
2025-02-27T07:29:36.228400+0300 | INFO | [158,  3300] loss: 1.497
2025-02-27T07:29:47.169994+0300 | INFO | [158,  3400] loss: 1.492
2025-02-27T07:29:58.075705+0300 | INFO | [158,  3500] loss: 1.479
2025-02-27T07:30:09.052780+0300 | INFO | [158,  3600] loss: 1.495
2025-02-27T07:30:20.072109+0300 | INFO | [158,  3700] loss: 1.488
2025-02-27T07:30:31.242417+0300 | INFO | [158,  3800] loss: 1.489
2025-02-27T07:30:41.379914+0300 | INFO | [158,  3900] loss: 1.496
2025-02-27T07:30:53.918200+0300 | INFO | [158,  4000] loss: 1.494
2025-02-27T07:31:08.998712+0300 | INFO | [158,  4100] loss: 1.496
2025-02-27T07:31:20.598753+0300 | INFO | [158,  4200] loss: 1.490
2025-02-27T07:31:31.632731+0300 | INFO | [158,  4300] loss: 1.489
2025-02-27T07:31:41.926330+0300 | INFO | [158,  4400] loss: 1.484
2025-02-27T07:31:52.633323+0300 | INFO | [158,  4500] loss: 1.490
2025-02-27T07:32:03.626620+0300 | INFO | [158,  4600] loss: 1.489
2025-02-27T07:32:13.710778+0300 | INFO | [158,  4700] loss: 1.491
2025-02-27T07:32:24.645842+0300 | INFO | [158,  4800] loss: 1.503
2025-02-27T07:32:35.733761+0300 | INFO | [158,  4900] loss: 1.484
2025-02-27T07:32:45.689050+0300 | DEBUG | Saving model to flat file storage. Save #158
2025-02-27T07:32:45.704781+0300 | INFO | Averaging client parameters
2025-02-27T07:32:45.717908+0300 | INFO | Updating parameters on client #0
2025-02-27T07:33:01.757176+0300 | DEBUG | Test set: Accuracy: 7950/10000 (80%)
2025-02-27T07:33:01.758177+0300 | DEBUG | Test set: Loss: 1.6658601760864258
2025-02-27T07:33:01.855405+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.90      0.93      0.91      1000
           2       0.75      0.72      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.80      0.79      1000
           5       0.55      0.63      0.59       800
           6       0.85      0.85      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.80      0.79     10000

2025-02-27T07:33:01.857408+0300 | DEBUG | Confusion Matrix:
[[842  14  39   8  16   6   5   4  40  26]
 [  5 928   2   0   1   1   3   0  16  44]
 [ 54   7 722  37  68  42  39  17   8   6]
 [ 23   8  58 678  56 246  49  42  17  23]
 [ 10   5  38  46 800  36  28  28   6   3]
 [ 20   3  37 148  25 501  14  39   6   7]
 [  7   5  40  38  20  22 852   8   5   3]
 [ 19   4  16  19  47  49   2 830   2  12]
 [ 35  13   8   7   2   2   3   2 915  13]
 [ 23  45   7   4   2   3   8   5  21 882]]
2025-02-27T07:33:01.859550+0300 | DEBUG | Class precision: [0.81117534 0.89922481 0.74663909 0.68832487 0.77145612 0.55176211
 0.84945165 0.85128205 0.88320463 0.86555447]
2025-02-27T07:33:01.864071+0300 | DEBUG | Class recall: [0.842   0.928   0.722   0.565   0.8     0.62625 0.852   0.83    0.915
 0.882  ]
2025-02-27T07:33:01.920180+0300 | INFO | Training epoch #159 on client #0
2025-02-27T07:33:01.921193+0300 | DEBUG | Saving model to flat file storage. Save #159
2025-02-27T07:33:02.140261+0300 | INFO | [159,     0] loss: 0.019
2025-02-27T07:33:14.191548+0300 | INFO | [159,   100] loss: 1.483
2025-02-27T07:33:25.084997+0300 | INFO | [159,   200] loss: 1.492
2025-02-27T07:33:35.389149+0300 | INFO | [159,   300] loss: 1.491
2025-02-27T07:33:46.544777+0300 | INFO | [159,   400] loss: 1.488
2025-02-27T07:33:57.697007+0300 | INFO | [159,   500] loss: 1.487
2025-02-27T07:34:08.202063+0300 | INFO | [159,   600] loss: 1.496
2025-02-27T07:34:19.803874+0300 | INFO | [159,   700] loss: 1.493
2025-02-27T07:34:30.969822+0300 | INFO | [159,   800] loss: 1.492
2025-02-27T07:34:43.316076+0300 | INFO | [159,   900] loss: 1.486
2025-02-27T07:34:53.480807+0300 | INFO | [159,  1000] loss: 1.505
2025-02-27T07:35:04.700282+0300 | INFO | [159,  1100] loss: 1.488
2025-02-27T07:35:15.805868+0300 | INFO | [159,  1200] loss: 1.486
2025-02-27T07:35:26.830851+0300 | INFO | [159,  1300] loss: 1.486
2025-02-27T07:35:38.289969+0300 | INFO | [159,  1400] loss: 1.492
2025-02-27T07:35:50.067407+0300 | INFO | [159,  1500] loss: 1.489
2025-02-27T07:36:01.333149+0300 | INFO | [159,  1600] loss: 1.495
2025-02-27T07:36:13.255692+0300 | INFO | [159,  1700] loss: 1.480
2025-02-27T07:36:26.364458+0300 | INFO | [159,  1800] loss: 1.489
2025-02-27T07:36:38.472662+0300 | INFO | [159,  1900] loss: 1.482
2025-02-27T07:36:51.706513+0300 | INFO | [159,  2000] loss: 1.485
2025-02-27T07:37:03.528847+0300 | INFO | [159,  2100] loss: 1.500
2025-02-27T07:37:15.467683+0300 | INFO | [159,  2200] loss: 1.484
2025-02-27T07:37:27.286635+0300 | INFO | [159,  2300] loss: 1.488
2025-02-27T07:37:39.185233+0300 | INFO | [159,  2400] loss: 1.490
2025-02-27T07:37:50.664143+0300 | INFO | [159,  2500] loss: 1.493
2025-02-27T07:38:03.686509+0300 | INFO | [159,  2600] loss: 1.493
2025-02-27T07:38:16.366187+0300 | INFO | [159,  2700] loss: 1.484
2025-02-27T07:38:28.758643+0300 | INFO | [159,  2800] loss: 1.488
2025-02-27T07:38:40.332636+0300 | INFO | [159,  2900] loss: 1.496
2025-02-27T07:38:51.743121+0300 | INFO | [159,  3000] loss: 1.493
2025-02-27T07:39:03.420208+0300 | INFO | [159,  3100] loss: 1.484
2025-02-27T07:39:14.222065+0300 | INFO | [159,  3200] loss: 1.495
2025-02-27T07:39:25.492924+0300 | INFO | [159,  3300] loss: 1.497
2025-02-27T07:39:37.051719+0300 | INFO | [159,  3400] loss: 1.485
2025-02-27T07:39:52.807020+0300 | INFO | [159,  3500] loss: 1.481
2025-02-27T07:40:04.951078+0300 | INFO | [159,  3600] loss: 1.497
2025-02-27T07:40:15.492874+0300 | INFO | [159,  3700] loss: 1.482
2025-02-27T07:40:26.711869+0300 | INFO | [159,  3800] loss: 1.481
2025-02-27T07:40:37.600429+0300 | INFO | [159,  3900] loss: 1.495
2025-02-27T07:40:47.869272+0300 | INFO | [159,  4000] loss: 1.502
2025-02-27T07:40:59.009738+0300 | INFO | [159,  4100] loss: 1.496
2025-02-27T07:41:09.990193+0300 | INFO | [159,  4200] loss: 1.495
2025-02-27T07:41:20.146343+0300 | INFO | [159,  4300] loss: 1.493
2025-02-27T07:41:31.339851+0300 | INFO | [159,  4400] loss: 1.495
2025-02-27T07:41:42.421272+0300 | INFO | [159,  4500] loss: 1.491
2025-02-27T07:41:52.429958+0300 | INFO | [159,  4600] loss: 1.493
2025-02-27T07:42:03.722945+0300 | INFO | [159,  4700] loss: 1.493
2025-02-27T07:42:14.985271+0300 | INFO | [159,  4800] loss: 1.494
2025-02-27T07:42:25.230079+0300 | INFO | [159,  4900] loss: 1.484
2025-02-27T07:42:36.210070+0300 | DEBUG | Saving model to flat file storage. Save #159
2025-02-27T07:42:36.237788+0300 | INFO | Averaging client parameters
2025-02-27T07:42:36.250963+0300 | INFO | Updating parameters on client #0
2025-02-27T07:42:53.908752+0300 | DEBUG | Test set: Accuracy: 7951/10000 (80%)
2025-02-27T07:42:53.910755+0300 | DEBUG | Test set: Loss: 1.6646088361740112
2025-02-27T07:42:54.012504+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.76      0.71      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.54      0.64      0.58       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.79     10000

2025-02-27T07:42:54.015503+0300 | DEBUG | Confusion Matrix:
[[834  16  40   7  16   7   6   6  40  28]
 [  5 927   2   0   1   1   4   0  19  41]
 [ 55   7 714  38  74  39  44  16   7   6]
 [ 21   5  50 678  57 269  52  36  15  17]
 [ 11   5  31  48 809  35  27  26   6   2]
 [ 14   1  40 144  26 510  15  39   4   7]
 [ 10   5  38  35  18  21 859   6   5   3]
 [ 20   4  14  23  46  57   2 820   2  12]
 [ 28  18   8   8   2   2   3   2 920   9]
 [ 25  46   7   3   1   3   9   5  21 880]]
2025-02-27T07:42:54.017507+0300 | DEBUG | Class precision: [0.81524927 0.89651838 0.75635593 0.68902439 0.77047619 0.54025424
 0.84133203 0.85774059 0.88546679 0.87562189]
2025-02-27T07:42:54.018592+0300 | DEBUG | Class recall: [0.834  0.927  0.714  0.565  0.809  0.6375 0.859  0.82   0.92   0.88  ]
2025-02-27T07:42:54.075496+0300 | INFO | Training epoch #160 on client #0
2025-02-27T07:42:54.077675+0300 | DEBUG | Saving model to flat file storage. Save #160
2025-02-27T07:42:54.314456+0300 | INFO | [160,     0] loss: 0.015
2025-02-27T07:43:05.990075+0300 | INFO | [160,   100] loss: 1.493
2025-02-27T07:43:17.358235+0300 | INFO | [160,   200] loss: 1.490
2025-02-27T07:43:27.565337+0300 | INFO | [160,   300] loss: 1.485
2025-02-27T07:43:38.463985+0300 | INFO | [160,   400] loss: 1.488
2025-02-27T07:43:49.174293+0300 | INFO | [160,   500] loss: 1.486
2025-02-27T07:43:59.435346+0300 | INFO | [160,   600] loss: 1.486
2025-02-27T07:44:10.447237+0300 | INFO | [160,   700] loss: 1.490
2025-02-27T07:44:21.931854+0300 | INFO | [160,   800] loss: 1.491
2025-02-27T07:44:32.635809+0300 | INFO | [160,   900] loss: 1.489
2025-02-27T07:44:43.988300+0300 | INFO | [160,  1000] loss: 1.493
2025-02-27T07:44:54.944674+0300 | INFO | [160,  1100] loss: 1.497
2025-02-27T07:45:05.631057+0300 | INFO | [160,  1200] loss: 1.486
2025-02-27T07:45:16.704635+0300 | INFO | [160,  1300] loss: 1.481
2025-02-27T07:45:27.864684+0300 | INFO | [160,  1400] loss: 1.484
2025-02-27T07:45:38.002945+0300 | INFO | [160,  1500] loss: 1.493
2025-02-27T07:45:48.586557+0300 | INFO | [160,  1600] loss: 1.489
2025-02-27T07:46:00.474938+0300 | INFO | [160,  1700] loss: 1.486
2025-02-27T07:46:11.553234+0300 | INFO | [160,  1800] loss: 1.488
2025-02-27T07:46:21.658906+0300 | INFO | [160,  1900] loss: 1.481
2025-02-27T07:46:32.803300+0300 | INFO | [160,  2000] loss: 1.491
2025-02-27T07:46:44.985657+0300 | INFO | [160,  2100] loss: 1.495
2025-02-27T07:46:55.696266+0300 | INFO | [160,  2200] loss: 1.491
2025-02-27T07:47:07.049696+0300 | INFO | [160,  2300] loss: 1.490
2025-02-27T07:47:18.042075+0300 | INFO | [160,  2400] loss: 1.488
2025-02-27T07:47:28.154518+0300 | INFO | [160,  2500] loss: 1.491
2025-02-27T07:47:39.111533+0300 | INFO | [160,  2600] loss: 1.493
2025-02-27T07:47:51.754768+0300 | INFO | [160,  2700] loss: 1.503
2025-02-27T07:48:01.510602+0300 | INFO | [160,  2800] loss: 1.489
2025-02-27T07:48:12.866766+0300 | INFO | [160,  2900] loss: 1.490
2025-02-27T07:48:27.437124+0300 | INFO | [160,  3000] loss: 1.494
2025-02-27T07:48:40.345606+0300 | INFO | [160,  3100] loss: 1.495
2025-02-27T07:48:51.012816+0300 | INFO | [160,  3200] loss: 1.491
2025-02-27T07:49:02.340442+0300 | INFO | [160,  3300] loss: 1.496
2025-02-27T07:49:13.867610+0300 | INFO | [160,  3400] loss: 1.487
2025-02-27T07:49:25.225519+0300 | INFO | [160,  3500] loss: 1.491
2025-02-27T07:49:36.166571+0300 | INFO | [160,  3600] loss: 1.486
2025-02-27T07:49:46.914512+0300 | INFO | [160,  3700] loss: 1.496
2025-02-27T07:49:59.432433+0300 | INFO | [160,  3800] loss: 1.498
2025-02-27T07:50:09.473486+0300 | INFO | [160,  3900] loss: 1.493
2025-02-27T07:50:20.491295+0300 | INFO | [160,  4000] loss: 1.502
2025-02-27T07:50:31.737046+0300 | INFO | [160,  4100] loss: 1.491
2025-02-27T07:50:42.913722+0300 | INFO | [160,  4200] loss: 1.484
2025-02-27T07:50:53.056327+0300 | INFO | [160,  4300] loss: 1.500
2025-02-27T07:51:05.325368+0300 | INFO | [160,  4400] loss: 1.491
2025-02-27T07:51:16.114264+0300 | INFO | [160,  4500] loss: 1.493
2025-02-27T07:51:27.679777+0300 | INFO | [160,  4600] loss: 1.485
2025-02-27T07:51:39.183528+0300 | INFO | [160,  4700] loss: 1.484
2025-02-27T07:51:50.070331+0300 | INFO | [160,  4800] loss: 1.500
2025-02-27T07:52:00.294506+0300 | INFO | [160,  4900] loss: 1.496
2025-02-27T07:52:11.919489+0300 | DEBUG | Saving model to flat file storage. Save #160
2025-02-27T07:52:11.944027+0300 | INFO | Averaging client parameters
2025-02-27T07:52:11.951256+0300 | INFO | Updating parameters on client #0
2025-02-27T07:52:27.810002+0300 | DEBUG | Test set: Accuracy: 7951/10000 (80%)
2025-02-27T07:52:27.811001+0300 | DEBUG | Test set: Loss: 1.6647650003433228
2025-02-27T07:52:27.919866+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.73      0.73      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.80      0.79      1000
           5       0.56      0.61      0.59       800
           6       0.82      0.88      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.93      0.91      1000
           9       0.88      0.87      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.80      0.79     10000

2025-02-27T07:52:27.922862+0300 | DEBUG | Confusion Matrix:
[[827  15  42   7  19   7   7   6  42  28]
 [  4 926   3   0   1   1   4   0  19  42]
 [ 50   7 729  36  66  28  51  18   7   8]
 [ 20   8  65 670  59 249  61  39  16  13]
 [ 11   4  37  39 802  32  36  31   6   2]
 [ 16   1  47 152  26 489  20  37   5   7]
 [  6   6  40  31  17  10 875   7   5   3]
 [ 15   4  20  20  47  48   3 830   3  10]
 [ 26  13   7   7   2   2   4   0 929  10]
 [ 20  54   7   4   2   3  10   6  20 874]]
2025-02-27T07:52:27.923867+0300 | DEBUG | Class precision: [0.83115578 0.89210019 0.73119358 0.69358178 0.77041306 0.56271577
 0.81699346 0.85215606 0.88307985 0.87662989]
2025-02-27T07:52:27.925871+0300 | DEBUG | Class recall: [0.827      0.926      0.729      0.55833333 0.802      0.61125
 0.875      0.83       0.929      0.874     ]
2025-02-27T07:52:27.976250+0300 | INFO | Training epoch #161 on client #0
2025-02-27T07:52:27.978689+0300 | DEBUG | Saving model to flat file storage. Save #161
2025-02-27T07:52:28.183019+0300 | INFO | [161,     0] loss: 0.015
2025-02-27T07:52:39.593934+0300 | INFO | [161,   100] loss: 1.492
2025-02-27T07:52:49.727162+0300 | INFO | [161,   200] loss: 1.485
2025-02-27T07:53:00.811206+0300 | INFO | [161,   300] loss: 1.489
2025-02-27T07:53:12.111140+0300 | INFO | [161,   400] loss: 1.497
2025-02-27T07:53:23.158386+0300 | INFO | [161,   500] loss: 1.482
2025-02-27T07:53:33.386296+0300 | INFO | [161,   600] loss: 1.489
2025-02-27T07:53:45.831986+0300 | INFO | [161,   700] loss: 1.483
2025-02-27T07:53:56.749141+0300 | INFO | [161,   800] loss: 1.496
2025-02-27T07:54:06.960708+0300 | INFO | [161,   900] loss: 1.490
2025-02-27T07:54:17.839291+0300 | INFO | [161,  1000] loss: 1.497
2025-02-27T07:54:29.754147+0300 | INFO | [161,  1100] loss: 1.496
2025-02-27T07:54:41.562707+0300 | INFO | [161,  1200] loss: 1.492
2025-02-27T07:54:52.193460+0300 | INFO | [161,  1300] loss: 1.492
2025-02-27T07:55:03.486219+0300 | INFO | [161,  1400] loss: 1.488
2025-02-27T07:55:15.179096+0300 | INFO | [161,  1500] loss: 1.492
2025-02-27T07:55:25.799877+0300 | INFO | [161,  1600] loss: 1.489
2025-02-27T07:55:36.832410+0300 | INFO | [161,  1700] loss: 1.501
2025-02-27T07:55:47.743515+0300 | INFO | [161,  1800] loss: 1.488
2025-02-27T07:55:58.095901+0300 | INFO | [161,  1900] loss: 1.502
2025-02-27T07:56:09.252366+0300 | INFO | [161,  2000] loss: 1.485
2025-02-27T07:56:20.180431+0300 | INFO | [161,  2100] loss: 1.493
2025-02-27T07:56:30.246414+0300 | INFO | [161,  2200] loss: 1.495
2025-02-27T07:56:41.449732+0300 | INFO | [161,  2300] loss: 1.488
2025-02-27T07:56:52.556988+0300 | INFO | [161,  2400] loss: 1.492
2025-02-27T07:57:02.682848+0300 | INFO | [161,  2500] loss: 1.495
2025-02-27T07:57:18.838914+0300 | INFO | [161,  2600] loss: 1.493
2025-02-27T07:57:29.819803+0300 | INFO | [161,  2700] loss: 1.497
2025-02-27T07:57:40.883059+0300 | INFO | [161,  2800] loss: 1.483
2025-02-27T07:57:52.156506+0300 | INFO | [161,  2900] loss: 1.483
2025-02-27T07:58:03.275181+0300 | INFO | [161,  3000] loss: 1.487
2025-02-27T07:58:14.321125+0300 | INFO | [161,  3100] loss: 1.493
2025-02-27T07:58:25.336324+0300 | INFO | [161,  3200] loss: 1.489
2025-02-27T07:58:36.397848+0300 | INFO | [161,  3300] loss: 1.490
2025-02-27T07:58:47.360380+0300 | INFO | [161,  3400] loss: 1.489
2025-02-27T07:58:57.266722+0300 | INFO | [161,  3500] loss: 1.493
2025-02-27T07:59:08.319024+0300 | INFO | [161,  3600] loss: 1.503
2025-02-27T07:59:19.321039+0300 | INFO | [161,  3700] loss: 1.480
2025-02-27T07:59:29.670992+0300 | INFO | [161,  3800] loss: 1.492
2025-02-27T07:59:40.541004+0300 | INFO | [161,  3900] loss: 1.497
2025-02-27T07:59:51.512246+0300 | INFO | [161,  4000] loss: 1.484
2025-02-27T08:00:03.448120+0300 | INFO | [161,  4100] loss: 1.485
2025-02-27T08:00:13.761565+0300 | INFO | [161,  4200] loss: 1.486
2025-02-27T08:00:25.134063+0300 | INFO | [161,  4300] loss: 1.492
2025-02-27T08:00:36.181510+0300 | INFO | [161,  4400] loss: 1.498
2025-02-27T08:00:48.674033+0300 | INFO | [161,  4500] loss: 1.480
2025-02-27T08:00:59.205539+0300 | INFO | [161,  4600] loss: 1.494
2025-02-27T08:01:10.189725+0300 | INFO | [161,  4700] loss: 1.486
2025-02-27T08:01:21.245192+0300 | INFO | [161,  4800] loss: 1.493
2025-02-27T08:01:32.564555+0300 | INFO | [161,  4900] loss: 1.489
2025-02-27T08:01:43.323079+0300 | DEBUG | Saving model to flat file storage. Save #161
2025-02-27T08:01:43.353349+0300 | INFO | Averaging client parameters
2025-02-27T08:01:43.367411+0300 | INFO | Updating parameters on client #0
2025-02-27T08:01:59.153635+0300 | DEBUG | Test set: Accuracy: 7938/10000 (79%)
2025-02-27T08:01:59.154628+0300 | DEBUG | Test set: Loss: 1.666854739189148
2025-02-27T08:01:59.252701+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.76      0.72      0.74      1000
           3       0.70      0.56      0.62      1200
           4       0.80      0.78      0.79      1000
           5       0.54      0.63      0.58       800
           6       0.84      0.87      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.85      0.93      0.89      1000
           9       0.88      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T08:01:59.254817+0300 | DEBUG | Confusion Matrix:
[[839  14  34   7  12   6   7   7  49  25]
 [  6 928   1   0   1   1   3   0  23  37]
 [ 58   7 720  38  60  38  41  18  14   6]
 [ 20   7  55 666  49 267  51  39  25  21]
 [ 13   6  37  43 780  38  38  37   6   2]
 [ 17   3  37 141  21 504  18  44   7   8]
 [  9   5  40  26  15  19 866   7  10   3]
 [ 15   4  14  20  39  50   4 839   3  12]
 [ 27  14   5   5   1   4   2   1 932   9]
 [ 22  59   7   3   1   3   7   7  27 864]]
2025-02-27T08:01:59.256807+0300 | DEBUG | Class precision: [0.81773879 0.88634193 0.75789474 0.70179136 0.79673136 0.54193548
 0.83510125 0.83983984 0.85036496 0.87537994]
2025-02-27T08:01:59.256807+0300 | DEBUG | Class recall: [0.839 0.928 0.72  0.555 0.78  0.63  0.866 0.839 0.932 0.864]
2025-02-27T08:01:59.312474+0300 | INFO | Training epoch #162 on client #0
2025-02-27T08:01:59.314733+0300 | DEBUG | Saving model to flat file storage. Save #162
2025-02-27T08:01:59.532516+0300 | INFO | [162,     0] loss: 0.016
2025-02-27T08:02:10.274981+0300 | INFO | [162,   100] loss: 1.490
2025-02-27T08:02:21.173898+0300 | INFO | [162,   200] loss: 1.486
2025-02-27T08:02:33.756877+0300 | INFO | [162,   300] loss: 1.494
2025-02-27T08:02:44.806614+0300 | INFO | [162,   400] loss: 1.487
2025-02-27T08:02:55.115567+0300 | INFO | [162,   500] loss: 1.490
2025-02-27T08:03:06.195473+0300 | INFO | [162,   600] loss: 1.494
2025-02-27T08:03:17.120935+0300 | INFO | [162,   700] loss: 1.494
2025-02-27T08:03:27.477179+0300 | INFO | [162,   800] loss: 1.485
2025-02-27T08:03:38.586793+0300 | INFO | [162,   900] loss: 1.486
2025-02-27T08:03:49.909608+0300 | INFO | [162,  1000] loss: 1.482
2025-02-27T08:04:00.014659+0300 | INFO | [162,  1100] loss: 1.488
2025-02-27T08:04:11.403514+0300 | INFO | [162,  1200] loss: 1.490
2025-02-27T08:04:22.792799+0300 | INFO | [162,  1300] loss: 1.487
2025-02-27T08:04:35.900210+0300 | INFO | [162,  1400] loss: 1.493
2025-02-27T08:04:46.009540+0300 | INFO | [162,  1500] loss: 1.494
2025-02-27T08:04:57.095204+0300 | INFO | [162,  1600] loss: 1.498
2025-02-27T08:05:08.171829+0300 | INFO | [162,  1700] loss: 1.492
2025-02-27T08:05:18.434834+0300 | INFO | [162,  1800] loss: 1.493
2025-02-27T08:05:29.524122+0300 | INFO | [162,  1900] loss: 1.492
2025-02-27T08:05:40.592998+0300 | INFO | [162,  2000] loss: 1.499
2025-02-27T08:05:50.812552+0300 | INFO | [162,  2100] loss: 1.483
2025-02-27T08:06:07.957847+0300 | INFO | [162,  2200] loss: 1.486
2025-02-27T08:06:18.990632+0300 | INFO | [162,  2300] loss: 1.494
2025-02-27T08:06:30.379873+0300 | INFO | [162,  2400] loss: 1.494
2025-02-27T08:06:40.805271+0300 | INFO | [162,  2500] loss: 1.489
2025-02-27T08:06:51.651705+0300 | INFO | [162,  2600] loss: 1.496
2025-02-27T08:07:02.675836+0300 | INFO | [162,  2700] loss: 1.487
2025-02-27T08:07:13.011203+0300 | INFO | [162,  2800] loss: 1.497
2025-02-27T08:07:24.186905+0300 | INFO | [162,  2900] loss: 1.485
2025-02-27T08:07:35.925300+0300 | INFO | [162,  3000] loss: 1.489
2025-02-27T08:07:47.021078+0300 | INFO | [162,  3100] loss: 1.498
2025-02-27T08:07:57.961542+0300 | INFO | [162,  3200] loss: 1.490
2025-02-27T08:08:09.789972+0300 | INFO | [162,  3300] loss: 1.489
2025-02-27T08:08:21.461397+0300 | INFO | [162,  3400] loss: 1.483
2025-02-27T08:08:31.749602+0300 | INFO | [162,  3500] loss: 1.479
2025-02-27T08:08:43.363982+0300 | INFO | [162,  3600] loss: 1.480
2025-02-27T08:08:54.466511+0300 | INFO | [162,  3700] loss: 1.491
2025-02-27T08:09:04.680808+0300 | INFO | [162,  3800] loss: 1.494
2025-02-27T08:09:16.132004+0300 | INFO | [162,  3900] loss: 1.492
2025-02-27T08:09:28.439824+0300 | INFO | [162,  4000] loss: 1.488
2025-02-27T08:09:39.858660+0300 | INFO | [162,  4100] loss: 1.494
2025-02-27T08:09:49.731271+0300 | INFO | [162,  4200] loss: 1.491
2025-02-27T08:10:00.713740+0300 | INFO | [162,  4300] loss: 1.494
2025-02-27T08:10:11.871944+0300 | INFO | [162,  4400] loss: 1.494
2025-02-27T08:10:22.057003+0300 | INFO | [162,  4500] loss: 1.500
2025-02-27T08:10:32.864213+0300 | INFO | [162,  4600] loss: 1.483
2025-02-27T08:10:44.692800+0300 | INFO | [162,  4700] loss: 1.492
2025-02-27T08:10:54.931893+0300 | INFO | [162,  4800] loss: 1.489
2025-02-27T08:11:05.874606+0300 | INFO | [162,  4900] loss: 1.493
2025-02-27T08:11:16.942207+0300 | DEBUG | Saving model to flat file storage. Save #162
2025-02-27T08:11:17.003742+0300 | INFO | Averaging client parameters
2025-02-27T08:11:17.010731+0300 | INFO | Updating parameters on client #0
2025-02-27T08:11:33.225683+0300 | DEBUG | Test set: Accuracy: 7947/10000 (79%)
2025-02-27T08:11:33.228756+0300 | DEBUG | Test set: Loss: 1.665423035621643
2025-02-27T08:11:33.349411+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.85      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.78      0.67      0.72      1000
           3       0.68      0.59      0.63      1200
           4       0.76      0.81      0.79      1000
           5       0.54      0.62      0.58       800
           6       0.83      0.86      0.84      1000
           7       0.84      0.84      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T08:11:33.352429+0300 | DEBUG | Confusion Matrix:
[[850  14  28   7  16   8   6  10  43  18]
 [  9 917   2   2   1   1   5   1  21  41]
 [ 57   7 671  53  80  49  47  21   9   6]
 [ 14   5  38 707  58 259  51  37  16  15]
 [  9   3  30  38 811  33  38  30   6   2]
 [ 15   2  31 159  26 499  20  39   5   4]
 [  8   4  29  39  22  19 864   8   5   2]
 [ 14   4  13  25  45  46   4 838   3   8]
 [ 34  13   6   7   2   3   3   2 920  10]
 [ 28  50   7   4   2   4   8   6  21 870]]
2025-02-27T08:11:33.353899+0300 | DEBUG | Class precision: [0.81888247 0.89990186 0.78479532 0.67915466 0.76293509 0.54180239
 0.82600382 0.84475806 0.87702574 0.89139344]
2025-02-27T08:11:33.356921+0300 | DEBUG | Class recall: [0.85       0.917      0.671      0.58916667 0.811      0.62375
 0.864      0.838      0.92       0.87      ]
2025-02-27T08:11:33.414771+0300 | INFO | Training epoch #163 on client #0
2025-02-27T08:11:33.417763+0300 | DEBUG | Saving model to flat file storage. Save #163
2025-02-27T08:11:33.666698+0300 | INFO | [163,     0] loss: 0.015
2025-02-27T08:11:43.850966+0300 | INFO | [163,   100] loss: 1.489
2025-02-27T08:11:54.849996+0300 | INFO | [163,   200] loss: 1.495
2025-02-27T08:12:05.586877+0300 | INFO | [163,   300] loss: 1.494
2025-02-27T08:12:15.700517+0300 | INFO | [163,   400] loss: 1.491
2025-02-27T08:12:29.157388+0300 | INFO | [163,   500] loss: 1.489
2025-02-27T08:12:40.260234+0300 | INFO | [163,   600] loss: 1.488
2025-02-27T08:12:50.942374+0300 | INFO | [163,   700] loss: 1.493
2025-02-27T08:13:01.277046+0300 | INFO | [163,   800] loss: 1.486
2025-02-27T08:13:12.487708+0300 | INFO | [163,   900] loss: 1.489
2025-02-27T08:13:23.227368+0300 | INFO | [163,  1000] loss: 1.487
2025-02-27T08:13:33.463520+0300 | INFO | [163,  1100] loss: 1.488
2025-02-27T08:13:44.350033+0300 | INFO | [163,  1200] loss: 1.491
2025-02-27T08:13:55.964005+0300 | INFO | [163,  1300] loss: 1.493
2025-02-27T08:14:05.981990+0300 | INFO | [163,  1400] loss: 1.487
2025-02-27T08:14:17.086076+0300 | INFO | [163,  1500] loss: 1.500
2025-02-27T08:14:28.466645+0300 | INFO | [163,  1600] loss: 1.483
2025-02-27T08:14:44.462374+0300 | INFO | [163,  1700] loss: 1.488
2025-02-27T08:14:56.475789+0300 | INFO | [163,  1800] loss: 1.484
2025-02-27T08:15:08.110013+0300 | INFO | [163,  1900] loss: 1.491
2025-02-27T08:15:20.650717+0300 | INFO | [163,  2000] loss: 1.491
2025-02-27T08:15:32.252742+0300 | INFO | [163,  2100] loss: 1.485
2025-02-27T08:15:42.240517+0300 | INFO | [163,  2200] loss: 1.482
2025-02-27T08:15:55.045667+0300 | INFO | [163,  2300] loss: 1.496
2025-02-27T08:16:05.603528+0300 | INFO | [163,  2400] loss: 1.492
2025-02-27T08:16:15.668631+0300 | INFO | [163,  2500] loss: 1.487
2025-02-27T08:16:26.923000+0300 | INFO | [163,  2600] loss: 1.492
2025-02-27T08:16:38.029371+0300 | INFO | [163,  2700] loss: 1.498
2025-02-27T08:16:47.901152+0300 | INFO | [163,  2800] loss: 1.486
2025-02-27T08:16:59.541121+0300 | INFO | [163,  2900] loss: 1.493
2025-02-27T08:17:10.684387+0300 | INFO | [163,  3000] loss: 1.492
2025-02-27T08:17:20.688865+0300 | INFO | [163,  3100] loss: 1.491
2025-02-27T08:17:31.673587+0300 | INFO | [163,  3200] loss: 1.496
2025-02-27T08:17:43.054805+0300 | INFO | [163,  3300] loss: 1.492
2025-02-27T08:17:53.157712+0300 | INFO | [163,  3400] loss: 1.490
2025-02-27T08:18:04.472417+0300 | INFO | [163,  3500] loss: 1.490
2025-02-27T08:18:16.551799+0300 | INFO | [163,  3600] loss: 1.480
2025-02-27T08:18:27.916101+0300 | INFO | [163,  3700] loss: 1.494
2025-02-27T08:18:38.298447+0300 | INFO | [163,  3800] loss: 1.493
2025-02-27T08:18:48.930680+0300 | INFO | [163,  3900] loss: 1.487
2025-02-27T08:19:00.351968+0300 | INFO | [163,  4000] loss: 1.500
2025-02-27T08:19:11.141886+0300 | INFO | [163,  4100] loss: 1.486
2025-02-27T08:19:22.388509+0300 | INFO | [163,  4200] loss: 1.486
2025-02-27T08:19:33.512483+0300 | INFO | [163,  4300] loss: 1.494
2025-02-27T08:19:43.911605+0300 | INFO | [163,  4400] loss: 1.491
2025-02-27T08:19:54.902884+0300 | INFO | [163,  4500] loss: 1.492
2025-02-27T08:20:06.426769+0300 | INFO | [163,  4600] loss: 1.500
2025-02-27T08:20:16.842333+0300 | INFO | [163,  4700] loss: 1.492
2025-02-27T08:20:28.023583+0300 | INFO | [163,  4800] loss: 1.490
2025-02-27T08:20:38.982777+0300 | INFO | [163,  4900] loss: 1.486
2025-02-27T08:20:49.015354+0300 | DEBUG | Saving model to flat file storage. Save #163
2025-02-27T08:20:49.040934+0300 | INFO | Averaging client parameters
2025-02-27T08:20:49.055201+0300 | INFO | Updating parameters on client #0
2025-02-27T08:21:04.674455+0300 | DEBUG | Test set: Accuracy: 7932/10000 (79%)
2025-02-27T08:21:04.675913+0300 | DEBUG | Test set: Loss: 1.6670234203338623
2025-02-27T08:21:04.770049+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.80      0.66      0.72      1000
           3       0.67      0.59      0.63      1200
           4       0.78      0.79      0.79      1000
           5       0.53      0.63      0.58       800
           6       0.81      0.88      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T08:21:04.773053+0300 | DEBUG | Confusion Matrix:
[[832  17  27   7  15  12   7   8  45  30]
 [  4 926   4   1   1   1   7   0  18  38]
 [ 62   5 661  52  75  54  60  16   6   9]
 [ 14   4  31 712  50 261  55  38  16  19]
 [  9   5  29  47 794  37  44  27   6   2]
 [ 11   1  27 160  25 506  20  38   5   7]
 [  6   3  26  38  15  19 879   7   4   3]
 [ 14   3  10  32  43  54   4 827   3  10]
 [ 28  17   7   7   1   4   3   1 922  10]
 [ 18  60   6   5   1   4  11   5  17 873]]
2025-02-27T08:21:04.775048+0300 | DEBUG | Class precision: [0.83366733 0.8895293  0.79830918 0.67106503 0.77843137 0.53151261
 0.80642202 0.85522234 0.88483685 0.87212787]
2025-02-27T08:21:04.777049+0300 | DEBUG | Class recall: [0.832      0.926      0.661      0.59333333 0.794      0.6325
 0.879      0.827      0.922      0.873     ]
2025-02-27T08:21:04.829710+0300 | INFO | Training epoch #164 on client #0
2025-02-27T08:21:04.830711+0300 | DEBUG | Saving model to flat file storage. Save #164
2025-02-27T08:21:05.059226+0300 | INFO | [164,     0] loss: 0.015
2025-02-27T08:21:16.118108+0300 | INFO | [164,   100] loss: 1.490
2025-02-27T08:21:27.123538+0300 | INFO | [164,   200] loss: 1.483
2025-02-27T08:21:37.088806+0300 | INFO | [164,   300] loss: 1.490
2025-02-27T08:21:48.274130+0300 | INFO | [164,   400] loss: 1.484
2025-02-27T08:21:59.140358+0300 | INFO | [164,   500] loss: 1.493
2025-02-27T08:22:10.236158+0300 | INFO | [164,   600] loss: 1.487
2025-02-27T08:22:22.029013+0300 | INFO | [164,   700] loss: 1.500
2025-02-27T08:22:33.320665+0300 | INFO | [164,   800] loss: 1.487
2025-02-27T08:22:44.652393+0300 | INFO | [164,   900] loss: 1.486
2025-02-27T08:22:54.867512+0300 | INFO | [164,  1000] loss: 1.494
2025-02-27T08:23:06.639716+0300 | INFO | [164,  1100] loss: 1.493
2025-02-27T08:23:17.918120+0300 | INFO | [164,  1200] loss: 1.488
2025-02-27T08:23:34.046342+0300 | INFO | [164,  1300] loss: 1.502
2025-02-27T08:23:44.303187+0300 | INFO | [164,  1400] loss: 1.491
2025-02-27T08:23:55.037431+0300 | INFO | [164,  1500] loss: 1.497
2025-02-27T08:24:05.910884+0300 | INFO | [164,  1600] loss: 1.494
2025-02-27T08:24:15.999319+0300 | INFO | [164,  1700] loss: 1.489
2025-02-27T08:24:27.997381+0300 | INFO | [164,  1800] loss: 1.491
2025-02-27T08:24:39.997319+0300 | INFO | [164,  1900] loss: 1.488
2025-02-27T08:24:49.846589+0300 | INFO | [164,  2000] loss: 1.486
2025-02-27T08:25:02.849859+0300 | INFO | [164,  2100] loss: 1.489
2025-02-27T08:25:13.851582+0300 | INFO | [164,  2200] loss: 1.495
2025-02-27T08:25:25.073375+0300 | INFO | [164,  2300] loss: 1.481
2025-02-27T08:25:35.259281+0300 | INFO | [164,  2400] loss: 1.504
2025-02-27T08:25:46.235991+0300 | INFO | [164,  2500] loss: 1.488
2025-02-27T08:25:57.899225+0300 | INFO | [164,  2600] loss: 1.484
2025-02-27T08:26:11.075134+0300 | INFO | [164,  2700] loss: 1.495
2025-02-27T08:26:22.353838+0300 | INFO | [164,  2800] loss: 1.480
2025-02-27T08:26:33.439319+0300 | INFO | [164,  2900] loss: 1.503
2025-02-27T08:26:44.671301+0300 | INFO | [164,  3000] loss: 1.488
2025-02-27T08:26:54.969547+0300 | INFO | [164,  3100] loss: 1.485
2025-02-27T08:27:07.444207+0300 | INFO | [164,  3200] loss: 1.494
2025-02-27T08:27:18.078077+0300 | INFO | [164,  3300] loss: 1.499
2025-02-27T08:27:28.368909+0300 | INFO | [164,  3400] loss: 1.483
2025-02-27T08:27:39.549738+0300 | INFO | [164,  3500] loss: 1.488
2025-02-27T08:27:50.851552+0300 | INFO | [164,  3600] loss: 1.489
2025-02-27T08:28:00.847697+0300 | INFO | [164,  3700] loss: 1.496
2025-02-27T08:28:11.958461+0300 | INFO | [164,  3800] loss: 1.482
2025-02-27T08:28:22.975065+0300 | INFO | [164,  3900] loss: 1.487
2025-02-27T08:28:33.034839+0300 | INFO | [164,  4000] loss: 1.490
2025-02-27T08:28:43.855176+0300 | INFO | [164,  4100] loss: 1.485
2025-02-27T08:28:54.657038+0300 | INFO | [164,  4200] loss: 1.494
2025-02-27T08:29:04.826859+0300 | INFO | [164,  4300] loss: 1.490
2025-02-27T08:29:15.946663+0300 | INFO | [164,  4400] loss: 1.499
2025-02-27T08:29:27.873054+0300 | INFO | [164,  4500] loss: 1.490
2025-02-27T08:29:39.276412+0300 | INFO | [164,  4600] loss: 1.491
2025-02-27T08:29:50.045817+0300 | INFO | [164,  4700] loss: 1.496
2025-02-27T08:30:01.227151+0300 | INFO | [164,  4800] loss: 1.486
2025-02-27T08:30:12.086276+0300 | INFO | [164,  4900] loss: 1.494
2025-02-27T08:30:22.398355+0300 | DEBUG | Saving model to flat file storage. Save #164
2025-02-27T08:30:22.425805+0300 | INFO | Averaging client parameters
2025-02-27T08:30:22.434800+0300 | INFO | Updating parameters on client #0
2025-02-27T08:30:38.071740+0300 | DEBUG | Test set: Accuracy: 7931/10000 (79%)
2025-02-27T08:30:38.072739+0300 | DEBUG | Test set: Loss: 1.6680262088775635
2025-02-27T08:30:38.161994+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.82      0.83      1000
           1       0.92      0.91      0.91      1000
           2       0.78      0.68      0.72      1000
           3       0.68      0.60      0.63      1200
           4       0.79      0.78      0.78      1000
           5       0.52      0.66      0.58       800
           6       0.83      0.86      0.85      1000
           7       0.85      0.82      0.83      1000
           8       0.87      0.92      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T08:30:38.164992+0300 | DEBUG | Confusion Matrix:
[[822  13  30  10  16  11   6  11  49  32]
 [  3 909   3   1   1   2   6   4  23  48]
 [ 56   4 677  51  65  63  49  18   8   9]
 [ 13   2  41 717  38 277  42  37  16  17]
 [ 10   3  33  58 777  44  35  30   7   3]
 [ 15   2  33 138  23 526  17  36   5   5]
 [  7   2  26  44  16  26 865   6   6   2]
 [ 16   3  12  28  43  60   5 822   2   9]
 [ 28  10   9   9   3   4   3   2 923   9]
 [ 14  42   7   6   2   5   8   5  18 893]]
2025-02-27T08:30:38.166988+0300 | DEBUG | Class precision: [0.83536585 0.91818182 0.77726751 0.67514124 0.78963415 0.51669941
 0.83494208 0.84654995 0.87322611 0.86952288]
2025-02-27T08:30:38.170109+0300 | DEBUG | Class recall: [0.822  0.909  0.677  0.5975 0.777  0.6575 0.865  0.822  0.923  0.893 ]
2025-02-27T08:30:38.220766+0300 | INFO | Training epoch #165 on client #0
2025-02-27T08:30:38.222772+0300 | DEBUG | Saving model to flat file storage. Save #165
2025-02-27T08:30:38.433081+0300 | INFO | [165,     0] loss: 0.015
2025-02-27T08:30:49.885133+0300 | INFO | [165,   100] loss: 1.502
2025-02-27T08:31:01.038190+0300 | INFO | [165,   200] loss: 1.492
2025-02-27T08:31:11.367999+0300 | INFO | [165,   300] loss: 1.489
2025-02-27T08:31:22.350199+0300 | INFO | [165,   400] loss: 1.497
2025-02-27T08:31:33.457402+0300 | INFO | [165,   500] loss: 1.491
2025-02-27T08:31:43.713965+0300 | INFO | [165,   600] loss: 1.476
2025-02-27T08:31:54.523122+0300 | INFO | [165,   700] loss: 1.487
2025-02-27T08:32:05.517264+0300 | INFO | [165,   800] loss: 1.490
2025-02-27T08:32:20.619145+0300 | INFO | [165,   900] loss: 1.498
2025-02-27T08:32:32.921059+0300 | INFO | [165,  1000] loss: 1.499
2025-02-27T08:32:44.109106+0300 | INFO | [165,  1100] loss: 1.485
2025-02-27T08:32:54.985135+0300 | INFO | [165,  1200] loss: 1.488
2025-02-27T08:33:04.948718+0300 | INFO | [165,  1300] loss: 1.486
2025-02-27T08:33:16.117994+0300 | INFO | [165,  1400] loss: 1.499
2025-02-27T08:33:27.119013+0300 | INFO | [165,  1500] loss: 1.491
2025-02-27T08:33:37.428347+0300 | INFO | [165,  1600] loss: 1.493
2025-02-27T08:33:48.260206+0300 | INFO | [165,  1700] loss: 1.486
2025-02-27T08:33:59.176875+0300 | INFO | [165,  1800] loss: 1.494
2025-02-27T08:34:09.436128+0300 | INFO | [165,  1900] loss: 1.490
2025-02-27T08:34:20.431819+0300 | INFO | [165,  2000] loss: 1.489
2025-02-27T08:34:31.502881+0300 | INFO | [165,  2100] loss: 1.493
2025-02-27T08:34:41.594033+0300 | INFO | [165,  2200] loss: 1.487
2025-02-27T08:34:52.664390+0300 | INFO | [165,  2300] loss: 1.499
2025-02-27T08:35:03.649585+0300 | INFO | [165,  2400] loss: 1.483
2025-02-27T08:35:13.672381+0300 | INFO | [165,  2500] loss: 1.487
2025-02-27T08:35:24.629675+0300 | INFO | [165,  2600] loss: 1.493
2025-02-27T08:35:36.672829+0300 | INFO | [165,  2700] loss: 1.478
2025-02-27T08:35:47.606719+0300 | INFO | [165,  2800] loss: 1.494
2025-02-27T08:35:58.896463+0300 | INFO | [165,  2900] loss: 1.490
2025-02-27T08:36:09.936329+0300 | INFO | [165,  3000] loss: 1.488
2025-02-27T08:36:20.983066+0300 | INFO | [165,  3100] loss: 1.488
2025-02-27T08:36:31.234517+0300 | INFO | [165,  3200] loss: 1.487
2025-02-27T08:36:45.616971+0300 | INFO | [165,  3300] loss: 1.483
2025-02-27T08:36:57.111834+0300 | INFO | [165,  3400] loss: 1.489
2025-02-27T08:37:08.163773+0300 | INFO | [165,  3500] loss: 1.487
2025-02-27T08:37:18.163511+0300 | INFO | [165,  3600] loss: 1.493
2025-02-27T08:37:29.469853+0300 | INFO | [165,  3700] loss: 1.486
2025-02-27T08:37:40.574495+0300 | INFO | [165,  3800] loss: 1.487
2025-02-27T08:37:51.027372+0300 | INFO | [165,  3900] loss: 1.486
2025-02-27T08:38:02.859697+0300 | INFO | [165,  4000] loss: 1.490
2025-02-27T08:38:14.007727+0300 | INFO | [165,  4100] loss: 1.490
2025-02-27T08:38:24.947750+0300 | INFO | [165,  4200] loss: 1.507
2025-02-27T08:38:37.131768+0300 | INFO | [165,  4300] loss: 1.492
2025-02-27T08:38:48.503507+0300 | INFO | [165,  4400] loss: 1.492
2025-02-27T08:39:00.259852+0300 | INFO | [165,  4500] loss: 1.486
2025-02-27T08:39:11.087760+0300 | INFO | [165,  4600] loss: 1.496
2025-02-27T08:39:23.215344+0300 | INFO | [165,  4700] loss: 1.484
2025-02-27T08:39:35.608275+0300 | INFO | [165,  4800] loss: 1.499
2025-02-27T08:39:49.129766+0300 | INFO | [165,  4900] loss: 1.491
2025-02-27T08:40:00.037508+0300 | DEBUG | Saving model to flat file storage. Save #165
2025-02-27T08:40:00.065518+0300 | INFO | Averaging client parameters
2025-02-27T08:40:00.071706+0300 | INFO | Updating parameters on client #0
2025-02-27T08:40:16.716334+0300 | DEBUG | Test set: Accuracy: 7946/10000 (79%)
2025-02-27T08:40:16.717331+0300 | DEBUG | Test set: Loss: 1.6658214330673218
2025-02-27T08:40:16.820609+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.91      0.92      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.68      0.60      0.64      1200
           4       0.76      0.81      0.79      1000
           5       0.54      0.62      0.58       800
           6       0.85      0.84      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T08:40:16.821605+0300 | DEBUG | Confusion Matrix:
[[850  12  32   8  17  10   6   9  36  20]
 [  7 921   4   1   1   2   5   2  19  38]
 [ 66   4 686  49  78  45  42  19   6   5]
 [ 15   2  47 726  58 243  36  39  16  18]
 [  9   4  32  45 811  36  27  29   5   2]
 [ 19   1  38 154  27 497  17  39   4   4]
 [  6   4  37  45  22  28 844   8   5   1]
 [ 15   3  11  26  47  54   3 830   3   8]
 [ 36  14   7   8   3   5   3   2 912  10]
 [ 26  52   7   6   2   4   8  10  16 869]]
2025-02-27T08:40:16.823827+0300 | DEBUG | Class precision: [0.81029552 0.90560472 0.76137625 0.67977528 0.76078799 0.53787879
 0.85166498 0.84093212 0.89236791 0.89128205]
2025-02-27T08:40:16.824843+0300 | DEBUG | Class recall: [0.85    0.921   0.686   0.605   0.811   0.62125 0.844   0.83    0.912
 0.869  ]
2025-02-27T08:40:16.872315+0300 | INFO | Training epoch #166 on client #0
2025-02-27T08:40:16.873316+0300 | DEBUG | Saving model to flat file storage. Save #166
2025-02-27T08:40:17.133008+0300 | INFO | [166,     0] loss: 0.015
2025-02-27T08:40:29.268903+0300 | INFO | [166,   100] loss: 1.482
2025-02-27T08:40:41.286888+0300 | INFO | [166,   200] loss: 1.501
2025-02-27T08:40:53.046524+0300 | INFO | [166,   300] loss: 1.493
2025-02-27T08:41:08.243996+0300 | INFO | [166,   400] loss: 1.492
2025-02-27T08:41:21.076563+0300 | INFO | [166,   500] loss: 1.489
2025-02-27T08:41:33.372618+0300 | INFO | [166,   600] loss: 1.486
2025-02-27T08:41:44.964896+0300 | INFO | [166,   700] loss: 1.482
2025-02-27T08:41:56.892640+0300 | INFO | [166,   800] loss: 1.487
2025-02-27T08:42:08.561699+0300 | INFO | [166,   900] loss: 1.496
2025-02-27T08:42:20.434868+0300 | INFO | [166,  1000] loss: 1.492
2025-02-27T08:42:32.872001+0300 | INFO | [166,  1100] loss: 1.488
2025-02-27T08:42:43.997421+0300 | INFO | [166,  1200] loss: 1.496
2025-02-27T08:42:54.155052+0300 | INFO | [166,  1300] loss: 1.500
2025-02-27T08:43:05.214483+0300 | INFO | [166,  1400] loss: 1.488
2025-02-27T08:43:16.655651+0300 | INFO | [166,  1500] loss: 1.498
2025-02-27T08:43:26.820173+0300 | INFO | [166,  1600] loss: 1.488
2025-02-27T08:43:37.874543+0300 | INFO | [166,  1700] loss: 1.493
2025-02-27T08:43:48.864347+0300 | INFO | [166,  1800] loss: 1.479
2025-02-27T08:43:58.917241+0300 | INFO | [166,  1900] loss: 1.487
2025-02-27T08:44:10.090076+0300 | INFO | [166,  2000] loss: 1.489
2025-02-27T08:44:20.915630+0300 | INFO | [166,  2100] loss: 1.493
2025-02-27T08:44:31.233976+0300 | INFO | [166,  2200] loss: 1.499
2025-02-27T08:44:42.058780+0300 | INFO | [166,  2300] loss: 1.483
2025-02-27T08:44:53.163043+0300 | INFO | [166,  2400] loss: 1.500
2025-02-27T08:45:04.593366+0300 | INFO | [166,  2500] loss: 1.490
2025-02-27T08:45:16.162246+0300 | INFO | [166,  2600] loss: 1.482
2025-02-27T08:45:27.242619+0300 | INFO | [166,  2700] loss: 1.490
2025-02-27T08:45:37.251621+0300 | INFO | [166,  2800] loss: 1.490
2025-02-27T08:45:48.028179+0300 | INFO | [166,  2900] loss: 1.492
2025-02-27T08:45:58.838601+0300 | INFO | [166,  3000] loss: 1.498
2025-02-27T08:46:09.061937+0300 | INFO | [166,  3100] loss: 1.495
2025-02-27T08:46:19.900521+0300 | INFO | [166,  3200] loss: 1.495
2025-02-27T08:46:30.980581+0300 | INFO | [166,  3300] loss: 1.494
2025-02-27T08:46:41.141232+0300 | INFO | [166,  3400] loss: 1.487
2025-02-27T08:46:51.829550+0300 | INFO | [166,  3500] loss: 1.491
2025-02-27T08:47:02.723581+0300 | INFO | [166,  3600] loss: 1.491
2025-02-27T08:47:12.787811+0300 | INFO | [166,  3700] loss: 1.487
2025-02-27T08:47:23.766130+0300 | INFO | [166,  3800] loss: 1.488
2025-02-27T08:47:35.238416+0300 | INFO | [166,  3900] loss: 1.496
2025-02-27T08:47:45.641453+0300 | INFO | [166,  4000] loss: 1.483
2025-02-27T08:47:56.636690+0300 | INFO | [166,  4100] loss: 1.488
2025-02-27T08:48:08.248053+0300 | INFO | [166,  4200] loss: 1.484
2025-02-27T08:48:18.704090+0300 | INFO | [166,  4300] loss: 1.485
2025-02-27T08:48:29.292577+0300 | INFO | [166,  4400] loss: 1.491
2025-02-27T08:48:40.189840+0300 | INFO | [166,  4500] loss: 1.481
2025-02-27T08:48:50.858320+0300 | INFO | [166,  4600] loss: 1.495
2025-02-27T08:49:01.298557+0300 | INFO | [166,  4700] loss: 1.488
2025-02-27T08:49:12.338800+0300 | INFO | [166,  4800] loss: 1.490
2025-02-27T08:49:22.239714+0300 | INFO | [166,  4900] loss: 1.493
2025-02-27T08:49:39.608277+0300 | DEBUG | Saving model to flat file storage. Save #166
2025-02-27T08:49:39.637751+0300 | INFO | Averaging client parameters
2025-02-27T08:49:39.647535+0300 | INFO | Updating parameters on client #0
2025-02-27T08:49:54.833068+0300 | DEBUG | Test set: Accuracy: 7908/10000 (79%)
2025-02-27T08:49:54.834083+0300 | DEBUG | Test set: Loss: 1.6690502166748047
2025-02-27T08:49:54.970105+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.80      0.85      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.78      0.67      0.72      1000
           3       0.68      0.59      0.63      1200
           4       0.77      0.79      0.78      1000
           5       0.53      0.66      0.59       800
           6       0.83      0.86      0.84      1000
           7       0.86      0.81      0.84      1000
           8       0.90      0.89      0.89      1000
           9       0.86      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T08:49:54.973405+0300 | DEBUG | Confusion Matrix:
[[846  18  29   7  16   9   5   6  36  28]
 [  7 928   2   1   1   2   5   0   9  45]
 [ 67   5 669  46  73  52  51  21   8   8]
 [ 17   7  44 709  50 266  48  29  13  17]
 [ 14   5  30  53 789  40  35  26   6   2]
 [ 15   2  29 137  23 526  17  38   5   8]
 [  7   6  27  40  20  23 860   8   5   4]
 [ 19   4  10  27  44  63   4 815   3  11]
 [ 45  24   8   9   2   4   3   1 888  16]
 [ 17  60   6   7   1   6   9   4  12 878]]
2025-02-27T08:49:54.974414+0300 | DEBUG | Class precision: [0.80265655 0.87629839 0.78337237 0.68436293 0.77428852 0.53077699
 0.82931533 0.85970464 0.90152284 0.8633235 ]
2025-02-27T08:49:54.976413+0300 | DEBUG | Class recall: [0.846      0.928      0.669      0.59083333 0.789      0.6575
 0.86       0.815      0.888      0.878     ]
2025-02-27T08:49:54.983462+0300 | INFO | Training epoch #167 on client #0
2025-02-27T08:49:54.983462+0300 | DEBUG | Saving model to flat file storage. Save #167
2025-02-27T08:49:55.271106+0300 | INFO | [167,     0] loss: 0.015
2025-02-27T08:50:05.650224+0300 | INFO | [167,   100] loss: 1.495
2025-02-27T08:50:16.517618+0300 | INFO | [167,   200] loss: 1.487
2025-02-27T08:50:27.846910+0300 | INFO | [167,   300] loss: 1.487
2025-02-27T08:50:38.068685+0300 | INFO | [167,   400] loss: 1.483
2025-02-27T08:50:49.170347+0300 | INFO | [167,   500] loss: 1.486
2025-02-27T08:51:00.366755+0300 | INFO | [167,   600] loss: 1.492
2025-02-27T08:51:10.615463+0300 | INFO | [167,   700] loss: 1.491
2025-02-27T08:51:22.233828+0300 | INFO | [167,   800] loss: 1.485
2025-02-27T08:51:34.951995+0300 | INFO | [167,   900] loss: 1.494
2025-02-27T08:51:45.175791+0300 | INFO | [167,  1000] loss: 1.485
2025-02-27T08:51:56.378800+0300 | INFO | [167,  1100] loss: 1.494
2025-02-27T08:52:06.965773+0300 | INFO | [167,  1200] loss: 1.490
2025-02-27T08:52:17.069206+0300 | INFO | [167,  1300] loss: 1.493
2025-02-27T08:52:29.521113+0300 | INFO | [167,  1400] loss: 1.490
2025-02-27T08:52:41.360130+0300 | INFO | [167,  1500] loss: 1.497
2025-02-27T08:52:52.485778+0300 | INFO | [167,  1600] loss: 1.485
2025-02-27T08:53:02.752190+0300 | INFO | [167,  1700] loss: 1.492
2025-02-27T08:53:14.234259+0300 | INFO | [167,  1800] loss: 1.485
2025-02-27T08:53:25.122191+0300 | INFO | [167,  1900] loss: 1.492
2025-02-27T08:53:35.635042+0300 | INFO | [167,  2000] loss: 1.490
2025-02-27T08:53:46.472361+0300 | INFO | [167,  2100] loss: 1.495
2025-02-27T08:53:57.631402+0300 | INFO | [167,  2200] loss: 1.487
2025-02-27T08:54:07.696346+0300 | INFO | [167,  2300] loss: 1.492
2025-02-27T08:54:19.158467+0300 | INFO | [167,  2400] loss: 1.489
2025-02-27T08:54:31.281431+0300 | INFO | [167,  2500] loss: 1.498
2025-02-27T08:54:41.593395+0300 | INFO | [167,  2600] loss: 1.494
2025-02-27T08:54:52.528627+0300 | INFO | [167,  2700] loss: 1.493
2025-02-27T08:55:03.466891+0300 | INFO | [167,  2800] loss: 1.488
2025-02-27T08:55:13.479755+0300 | INFO | [167,  2900] loss: 1.486
2025-02-27T08:55:25.439229+0300 | INFO | [167,  3000] loss: 1.493
2025-02-27T08:55:36.403355+0300 | INFO | [167,  3100] loss: 1.489
2025-02-27T08:55:46.772846+0300 | INFO | [167,  3200] loss: 1.500
2025-02-27T08:55:57.369687+0300 | INFO | [167,  3300] loss: 1.485
2025-02-27T08:56:09.022463+0300 | INFO | [167,  3400] loss: 1.486
2025-02-27T08:56:19.846201+0300 | INFO | [167,  3500] loss: 1.486
2025-02-27T08:56:30.662611+0300 | INFO | [167,  3600] loss: 1.491
2025-02-27T08:56:41.712609+0300 | INFO | [167,  3700] loss: 1.482
2025-02-27T08:56:52.797860+0300 | INFO | [167,  3800] loss: 1.495
2025-02-27T08:57:03.149356+0300 | INFO | [167,  3900] loss: 1.502
2025-02-27T08:57:14.218913+0300 | INFO | [167,  4000] loss: 1.486
2025-02-27T08:57:26.246767+0300 | INFO | [167,  4100] loss: 1.497
2025-02-27T08:57:36.581373+0300 | INFO | [167,  4200] loss: 1.487
2025-02-27T08:57:47.897948+0300 | INFO | [167,  4300] loss: 1.496
2025-02-27T08:57:59.000120+0300 | INFO | [167,  4400] loss: 1.482
2025-02-27T08:58:11.627279+0300 | INFO | [167,  4500] loss: 1.492
2025-02-27T08:58:25.072936+0300 | INFO | [167,  4600] loss: 1.492
2025-02-27T08:58:36.460906+0300 | INFO | [167,  4700] loss: 1.490
2025-02-27T08:58:47.243898+0300 | INFO | [167,  4800] loss: 1.490
2025-02-27T08:58:57.778811+0300 | INFO | [167,  4900] loss: 1.491
2025-02-27T08:59:08.214496+0300 | DEBUG | Saving model to flat file storage. Save #167
2025-02-27T08:59:08.239196+0300 | INFO | Averaging client parameters
2025-02-27T08:59:08.245595+0300 | INFO | Updating parameters on client #0
2025-02-27T08:59:23.668097+0300 | DEBUG | Test set: Accuracy: 7939/10000 (79%)
2025-02-27T08:59:23.670097+0300 | DEBUG | Test set: Loss: 1.6664007902145386
2025-02-27T08:59:23.765911+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.84      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.69      0.73      1000
           3       0.68      0.58      0.63      1200
           4       0.77      0.80      0.79      1000
           5       0.54      0.63      0.58       800
           6       0.81      0.87      0.84      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T08:59:23.767911+0300 | DEBUG | Confusion Matrix:
[[843  15  34   9  13   8   7   6  39  26]
 [  7 921   3   0   1   2   5   1  15  45]
 [ 58   4 686  46  74  43  57  18   8   6]
 [ 17   5  45 701  54 257  56  31  17  17]
 [ 13   4  34  44 803  34  35  25   6   2]
 [ 14   1  33 152  26 506  19  37   5   7]
 [  6   4  29  38  17  20 872   7   4   3]
 [ 16   4  11  27  51  57   5 818   3   8]
 [ 32  17   7   7   3   3   4   2 911  14]
 [ 21  53   6   4   1   5  11   6  15 878]]
2025-02-27T08:59:23.770907+0300 | DEBUG | Class precision: [0.82083739 0.8959144  0.77252252 0.68190661 0.76989453 0.54117647
 0.81419234 0.86014721 0.89051808 0.87276342]
2025-02-27T08:59:23.774237+0300 | DEBUG | Class recall: [0.843      0.921      0.686      0.58416667 0.803      0.6325
 0.872      0.818      0.911      0.878     ]
2025-02-27T08:59:23.822893+0300 | INFO | Training epoch #168 on client #0
2025-02-27T08:59:23.824891+0300 | DEBUG | Saving model to flat file storage. Save #168
2025-02-27T08:59:24.040573+0300 | INFO | [168,     0] loss: 0.017
2025-02-27T08:59:35.474786+0300 | INFO | [168,   100] loss: 1.498
2025-02-27T08:59:45.430304+0300 | INFO | [168,   200] loss: 1.498
2025-02-27T08:59:56.481262+0300 | INFO | [168,   300] loss: 1.483
2025-02-27T09:00:07.502323+0300 | INFO | [168,   400] loss: 1.498
2025-02-27T09:00:17.665778+0300 | INFO | [168,   500] loss: 1.483
2025-02-27T09:00:28.781662+0300 | INFO | [168,   600] loss: 1.497
2025-02-27T09:00:40.585198+0300 | INFO | [168,   700] loss: 1.493
2025-02-27T09:00:51.282214+0300 | INFO | [168,   800] loss: 1.490
2025-02-27T09:01:01.668731+0300 | INFO | [168,   900] loss: 1.484
2025-02-27T09:01:12.701265+0300 | INFO | [168,  1000] loss: 1.488
2025-02-27T09:01:23.702622+0300 | INFO | [168,  1100] loss: 1.493
2025-02-27T09:01:34.262049+0300 | INFO | [168,  1200] loss: 1.501
2025-02-27T09:01:45.312825+0300 | INFO | [168,  1300] loss: 1.483
2025-02-27T09:01:56.612478+0300 | INFO | [168,  1400] loss: 1.485
2025-02-27T09:02:06.939523+0300 | INFO | [168,  1500] loss: 1.490
2025-02-27T09:02:17.809393+0300 | INFO | [168,  1600] loss: 1.492
2025-02-27T09:02:28.985914+0300 | INFO | [168,  1700] loss: 1.493
2025-02-27T09:02:39.987849+0300 | INFO | [168,  1800] loss: 1.487
2025-02-27T09:02:51.300851+0300 | INFO | [168,  1900] loss: 1.491
2025-02-27T09:03:02.308313+0300 | INFO | [168,  2000] loss: 1.485
2025-02-27T09:03:12.566471+0300 | INFO | [168,  2100] loss: 1.493
2025-02-27T09:03:24.837771+0300 | INFO | [168,  2200] loss: 1.485
2025-02-27T09:03:36.710467+0300 | INFO | [168,  2300] loss: 1.485
2025-02-27T09:03:47.668496+0300 | INFO | [168,  2400] loss: 1.479
2025-02-27T09:03:57.965439+0300 | INFO | [168,  2500] loss: 1.486
2025-02-27T09:04:08.958200+0300 | INFO | [168,  2600] loss: 1.490
2025-02-27T09:04:19.831851+0300 | INFO | [168,  2700] loss: 1.484
2025-02-27T09:04:30.453035+0300 | INFO | [168,  2800] loss: 1.493
2025-02-27T09:04:41.389942+0300 | INFO | [168,  2900] loss: 1.488
2025-02-27T09:04:52.137299+0300 | INFO | [168,  3000] loss: 1.488
2025-02-27T09:05:02.481612+0300 | INFO | [168,  3100] loss: 1.503
2025-02-27T09:05:13.272815+0300 | INFO | [168,  3200] loss: 1.488
2025-02-27T09:05:24.142327+0300 | INFO | [168,  3300] loss: 1.492
2025-02-27T09:05:34.464220+0300 | INFO | [168,  3400] loss: 1.497
2025-02-27T09:05:45.497188+0300 | INFO | [168,  3500] loss: 1.494
2025-02-27T09:05:56.729217+0300 | INFO | [168,  3600] loss: 1.492
2025-02-27T09:06:07.732694+0300 | INFO | [168,  3700] loss: 1.493
2025-02-27T09:06:19.415707+0300 | INFO | [168,  3800] loss: 1.490
2025-02-27T09:06:31.434049+0300 | INFO | [168,  3900] loss: 1.484
2025-02-27T09:06:50.030556+0300 | INFO | [168,  4000] loss: 1.488
2025-02-27T09:07:02.173599+0300 | INFO | [168,  4100] loss: 1.500
2025-02-27T09:07:13.333645+0300 | INFO | [168,  4200] loss: 1.502
2025-02-27T09:07:24.980989+0300 | INFO | [168,  4300] loss: 1.487
2025-02-27T09:07:37.046019+0300 | INFO | [168,  4400] loss: 1.500
2025-02-27T09:07:49.162338+0300 | INFO | [168,  4500] loss: 1.482
2025-02-27T09:08:01.404083+0300 | INFO | [168,  4600] loss: 1.491
2025-02-27T09:08:13.423444+0300 | INFO | [168,  4700] loss: 1.488
2025-02-27T09:08:25.582499+0300 | INFO | [168,  4800] loss: 1.478
2025-02-27T09:08:39.232651+0300 | INFO | [168,  4900] loss: 1.495
2025-02-27T09:08:50.594675+0300 | DEBUG | Saving model to flat file storage. Save #168
2025-02-27T09:08:50.617406+0300 | INFO | Averaging client parameters
2025-02-27T09:08:50.629237+0300 | INFO | Updating parameters on client #0
2025-02-27T09:09:07.330069+0300 | DEBUG | Test set: Accuracy: 7963/10000 (80%)
2025-02-27T09:09:07.331078+0300 | DEBUG | Test set: Loss: 1.664618730545044
2025-02-27T09:09:07.461523+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.85      0.83      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.72      0.73      1000
           3       0.69      0.60      0.64      1200
           4       0.78      0.81      0.79      1000
           5       0.55      0.60      0.58       800
           6       0.83      0.86      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.80     10000

2025-02-27T09:09:07.463490+0300 | DEBUG | Confusion Matrix:
[[847  16  39   9  10   8   5   8  36  22]
 [  4 926   4   1   1   2   6   2  15  39]
 [ 54   5 723  43  68  31  44  18   7   7]
 [ 17   4  62 725  49 234  45  37  15  12]
 [ 13   3  37  41 806  35  32  25   6   2]
 [ 16   1  44 160  27 484  20  38   5   5]
 [  6   4  45  40  17  18 858   7   4   1]
 [ 15   3  12  19  53  55   4 827   3   9]
 [ 36  18   8   9   4   5   4   1 906   9]
 [ 21  65   7   8   1   5  10   6  16 861]]
2025-02-27T09:09:07.464900+0300 | DEBUG | Class precision: [0.82312925 0.8861244  0.73700306 0.68720379 0.77799228 0.55188141
 0.83463035 0.85345717 0.89437315 0.89038263]
2025-02-27T09:09:07.465914+0300 | DEBUG | Class recall: [0.847      0.926      0.723      0.60416667 0.806      0.605
 0.858      0.827      0.906      0.861     ]
2025-02-27T09:09:07.466912+0300 | INFO | Training epoch #169 on client #0
2025-02-27T09:09:07.469303+0300 | DEBUG | Saving model to flat file storage. Save #169
2025-02-27T09:09:07.746881+0300 | INFO | [169,     0] loss: 0.015
2025-02-27T09:09:18.985646+0300 | INFO | [169,   100] loss: 1.486
2025-02-27T09:09:32.404730+0300 | INFO | [169,   200] loss: 1.485
2025-02-27T09:09:44.095027+0300 | INFO | [169,   300] loss: 1.489
2025-02-27T09:09:55.689035+0300 | INFO | [169,   400] loss: 1.494
2025-02-27T09:10:06.464198+0300 | INFO | [169,   500] loss: 1.493
2025-02-27T09:10:18.849472+0300 | INFO | [169,   600] loss: 1.491
2025-02-27T09:10:30.747600+0300 | INFO | [169,   700] loss: 1.487
2025-02-27T09:10:41.813469+0300 | INFO | [169,   800] loss: 1.487
2025-02-27T09:10:53.676450+0300 | INFO | [169,   900] loss: 1.490
2025-02-27T09:11:05.059427+0300 | INFO | [169,  1000] loss: 1.494
2025-02-27T09:11:16.205573+0300 | INFO | [169,  1100] loss: 1.488
2025-02-27T09:11:26.464470+0300 | INFO | [169,  1200] loss: 1.487
2025-02-27T09:11:39.242337+0300 | INFO | [169,  1300] loss: 1.493
2025-02-27T09:11:50.084884+0300 | INFO | [169,  1400] loss: 1.481
2025-02-27T09:12:00.153503+0300 | INFO | [169,  1500] loss: 1.496
2025-02-27T09:12:11.024346+0300 | INFO | [169,  1600] loss: 1.490
2025-02-27T09:12:21.953115+0300 | INFO | [169,  1700] loss: 1.496
2025-02-27T09:12:33.876637+0300 | INFO | [169,  1800] loss: 1.492
2025-02-27T09:12:45.201919+0300 | INFO | [169,  1900] loss: 1.493
2025-02-27T09:12:56.265039+0300 | INFO | [169,  2000] loss: 1.493
2025-02-27T09:13:06.753888+0300 | INFO | [169,  2100] loss: 1.489
2025-02-27T09:13:18.210947+0300 | INFO | [169,  2200] loss: 1.506
2025-02-27T09:13:29.152727+0300 | INFO | [169,  2300] loss: 1.483
2025-02-27T09:13:40.475806+0300 | INFO | [169,  2400] loss: 1.487
2025-02-27T09:13:50.751878+0300 | INFO | [169,  2500] loss: 1.482
2025-02-27T09:14:01.647408+0300 | INFO | [169,  2600] loss: 1.493
2025-02-27T09:14:12.428313+0300 | INFO | [169,  2700] loss: 1.494
2025-02-27T09:14:22.673855+0300 | INFO | [169,  2800] loss: 1.490
2025-02-27T09:14:35.386371+0300 | INFO | [169,  2900] loss: 1.501
2025-02-27T09:14:46.114735+0300 | INFO | [169,  3000] loss: 1.487
2025-02-27T09:14:56.196057+0300 | INFO | [169,  3100] loss: 1.495
2025-02-27T09:15:07.521767+0300 | INFO | [169,  3200] loss: 1.494
2025-02-27T09:15:18.451208+0300 | INFO | [169,  3300] loss: 1.492
2025-02-27T09:15:29.497121+0300 | INFO | [169,  3400] loss: 1.483
2025-02-27T09:15:42.984839+0300 | INFO | [169,  3500] loss: 1.483
2025-02-27T09:16:00.549661+0300 | INFO | [169,  3600] loss: 1.494
2025-02-27T09:16:13.920559+0300 | INFO | [169,  3700] loss: 1.486
2025-02-27T09:16:25.707545+0300 | INFO | [169,  3800] loss: 1.495
2025-02-27T09:16:38.651072+0300 | INFO | [169,  3900] loss: 1.486
2025-02-27T09:16:49.109711+0300 | INFO | [169,  4000] loss: 1.487
2025-02-27T09:17:01.897629+0300 | INFO | [169,  4100] loss: 1.490
2025-02-27T09:17:12.798586+0300 | INFO | [169,  4200] loss: 1.495
2025-02-27T09:17:23.617065+0300 | INFO | [169,  4300] loss: 1.480
2025-02-27T09:17:34.019312+0300 | INFO | [169,  4400] loss: 1.494
2025-02-27T09:17:45.027549+0300 | INFO | [169,  4500] loss: 1.499
2025-02-27T09:17:56.205668+0300 | INFO | [169,  4600] loss: 1.493
2025-02-27T09:18:06.476436+0300 | INFO | [169,  4700] loss: 1.497
2025-02-27T09:18:17.625031+0300 | INFO | [169,  4800] loss: 1.486
2025-02-27T09:18:28.833918+0300 | INFO | [169,  4900] loss: 1.486
2025-02-27T09:18:39.264360+0300 | DEBUG | Saving model to flat file storage. Save #169
2025-02-27T09:18:39.286383+0300 | INFO | Averaging client parameters
2025-02-27T09:18:39.298022+0300 | INFO | Updating parameters on client #0
2025-02-27T09:18:55.180486+0300 | DEBUG | Test set: Accuracy: 7914/10000 (79%)
2025-02-27T09:18:55.180486+0300 | DEBUG | Test set: Loss: 1.6684539318084717
2025-02-27T09:18:55.274924+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.88      0.93      0.90      1000
           2       0.74      0.71      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.54      0.62      0.57       800
           6       0.85      0.85      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T09:18:55.278928+0300 | DEBUG | Confusion Matrix:
[[837  15  40   7  14   7   5   9  41  25]
 [  5 926   3   0   1   2   4   1  15  43]
 [ 58   7 713  41  69  38  43  18   7   6]
 [ 25  10  63 678  56 255  42  37  16  18]
 [ 12   4  39  36 805  35  29  32   6   2]
 [ 18   3  42 151  29 493  17  36   6   5]
 [  7   6  37  39  20  21 855   6   5   4]
 [ 17   4  13  17  48  56   3 828   3  11]
 [ 35  19   8   4   3   3   3   1 914  10]
 [ 20  62   8   4   1   5  10   8  17 865]]
2025-02-27T09:18:55.280927+0300 | DEBUG | Class precision: [0.80947776 0.87689394 0.73809524 0.69396111 0.76959847 0.53879781
 0.84569733 0.84836066 0.88737864 0.87462083]
2025-02-27T09:18:55.282930+0300 | DEBUG | Class recall: [0.837   0.926   0.713   0.565   0.805   0.61625 0.855   0.828   0.914
 0.865  ]
2025-02-27T09:18:55.333146+0300 | INFO | Training epoch #170 on client #0
2025-02-27T09:18:55.334154+0300 | DEBUG | Saving model to flat file storage. Save #170
2025-02-27T09:18:55.548802+0300 | INFO | [170,     0] loss: 0.015
2025-02-27T09:19:07.335467+0300 | INFO | [170,   100] loss: 1.497
2025-02-27T09:19:18.876860+0300 | INFO | [170,   200] loss: 1.489
2025-02-27T09:19:29.752895+0300 | INFO | [170,   300] loss: 1.489
2025-02-27T09:19:41.502549+0300 | INFO | [170,   400] loss: 1.478
2025-02-27T09:19:52.468085+0300 | INFO | [170,   500] loss: 1.493
2025-02-27T09:20:03.321156+0300 | INFO | [170,   600] loss: 1.489
2025-02-27T09:20:13.366673+0300 | INFO | [170,   700] loss: 1.498
2025-02-27T09:20:24.147618+0300 | INFO | [170,   800] loss: 1.489
2025-02-27T09:20:37.055218+0300 | INFO | [170,   900] loss: 1.489
2025-02-27T09:20:47.185830+0300 | INFO | [170,  1000] loss: 1.499
2025-02-27T09:20:58.030990+0300 | INFO | [170,  1100] loss: 1.489
2025-02-27T09:21:09.266329+0300 | INFO | [170,  1200] loss: 1.501
2025-02-27T09:21:19.133869+0300 | INFO | [170,  1300] loss: 1.489
2025-02-27T09:21:30.209027+0300 | INFO | [170,  1400] loss: 1.492
2025-02-27T09:21:41.385015+0300 | INFO | [170,  1500] loss: 1.494
2025-02-27T09:21:51.556163+0300 | INFO | [170,  1600] loss: 1.483
2025-02-27T09:22:02.571584+0300 | INFO | [170,  1700] loss: 1.494
2025-02-27T09:22:14.216088+0300 | INFO | [170,  1800] loss: 1.491
2025-02-27T09:22:24.552674+0300 | INFO | [170,  1900] loss: 1.497
2025-02-27T09:22:35.894515+0300 | INFO | [170,  2000] loss: 1.484
2025-02-27T09:22:47.639834+0300 | INFO | [170,  2100] loss: 1.492
2025-02-27T09:22:57.820703+0300 | INFO | [170,  2200] loss: 1.488
2025-02-27T09:23:08.764801+0300 | INFO | [170,  2300] loss: 1.495
2025-02-27T09:23:19.482842+0300 | INFO | [170,  2400] loss: 1.489
2025-02-27T09:23:29.744334+0300 | INFO | [170,  2500] loss: 1.485
2025-02-27T09:23:40.504746+0300 | INFO | [170,  2600] loss: 1.496
2025-02-27T09:23:51.623077+0300 | INFO | [170,  2700] loss: 1.482
2025-02-27T09:24:01.801011+0300 | INFO | [170,  2800] loss: 1.492
2025-02-27T09:24:12.540055+0300 | INFO | [170,  2900] loss: 1.493
2025-02-27T09:24:25.744317+0300 | INFO | [170,  3000] loss: 1.490
2025-02-27T09:24:41.156173+0300 | INFO | [170,  3100] loss: 1.491
2025-02-27T09:24:53.138533+0300 | INFO | [170,  3200] loss: 1.490
2025-02-27T09:25:03.262695+0300 | INFO | [170,  3300] loss: 1.489
2025-02-27T09:25:13.977500+0300 | INFO | [170,  3400] loss: 1.489
2025-02-27T09:25:24.794676+0300 | INFO | [170,  3500] loss: 1.494
2025-02-27T09:25:35.277629+0300 | INFO | [170,  3600] loss: 1.490
2025-02-27T09:25:46.444627+0300 | INFO | [170,  3700] loss: 1.495
2025-02-27T09:25:58.060967+0300 | INFO | [170,  3800] loss: 1.493
2025-02-27T09:26:09.334609+0300 | INFO | [170,  3900] loss: 1.486
2025-02-27T09:26:20.745128+0300 | INFO | [170,  4000] loss: 1.488
2025-02-27T09:26:32.136010+0300 | INFO | [170,  4100] loss: 1.491
2025-02-27T09:26:42.759064+0300 | INFO | [170,  4200] loss: 1.490
2025-02-27T09:26:53.021369+0300 | INFO | [170,  4300] loss: 1.484
2025-02-27T09:27:05.705864+0300 | INFO | [170,  4400] loss: 1.492
2025-02-27T09:27:17.189747+0300 | INFO | [170,  4500] loss: 1.488
2025-02-27T09:27:28.493524+0300 | INFO | [170,  4600] loss: 1.484
2025-02-27T09:27:39.619072+0300 | INFO | [170,  4700] loss: 1.487
2025-02-27T09:27:50.854365+0300 | INFO | [170,  4800] loss: 1.485
2025-02-27T09:28:01.019130+0300 | INFO | [170,  4900] loss: 1.493
2025-02-27T09:28:11.975041+0300 | DEBUG | Saving model to flat file storage. Save #170
2025-02-27T09:28:11.999035+0300 | INFO | Averaging client parameters
2025-02-27T09:28:12.009054+0300 | INFO | Updating parameters on client #0
2025-02-27T09:28:27.575361+0300 | DEBUG | Test set: Accuracy: 7953/10000 (80%)
2025-02-27T09:28:27.578362+0300 | DEBUG | Test set: Loss: 1.6658716201782227
2025-02-27T09:28:27.664145+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.90      0.91      0.90      1000
           2       0.77      0.70      0.73      1000
           3       0.69      0.58      0.63      1200
           4       0.78      0.80      0.79      1000
           5       0.54      0.64      0.59       800
           6       0.85      0.86      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.85      0.89      0.87      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.79     10000

2025-02-27T09:28:27.668518+0300 | DEBUG | Confusion Matrix:
[[837  14  38   7  14   7   5   7  40  31]
 [  4 905   4   0   1   1   6   2  21  56]
 [ 58   5 702  42  69  42  47  19   7   9]
 [ 21   8  46 691  52 262  40  38  18  24]
 [ 12   6  31  45 798  38  30  32   6   2]
 [ 17   1  33 147  25 513  13  37   5   9]
 [  7   5  34  42  17  22 857   6   5   5]
 [ 17   4   9  20  43  54   2 833   3  15]
 [ 33  11   7   5   2   3   4   1 924  10]
 [ 21  42   8   3   1   3   8   6  15 893]]
2025-02-27T09:28:27.670520+0300 | DEBUG | Class precision: [0.81499513 0.9040959  0.76973684 0.68962076 0.78082192 0.54285714
 0.84683794 0.84913354 0.88505747 0.84724858]
2025-02-27T09:28:27.671523+0300 | DEBUG | Class recall: [0.837      0.905      0.702      0.57583333 0.798      0.64125
 0.857      0.833      0.924      0.893     ]
2025-02-27T09:28:27.718094+0300 | INFO | Training epoch #171 on client #0
2025-02-27T09:28:27.720096+0300 | DEBUG | Saving model to flat file storage. Save #171
2025-02-27T09:28:27.948297+0300 | INFO | [171,     0] loss: 0.015
2025-02-27T09:28:39.012312+0300 | INFO | [171,   100] loss: 1.487
2025-02-27T09:28:49.427593+0300 | INFO | [171,   200] loss: 1.487
2025-02-27T09:29:01.338566+0300 | INFO | [171,   300] loss: 1.486
2025-02-27T09:29:14.372392+0300 | INFO | [171,   400] loss: 1.487
2025-02-27T09:29:24.803387+0300 | INFO | [171,   500] loss: 1.489
2025-02-27T09:29:36.988024+0300 | INFO | [171,   600] loss: 1.485
2025-02-27T09:29:47.989445+0300 | INFO | [171,   700] loss: 1.486
2025-02-27T09:29:59.240525+0300 | INFO | [171,   800] loss: 1.491
2025-02-27T09:30:10.654158+0300 | INFO | [171,   900] loss: 1.488
2025-02-27T09:30:21.668358+0300 | INFO | [171,  1000] loss: 1.499
2025-02-27T09:30:32.927141+0300 | INFO | [171,  1100] loss: 1.492
2025-02-27T09:30:44.127151+0300 | INFO | [171,  1200] loss: 1.493
2025-02-27T09:30:54.257234+0300 | INFO | [171,  1300] loss: 1.497
2025-02-27T09:31:06.930570+0300 | INFO | [171,  1400] loss: 1.499
2025-02-27T09:31:18.118010+0300 | INFO | [171,  1500] loss: 1.499
2025-02-27T09:31:28.993281+0300 | INFO | [171,  1600] loss: 1.491
2025-02-27T09:31:39.878971+0300 | INFO | [171,  1700] loss: 1.484
2025-02-27T09:31:50.985479+0300 | INFO | [171,  1800] loss: 1.487
2025-02-27T09:32:01.223369+0300 | INFO | [171,  1900] loss: 1.490
2025-02-27T09:32:12.607842+0300 | INFO | [171,  2000] loss: 1.484
2025-02-27T09:32:23.501471+0300 | INFO | [171,  2100] loss: 1.481
2025-02-27T09:32:33.797362+0300 | INFO | [171,  2200] loss: 1.491
2025-02-27T09:32:45.093359+0300 | INFO | [171,  2300] loss: 1.487
2025-02-27T09:32:56.155974+0300 | INFO | [171,  2400] loss: 1.491
2025-02-27T09:33:06.656114+0300 | INFO | [171,  2500] loss: 1.492
2025-02-27T09:33:17.006421+0300 | INFO | [171,  2600] loss: 1.498
2025-02-27T09:33:27.922251+0300 | INFO | [171,  2700] loss: 1.488
2025-02-27T09:33:42.378637+0300 | INFO | [171,  2800] loss: 1.489
2025-02-27T09:33:53.267797+0300 | INFO | [171,  2900] loss: 1.493
2025-02-27T09:34:02.872942+0300 | INFO | [171,  3000] loss: 1.486
2025-02-27T09:34:13.935887+0300 | INFO | [171,  3100] loss: 1.484
2025-02-27T09:34:23.870792+0300 | INFO | [171,  3200] loss: 1.496
2025-02-27T09:34:35.596113+0300 | INFO | [171,  3300] loss: 1.497
2025-02-27T09:34:46.520895+0300 | INFO | [171,  3400] loss: 1.495
2025-02-27T09:34:56.971826+0300 | INFO | [171,  3500] loss: 1.488
2025-02-27T09:35:08.547166+0300 | INFO | [171,  3600] loss: 1.485
2025-02-27T09:35:19.352680+0300 | INFO | [171,  3700] loss: 1.489
2025-02-27T09:35:29.569041+0300 | INFO | [171,  3800] loss: 1.491
2025-02-27T09:35:40.441652+0300 | INFO | [171,  3900] loss: 1.493
2025-02-27T09:35:51.398574+0300 | INFO | [171,  4000] loss: 1.496
2025-02-27T09:36:01.914193+0300 | INFO | [171,  4100] loss: 1.490
2025-02-27T09:36:12.900764+0300 | INFO | [171,  4200] loss: 1.490
2025-02-27T09:36:24.034693+0300 | INFO | [171,  4300] loss: 1.486
2025-02-27T09:36:35.328486+0300 | INFO | [171,  4400] loss: 1.484
2025-02-27T09:36:47.212675+0300 | INFO | [171,  4500] loss: 1.504
2025-02-27T09:36:59.064093+0300 | INFO | [171,  4600] loss: 1.494
2025-02-27T09:37:09.998407+0300 | INFO | [171,  4700] loss: 1.484
2025-02-27T09:37:20.075562+0300 | INFO | [171,  4800] loss: 1.486
2025-02-27T09:37:31.170709+0300 | INFO | [171,  4900] loss: 1.493
2025-02-27T09:37:42.119404+0300 | DEBUG | Saving model to flat file storage. Save #171
2025-02-27T09:37:42.139748+0300 | INFO | Averaging client parameters
2025-02-27T09:37:42.151738+0300 | INFO | Updating parameters on client #0
2025-02-27T09:37:59.585519+0300 | DEBUG | Test set: Accuracy: 7921/10000 (79%)
2025-02-27T09:37:59.586529+0300 | DEBUG | Test set: Loss: 1.6675076484680176
2025-02-27T09:37:59.687088+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.88      0.93      0.90      1000
           2       0.76      0.70      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.52      0.65      0.58       800
           6       0.86      0.85      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T09:37:59.689098+0300 | DEBUG | Confusion Matrix:
[[849  17  35   9  11   8   5   6  37  23]
 [  8 930   3   0   1   1   4   1  13  39]
 [ 57   8 702  45  70  48  39  17   6   8]
 [ 20  10  46 690  42 286  38  30  17  21]
 [ 12   6  37  49 789  42  26  30   6   3]
 [ 18   3  37 147  22 516  12  34   5   6]
 [  8   6  41  43  16  24 848   6   4   4]
 [ 15   4  13  26  43  60   2 819   4  14]
 [ 39  18   7   7   2   3   4   1 910   9]
 [ 25  60   7   4   1   4   8   6  17 868]]
2025-02-27T09:37:59.690585+0300 | DEBUG | Class precision: [0.80780209 0.87570621 0.75646552 0.67647059 0.79137412 0.52016129
 0.86004057 0.86210526 0.89303238 0.87236181]
2025-02-27T09:37:59.690585+0300 | DEBUG | Class recall: [0.849 0.93  0.702 0.575 0.789 0.645 0.848 0.819 0.91  0.868]
2025-02-27T09:37:59.748202+0300 | INFO | Training epoch #172 on client #0
2025-02-27T09:37:59.751202+0300 | DEBUG | Saving model to flat file storage. Save #172
2025-02-27T09:37:59.975365+0300 | INFO | [172,     0] loss: 0.015
2025-02-27T09:38:11.709824+0300 | INFO | [172,   100] loss: 1.488
2025-02-27T09:38:23.182337+0300 | INFO | [172,   200] loss: 1.486
2025-02-27T09:38:34.655100+0300 | INFO | [172,   300] loss: 1.505
2025-02-27T09:38:46.099313+0300 | INFO | [172,   400] loss: 1.489
2025-02-27T09:38:56.423916+0300 | INFO | [172,   500] loss: 1.485
2025-02-27T09:39:07.387622+0300 | INFO | [172,   600] loss: 1.494
2025-02-27T09:39:18.352588+0300 | INFO | [172,   700] loss: 1.493
2025-02-27T09:39:29.274568+0300 | INFO | [172,   800] loss: 1.494
2025-02-27T09:39:40.477435+0300 | INFO | [172,   900] loss: 1.491
2025-02-27T09:39:51.318591+0300 | INFO | [172,  1000] loss: 1.501
2025-02-27T09:40:01.703628+0300 | INFO | [172,  1100] loss: 1.495
2025-02-27T09:40:12.981373+0300 | INFO | [172,  1200] loss: 1.490
2025-02-27T09:40:23.912779+0300 | INFO | [172,  1300] loss: 1.483
2025-02-27T09:40:34.489044+0300 | INFO | [172,  1400] loss: 1.486
2025-02-27T09:40:45.122102+0300 | INFO | [172,  1500] loss: 1.483
2025-02-27T09:40:56.097727+0300 | INFO | [172,  1600] loss: 1.491
2025-02-27T09:41:06.248088+0300 | INFO | [172,  1700] loss: 1.489
2025-02-27T09:41:16.964992+0300 | INFO | [172,  1800] loss: 1.483
2025-02-27T09:41:34.605198+0300 | INFO | [172,  1900] loss: 1.495
2025-02-27T09:41:45.998252+0300 | INFO | [172,  2000] loss: 1.489
2025-02-27T09:41:57.164629+0300 | INFO | [172,  2100] loss: 1.493
2025-02-27T09:42:07.304623+0300 | INFO | [172,  2200] loss: 1.485
2025-02-27T09:42:18.373916+0300 | INFO | [172,  2300] loss: 1.488
2025-02-27T09:42:29.307551+0300 | INFO | [172,  2400] loss: 1.481
2025-02-27T09:42:40.252223+0300 | INFO | [172,  2500] loss: 1.490
2025-02-27T09:42:52.333453+0300 | INFO | [172,  2600] loss: 1.491
2025-02-27T09:43:04.002595+0300 | INFO | [172,  2700] loss: 1.495
2025-02-27T09:43:15.762267+0300 | INFO | [172,  2800] loss: 1.485
2025-02-27T09:43:27.059117+0300 | INFO | [172,  2900] loss: 1.484
2025-02-27T09:43:38.890291+0300 | INFO | [172,  3000] loss: 1.480
2025-02-27T09:43:50.811038+0300 | INFO | [172,  3100] loss: 1.484
2025-02-27T09:44:01.844340+0300 | INFO | [172,  3200] loss: 1.488
2025-02-27T09:44:13.428178+0300 | INFO | [172,  3300] loss: 1.487
2025-02-27T09:44:24.929214+0300 | INFO | [172,  3400] loss: 1.493
2025-02-27T09:44:36.985845+0300 | INFO | [172,  3500] loss: 1.498
2025-02-27T09:44:48.627790+0300 | INFO | [172,  3600] loss: 1.490
2025-02-27T09:45:00.425598+0300 | INFO | [172,  3700] loss: 1.487
2025-02-27T09:45:12.046231+0300 | INFO | [172,  3800] loss: 1.497
2025-02-27T09:45:23.704836+0300 | INFO | [172,  3900] loss: 1.495
2025-02-27T09:45:34.695230+0300 | INFO | [172,  4000] loss: 1.490
2025-02-27T09:45:46.367510+0300 | INFO | [172,  4100] loss: 1.500
2025-02-27T09:45:57.612311+0300 | INFO | [172,  4200] loss: 1.499
2025-02-27T09:46:07.460498+0300 | INFO | [172,  4300] loss: 1.495
2025-02-27T09:46:18.412481+0300 | INFO | [172,  4400] loss: 1.496
2025-02-27T09:46:29.266925+0300 | INFO | [172,  4500] loss: 1.487
2025-02-27T09:46:39.507547+0300 | INFO | [172,  4600] loss: 1.488
2025-02-27T09:46:50.209079+0300 | INFO | [172,  4700] loss: 1.492
2025-02-27T09:47:01.065043+0300 | INFO | [172,  4800] loss: 1.484
2025-02-27T09:47:11.049922+0300 | INFO | [172,  4900] loss: 1.489
2025-02-27T09:47:21.729539+0300 | DEBUG | Saving model to flat file storage. Save #172
2025-02-27T09:47:21.746905+0300 | INFO | Averaging client parameters
2025-02-27T09:47:21.753428+0300 | INFO | Updating parameters on client #0
2025-02-27T09:47:37.575901+0300 | DEBUG | Test set: Accuracy: 7922/10000 (79%)
2025-02-27T09:47:37.577891+0300 | DEBUG | Test set: Loss: 1.6686445474624634
2025-02-27T09:47:37.681819+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.74      0.71      0.73      1000
           3       0.68      0.57      0.62      1200
           4       0.77      0.80      0.79      1000
           5       0.53      0.64      0.58       800
           6       0.86      0.85      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.90      0.92      0.91      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T09:47:37.685354+0300 | DEBUG | Confusion Matrix:
[[818  17  43   9  20   8   5  12  40  28]
 [  5 925   3   1   1   1   4   2  15  43]
 [ 56   3 715  41  72  42  41  17   6   7]
 [ 21   5  59 689  51 274  34  37  13  17]
 [ 10   5  34  43 801  38  27  34   6   2]
 [ 15   2  38 148  25 511  15  38   4   4]
 [  6   4  41  46  18  26 847   6   4   2]
 [ 14   3  16  22  44  55   2 831   2  11]
 [ 34  14  10   5   1   4   3   2 917  10]
 [ 22  57   6   6   1   5   9   9  17 868]]
2025-02-27T09:47:37.687358+0300 | DEBUG | Class precision: [0.81718282 0.89371981 0.74093264 0.68217822 0.77466151 0.53008299
 0.85815603 0.84109312 0.89550781 0.875     ]
2025-02-27T09:47:37.690356+0300 | DEBUG | Class recall: [0.818      0.925      0.715      0.57416667 0.801      0.63875
 0.847      0.831      0.917      0.868     ]
2025-02-27T09:47:37.747387+0300 | INFO | Training epoch #173 on client #0
2025-02-27T09:47:37.749666+0300 | DEBUG | Saving model to flat file storage. Save #173
2025-02-27T09:47:37.994346+0300 | INFO | [173,     0] loss: 0.015
2025-02-27T09:47:49.430806+0300 | INFO | [173,   100] loss: 1.488
2025-02-27T09:48:00.710948+0300 | INFO | [173,   200] loss: 1.489
2025-02-27T09:48:11.596598+0300 | INFO | [173,   300] loss: 1.491
2025-02-27T09:48:22.310888+0300 | INFO | [173,   400] loss: 1.488
2025-02-27T09:48:32.541303+0300 | INFO | [173,   500] loss: 1.485
2025-02-27T09:48:43.527176+0300 | INFO | [173,   600] loss: 1.500
2025-02-27T09:48:54.673437+0300 | INFO | [173,   700] loss: 1.490
2025-02-27T09:49:07.795058+0300 | INFO | [173,   800] loss: 1.484
2025-02-27T09:49:20.791777+0300 | INFO | [173,   900] loss: 1.497
2025-02-27T09:49:32.448608+0300 | INFO | [173,  1000] loss: 1.493
2025-02-27T09:49:43.504071+0300 | INFO | [173,  1100] loss: 1.491
2025-02-27T09:49:53.473288+0300 | INFO | [173,  1200] loss: 1.486
2025-02-27T09:50:04.285560+0300 | INFO | [173,  1300] loss: 1.491
2025-02-27T09:50:15.166713+0300 | INFO | [173,  1400] loss: 1.492
2025-02-27T09:50:25.330419+0300 | INFO | [173,  1500] loss: 1.491
2025-02-27T09:50:36.550728+0300 | INFO | [173,  1600] loss: 1.488
2025-02-27T09:50:47.434546+0300 | INFO | [173,  1700] loss: 1.480
2025-02-27T09:50:58.977402+0300 | INFO | [173,  1800] loss: 1.483
2025-02-27T09:51:09.416510+0300 | INFO | [173,  1900] loss: 1.496
2025-02-27T09:51:20.474869+0300 | INFO | [173,  2000] loss: 1.480
2025-02-27T09:51:31.412251+0300 | INFO | [173,  2100] loss: 1.483
2025-02-27T09:51:41.588971+0300 | INFO | [173,  2200] loss: 1.497
2025-02-27T09:51:52.743958+0300 | INFO | [173,  2300] loss: 1.492
2025-02-27T09:52:03.701249+0300 | INFO | [173,  2400] loss: 1.500
2025-02-27T09:52:13.685652+0300 | INFO | [173,  2500] loss: 1.491
2025-02-27T09:52:24.382510+0300 | INFO | [173,  2600] loss: 1.501
2025-02-27T09:52:35.432233+0300 | INFO | [173,  2700] loss: 1.496
2025-02-27T09:52:45.824535+0300 | INFO | [173,  2800] loss: 1.479
2025-02-27T09:52:56.923070+0300 | INFO | [173,  2900] loss: 1.488
2025-02-27T09:53:07.541187+0300 | INFO | [173,  3000] loss: 1.491
2025-02-27T09:53:17.438464+0300 | INFO | [173,  3100] loss: 1.483
2025-02-27T09:53:28.230421+0300 | INFO | [173,  3200] loss: 1.491
2025-02-27T09:53:38.901669+0300 | INFO | [173,  3300] loss: 1.502
2025-02-27T09:53:51.939954+0300 | INFO | [173,  3400] loss: 1.494
2025-02-27T09:54:07.077168+0300 | INFO | [173,  3500] loss: 1.490
2025-02-27T09:54:18.495857+0300 | INFO | [173,  3600] loss: 1.500
2025-02-27T09:54:32.981146+0300 | INFO | [173,  3700] loss: 1.489
2025-02-27T09:54:47.239272+0300 | INFO | [173,  3800] loss: 1.481
2025-02-27T09:55:00.267528+0300 | INFO | [173,  3900] loss: 1.485
2025-02-27T09:55:10.775434+0300 | INFO | [173,  4000] loss: 1.492
2025-02-27T09:55:22.175447+0300 | INFO | [173,  4100] loss: 1.488
2025-02-27T09:55:33.588700+0300 | INFO | [173,  4200] loss: 1.488
2025-02-27T09:55:44.373609+0300 | INFO | [173,  4300] loss: 1.490
2025-02-27T09:55:55.448697+0300 | INFO | [173,  4400] loss: 1.486
2025-02-27T09:56:07.217742+0300 | INFO | [173,  4500] loss: 1.489
2025-02-27T09:56:17.811532+0300 | INFO | [173,  4600] loss: 1.497
2025-02-27T09:56:29.451527+0300 | INFO | [173,  4700] loss: 1.488
2025-02-27T09:56:41.224141+0300 | INFO | [173,  4800] loss: 1.490
2025-02-27T09:56:58.343731+0300 | INFO | [173,  4900] loss: 1.496
2025-02-27T09:57:09.701823+0300 | DEBUG | Saving model to flat file storage. Save #173
2025-02-27T09:57:09.725556+0300 | INFO | Averaging client parameters
2025-02-27T09:57:09.731564+0300 | INFO | Updating parameters on client #0
2025-02-27T09:57:26.306393+0300 | DEBUG | Test set: Accuracy: 7917/10000 (79%)
2025-02-27T09:57:26.307408+0300 | DEBUG | Test set: Loss: 1.668486475944519
2025-02-27T09:57:26.420076+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.84      0.82      1000
           1       0.87      0.94      0.90      1000
           2       0.77      0.67      0.72      1000
           3       0.69      0.56      0.62      1200
           4       0.77      0.81      0.79      1000
           5       0.55      0.63      0.58       800
           6       0.84      0.86      0.85      1000
           7       0.82      0.85      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.89      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T09:57:26.424093+0300 | DEBUG | Confusion Matrix:
[[841  17  32   8  16   6   3  11  43  23]
 [  4 938   2   0   1   0   2   1  16  36]
 [ 70   8 674  44  77  40  50  26   6   5]
 [ 30  11  48 673  56 261  42  44  16  19]
 [ 12   4  28  35 807  38  28  40   6   2]
 [ 19   4  37 146  25 504  16  43   3   3]
 [  7   6  32  37  22  20 860   8   5   3]
 [ 17   4   9  21  37  48   4 850   1   9]
 [ 36  20   7   5   4   3   3   2 911   9]
 [ 25  65   6   4   1   4  10   9  17 859]]
2025-02-27T09:57:26.425610+0300 | DEBUG | Class precision: [0.79264844 0.87093779 0.77028571 0.69167523 0.77151052 0.54545455
 0.84479371 0.82205029 0.88964844 0.88739669]
2025-02-27T09:57:26.426641+0300 | DEBUG | Class recall: [0.841      0.938      0.674      0.56083333 0.807      0.63
 0.86       0.85       0.911      0.859     ]
2025-02-27T09:57:26.485335+0300 | INFO | Training epoch #174 on client #0
2025-02-27T09:57:26.487349+0300 | DEBUG | Saving model to flat file storage. Save #174
2025-02-27T09:57:26.719849+0300 | INFO | [174,     0] loss: 0.015
2025-02-27T09:57:38.625452+0300 | INFO | [174,   100] loss: 1.492
2025-02-27T09:57:49.931285+0300 | INFO | [174,   200] loss: 1.478
2025-02-27T09:58:01.353207+0300 | INFO | [174,   300] loss: 1.497
2025-02-27T09:58:12.822625+0300 | INFO | [174,   400] loss: 1.489
2025-02-27T09:58:23.386550+0300 | INFO | [174,   500] loss: 1.492
2025-02-27T09:58:35.053035+0300 | INFO | [174,   600] loss: 1.487
2025-02-27T09:58:46.377982+0300 | INFO | [174,   700] loss: 1.488
2025-02-27T09:58:57.415278+0300 | INFO | [174,   800] loss: 1.485
2025-02-27T09:59:08.735528+0300 | INFO | [174,   900] loss: 1.490
2025-02-27T09:59:20.155440+0300 | INFO | [174,  1000] loss: 1.500
2025-02-27T09:59:31.678614+0300 | INFO | [174,  1100] loss: 1.491
2025-02-27T09:59:42.327674+0300 | INFO | [174,  1200] loss: 1.500
2025-02-27T09:59:53.588174+0300 | INFO | [174,  1300] loss: 1.498
2025-02-27T10:00:06.318374+0300 | INFO | [174,  1400] loss: 1.496
2025-02-27T10:00:17.166764+0300 | INFO | [174,  1500] loss: 1.494
2025-02-27T10:00:28.860246+0300 | INFO | [174,  1600] loss: 1.495
2025-02-27T10:00:40.519101+0300 | INFO | [174,  1700] loss: 1.497
2025-02-27T10:00:52.853408+0300 | INFO | [174,  1800] loss: 1.488
2025-02-27T10:01:03.763187+0300 | INFO | [174,  1900] loss: 1.480
2025-02-27T10:01:15.115669+0300 | INFO | [174,  2000] loss: 1.490
2025-02-27T10:01:26.525287+0300 | INFO | [174,  2100] loss: 1.485
2025-02-27T10:01:37.493885+0300 | INFO | [174,  2200] loss: 1.483
2025-02-27T10:01:49.201157+0300 | INFO | [174,  2300] loss: 1.488
2025-02-27T10:02:00.575627+0300 | INFO | [174,  2400] loss: 1.499
2025-02-27T10:02:11.727763+0300 | INFO | [174,  2500] loss: 1.500
2025-02-27T10:02:22.350774+0300 | INFO | [174,  2600] loss: 1.492
2025-02-27T10:02:33.848073+0300 | INFO | [174,  2700] loss: 1.482
2025-02-27T10:02:45.528741+0300 | INFO | [174,  2800] loss: 1.490
2025-02-27T10:02:56.446178+0300 | INFO | [174,  2900] loss: 1.491
2025-02-27T10:03:07.644802+0300 | INFO | [174,  3000] loss: 1.491
2025-02-27T10:03:18.967709+0300 | INFO | [174,  3100] loss: 1.495
2025-02-27T10:03:31.662043+0300 | INFO | [174,  3200] loss: 1.483
2025-02-27T10:03:42.722991+0300 | INFO | [174,  3300] loss: 1.483
2025-02-27T10:03:54.478816+0300 | INFO | [174,  3400] loss: 1.492
2025-02-27T10:04:07.055172+0300 | INFO | [174,  3500] loss: 1.486
2025-02-27T10:04:17.531510+0300 | INFO | [174,  3600] loss: 1.497
2025-02-27T10:04:29.439027+0300 | INFO | [174,  3700] loss: 1.486
2025-02-27T10:04:42.986385+0300 | INFO | [174,  3800] loss: 1.488
2025-02-27T10:04:58.775516+0300 | INFO | [174,  3900] loss: 1.482
2025-02-27T10:05:10.705697+0300 | INFO | [174,  4000] loss: 1.498
2025-02-27T10:05:21.505463+0300 | INFO | [174,  4100] loss: 1.475
2025-02-27T10:05:33.329697+0300 | INFO | [174,  4200] loss: 1.494
2025-02-27T10:05:44.904247+0300 | INFO | [174,  4300] loss: 1.499
2025-02-27T10:05:56.860082+0300 | INFO | [174,  4400] loss: 1.489
2025-02-27T10:06:07.888192+0300 | INFO | [174,  4500] loss: 1.498
2025-02-27T10:06:20.648540+0300 | INFO | [174,  4600] loss: 1.495
2025-02-27T10:06:33.175414+0300 | INFO | [174,  4700] loss: 1.492
2025-02-27T10:06:44.936063+0300 | INFO | [174,  4800] loss: 1.490
2025-02-27T10:06:55.881400+0300 | INFO | [174,  4900] loss: 1.484
2025-02-27T10:07:07.280566+0300 | DEBUG | Saving model to flat file storage. Save #174
2025-02-27T10:07:07.315510+0300 | INFO | Averaging client parameters
2025-02-27T10:07:07.328455+0300 | INFO | Updating parameters on client #0
2025-02-27T10:07:24.495770+0300 | DEBUG | Test set: Accuracy: 7913/10000 (79%)
2025-02-27T10:07:24.496785+0300 | DEBUG | Test set: Loss: 1.667986273765564
2025-02-27T10:07:24.564634+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.88      0.93      0.91      1000
           2       0.76      0.69      0.73      1000
           3       0.67      0.58      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.52      0.63      0.57       800
           6       0.85      0.86      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.87      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T10:07:24.565630+0300 | DEBUG | Confusion Matrix:
[[834  16  36  10  13   8   6   8  43  26]
 [  6 929   2   1   1   0   3   1  16  41]
 [ 63   7 693  48  71  44  44  17   6   7]
 [ 19   8  46 697  45 280  38  33  16  18]
 [ 11   6  33  51 786  44  31  31   5   2]
 [ 16   2  41 154  26 501  12  39   4   5]
 [  7   5  36  39  16  26 857   6   4   4]
 [ 14   4  11  26  40  57   3 831   3  11]
 [ 32  15   6   7   2   4   5   1 918  10]
 [ 21  61   6   4   1   6   8   7  19 867]]
2025-02-27T10:07:24.566692+0300 | DEBUG | Class precision: [0.81524927 0.88224122 0.76153846 0.67213115 0.78521479 0.51649485
 0.8510427  0.85318275 0.88781431 0.87487386]
2025-02-27T10:07:24.568702+0300 | DEBUG | Class recall: [0.834      0.929      0.693      0.58083333 0.786      0.62625
 0.857      0.831      0.918      0.867     ]
2025-02-27T10:07:24.647784+0300 | INFO | Training epoch #175 on client #0
2025-02-27T10:07:24.648786+0300 | DEBUG | Saving model to flat file storage. Save #175
2025-02-27T10:07:24.823214+0300 | INFO | [175,     0] loss: 0.016
2025-02-27T10:07:36.554590+0300 | INFO | [175,   100] loss: 1.504
2025-02-27T10:07:48.289353+0300 | INFO | [175,   200] loss: 1.491
2025-02-27T10:07:59.905518+0300 | INFO | [175,   300] loss: 1.495
2025-02-27T10:08:12.456215+0300 | INFO | [175,   400] loss: 1.483
2025-02-27T10:08:24.652648+0300 | INFO | [175,   500] loss: 1.499
2025-02-27T10:08:36.725530+0300 | INFO | [175,   600] loss: 1.497
2025-02-27T10:08:47.673819+0300 | INFO | [175,   700] loss: 1.488
2025-02-27T10:08:59.111907+0300 | INFO | [175,   800] loss: 1.490
2025-02-27T10:09:11.219477+0300 | INFO | [175,   900] loss: 1.486
2025-02-27T10:09:22.490004+0300 | INFO | [175,  1000] loss: 1.480
2025-02-27T10:09:35.003055+0300 | INFO | [175,  1100] loss: 1.494
2025-02-27T10:09:46.671513+0300 | INFO | [175,  1200] loss: 1.493
2025-02-27T10:09:58.047701+0300 | INFO | [175,  1300] loss: 1.498
2025-02-27T10:10:08.887620+0300 | INFO | [175,  1400] loss: 1.488
2025-02-27T10:10:20.247018+0300 | INFO | [175,  1500] loss: 1.489
2025-02-27T10:10:31.916316+0300 | INFO | [175,  1600] loss: 1.488
2025-02-27T10:10:44.332170+0300 | INFO | [175,  1700] loss: 1.479
2025-02-27T10:10:55.044635+0300 | INFO | [175,  1800] loss: 1.486
2025-02-27T10:11:06.638167+0300 | INFO | [175,  1900] loss: 1.487
2025-02-27T10:11:18.033740+0300 | INFO | [175,  2000] loss: 1.490
2025-02-27T10:11:28.688602+0300 | INFO | [175,  2100] loss: 1.491
2025-02-27T10:11:40.317252+0300 | INFO | [175,  2200] loss: 1.481
2025-02-27T10:11:51.723698+0300 | INFO | [175,  2300] loss: 1.491
2025-02-27T10:12:03.082314+0300 | INFO | [175,  2400] loss: 1.486
2025-02-27T10:12:13.893322+0300 | INFO | [175,  2500] loss: 1.489
2025-02-27T10:12:25.392486+0300 | INFO | [175,  2600] loss: 1.492
2025-02-27T10:12:36.977442+0300 | INFO | [175,  2700] loss: 1.491
2025-02-27T10:12:52.236282+0300 | INFO | [175,  2800] loss: 1.493
2025-02-27T10:13:05.326688+0300 | INFO | [175,  2900] loss: 1.495
2025-02-27T10:13:16.605496+0300 | INFO | [175,  3000] loss: 1.493
2025-02-27T10:13:28.446475+0300 | INFO | [175,  3100] loss: 1.490
2025-02-27T10:13:39.915607+0300 | INFO | [175,  3200] loss: 1.489
2025-02-27T10:13:50.764455+0300 | INFO | [175,  3300] loss: 1.495
2025-02-27T10:14:02.904318+0300 | INFO | [175,  3400] loss: 1.502
2025-02-27T10:14:14.219504+0300 | INFO | [175,  3500] loss: 1.488
2025-02-27T10:14:24.766149+0300 | INFO | [175,  3600] loss: 1.488
2025-02-27T10:14:36.261663+0300 | INFO | [175,  3700] loss: 1.489
2025-02-27T10:14:48.005776+0300 | INFO | [175,  3800] loss: 1.481
2025-02-27T10:14:59.317135+0300 | INFO | [175,  3900] loss: 1.487
2025-02-27T10:15:10.357283+0300 | INFO | [175,  4000] loss: 1.494
2025-02-27T10:15:21.882803+0300 | INFO | [175,  4100] loss: 1.490
2025-02-27T10:15:34.538728+0300 | INFO | [175,  4200] loss: 1.488
2025-02-27T10:15:45.153080+0300 | INFO | [175,  4300] loss: 1.494
2025-02-27T10:15:56.567201+0300 | INFO | [175,  4400] loss: 1.487
2025-02-27T10:16:07.820535+0300 | INFO | [175,  4500] loss: 1.483
2025-02-27T10:16:18.700214+0300 | INFO | [175,  4600] loss: 1.492
2025-02-27T10:16:29.589777+0300 | INFO | [175,  4700] loss: 1.485
2025-02-27T10:16:41.121776+0300 | INFO | [175,  4800] loss: 1.490
2025-02-27T10:16:52.703164+0300 | INFO | [175,  4900] loss: 1.494
2025-02-27T10:17:03.275292+0300 | DEBUG | Saving model to flat file storage. Save #175
2025-02-27T10:17:03.309150+0300 | INFO | Averaging client parameters
2025-02-27T10:17:03.324206+0300 | INFO | Updating parameters on client #0
2025-02-27T10:17:20.695826+0300 | DEBUG | Test set: Accuracy: 7949/10000 (79%)
2025-02-27T10:17:20.697859+0300 | DEBUG | Test set: Loss: 1.665661334991455
2025-02-27T10:17:20.796428+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.88      0.93      0.91      1000
           2       0.76      0.71      0.73      1000
           3       0.66      0.60      0.63      1200
           4       0.78      0.79      0.79      1000
           5       0.54      0.60      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.89      0.86      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T10:17:20.800794+0300 | DEBUG | Confusion Matrix:
[[850  16  36   7  10   8   4   8  41  20]
 [  6 933   2   2   1   1   2   1  17  35]
 [ 60   5 707  54  73  34  42  14   6   5]
 [ 21   8  53 719  46 242  47  36  14  14]
 [ 11   6  34  54 794  42  27  24   6   2]
 [ 14   3  43 170  24 482  18  39   4   3]
 [  7   4  33  42  18  18 864   7   6   1]
 [ 17   4  12  27  44  52   5 825   3  11]
 [ 33  18   8   7   2   4   4   1 912  11]
 [ 25  63   6   6   1   4  10   7  15 863]]
2025-02-27T10:17:20.803310+0300 | DEBUG | Class precision: [0.81417625 0.88018868 0.75695931 0.66084559 0.78381046 0.54340474
 0.84457478 0.85758836 0.890625   0.89430052]
2025-02-27T10:17:20.806561+0300 | DEBUG | Class recall: [0.85       0.933      0.707      0.59916667 0.794      0.6025
 0.864      0.825      0.912      0.863     ]
2025-02-27T10:17:20.863508+0300 | INFO | Training epoch #176 on client #0
2025-02-27T10:17:20.865382+0300 | DEBUG | Saving model to flat file storage. Save #176
2025-02-27T10:17:21.077879+0300 | INFO | [176,     0] loss: 0.015
2025-02-27T10:17:32.832714+0300 | INFO | [176,   100] loss: 1.487
2025-02-27T10:17:45.181927+0300 | INFO | [176,   200] loss: 1.480
2025-02-27T10:17:56.853414+0300 | INFO | [176,   300] loss: 1.489
2025-02-27T10:18:07.808255+0300 | INFO | [176,   400] loss: 1.489
2025-02-27T10:18:19.363481+0300 | INFO | [176,   500] loss: 1.487
2025-02-27T10:18:31.112462+0300 | INFO | [176,   600] loss: 1.480
2025-02-27T10:18:43.025724+0300 | INFO | [176,   700] loss: 1.494
2025-02-27T10:18:54.321883+0300 | INFO | [176,   800] loss: 1.487
2025-02-27T10:19:06.035376+0300 | INFO | [176,   900] loss: 1.500
2025-02-27T10:19:17.412186+0300 | INFO | [176,  1000] loss: 1.489
2025-02-27T10:19:28.160824+0300 | INFO | [176,  1100] loss: 1.485
2025-02-27T10:19:39.873823+0300 | INFO | [176,  1200] loss: 1.495
2025-02-27T10:19:51.864335+0300 | INFO | [176,  1300] loss: 1.489
2025-02-27T10:20:03.133459+0300 | INFO | [176,  1400] loss: 1.491
2025-02-27T10:20:14.239295+0300 | INFO | [176,  1500] loss: 1.492
2025-02-27T10:20:25.720259+0300 | INFO | [176,  1600] loss: 1.485
2025-02-27T10:20:38.018099+0300 | INFO | [176,  1700] loss: 1.487
2025-02-27T10:20:54.826155+0300 | INFO | [176,  1800] loss: 1.493
2025-02-27T10:21:05.948708+0300 | INFO | [176,  1900] loss: 1.495
2025-02-27T10:21:17.693522+0300 | INFO | [176,  2000] loss: 1.491
2025-02-27T10:21:29.097256+0300 | INFO | [176,  2100] loss: 1.495
2025-02-27T10:21:40.727398+0300 | INFO | [176,  2200] loss: 1.499
2025-02-27T10:21:51.553538+0300 | INFO | [176,  2300] loss: 1.486
2025-02-27T10:22:03.132511+0300 | INFO | [176,  2400] loss: 1.494
2025-02-27T10:22:14.649469+0300 | INFO | [176,  2500] loss: 1.499
2025-02-27T10:22:25.903744+0300 | INFO | [176,  2600] loss: 1.487
2025-02-27T10:22:37.468484+0300 | INFO | [176,  2700] loss: 1.477
2025-02-27T10:22:49.220637+0300 | INFO | [176,  2800] loss: 1.493
2025-02-27T10:23:00.649674+0300 | INFO | [176,  2900] loss: 1.494
2025-02-27T10:23:11.685657+0300 | INFO | [176,  3000] loss: 1.488
2025-02-27T10:23:23.271567+0300 | INFO | [176,  3100] loss: 1.494
2025-02-27T10:23:35.059167+0300 | INFO | [176,  3200] loss: 1.491
2025-02-27T10:23:47.299169+0300 | INFO | [176,  3300] loss: 1.491
2025-02-27T10:23:58.781275+0300 | INFO | [176,  3400] loss: 1.488
2025-02-27T10:24:10.809933+0300 | INFO | [176,  3500] loss: 1.499
2025-02-27T10:24:22.097129+0300 | INFO | [176,  3600] loss: 1.499
2025-02-27T10:24:33.811413+0300 | INFO | [176,  3700] loss: 1.482
2025-02-27T10:24:45.790231+0300 | INFO | [176,  3800] loss: 1.493
2025-02-27T10:24:57.585305+0300 | INFO | [176,  3900] loss: 1.490
2025-02-27T10:25:08.989602+0300 | INFO | [176,  4000] loss: 1.489
2025-02-27T10:25:19.483880+0300 | INFO | [176,  4100] loss: 1.493
2025-02-27T10:25:30.845254+0300 | INFO | [176,  4200] loss: 1.480
2025-02-27T10:25:42.241304+0300 | INFO | [176,  4300] loss: 1.491
2025-02-27T10:25:52.880294+0300 | INFO | [176,  4400] loss: 1.489
2025-02-27T10:26:05.427380+0300 | INFO | [176,  4500] loss: 1.493
2025-02-27T10:26:17.474486+0300 | INFO | [176,  4600] loss: 1.486
2025-02-27T10:26:28.818877+0300 | INFO | [176,  4700] loss: 1.492
2025-02-27T10:26:39.873800+0300 | INFO | [176,  4800] loss: 1.494
2025-02-27T10:26:51.805352+0300 | INFO | [176,  4900] loss: 1.490
2025-02-27T10:27:04.104539+0300 | DEBUG | Saving model to flat file storage. Save #176
2025-02-27T10:27:04.126909+0300 | INFO | Averaging client parameters
2025-02-27T10:27:04.135687+0300 | INFO | Updating parameters on client #0
2025-02-27T10:27:21.031317+0300 | DEBUG | Test set: Accuracy: 7948/10000 (79%)
2025-02-27T10:27:21.032331+0300 | DEBUG | Test set: Loss: 1.6651663780212402
2025-02-27T10:27:21.128215+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.76      0.71      0.73      1000
           3       0.67      0.59      0.63      1200
           4       0.78      0.80      0.79      1000
           5       0.55      0.62      0.58       800
           6       0.84      0.87      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.89      0.86      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T10:27:21.132543+0300 | DEBUG | Confusion Matrix:
[[835  16  38   8  13   9   6   8  45  22]
 [  5 918   3   1   1   0   5   4  22  41]
 [ 54   5 712  47  70  38  46  16   6   6]
 [ 18   8  50 706  49 246  48  43  15  17]
 [ 10   3  35  49 797  41  30  28   5   2]
 [ 14   2  39 162  26 494  15  41   4   3]
 [  6   3  36  37  16  17 868   9   5   3]
 [ 13   4  11  24  45  51   5 838   2   7]
 [ 33  14   8   8   3   3   3   2 916  10]
 [ 26  50   7   5   1   4  13  11  19 864]]
2025-02-27T10:27:21.135137+0300 | DEBUG | Class precision: [0.8234714  0.8973607  0.75825346 0.67430755 0.78060725 0.54706534
 0.83541867 0.838      0.88161694 0.88615385]
2025-02-27T10:27:21.137663+0300 | DEBUG | Class recall: [0.835      0.918      0.712      0.58833333 0.797      0.6175
 0.868      0.838      0.916      0.864     ]
2025-02-27T10:27:21.189848+0300 | INFO | Training epoch #177 on client #0
2025-02-27T10:27:21.192865+0300 | DEBUG | Saving model to flat file storage. Save #177
2025-02-27T10:27:21.421345+0300 | INFO | [177,     0] loss: 0.015
2025-02-27T10:27:51.744261+0300 | INFO | [177,   100] loss: 1.493
2025-02-27T10:28:58.347016+0300 | INFO | [177,   200] loss: 1.487
2025-02-27T10:30:01.314317+0300 | INFO | [177,   300] loss: 1.481
2025-02-27T10:31:00.459999+0300 | INFO | [177,   400] loss: 1.494
2025-02-27T10:32:02.242180+0300 | INFO | [177,   500] loss: 1.494
2025-02-27T10:33:06.637548+0300 | INFO | [177,   600] loss: 1.495
2025-02-27T10:34:06.110021+0300 | INFO | [177,   700] loss: 1.485
2025-02-27T10:35:39.473336+0300 | INFO | [177,   800] loss: 1.493
2025-02-27T10:36:48.314339+0300 | INFO | [177,   900] loss: 1.484
2025-02-27T10:37:50.674058+0300 | INFO | [177,  1000] loss: 1.488
2025-02-27T10:38:50.607017+0300 | INFO | [177,  1100] loss: 1.490
2025-02-27T10:40:06.408277+0300 | INFO | [177,  1200] loss: 1.487
2025-02-27T10:41:26.214265+0300 | INFO | [177,  1300] loss: 1.488
2025-02-27T10:42:27.003647+0300 | INFO | [177,  1400] loss: 1.496
2025-02-27T10:43:25.774300+0300 | INFO | [177,  1500] loss: 1.490
2025-02-27T10:44:54.647856+0300 | INFO | [177,  1600] loss: 1.491
2025-02-27T10:46:15.703922+0300 | INFO | [177,  1700] loss: 1.490
2025-02-27T10:47:30.426814+0300 | INFO | [177,  1800] loss: 1.498
2025-02-27T10:49:12.763513+0300 | INFO | [177,  1900] loss: 1.494
2025-02-27T10:50:24.918386+0300 | INFO | [177,  2000] loss: 1.482
2025-02-27T10:51:35.729830+0300 | INFO | [177,  2100] loss: 1.490
2025-02-27T10:52:45.125422+0300 | INFO | [177,  2200] loss: 1.490
2025-02-27T10:53:51.008235+0300 | INFO | [177,  2300] loss: 1.491
2025-02-27T10:54:58.927585+0300 | INFO | [177,  2400] loss: 1.486
2025-02-27T10:56:04.303024+0300 | INFO | [177,  2500] loss: 1.487
2025-02-27T10:57:03.640423+0300 | INFO | [177,  2600] loss: 1.490
2025-02-27T10:57:59.415742+0300 | INFO | [177,  2700] loss: 1.491
2025-02-27T10:58:53.561548+0300 | INFO | [177,  2800] loss: 1.489
2025-02-27T10:59:49.650329+0300 | INFO | [177,  2900] loss: 1.486
2025-02-27T11:00:48.521309+0300 | INFO | [177,  3000] loss: 1.499
2025-02-27T11:01:45.075280+0300 | INFO | [177,  3100] loss: 1.487
2025-02-27T11:02:41.235449+0300 | INFO | [177,  3200] loss: 1.488
2025-02-27T11:03:41.501005+0300 | INFO | [177,  3300] loss: 1.484
2025-02-27T11:04:39.277609+0300 | INFO | [177,  3400] loss: 1.494
2025-02-27T11:05:35.413567+0300 | INFO | [177,  3500] loss: 1.485
2025-02-27T11:06:35.095815+0300 | INFO | [177,  3600] loss: 1.495
2025-02-27T11:07:35.592345+0300 | INFO | [177,  3700] loss: 1.498
2025-02-27T11:08:31.900962+0300 | INFO | [177,  3800] loss: 1.491
2025-02-27T11:09:31.350212+0300 | INFO | [177,  3900] loss: 1.495
2025-02-27T11:10:26.650593+0300 | INFO | [177,  4000] loss: 1.493
2025-02-27T11:11:23.507154+0300 | INFO | [177,  4100] loss: 1.482
2025-02-27T11:12:19.593217+0300 | INFO | [177,  4200] loss: 1.487
2025-02-27T11:13:16.753850+0300 | INFO | [177,  4300] loss: 1.483
2025-02-27T11:14:12.680963+0300 | INFO | [177,  4400] loss: 1.492
2025-02-27T11:15:09.365395+0300 | INFO | [177,  4500] loss: 1.493
2025-02-27T11:16:06.237112+0300 | INFO | [177,  4600] loss: 1.484
2025-02-27T11:17:02.105759+0300 | INFO | [177,  4700] loss: 1.495
2025-02-27T11:17:59.611393+0300 | INFO | [177,  4800] loss: 1.484
2025-02-27T11:18:56.668602+0300 | INFO | [177,  4900] loss: 1.500
2025-02-27T11:19:57.363333+0300 | DEBUG | Saving model to flat file storage. Save #177
2025-02-27T11:19:57.391452+0300 | INFO | Averaging client parameters
2025-02-27T11:19:57.408008+0300 | INFO | Updating parameters on client #0
2025-02-27T11:20:54.183768+0300 | DEBUG | Test set: Accuracy: 7958/10000 (80%)
2025-02-27T11:20:54.190563+0300 | DEBUG | Test set: Loss: 1.6646308898925781
2025-02-27T11:20:54.339458+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.90      0.91      0.91      1000
           2       0.77      0.68      0.72      1000
           3       0.70      0.56      0.63      1200
           4       0.77      0.82      0.79      1000
           5       0.55      0.64      0.59       800
           6       0.85      0.86      0.86      1000
           7       0.82      0.84      0.83      1000
           8       0.90      0.92      0.91      1000
           9       0.86      0.89      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.79     10000

2025-02-27T11:20:54.341462+0300 | DEBUG | Confusion Matrix:
[[851  14  30   7  15   8   4   9  38  24]
 [  5 912   3   0   1   2   3   3  18  53]
 [ 66   6 684  42  78  42  47  21   6   8]
 [ 23   7  48 676  58 261  43  47  17  20]
 [ 10   4  31  37 820  33  26  31   4   4]
 [ 18   3  35 134  29 508  17  48   4   4]
 [  7   4  33  36  21  19 863   8   5   4]
 [ 16   4  12  21  45  48   3 841   1   9]
 [ 34  14   7   7   3   2   3   2 915  13]
 [ 23  42   6   3   1   4   9  11  13 888]]
2025-02-27T11:20:54.347247+0300 | DEBUG | Class precision: [0.80816714 0.9029703  0.76940382 0.701973   0.76563959 0.54800431
 0.84774067 0.82370225 0.89618022 0.86465433]
2025-02-27T11:20:54.348250+0300 | DEBUG | Class recall: [0.851      0.912      0.684      0.56333333 0.82       0.635
 0.863      0.841      0.915      0.888     ]
2025-02-27T11:20:54.350252+0300 | INFO | Training epoch #178 on client #0
2025-02-27T11:20:54.351167+0300 | DEBUG | Saving model to flat file storage. Save #178
2025-02-27T11:20:55.163008+0300 | INFO | [178,     0] loss: 0.016
2025-02-27T11:22:20.844412+0300 | INFO | [178,   100] loss: 1.486
2025-02-27T11:23:18.133822+0300 | INFO | [178,   200] loss: 1.490
2025-02-27T11:24:12.612396+0300 | INFO | [178,   300] loss: 1.490
2025-02-27T11:25:11.868772+0300 | INFO | [178,   400] loss: 1.497
2025-02-27T11:26:09.282187+0300 | INFO | [178,   500] loss: 1.489
2025-02-27T11:27:05.022339+0300 | INFO | [178,   600] loss: 1.490
2025-02-27T11:28:02.650727+0300 | INFO | [178,   700] loss: 1.490
2025-02-27T11:28:59.328304+0300 | INFO | [178,   800] loss: 1.500
2025-02-27T11:29:55.909053+0300 | INFO | [178,   900] loss: 1.495
2025-02-27T11:30:52.103245+0300 | INFO | [178,  1000] loss: 1.485
2025-02-27T11:31:47.706882+0300 | INFO | [178,  1100] loss: 1.493
2025-02-27T11:32:46.108414+0300 | INFO | [178,  1200] loss: 1.499
2025-02-27T11:33:14.519842+0300 | INFO | [178,  1300] loss: 1.488
2025-02-27T11:33:22.928663+0300 | INFO | [178,  1400] loss: 1.497
2025-02-27T11:33:31.957658+0300 | INFO | [178,  1500] loss: 1.487
2025-02-27T11:33:48.007507+0300 | INFO | [178,  1600] loss: 1.488
2025-02-27T11:33:59.545055+0300 | INFO | [178,  1700] loss: 1.482
2025-02-27T11:34:08.377199+0300 | INFO | [178,  1800] loss: 1.492
2025-02-27T11:34:17.543736+0300 | INFO | [178,  1900] loss: 1.494
2025-02-27T11:34:26.491007+0300 | INFO | [178,  2000] loss: 1.497
2025-02-27T11:34:35.323316+0300 | INFO | [178,  2100] loss: 1.484
2025-02-27T11:34:44.080512+0300 | INFO | [178,  2200] loss: 1.502
2025-02-27T11:34:52.675431+0300 | INFO | [178,  2300] loss: 1.489
2025-02-27T11:35:01.440448+0300 | INFO | [178,  2400] loss: 1.491
2025-02-27T11:35:10.300698+0300 | INFO | [178,  2500] loss: 1.488
2025-02-27T11:35:19.179307+0300 | INFO | [178,  2600] loss: 1.491
2025-02-27T11:35:27.970881+0300 | INFO | [178,  2700] loss: 1.489
2025-02-27T11:35:36.658657+0300 | INFO | [178,  2800] loss: 1.488
2025-02-27T11:35:45.821413+0300 | INFO | [178,  2900] loss: 1.488
2025-02-27T11:35:54.693837+0300 | INFO | [178,  3000] loss: 1.484
2025-02-27T11:36:03.469911+0300 | INFO | [178,  3100] loss: 1.487
2025-02-27T11:36:11.974080+0300 | INFO | [178,  3200] loss: 1.490
2025-02-27T11:36:21.426350+0300 | INFO | [178,  3300] loss: 1.480
2025-02-27T11:36:30.148737+0300 | INFO | [178,  3400] loss: 1.490
2025-02-27T11:36:38.856254+0300 | INFO | [178,  3500] loss: 1.489
2025-02-27T11:36:47.596139+0300 | INFO | [178,  3600] loss: 1.487
2025-02-27T11:36:58.802587+0300 | INFO | [178,  3700] loss: 1.490
2025-02-27T11:37:10.029356+0300 | INFO | [178,  3800] loss: 1.492
2025-02-27T11:37:20.376722+0300 | INFO | [178,  3900] loss: 1.498
2025-02-27T11:37:31.943146+0300 | INFO | [178,  4000] loss: 1.498
2025-02-27T11:37:42.224653+0300 | INFO | [178,  4100] loss: 1.490
2025-02-27T11:37:54.692828+0300 | INFO | [178,  4200] loss: 1.483
2025-02-27T11:38:07.328988+0300 | INFO | [178,  4300] loss: 1.489
2025-02-27T11:38:19.689757+0300 | INFO | [178,  4400] loss: 1.490
2025-02-27T11:38:32.335188+0300 | INFO | [178,  4500] loss: 1.481
2025-02-27T11:38:42.871095+0300 | INFO | [178,  4600] loss: 1.491
2025-02-27T11:38:54.157831+0300 | INFO | [178,  4700] loss: 1.500
2025-02-27T11:39:07.617548+0300 | INFO | [178,  4800] loss: 1.487
2025-02-27T11:39:19.552889+0300 | INFO | [178,  4900] loss: 1.484
2025-02-27T11:39:31.667327+0300 | DEBUG | Saving model to flat file storage. Save #178
2025-02-27T11:39:31.712147+0300 | INFO | Averaging client parameters
2025-02-27T11:39:31.730147+0300 | INFO | Updating parameters on client #0
2025-02-27T11:39:51.264956+0300 | DEBUG | Test set: Accuracy: 7914/10000 (79%)
2025-02-27T11:39:51.264956+0300 | DEBUG | Test set: Loss: 1.6679177284240723
2025-02-27T11:39:51.359933+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.83      1000
           1       0.89      0.92      0.90      1000
           2       0.74      0.71      0.73      1000
           3       0.69      0.54      0.60      1200
           4       0.79      0.78      0.79      1000
           5       0.53      0.64      0.58       800
           6       0.83      0.87      0.85      1000
           7       0.82      0.84      0.83      1000
           8       0.90      0.91      0.91      1000
           9       0.87      0.88      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T11:39:51.362933+0300 | DEBUG | Confusion Matrix:
[[832  16  38   9  10  10   6  14  38  27]
 [  5 922   3   0   1   2   4   4  13  46]
 [ 59   7 715  36  61  44  47  19   6   6]
 [ 19   7  59 647  51 279  49  50  16  23]
 [ 10   6  37  46 784  39  35  35   5   3]
 [ 16   3  42 139  23 508  16  45   4   4]
 [  6   6  38  34  15  19 868   8   4   2]
 [ 13   4  15  21  42  45   3 842   2  13]
 [ 29  19   8   8   3   3   4   1 914  11]
 [ 22  49   7   3   1   3  10   9  14 882]]
2025-02-27T11:39:51.363932+0300 | DEBUG | Class precision: [0.82294758 0.88739172 0.74324324 0.68610817 0.79112008 0.53361345
 0.83301344 0.81986368 0.8996063  0.86725664]
2025-02-27T11:39:51.364934+0300 | DEBUG | Class recall: [0.832      0.922      0.715      0.53916667 0.784      0.635
 0.868      0.842      0.914      0.882     ]
2025-02-27T11:39:51.408090+0300 | INFO | Training epoch #179 on client #0
2025-02-27T11:39:51.410089+0300 | DEBUG | Saving model to flat file storage. Save #179
2025-02-27T11:39:51.650121+0300 | INFO | [179,     0] loss: 0.015
2025-02-27T11:40:04.507784+0300 | INFO | [179,   100] loss: 1.490
2025-02-27T11:40:15.348461+0300 | INFO | [179,   200] loss: 1.489
2025-02-27T11:40:25.160434+0300 | INFO | [179,   300] loss: 1.491
2025-02-27T11:40:35.352277+0300 | INFO | [179,   400] loss: 1.493
2025-02-27T11:40:45.961126+0300 | INFO | [179,   500] loss: 1.492
2025-02-27T11:40:59.588403+0300 | INFO | [179,   600] loss: 1.489
2025-02-27T11:41:14.009883+0300 | INFO | [179,   700] loss: 1.491
2025-02-27T11:41:26.279214+0300 | INFO | [179,   800] loss: 1.496
2025-02-27T11:41:40.162556+0300 | INFO | [179,   900] loss: 1.488
2025-02-27T11:41:55.239671+0300 | INFO | [179,  1000] loss: 1.488
2025-02-27T11:42:07.503387+0300 | INFO | [179,  1100] loss: 1.489
2025-02-27T11:42:20.490570+0300 | INFO | [179,  1200] loss: 1.488
2025-02-27T11:42:34.714294+0300 | INFO | [179,  1300] loss: 1.486
2025-02-27T11:42:49.019853+0300 | INFO | [179,  1400] loss: 1.492
2025-02-27T11:43:03.031052+0300 | INFO | [179,  1500] loss: 1.478
2025-02-27T11:43:15.212335+0300 | INFO | [179,  1600] loss: 1.481
2025-02-27T11:43:27.126707+0300 | INFO | [179,  1700] loss: 1.483
2025-02-27T11:43:39.130105+0300 | INFO | [179,  1800] loss: 1.489
2025-02-27T11:43:51.596120+0300 | INFO | [179,  1900] loss: 1.496
2025-02-27T11:44:05.107398+0300 | INFO | [179,  2000] loss: 1.495
2025-02-27T11:44:17.724620+0300 | INFO | [179,  2100] loss: 1.485
2025-02-27T11:44:30.127526+0300 | INFO | [179,  2200] loss: 1.486
2025-02-27T11:44:43.414844+0300 | INFO | [179,  2300] loss: 1.493
2025-02-27T11:44:56.824932+0300 | INFO | [179,  2400] loss: 1.482
2025-02-27T11:45:09.809710+0300 | INFO | [179,  2500] loss: 1.488
2025-02-27T11:45:22.934482+0300 | INFO | [179,  2600] loss: 1.494
2025-02-27T11:45:34.006679+0300 | INFO | [179,  2700] loss: 1.497
2025-02-27T11:45:46.381454+0300 | INFO | [179,  2800] loss: 1.489
2025-02-27T11:45:59.130883+0300 | INFO | [179,  2900] loss: 1.495
2025-02-27T11:46:09.381296+0300 | INFO | [179,  3000] loss: 1.497
2025-02-27T11:46:21.316471+0300 | INFO | [179,  3100] loss: 1.485
2025-02-27T11:46:41.123305+0300 | INFO | [179,  3200] loss: 1.488
2025-02-27T11:46:52.805660+0300 | INFO | [179,  3300] loss: 1.492
2025-02-27T11:47:06.522206+0300 | INFO | [179,  3400] loss: 1.491
2025-02-27T11:47:19.001201+0300 | INFO | [179,  3500] loss: 1.486
2025-02-27T11:47:32.362927+0300 | INFO | [179,  3600] loss: 1.485
2025-02-27T11:47:45.460788+0300 | INFO | [179,  3700] loss: 1.497
2025-02-27T11:47:59.086101+0300 | INFO | [179,  3800] loss: 1.497
2025-02-27T11:48:12.425865+0300 | INFO | [179,  3900] loss: 1.492
2025-02-27T11:48:26.573113+0300 | INFO | [179,  4000] loss: 1.482
2025-02-27T11:48:40.124696+0300 | INFO | [179,  4100] loss: 1.480
2025-02-27T11:48:54.144164+0300 | INFO | [179,  4200] loss: 1.494
2025-02-27T11:49:07.841130+0300 | INFO | [179,  4300] loss: 1.492
2025-02-27T11:49:21.266017+0300 | INFO | [179,  4400] loss: 1.497
2025-02-27T11:49:31.605109+0300 | INFO | [179,  4500] loss: 1.494
2025-02-27T11:49:40.955728+0300 | INFO | [179,  4600] loss: 1.495
2025-02-27T11:49:51.652427+0300 | INFO | [179,  4700] loss: 1.489
2025-02-27T11:50:02.139976+0300 | INFO | [179,  4800] loss: 1.488
2025-02-27T11:50:16.965284+0300 | INFO | [179,  4900] loss: 1.497
2025-02-27T11:50:30.657769+0300 | DEBUG | Saving model to flat file storage. Save #179
2025-02-27T11:50:30.671742+0300 | INFO | Averaging client parameters
2025-02-27T11:50:30.677665+0300 | INFO | Updating parameters on client #0
2025-02-27T11:50:51.150922+0300 | DEBUG | Test set: Accuracy: 7958/10000 (80%)
2025-02-27T11:50:51.158826+0300 | DEBUG | Test set: Loss: 1.6648273468017578
2025-02-27T11:50:51.281454+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.90      0.92      0.91      1000
           2       0.77      0.70      0.73      1000
           3       0.67      0.59      0.62      1200
           4       0.78      0.81      0.79      1000
           5       0.53      0.63      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.91      0.91      0.91      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.80     10000

2025-02-27T11:50:51.282445+0300 | DEBUG | Confusion Matrix:
[[827  16  42  12  17  10   5  11  35  25]
 [  7 922   4   0   1   2   5   4  12  43]
 [ 48   5 704  47  72  49  45  19   6   5]
 [ 15   4  48 703  51 277  43  32  13  14]
 [ 10   3  29  47 809  37  30  28   5   2]
 [ 14   2  34 159  23 504  17  40   3   4]
 [  6   5  27  41  16  25 865   7   6   2]
 [ 15   3  12  26  47  45   4 835   1  12]
 [ 33  15   9  10   3   5   4   2 906  13]
 [ 24  48   7   6   1   5   9   9   8 883]]
2025-02-27T11:50:51.286394+0300 | DEBUG | Class precision: [0.82782783 0.90127077 0.76855895 0.66888677 0.77788462 0.52554745
 0.84225901 0.84599797 0.91055276 0.88035892]
2025-02-27T11:50:51.288345+0300 | DEBUG | Class recall: [0.827      0.922      0.704      0.58583333 0.809      0.63
 0.865      0.835      0.906      0.883     ]
2025-02-27T11:50:51.347085+0300 | INFO | Training epoch #180 on client #0
2025-02-27T11:50:51.348065+0300 | DEBUG | Saving model to flat file storage. Save #180
2025-02-27T11:50:51.549375+0300 | INFO | [180,     0] loss: 0.015
2025-02-27T11:51:05.769596+0300 | INFO | [180,   100] loss: 1.490
2025-02-27T11:51:17.709471+0300 | INFO | [180,   200] loss: 1.483
2025-02-27T11:51:28.756327+0300 | INFO | [180,   300] loss: 1.489
2025-02-27T11:51:40.883592+0300 | INFO | [180,   400] loss: 1.486
2025-02-27T11:51:53.540074+0300 | INFO | [180,   500] loss: 1.480
2025-02-27T11:52:05.430874+0300 | INFO | [180,   600] loss: 1.499
2025-02-27T11:52:15.123677+0300 | INFO | [180,   700] loss: 1.485
2025-02-27T11:52:24.572265+0300 | INFO | [180,   800] loss: 1.485
2025-02-27T11:52:33.763495+0300 | INFO | [180,   900] loss: 1.490
2025-02-27T11:52:44.044445+0300 | INFO | [180,  1000] loss: 1.497
2025-02-27T11:52:53.575167+0300 | INFO | [180,  1100] loss: 1.490
2025-02-27T11:53:03.286800+0300 | INFO | [180,  1200] loss: 1.493
2025-02-27T11:53:12.518686+0300 | INFO | [180,  1300] loss: 1.489
2025-02-27T11:53:22.081260+0300 | INFO | [180,  1400] loss: 1.492
2025-02-27T11:53:32.392560+0300 | INFO | [180,  1500] loss: 1.493
2025-02-27T11:53:42.759898+0300 | INFO | [180,  1600] loss: 1.491
2025-02-27T11:53:52.176620+0300 | INFO | [180,  1700] loss: 1.494
2025-02-27T11:54:02.971907+0300 | INFO | [180,  1800] loss: 1.489
2025-02-27T11:54:12.786972+0300 | INFO | [180,  1900] loss: 1.493
2025-02-27T11:54:22.277386+0300 | INFO | [180,  2000] loss: 1.487
2025-02-27T11:54:35.555533+0300 | INFO | [180,  2100] loss: 1.487
2025-02-27T11:54:50.625754+0300 | INFO | [180,  2200] loss: 1.497
2025-02-27T11:55:08.117538+0300 | INFO | [180,  2300] loss: 1.487
2025-02-27T11:55:20.064501+0300 | INFO | [180,  2400] loss: 1.494
2025-02-27T11:55:30.361549+0300 | INFO | [180,  2500] loss: 1.487
2025-02-27T11:55:41.361061+0300 | INFO | [180,  2600] loss: 1.483
2025-02-27T11:55:52.201048+0300 | INFO | [180,  2700] loss: 1.496
2025-02-27T11:56:03.227528+0300 | INFO | [180,  2800] loss: 1.481
2025-02-27T11:56:13.252734+0300 | INFO | [180,  2900] loss: 1.496
2025-02-27T11:56:24.323555+0300 | INFO | [180,  3000] loss: 1.485
2025-02-27T11:56:35.097886+0300 | INFO | [180,  3100] loss: 1.492
2025-02-27T11:56:50.014541+0300 | INFO | [180,  3200] loss: 1.485
2025-02-27T11:57:04.288064+0300 | INFO | [180,  3300] loss: 1.495
2025-02-27T11:57:17.024946+0300 | INFO | [180,  3400] loss: 1.494
2025-02-27T11:57:29.601270+0300 | INFO | [180,  3500] loss: 1.493
2025-02-27T11:57:42.771376+0300 | INFO | [180,  3600] loss: 1.490
2025-02-27T11:57:55.885479+0300 | INFO | [180,  3700] loss: 1.495
2025-02-27T11:58:09.177243+0300 | INFO | [180,  3800] loss: 1.494
2025-02-27T11:58:22.903927+0300 | INFO | [180,  3900] loss: 1.486
2025-02-27T11:58:38.724654+0300 | INFO | [180,  4000] loss: 1.488
2025-02-27T11:58:54.393076+0300 | INFO | [180,  4100] loss: 1.488
2025-02-27T11:59:09.230715+0300 | INFO | [180,  4200] loss: 1.488
2025-02-27T11:59:24.038143+0300 | INFO | [180,  4300] loss: 1.493
2025-02-27T11:59:35.317007+0300 | INFO | [180,  4400] loss: 1.494
2025-02-27T11:59:48.896939+0300 | INFO | [180,  4500] loss: 1.491
2025-02-27T12:00:03.014642+0300 | INFO | [180,  4600] loss: 1.486
2025-02-27T12:00:21.990715+0300 | INFO | [180,  4700] loss: 1.487
2025-02-27T12:00:37.514839+0300 | INFO | [180,  4800] loss: 1.492
2025-02-27T12:00:53.578224+0300 | INFO | [180,  4900] loss: 1.496
2025-02-27T12:01:09.410951+0300 | DEBUG | Saving model to flat file storage. Save #180
2025-02-27T12:01:09.449882+0300 | INFO | Averaging client parameters
2025-02-27T12:01:09.466737+0300 | INFO | Updating parameters on client #0
2025-02-27T12:01:32.219539+0300 | DEBUG | Test set: Accuracy: 7930/10000 (79%)
2025-02-27T12:01:32.221544+0300 | DEBUG | Test set: Loss: 1.6666327714920044
2025-02-27T12:01:32.346106+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.75      0.70      0.72      1000
           3       0.66      0.59      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.53      0.62      0.57       800
           6       0.85      0.86      0.86      1000
           7       0.82      0.85      0.84      1000
           8       0.90      0.90      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T12:01:32.349098+0300 | DEBUG | Confusion Matrix:
[[828  15  39  13  14  12   6  12  36  25]
 [  7 927   4   2   1   2   4   3  13  37]
 [ 53   6 701  47  70  51  40  20   8   4]
 [ 17   4  55 704  45 266  39  44  14  12]
 [ 10   4  32  53 789  39  29  38   4   2]
 [ 17   2  37 158  23 495  18  44   4   2]
 [  7   5  35  44  14  19 862   7   5   2]
 [ 12   3  13  23  38  45   3 851   2  10]
 [ 38  14  10  10   1   6   5   2 902  12]
 [ 27  48   8   6   1   4  10  12  13 871]]
2025-02-27T12:01:32.350106+0300 | DEBUG | Class precision: [0.81496063 0.90175097 0.75053533 0.66415094 0.79216867 0.52715655
 0.8484252  0.82381413 0.9010989  0.89150461]
2025-02-27T12:01:32.351105+0300 | DEBUG | Class recall: [0.828      0.927      0.701      0.58666667 0.789      0.61875
 0.862      0.851      0.902      0.871     ]
2025-02-27T12:01:32.418657+0300 | INFO | Training epoch #181 on client #0
2025-02-27T12:01:32.421647+0300 | DEBUG | Saving model to flat file storage. Save #181
2025-02-27T12:01:32.680780+0300 | INFO | [181,     0] loss: 0.015
2025-02-27T12:01:47.826165+0300 | INFO | [181,   100] loss: 1.486
2025-02-27T12:02:01.851925+0300 | INFO | [181,   200] loss: 1.490
2025-02-27T12:02:14.888188+0300 | INFO | [181,   300] loss: 1.486
2025-02-27T12:02:30.004861+0300 | INFO | [181,   400] loss: 1.486
2025-02-27T12:02:46.682036+0300 | INFO | [181,   500] loss: 1.497
2025-02-27T12:03:02.149166+0300 | INFO | [181,   600] loss: 1.494
2025-02-27T12:03:17.464075+0300 | INFO | [181,   700] loss: 1.493
2025-02-27T12:03:32.250252+0300 | INFO | [181,   800] loss: 1.492
2025-02-27T12:03:48.092826+0300 | INFO | [181,   900] loss: 1.485
2025-02-27T12:04:04.423572+0300 | INFO | [181,  1000] loss: 1.488
2025-02-27T12:04:20.327834+0300 | INFO | [181,  1100] loss: 1.493
2025-02-27T12:04:35.290105+0300 | INFO | [181,  1200] loss: 1.491
2025-02-27T12:05:00.098613+0300 | INFO | [181,  1300] loss: 1.485
2025-02-27T12:05:15.897017+0300 | INFO | [181,  1400] loss: 1.490
2025-02-27T12:05:33.398526+0300 | INFO | [181,  1500] loss: 1.493
2025-02-27T12:05:49.324349+0300 | INFO | [181,  1600] loss: 1.492
2025-02-27T12:06:04.577962+0300 | INFO | [181,  1700] loss: 1.487
2025-02-27T12:06:18.926608+0300 | INFO | [181,  1800] loss: 1.485
2025-02-27T12:06:35.740065+0300 | INFO | [181,  1900] loss: 1.486
2025-02-27T12:06:50.730899+0300 | INFO | [181,  2000] loss: 1.498
2025-02-27T12:07:06.235941+0300 | INFO | [181,  2100] loss: 1.487
2025-02-27T12:07:20.848786+0300 | INFO | [181,  2200] loss: 1.489
2025-02-27T12:07:34.893328+0300 | INFO | [181,  2300] loss: 1.498
2025-02-27T12:07:49.051115+0300 | INFO | [181,  2400] loss: 1.491
2025-02-27T12:08:04.075681+0300 | INFO | [181,  2500] loss: 1.485
2025-02-27T12:08:19.006453+0300 | INFO | [181,  2600] loss: 1.496
2025-02-27T12:08:34.151751+0300 | INFO | [181,  2700] loss: 1.487
2025-02-27T12:08:50.339635+0300 | INFO | [181,  2800] loss: 1.489
2025-02-27T12:09:06.307631+0300 | INFO | [181,  2900] loss: 1.490
2025-02-27T12:09:23.176739+0300 | INFO | [181,  3000] loss: 1.496
2025-02-27T12:09:38.890352+0300 | INFO | [181,  3100] loss: 1.492
2025-02-27T12:09:56.017720+0300 | INFO | [181,  3200] loss: 1.488
2025-02-27T12:10:12.240884+0300 | INFO | [181,  3300] loss: 1.502
2025-02-27T12:10:27.179284+0300 | INFO | [181,  3400] loss: 1.495
2025-02-27T12:10:43.115553+0300 | INFO | [181,  3500] loss: 1.489
2025-02-27T12:10:58.325989+0300 | INFO | [181,  3600] loss: 1.486
2025-02-27T12:11:13.984667+0300 | INFO | [181,  3700] loss: 1.487
2025-02-27T12:11:30.158926+0300 | INFO | [181,  3800] loss: 1.497
2025-02-27T12:11:46.884991+0300 | INFO | [181,  3900] loss: 1.484
2025-02-27T12:12:02.417340+0300 | INFO | [181,  4000] loss: 1.480
2025-02-27T12:12:19.135050+0300 | INFO | [181,  4100] loss: 1.487
2025-02-27T12:12:35.012481+0300 | INFO | [181,  4200] loss: 1.491
2025-02-27T12:12:50.720666+0300 | INFO | [181,  4300] loss: 1.488
2025-02-27T12:13:08.312319+0300 | INFO | [181,  4400] loss: 1.487
2025-02-27T12:13:23.405293+0300 | INFO | [181,  4500] loss: 1.494
2025-02-27T12:13:41.470794+0300 | INFO | [181,  4600] loss: 1.484
2025-02-27T12:13:57.214165+0300 | INFO | [181,  4700] loss: 1.479
2025-02-27T12:14:14.642520+0300 | INFO | [181,  4800] loss: 1.494
2025-02-27T12:14:30.677167+0300 | INFO | [181,  4900] loss: 1.500
2025-02-27T12:14:48.014600+0300 | DEBUG | Saving model to flat file storage. Save #181
2025-02-27T12:14:48.071130+0300 | INFO | Averaging client parameters
2025-02-27T12:14:48.084131+0300 | INFO | Updating parameters on client #0
2025-02-27T12:15:17.529089+0300 | DEBUG | Test set: Accuracy: 7917/10000 (79%)
2025-02-27T12:15:17.536079+0300 | DEBUG | Test set: Loss: 1.6680142879486084
2025-02-27T12:15:17.787427+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.90      0.91      0.91      1000
           2       0.76      0.68      0.72      1000
           3       0.67      0.57      0.62      1200
           4       0.78      0.79      0.79      1000
           5       0.53      0.63      0.58       800
           6       0.81      0.88      0.85      1000
           7       0.85      0.84      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.89      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T12:15:17.797754+0300 | DEBUG | Confusion Matrix:
[[835  15  37  13  18  11   5   8  38  20]
 [ 10 914   4   2   1   1   6   2  21  39]
 [ 59   3 683  45  70  54  55  19   8   4]
 [ 17   4  50 681  47 269  62  39  15  16]
 [ 10   5  31  47 794  43  34  28   5   3]
 [ 14   2  32 158  26 505  17  39   4   3]
 [  7   3  30  31  13  17 883   8   4   4]
 [ 14   4  15  25  42  42   4 840   3  11]
 [ 38  13  11   5   0   3   6   1 913  10]
 [ 27  51   8   3   1   5  12   7  17 869]]
2025-02-27T12:15:17.803643+0300 | DEBUG | Class precision: [0.80989331 0.90138067 0.75804661 0.67425743 0.78458498 0.53157895
 0.81457565 0.84762866 0.8881323  0.88764045]
2025-02-27T12:15:17.806654+0300 | DEBUG | Class recall: [0.835   0.914   0.683   0.5675  0.794   0.63125 0.883   0.84    0.913
 0.869  ]
2025-02-27T12:15:17.919526+0300 | INFO | Training epoch #182 on client #0
2025-02-27T12:15:17.923647+0300 | DEBUG | Saving model to flat file storage. Save #182
2025-02-27T12:15:18.202308+0300 | INFO | [182,     0] loss: 0.015
2025-02-27T12:15:36.972549+0300 | INFO | [182,   100] loss: 1.488
2025-02-27T12:15:55.965319+0300 | INFO | [182,   200] loss: 1.486
2025-02-27T12:16:22.555005+0300 | INFO | [182,   300] loss: 1.488
2025-02-27T12:16:39.680039+0300 | INFO | [182,   400] loss: 1.481
2025-02-27T12:16:51.569563+0300 | INFO | [182,   500] loss: 1.503
2025-02-27T12:17:04.563332+0300 | INFO | [182,   600] loss: 1.490
2025-02-27T12:17:22.409521+0300 | INFO | [182,   700] loss: 1.495
2025-02-27T12:17:36.476314+0300 | INFO | [182,   800] loss: 1.491
2025-02-27T12:17:52.860867+0300 | INFO | [182,   900] loss: 1.493
2025-02-27T12:18:08.864222+0300 | INFO | [182,  1000] loss: 1.491
2025-02-27T12:18:22.768303+0300 | INFO | [182,  1100] loss: 1.487
2025-02-27T12:18:38.943160+0300 | INFO | [182,  1200] loss: 1.498
2025-02-27T12:18:53.364657+0300 | INFO | [182,  1300] loss: 1.490
2025-02-27T12:19:08.485281+0300 | INFO | [182,  1400] loss: 1.487
2025-02-27T12:19:25.407061+0300 | INFO | [182,  1500] loss: 1.483
2025-02-27T12:19:41.888074+0300 | INFO | [182,  1600] loss: 1.488
2025-02-27T12:19:59.474357+0300 | INFO | [182,  1700] loss: 1.485
2025-02-27T12:20:15.430037+0300 | INFO | [182,  1800] loss: 1.487
2025-02-27T12:20:30.630792+0300 | INFO | [182,  1900] loss: 1.485
2025-02-27T12:20:45.845222+0300 | INFO | [182,  2000] loss: 1.488
2025-02-27T12:21:00.470613+0300 | INFO | [182,  2100] loss: 1.496
2025-02-27T12:21:14.986000+0300 | INFO | [182,  2200] loss: 1.484
2025-02-27T12:21:29.939119+0300 | INFO | [182,  2300] loss: 1.487
2025-02-27T12:21:45.930703+0300 | INFO | [182,  2400] loss: 1.483
2025-02-27T12:22:01.715965+0300 | INFO | [182,  2500] loss: 1.489
2025-02-27T12:22:17.231429+0300 | INFO | [182,  2600] loss: 1.499
2025-02-27T12:22:32.532900+0300 | INFO | [182,  2700] loss: 1.481
2025-02-27T12:22:47.294955+0300 | INFO | [182,  2800] loss: 1.495
2025-02-27T12:23:00.282629+0300 | INFO | [182,  2900] loss: 1.488
2025-02-27T12:23:15.557296+0300 | INFO | [182,  3000] loss: 1.492
2025-02-27T12:23:30.855863+0300 | INFO | [182,  3100] loss: 1.491
2025-02-27T12:23:46.598333+0300 | INFO | [182,  3200] loss: 1.486
2025-02-27T12:24:02.462442+0300 | INFO | [182,  3300] loss: 1.494
2025-02-27T12:24:16.683087+0300 | INFO | [182,  3400] loss: 1.500
2025-02-27T12:24:32.645648+0300 | INFO | [182,  3500] loss: 1.487
2025-02-27T12:24:47.155922+0300 | INFO | [182,  3600] loss: 1.484
2025-02-27T12:25:01.965095+0300 | INFO | [182,  3700] loss: 1.499
2025-02-27T12:25:19.023539+0300 | INFO | [182,  3800] loss: 1.495
2025-02-27T12:25:35.957638+0300 | INFO | [182,  3900] loss: 1.487
2025-02-27T12:25:51.649450+0300 | INFO | [182,  4000] loss: 1.489
2025-02-27T12:26:07.581446+0300 | INFO | [182,  4100] loss: 1.490
2025-02-27T12:26:19.374629+0300 | INFO | [182,  4200] loss: 1.493
2025-02-27T12:26:31.756104+0300 | INFO | [182,  4300] loss: 1.495
2025-02-27T12:26:52.018637+0300 | INFO | [182,  4400] loss: 1.483
2025-02-27T12:27:11.215174+0300 | INFO | [182,  4500] loss: 1.486
2025-02-27T12:27:28.291391+0300 | INFO | [182,  4600] loss: 1.493
2025-02-27T12:27:47.349079+0300 | INFO | [182,  4700] loss: 1.490
2025-02-27T12:28:00.818937+0300 | INFO | [182,  4800] loss: 1.487
2025-02-27T12:28:18.601160+0300 | INFO | [182,  4900] loss: 1.489
2025-02-27T12:28:34.354847+0300 | DEBUG | Saving model to flat file storage. Save #182
2025-02-27T12:28:34.396867+0300 | INFO | Averaging client parameters
2025-02-27T12:28:34.407878+0300 | INFO | Updating parameters on client #0
2025-02-27T12:28:59.928197+0300 | DEBUG | Test set: Accuracy: 7938/10000 (79%)
2025-02-27T12:28:59.934215+0300 | DEBUG | Test set: Loss: 1.6668826341629028
2025-02-27T12:29:00.135128+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.74      0.83      0.78      1000
           5       0.56      0.61      0.58       800
           6       0.83      0.87      0.85      1000
           7       0.86      0.82      0.84      1000
           8       0.88      0.91      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T12:29:00.149652+0300 | DEBUG | Confusion Matrix:
[[827  15  37   8  24   8   4   8  44  25]
 [  6 925   5   0   1   1   4   1  19  38]
 [ 55   4 702  42  83  37  50  14   9   4]
 [ 17   6  54 677  72 248  56  38  16  16]
 [ 10   4  31  33 831  30  28  23   5   5]
 [ 16   4  38 150  38 487  18  39   5   5]
 [  8   6  30  36  18  13 874   6   5   4]
 [ 16   4  16  23  55  40   6 822   3  15]
 [ 35  14  11   3   5   2   4   2 914  10]
 [ 25  44   8   4   1   4  11   6  18 879]]
2025-02-27T12:29:00.152650+0300 | DEBUG | Class precision: [0.81477833 0.90155945 0.75321888 0.69364754 0.73670213 0.55977011
 0.82843602 0.85714286 0.8805395  0.87812188]
2025-02-27T12:29:00.155669+0300 | DEBUG | Class recall: [0.827      0.925      0.702      0.56416667 0.831      0.60875
 0.874      0.822      0.914      0.879     ]
2025-02-27T12:29:00.295264+0300 | INFO | Training epoch #183 on client #0
2025-02-27T12:29:00.301243+0300 | DEBUG | Saving model to flat file storage. Save #183
2025-02-27T12:29:00.585317+0300 | INFO | [183,     0] loss: 0.015
2025-02-27T12:29:17.028586+0300 | INFO | [183,   100] loss: 1.501
2025-02-27T12:29:38.225952+0300 | INFO | [183,   200] loss: 1.482
2025-02-27T12:29:59.347318+0300 | INFO | [183,   300] loss: 1.496
2025-02-27T12:30:13.446686+0300 | INFO | [183,   400] loss: 1.488
2025-02-27T12:30:24.969335+0300 | INFO | [183,   500] loss: 1.492
2025-02-27T12:30:36.843048+0300 | INFO | [183,   600] loss: 1.495
2025-02-27T12:30:49.430336+0300 | INFO | [183,   700] loss: 1.494
2025-02-27T12:31:02.072676+0300 | INFO | [183,   800] loss: 1.495
2025-02-27T12:31:14.951026+0300 | INFO | [183,   900] loss: 1.491
2025-02-27T12:31:25.993153+0300 | INFO | [183,  1000] loss: 1.499
2025-02-27T12:31:41.746493+0300 | INFO | [183,  1100] loss: 1.498
2025-02-27T12:31:54.595701+0300 | INFO | [183,  1200] loss: 1.489
2025-02-27T12:32:06.614297+0300 | INFO | [183,  1300] loss: 1.480
2025-02-27T12:32:17.647477+0300 | INFO | [183,  1400] loss: 1.487
2025-02-27T12:32:30.614700+0300 | INFO | [183,  1500] loss: 1.485
2025-02-27T12:32:42.009872+0300 | INFO | [183,  1600] loss: 1.498
2025-02-27T12:32:55.043957+0300 | INFO | [183,  1700] loss: 1.492
2025-02-27T12:33:05.346262+0300 | INFO | [183,  1800] loss: 1.490
2025-02-27T12:33:16.478762+0300 | INFO | [183,  1900] loss: 1.489
2025-02-27T12:33:27.192609+0300 | INFO | [183,  2000] loss: 1.492
2025-02-27T12:33:40.125598+0300 | INFO | [183,  2100] loss: 1.491
2025-02-27T12:33:53.630551+0300 | INFO | [183,  2200] loss: 1.500
2025-02-27T12:34:05.155018+0300 | INFO | [183,  2300] loss: 1.483
2025-02-27T12:34:16.927497+0300 | INFO | [183,  2400] loss: 1.480
2025-02-27T12:34:28.490220+0300 | INFO | [183,  2500] loss: 1.487
2025-02-27T12:34:40.494685+0300 | INFO | [183,  2600] loss: 1.487
2025-02-27T12:34:53.495286+0300 | INFO | [183,  2700] loss: 1.489
2025-02-27T12:35:06.285415+0300 | INFO | [183,  2800] loss: 1.491
2025-02-27T12:35:20.477427+0300 | INFO | [183,  2900] loss: 1.494
2025-02-27T12:35:32.104339+0300 | INFO | [183,  3000] loss: 1.497
2025-02-27T12:35:44.352334+0300 | INFO | [183,  3100] loss: 1.487
2025-02-27T12:35:56.090403+0300 | INFO | [183,  3200] loss: 1.498
2025-02-27T12:36:08.371109+0300 | INFO | [183,  3300] loss: 1.487
2025-02-27T12:36:19.548911+0300 | INFO | [183,  3400] loss: 1.492
2025-02-27T12:36:30.562878+0300 | INFO | [183,  3500] loss: 1.492
2025-02-27T12:36:43.090944+0300 | INFO | [183,  3600] loss: 1.478
2025-02-27T12:36:58.104851+0300 | INFO | [183,  3700] loss: 1.487
2025-02-27T12:37:13.304557+0300 | INFO | [183,  3800] loss: 1.492
2025-02-27T12:37:26.095813+0300 | INFO | [183,  3900] loss: 1.488
2025-02-27T12:37:38.368383+0300 | INFO | [183,  4000] loss: 1.489
2025-02-27T12:37:51.176274+0300 | INFO | [183,  4100] loss: 1.486
2025-02-27T12:38:06.338271+0300 | INFO | [183,  4200] loss: 1.493
2025-02-27T12:38:22.459354+0300 | INFO | [183,  4300] loss: 1.493
2025-02-27T12:38:34.788110+0300 | INFO | [183,  4400] loss: 1.484
2025-02-27T12:38:48.584545+0300 | INFO | [183,  4500] loss: 1.483
2025-02-27T12:39:00.105496+0300 | INFO | [183,  4600] loss: 1.485
2025-02-27T12:39:11.672199+0300 | INFO | [183,  4700] loss: 1.492
2025-02-27T12:39:28.693410+0300 | INFO | [183,  4800] loss: 1.485
2025-02-27T12:39:41.405965+0300 | INFO | [183,  4900] loss: 1.486
2025-02-27T12:39:53.589435+0300 | DEBUG | Saving model to flat file storage. Save #183
2025-02-27T12:39:53.631974+0300 | INFO | Averaging client parameters
2025-02-27T12:39:53.639970+0300 | INFO | Updating parameters on client #0
2025-02-27T12:40:23.681418+0300 | DEBUG | Test set: Accuracy: 7939/10000 (79%)
2025-02-27T12:40:23.686415+0300 | DEBUG | Test set: Loss: 1.6665161848068237
2025-02-27T12:40:23.769970+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82      1000
           1       0.91      0.92      0.91      1000
           2       0.76      0.70      0.73      1000
           3       0.69      0.57      0.62      1200
           4       0.75      0.81      0.78      1000
           5       0.54      0.62      0.58       800
           6       0.85      0.86      0.86      1000
           7       0.85      0.84      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.86      0.89      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T12:40:23.772979+0300 | DEBUG | Confusion Matrix:
[[823  13  38  10  18   7   4  10  44  33]
 [  5 919   6   0   1   1   3   1  18  46]
 [ 61   5 697  41  79  43  41  16   8   9]
 [ 18   7  48 684  67 263  43  36  17  17]
 [ 11   4  33  37 814  37  22  31   5   6]
 [ 14   3  36 152  32 494  19  37   8   5]
 [  8   4  30  41  20  19 862   7   5   4]
 [ 14   4  14  23  47  42   4 836   2  14]
 [ 32  12   9   4   5   2   4   3 918  11]
 [ 18  40   6   4   1   4  10   9  16 892]]
2025-02-27T12:40:23.776975+0300 | DEBUG | Class precision: [0.81972112 0.90900099 0.76008724 0.68674699 0.75092251 0.54166667
 0.85177866 0.84787018 0.88184438 0.86017358]
2025-02-27T12:40:23.778976+0300 | DEBUG | Class recall: [0.823  0.919  0.697  0.57   0.814  0.6175 0.862  0.836  0.918  0.892 ]
2025-02-27T12:40:23.847986+0300 | INFO | Training epoch #184 on client #0
2025-02-27T12:40:23.848986+0300 | DEBUG | Saving model to flat file storage. Save #184
2025-02-27T12:40:24.087593+0300 | INFO | [184,     0] loss: 0.015
2025-02-27T12:40:37.594231+0300 | INFO | [184,   100] loss: 1.485
2025-02-27T12:40:50.534197+0300 | INFO | [184,   200] loss: 1.489
2025-02-27T12:41:04.222137+0300 | INFO | [184,   300] loss: 1.492
2025-02-27T12:41:16.399610+0300 | INFO | [184,   400] loss: 1.489
2025-02-27T12:41:28.254350+0300 | INFO | [184,   500] loss: 1.493
2025-02-27T12:41:39.110140+0300 | INFO | [184,   600] loss: 1.488
2025-02-27T12:41:51.226683+0300 | INFO | [184,   700] loss: 1.483
2025-02-27T12:42:03.258446+0300 | INFO | [184,   800] loss: 1.487
2025-02-27T12:42:16.106662+0300 | INFO | [184,   900] loss: 1.496
2025-02-27T12:42:27.414279+0300 | INFO | [184,  1000] loss: 1.482
2025-02-27T12:42:39.142764+0300 | INFO | [184,  1100] loss: 1.495
2025-02-27T12:42:49.858472+0300 | INFO | [184,  1200] loss: 1.485
2025-02-27T12:43:00.445336+0300 | INFO | [184,  1300] loss: 1.490
2025-02-27T12:43:10.260131+0300 | INFO | [184,  1400] loss: 1.497
2025-02-27T12:43:20.353082+0300 | INFO | [184,  1500] loss: 1.487
2025-02-27T12:43:30.275070+0300 | INFO | [184,  1600] loss: 1.498
2025-02-27T12:43:40.391831+0300 | INFO | [184,  1700] loss: 1.484
2025-02-27T12:43:51.120311+0300 | INFO | [184,  1800] loss: 1.494
2025-02-27T12:44:02.010681+0300 | INFO | [184,  1900] loss: 1.489
2025-02-27T12:44:15.782620+0300 | INFO | [184,  2000] loss: 1.487
2025-02-27T12:44:28.100723+0300 | INFO | [184,  2100] loss: 1.487
2025-02-27T12:44:40.086340+0300 | INFO | [184,  2200] loss: 1.486
2025-02-27T12:44:50.565159+0300 | INFO | [184,  2300] loss: 1.490
2025-02-27T12:45:00.824789+0300 | INFO | [184,  2400] loss: 1.490
2025-02-27T12:45:11.057697+0300 | INFO | [184,  2500] loss: 1.494
2025-02-27T12:45:21.202413+0300 | INFO | [184,  2600] loss: 1.483
2025-02-27T12:45:40.425313+0300 | INFO | [184,  2700] loss: 1.493
2025-02-27T12:45:54.256761+0300 | INFO | [184,  2800] loss: 1.490
2025-02-27T12:46:05.347426+0300 | INFO | [184,  2900] loss: 1.493
2025-02-27T12:46:17.588083+0300 | INFO | [184,  3000] loss: 1.491
2025-02-27T12:46:29.424510+0300 | INFO | [184,  3100] loss: 1.508
2025-02-27T12:46:40.318700+0300 | INFO | [184,  3200] loss: 1.500
2025-02-27T12:46:51.677787+0300 | INFO | [184,  3300] loss: 1.488
2025-02-27T12:47:03.692914+0300 | INFO | [184,  3400] loss: 1.486
2025-02-27T12:47:15.523568+0300 | INFO | [184,  3500] loss: 1.488
2025-02-27T12:47:26.499375+0300 | INFO | [184,  3600] loss: 1.496
2025-02-27T12:47:37.514329+0300 | INFO | [184,  3700] loss: 1.488
2025-02-27T12:47:49.545450+0300 | INFO | [184,  3800] loss: 1.490
2025-02-27T12:48:00.397389+0300 | INFO | [184,  3900] loss: 1.491
2025-02-27T12:48:12.606042+0300 | INFO | [184,  4000] loss: 1.499
2025-02-27T12:48:29.375404+0300 | INFO | [184,  4100] loss: 1.492
2025-02-27T12:48:42.582935+0300 | INFO | [184,  4200] loss: 1.485
2025-02-27T12:48:55.667085+0300 | INFO | [184,  4300] loss: 1.484
2025-02-27T12:49:14.540563+0300 | INFO | [184,  4400] loss: 1.484
2025-02-27T12:49:28.107995+0300 | INFO | [184,  4500] loss: 1.487
2025-02-27T12:49:40.800651+0300 | INFO | [184,  4600] loss: 1.494
2025-02-27T12:49:52.931232+0300 | INFO | [184,  4700] loss: 1.484
2025-02-27T12:50:09.338455+0300 | INFO | [184,  4800] loss: 1.484
2025-02-27T12:50:24.337796+0300 | INFO | [184,  4900] loss: 1.487
2025-02-27T12:50:40.797260+0300 | DEBUG | Saving model to flat file storage. Save #184
2025-02-27T12:50:40.833270+0300 | INFO | Averaging client parameters
2025-02-27T12:50:40.846790+0300 | INFO | Updating parameters on client #0
2025-02-27T12:51:11.557799+0300 | DEBUG | Test set: Accuracy: 7924/10000 (79%)
2025-02-27T12:51:11.560797+0300 | DEBUG | Test set: Loss: 1.666449785232544
2025-02-27T12:51:11.680844+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.90      0.93      0.91      1000
           2       0.74      0.71      0.72      1000
           3       0.68      0.57      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.51      0.63      0.56       800
           6       0.85      0.85      0.85      1000
           7       0.84      0.83      0.84      1000
           8       0.90      0.91      0.91      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T12:51:11.691847+0300 | DEBUG | Confusion Matrix:
[[830  17  43  12  12  10   6  10  37  23]
 [  6 926   5   0   1   2   5   4  14  37]
 [ 52   3 708  39  68  57  44  17   6   6]
 [ 18   4  54 679  51 289  38  36  15  16]
 [ 10   5  37  41 804  40  26  30   5   2]
 [ 16   3  39 148  27 505  17  37   5   3]
 [  7   3  41  42  15  25 853   7   5   2]
 [ 14   4  15  26  44  50   3 830   1  13]
 [ 32  16  12   3   5   4   4   2 913   9]
 [ 20  53   7   3   1   7  10  10  13 876]]
2025-02-27T12:51:11.695845+0300 | DEBUG | Class precision: [0.82587065 0.89555126 0.73673257 0.68378651 0.78210117 0.51061678
 0.84791252 0.84435402 0.90039448 0.88753799]
2025-02-27T12:51:11.697845+0300 | DEBUG | Class recall: [0.83       0.926      0.708      0.56583333 0.804      0.63125
 0.853      0.83       0.913      0.876     ]
2025-02-27T12:51:11.784384+0300 | INFO | Training epoch #185 on client #0
2025-02-27T12:51:11.786382+0300 | DEBUG | Saving model to flat file storage. Save #185
2025-02-27T12:51:12.113030+0300 | INFO | [185,     0] loss: 0.015
2025-02-27T12:51:23.387022+0300 | INFO | [185,   100] loss: 1.486
2025-02-27T12:51:35.606064+0300 | INFO | [185,   200] loss: 1.489
2025-02-27T12:51:49.154913+0300 | INFO | [185,   300] loss: 1.477
2025-02-27T12:52:04.137907+0300 | INFO | [185,   400] loss: 1.490
2025-02-27T12:52:20.277045+0300 | INFO | [185,   500] loss: 1.495
2025-02-27T12:52:32.775669+0300 | INFO | [185,   600] loss: 1.484
2025-02-27T12:52:47.929278+0300 | INFO | [185,   700] loss: 1.490
2025-02-27T12:53:02.336028+0300 | INFO | [185,   800] loss: 1.480
2025-02-27T12:53:19.450381+0300 | INFO | [185,   900] loss: 1.484
2025-02-27T12:53:37.617364+0300 | INFO | [185,  1000] loss: 1.491
2025-02-27T12:53:51.279918+0300 | INFO | [185,  1100] loss: 1.492
2025-02-27T12:54:06.761765+0300 | INFO | [185,  1200] loss: 1.488
2025-02-27T12:54:20.675915+0300 | INFO | [185,  1300] loss: 1.490
2025-02-27T12:54:37.561452+0300 | INFO | [185,  1400] loss: 1.491
2025-02-27T12:54:54.954089+0300 | INFO | [185,  1500] loss: 1.480
2025-02-27T12:55:08.546387+0300 | INFO | [185,  1600] loss: 1.491
2025-02-27T12:55:21.509536+0300 | INFO | [185,  1700] loss: 1.489
2025-02-27T12:55:32.681655+0300 | INFO | [185,  1800] loss: 1.486
2025-02-27T12:55:43.930661+0300 | INFO | [185,  1900] loss: 1.478
2025-02-27T12:55:56.906131+0300 | INFO | [185,  2000] loss: 1.500
2025-02-27T12:56:10.849979+0300 | INFO | [185,  2100] loss: 1.491
2025-02-27T12:56:21.568678+0300 | INFO | [185,  2200] loss: 1.489
2025-02-27T12:56:32.641726+0300 | INFO | [185,  2300] loss: 1.494
2025-02-27T12:56:44.617332+0300 | INFO | [185,  2400] loss: 1.484
2025-02-27T12:56:57.618149+0300 | INFO | [185,  2500] loss: 1.489
2025-02-27T12:57:10.780809+0300 | INFO | [185,  2600] loss: 1.488
2025-02-27T12:57:22.150597+0300 | INFO | [185,  2700] loss: 1.488
2025-02-27T12:57:34.102937+0300 | INFO | [185,  2800] loss: 1.501
2025-02-27T12:57:45.605960+0300 | INFO | [185,  2900] loss: 1.488
2025-02-27T12:57:57.038889+0300 | INFO | [185,  3000] loss: 1.488
2025-02-27T12:58:09.048809+0300 | INFO | [185,  3100] loss: 1.506
2025-02-27T12:58:20.683638+0300 | INFO | [185,  3200] loss: 1.483
2025-02-27T12:58:32.485228+0300 | INFO | [185,  3300] loss: 1.492
2025-02-27T12:58:44.570679+0300 | INFO | [185,  3400] loss: 1.491
2025-02-27T12:58:57.748000+0300 | INFO | [185,  3500] loss: 1.491
2025-02-27T12:59:12.617927+0300 | INFO | [185,  3600] loss: 1.489
2025-02-27T12:59:24.713834+0300 | INFO | [185,  3700] loss: 1.492
2025-02-27T12:59:37.649549+0300 | INFO | [185,  3800] loss: 1.493
2025-02-27T12:59:50.400505+0300 | INFO | [185,  3900] loss: 1.491
2025-02-27T13:00:02.456457+0300 | INFO | [185,  4000] loss: 1.488
2025-02-27T13:00:20.012476+0300 | INFO | [185,  4100] loss: 1.488
2025-02-27T13:00:40.151922+0300 | INFO | [185,  4200] loss: 1.496
2025-02-27T13:00:51.826224+0300 | INFO | [185,  4300] loss: 1.489
2025-02-27T13:01:04.100503+0300 | INFO | [185,  4400] loss: 1.501
2025-02-27T13:01:16.283143+0300 | INFO | [185,  4500] loss: 1.490
2025-02-27T13:01:29.179443+0300 | INFO | [185,  4600] loss: 1.487
2025-02-27T13:01:41.774127+0300 | INFO | [185,  4700] loss: 1.495
2025-02-27T13:01:55.723454+0300 | INFO | [185,  4800] loss: 1.494
2025-02-27T13:02:09.540427+0300 | INFO | [185,  4900] loss: 1.493
2025-02-27T13:02:22.452921+0300 | DEBUG | Saving model to flat file storage. Save #185
2025-02-27T13:02:22.542786+0300 | INFO | Averaging client parameters
2025-02-27T13:02:22.559955+0300 | INFO | Updating parameters on client #0
2025-02-27T13:02:56.396620+0300 | DEBUG | Test set: Accuracy: 7943/10000 (79%)
2025-02-27T13:02:56.403619+0300 | DEBUG | Test set: Loss: 1.6652636528015137
2025-02-27T13:02:56.518173+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.85      0.83      1000
           1       0.91      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.69      0.58      0.63      1200
           4       0.78      0.80      0.79      1000
           5       0.54      0.61      0.57       800
           6       0.84      0.86      0.85      1000
           7       0.82      0.85      0.84      1000
           8       0.89      0.92      0.90      1000
           9       0.90      0.87      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T13:02:56.525697+0300 | DEBUG | Confusion Matrix:
[[848  11  36   9  13   9   6  11  39  18]
 [ 11 915   3   1   1   2   6   4  18  39]
 [ 63   3 706  44  71  40  47  18   4   4]
 [ 17   5  53 692  55 263  43  43  18  11]
 [ 14   4  32  40 796  38  31  38   6   1]
 [ 16   1  41 156  25 488  17  44   8   4]
 [  7   4  42  34  16  17 865   8   6   1]
 [ 15   4  17  24  40  41   3 847   1   8]
 [ 34  14   8   5   5   2   4   2 919   7]
 [ 27  48   8   5   1   3  11  12  18 867]]
2025-02-27T13:02:56.529690+0300 | DEBUG | Class precision: [0.80608365 0.90683845 0.74630021 0.68514851 0.77810362 0.54042082
 0.83736689 0.82473223 0.88621022 0.903125  ]
2025-02-27T13:02:56.534694+0300 | DEBUG | Class recall: [0.848      0.915      0.706      0.57666667 0.796      0.61
 0.865      0.847      0.919      0.867     ]
2025-02-27T13:02:56.600694+0300 | INFO | Training epoch #186 on client #0
2025-02-27T13:02:56.604694+0300 | DEBUG | Saving model to flat file storage. Save #186
2025-02-27T13:02:56.902313+0300 | INFO | [186,     0] loss: 0.015
2025-02-27T13:03:11.061167+0300 | INFO | [186,   100] loss: 1.492
2025-02-27T13:03:24.227504+0300 | INFO | [186,   200] loss: 1.497
2025-02-27T13:03:37.893695+0300 | INFO | [186,   300] loss: 1.492
2025-02-27T13:03:52.283915+0300 | INFO | [186,   400] loss: 1.489
2025-02-27T13:04:07.378627+0300 | INFO | [186,   500] loss: 1.493
2025-02-27T13:04:21.934015+0300 | INFO | [186,   600] loss: 1.491
2025-02-27T13:04:37.930272+0300 | INFO | [186,   700] loss: 1.494
2025-02-27T13:04:52.183679+0300 | INFO | [186,   800] loss: 1.483
2025-02-27T13:05:06.903531+0300 | INFO | [186,   900] loss: 1.494
2025-02-27T13:05:21.052833+0300 | INFO | [186,  1000] loss: 1.490
2025-02-27T13:05:35.709140+0300 | INFO | [186,  1100] loss: 1.489
2025-02-27T13:05:50.959177+0300 | INFO | [186,  1200] loss: 1.493
2025-02-27T13:06:05.422629+0300 | INFO | [186,  1300] loss: 1.491
2025-02-27T13:06:19.919089+0300 | INFO | [186,  1400] loss: 1.489
2025-02-27T13:06:33.548001+0300 | INFO | [186,  1500] loss: 1.489
2025-02-27T13:06:49.489081+0300 | INFO | [186,  1600] loss: 1.498
2025-02-27T13:07:03.504368+0300 | INFO | [186,  1700] loss: 1.491
2025-02-27T13:07:16.436854+0300 | INFO | [186,  1800] loss: 1.491
2025-02-27T13:07:31.100863+0300 | INFO | [186,  1900] loss: 1.494
2025-02-27T13:07:45.814388+0300 | INFO | [186,  2000] loss: 1.494
2025-02-27T13:08:00.936264+0300 | INFO | [186,  2100] loss: 1.493
2025-02-27T13:08:16.116150+0300 | INFO | [186,  2200] loss: 1.489
2025-02-27T13:08:30.590753+0300 | INFO | [186,  2300] loss: 1.484
2025-02-27T13:08:45.815804+0300 | INFO | [186,  2400] loss: 1.487
2025-02-27T13:09:00.633556+0300 | INFO | [186,  2500] loss: 1.476
2025-02-27T13:09:14.226226+0300 | INFO | [186,  2600] loss: 1.490
2025-02-27T13:09:26.165112+0300 | INFO | [186,  2700] loss: 1.491
2025-02-27T13:09:38.422637+0300 | INFO | [186,  2800] loss: 1.498
2025-02-27T13:09:51.404694+0300 | INFO | [186,  2900] loss: 1.493
2025-02-27T13:10:02.178916+0300 | INFO | [186,  3000] loss: 1.489
2025-02-27T13:10:13.469862+0300 | INFO | [186,  3100] loss: 1.487
2025-02-27T13:10:25.723146+0300 | INFO | [186,  3200] loss: 1.489
2025-02-27T13:10:38.044235+0300 | INFO | [186,  3300] loss: 1.484
2025-02-27T13:10:50.671426+0300 | INFO | [186,  3400] loss: 1.481
2025-02-27T13:11:03.586000+0300 | INFO | [186,  3500] loss: 1.487
2025-02-27T13:11:19.305198+0300 | INFO | [186,  3600] loss: 1.481
2025-02-27T13:11:38.829381+0300 | INFO | [186,  3700] loss: 1.490
2025-02-27T13:11:52.000137+0300 | INFO | [186,  3800] loss: 1.499
2025-02-27T13:12:04.003690+0300 | INFO | [186,  3900] loss: 1.485
2025-02-27T13:12:16.920456+0300 | INFO | [186,  4000] loss: 1.491
2025-02-27T13:12:29.190730+0300 | INFO | [186,  4100] loss: 1.485
2025-02-27T13:12:40.673941+0300 | INFO | [186,  4200] loss: 1.498
2025-02-27T13:12:52.531474+0300 | INFO | [186,  4300] loss: 1.488
2025-02-27T13:13:03.887558+0300 | INFO | [186,  4400] loss: 1.481
2025-02-27T13:13:16.164912+0300 | INFO | [186,  4500] loss: 1.493
2025-02-27T13:13:28.845667+0300 | INFO | [186,  4600] loss: 1.482
2025-02-27T13:13:40.565444+0300 | INFO | [186,  4700] loss: 1.488
2025-02-27T13:13:53.084498+0300 | INFO | [186,  4800] loss: 1.492
2025-02-27T13:14:05.544827+0300 | INFO | [186,  4900] loss: 1.490
2025-02-27T13:14:19.038159+0300 | DEBUG | Saving model to flat file storage. Save #186
2025-02-27T13:14:19.088682+0300 | INFO | Averaging client parameters
2025-02-27T13:14:19.097685+0300 | INFO | Updating parameters on client #0
2025-02-27T13:14:51.898660+0300 | DEBUG | Test set: Accuracy: 7925/10000 (79%)
2025-02-27T13:14:51.901659+0300 | DEBUG | Test set: Loss: 1.6674355268478394
2025-02-27T13:14:52.061702+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.89      0.93      0.91      1000
           2       0.76      0.69      0.72      1000
           3       0.70      0.56      0.62      1200
           4       0.79      0.79      0.79      1000
           5       0.53      0.64      0.58       800
           6       0.81      0.88      0.84      1000
           7       0.86      0.83      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.88      0.87      0.87      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T13:14:52.064700+0300 | DEBUG | Confusion Matrix:
[[847  16  34   8  11   9   6   8  37  24]
 [  7 931   1   0   1   2   4   2  14  38]
 [ 66   5 688  37  66  51  58  17   6   6]
 [ 23   7  55 670  51 269  60  31  18  16]
 [ 14   6  32  40 793  43  36  26   5   5]
 [ 19   2  38 141  24 509  19  38   5   5]
 [  7   5  26  35  13  19 882   6   4   3]
 [ 17   4  15  25  43  44   8 829   2  13]
 [ 40  17   7   4   3   3   4   2 909  11]
 [ 27  55   8   2   1   5  11   7  17 867]]
2025-02-27T13:14:52.067700+0300 | DEBUG | Class precision: [0.79381443 0.88835878 0.76106195 0.6964657  0.78827038 0.53354298
 0.81066176 0.85817805 0.89380531 0.87753036]
2025-02-27T13:14:52.070702+0300 | DEBUG | Class recall: [0.847      0.931      0.688      0.55833333 0.793      0.63625
 0.882      0.829      0.909      0.867     ]
2025-02-27T13:14:52.131223+0300 | INFO | Training epoch #187 on client #0
2025-02-27T13:14:52.133223+0300 | DEBUG | Saving model to flat file storage. Save #187
2025-02-27T13:14:52.396814+0300 | INFO | [187,     0] loss: 0.017
2025-02-27T13:15:07.863247+0300 | INFO | [187,   100] loss: 1.484
2025-02-27T13:15:23.754643+0300 | INFO | [187,   200] loss: 1.481
2025-02-27T13:15:39.256459+0300 | INFO | [187,   300] loss: 1.489
2025-02-27T13:15:59.819092+0300 | INFO | [187,   400] loss: 1.486
2025-02-27T13:16:15.875402+0300 | INFO | [187,   500] loss: 1.489
2025-02-27T13:16:32.067563+0300 | INFO | [187,   600] loss: 1.492
2025-02-27T13:16:48.128683+0300 | INFO | [187,   700] loss: 1.493
2025-02-27T13:17:04.690294+0300 | INFO | [187,   800] loss: 1.493
2025-02-27T13:17:23.740928+0300 | INFO | [187,   900] loss: 1.495
2025-02-27T13:17:39.903245+0300 | INFO | [187,  1000] loss: 1.489
2025-02-27T13:17:54.930540+0300 | INFO | [187,  1100] loss: 1.488
2025-02-27T13:18:10.172610+0300 | INFO | [187,  1200] loss: 1.492
2025-02-27T13:18:25.162900+0300 | INFO | [187,  1300] loss: 1.484
2025-02-27T13:18:40.562692+0300 | INFO | [187,  1400] loss: 1.493
2025-02-27T13:18:56.556157+0300 | INFO | [187,  1500] loss: 1.486
2025-02-27T13:19:13.675242+0300 | INFO | [187,  1600] loss: 1.493
2025-02-27T13:19:34.134550+0300 | INFO | [187,  1700] loss: 1.484
2025-02-27T13:19:51.931303+0300 | INFO | [187,  1800] loss: 1.496
2025-02-27T13:20:12.482550+0300 | INFO | [187,  1900] loss: 1.485
2025-02-27T13:20:31.590559+0300 | INFO | [187,  2000] loss: 1.489
2025-02-27T13:20:49.012756+0300 | INFO | [187,  2100] loss: 1.496
2025-02-27T13:21:09.233225+0300 | INFO | [187,  2200] loss: 1.485
2025-02-27T13:21:26.732818+0300 | INFO | [187,  2300] loss: 1.484
2025-02-27T13:21:52.564341+0300 | INFO | [187,  2400] loss: 1.491
2025-02-27T13:22:11.203811+0300 | INFO | [187,  2500] loss: 1.492
2025-02-27T13:22:25.804289+0300 | INFO | [187,  2600] loss: 1.490
2025-02-27T13:22:39.303005+0300 | INFO | [187,  2700] loss: 1.489
2025-02-27T13:22:54.544023+0300 | INFO | [187,  2800] loss: 1.490
2025-02-27T13:23:08.844284+0300 | INFO | [187,  2900] loss: 1.491
2025-02-27T13:23:21.852003+0300 | INFO | [187,  3000] loss: 1.493
2025-02-27T13:23:35.467309+0300 | INFO | [187,  3100] loss: 1.484
2025-02-27T13:23:50.469100+0300 | INFO | [187,  3200] loss: 1.492
2025-02-27T13:24:05.004276+0300 | INFO | [187,  3300] loss: 1.494
2025-02-27T13:24:21.167380+0300 | INFO | [187,  3400] loss: 1.486
2025-02-27T13:24:35.041266+0300 | INFO | [187,  3500] loss: 1.490
2025-02-27T13:24:49.436374+0300 | INFO | [187,  3600] loss: 1.490
2025-02-27T13:25:04.382723+0300 | INFO | [187,  3700] loss: 1.484
2025-02-27T13:25:24.642645+0300 | INFO | [187,  3800] loss: 1.492
2025-02-27T13:25:42.719229+0300 | INFO | [187,  3900] loss: 1.493
2025-02-27T13:26:00.083254+0300 | INFO | [187,  4000] loss: 1.486
2025-02-27T13:26:15.308269+0300 | INFO | [187,  4100] loss: 1.490
2025-02-27T13:26:33.185381+0300 | INFO | [187,  4200] loss: 1.495
2025-02-27T13:26:49.680562+0300 | INFO | [187,  4300] loss: 1.491
2025-02-27T13:27:11.106116+0300 | INFO | [187,  4400] loss: 1.499
2025-02-27T13:27:30.058706+0300 | INFO | [187,  4500] loss: 1.493
2025-02-27T13:27:49.366940+0300 | INFO | [187,  4600] loss: 1.497
2025-02-27T13:28:05.429711+0300 | INFO | [187,  4700] loss: 1.493
2025-02-27T13:28:22.815532+0300 | INFO | [187,  4800] loss: 1.486
2025-02-27T13:28:38.975100+0300 | INFO | [187,  4900] loss: 1.484
2025-02-27T13:28:55.146968+0300 | DEBUG | Saving model to flat file storage. Save #187
2025-02-27T13:28:55.213667+0300 | INFO | Averaging client parameters
2025-02-27T13:28:55.227222+0300 | INFO | Updating parameters on client #0
2025-02-27T13:29:31.328300+0300 | DEBUG | Test set: Accuracy: 7946/10000 (79%)
2025-02-27T13:29:31.331300+0300 | DEBUG | Test set: Loss: 1.6652132272720337
2025-02-27T13:29:31.524835+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.90      0.93      0.91      1000
           2       0.77      0.70      0.73      1000
           3       0.69      0.57      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.52      0.64      0.57       800
           6       0.85      0.86      0.86      1000
           7       0.83      0.84      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.89      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.79      0.79     10000

2025-02-27T13:29:31.528842+0300 | DEBUG | Confusion Matrix:
[[832  17  35   9  12  10   4  12  45  24]
 [  5 931   3   0   1   2   5   3  10  40]
 [ 62   3 697  39  67  56  48  17   7   4]
 [ 17   6  44 684  52 283  41  40  19  14]
 [ 12   6  29  42 799  46  23  36   5   2]
 [ 17   2  37 149  27 510  12  39   3   4]
 [  6   5  30  41  16  28 861   8   4   1]
 [ 14   4  11  23  45  48   4 841   2   8]
 [ 32  17   8   7   3   3   4   3 914   9]
 [ 23  49   8   3   1   3  10  10  16 877]]
2025-02-27T13:29:31.535369+0300 | DEBUG | Class precision: [0.81568627 0.89519231 0.77272727 0.68605817 0.78103617 0.5156724
 0.85079051 0.83349851 0.89170732 0.89216684]
2025-02-27T13:29:31.538368+0300 | DEBUG | Class recall: [0.832  0.931  0.697  0.57   0.799  0.6375 0.861  0.841  0.914  0.877 ]
2025-02-27T13:29:31.613839+0300 | INFO | Training epoch #188 on client #0
2025-02-27T13:29:31.615850+0300 | DEBUG | Saving model to flat file storage. Save #188
2025-02-27T13:29:31.817458+0300 | INFO | [188,     0] loss: 0.017
2025-02-27T13:29:44.955577+0300 | INFO | [188,   100] loss: 1.495
2025-02-27T13:29:58.485315+0300 | INFO | [188,   200] loss: 1.482
2025-02-27T13:30:11.085411+0300 | INFO | [188,   300] loss: 1.489
2025-02-27T13:30:24.344639+0300 | INFO | [188,   400] loss: 1.499
2025-02-27T13:30:36.926097+0300 | INFO | [188,   500] loss: 1.487
2025-02-27T13:30:52.879348+0300 | INFO | [188,   600] loss: 1.493
2025-02-27T13:31:11.134495+0300 | INFO | [188,   700] loss: 1.491
2025-02-27T13:31:25.072875+0300 | INFO | [188,   800] loss: 1.483
2025-02-27T13:31:38.467034+0300 | INFO | [188,   900] loss: 1.482
2025-02-27T13:31:51.549673+0300 | INFO | [188,  1000] loss: 1.487
2025-02-27T13:32:04.473886+0300 | INFO | [188,  1100] loss: 1.486
2025-02-27T13:32:19.046632+0300 | INFO | [188,  1200] loss: 1.481
2025-02-27T13:32:33.780712+0300 | INFO | [188,  1300] loss: 1.495
2025-02-27T13:32:47.721818+0300 | INFO | [188,  1400] loss: 1.495
2025-02-27T13:33:01.929274+0300 | INFO | [188,  1500] loss: 1.495
2025-02-27T13:33:14.920089+0300 | INFO | [188,  1600] loss: 1.485
2025-02-27T13:33:28.751145+0300 | INFO | [188,  1700] loss: 1.490
2025-02-27T13:33:42.144902+0300 | INFO | [188,  1800] loss: 1.491
2025-02-27T13:33:57.641580+0300 | INFO | [188,  1900] loss: 1.496
2025-02-27T13:34:10.260744+0300 | INFO | [188,  2000] loss: 1.489
2025-02-27T13:34:22.665988+0300 | INFO | [188,  2100] loss: 1.495
2025-02-27T13:34:34.144424+0300 | INFO | [188,  2200] loss: 1.483
2025-02-27T13:34:45.566470+0300 | INFO | [188,  2300] loss: 1.483
2025-02-27T13:34:57.028164+0300 | INFO | [188,  2400] loss: 1.492
2025-02-27T13:35:08.127970+0300 | INFO | [188,  2500] loss: 1.500
2025-02-27T13:35:18.813679+0300 | INFO | [188,  2600] loss: 1.492
2025-02-27T13:35:34.997987+0300 | INFO | [188,  2700] loss: 1.486
2025-02-27T13:35:47.348374+0300 | INFO | [188,  2800] loss: 1.487
2025-02-27T13:36:02.661720+0300 | INFO | [188,  2900] loss: 1.495
2025-02-27T13:36:14.805706+0300 | INFO | [188,  3000] loss: 1.499
2025-02-27T13:36:27.541670+0300 | INFO | [188,  3100] loss: 1.482
2025-02-27T13:36:39.892752+0300 | INFO | [188,  3200] loss: 1.498
2025-02-27T13:36:51.798146+0300 | INFO | [188,  3300] loss: 1.492
2025-02-27T13:37:03.936913+0300 | INFO | [188,  3400] loss: 1.490
2025-02-27T13:37:16.429103+0300 | INFO | [188,  3500] loss: 1.491
2025-02-27T13:37:28.993522+0300 | INFO | [188,  3600] loss: 1.491
2025-02-27T13:37:42.253245+0300 | INFO | [188,  3700] loss: 1.488
2025-02-27T13:37:55.370394+0300 | INFO | [188,  3800] loss: 1.491
2025-02-27T13:38:08.550044+0300 | INFO | [188,  3900] loss: 1.478
2025-02-27T13:38:24.447692+0300 | INFO | [188,  4000] loss: 1.487
2025-02-27T13:38:39.776298+0300 | INFO | [188,  4100] loss: 1.487
2025-02-27T13:38:52.064638+0300 | INFO | [188,  4200] loss: 1.490
2025-02-27T13:39:04.237914+0300 | INFO | [188,  4300] loss: 1.500
2025-02-27T13:39:17.503517+0300 | INFO | [188,  4400] loss: 1.492
2025-02-27T13:39:31.483844+0300 | INFO | [188,  4500] loss: 1.486
2025-02-27T13:39:45.004989+0300 | INFO | [188,  4600] loss: 1.488
2025-02-27T13:39:57.461204+0300 | INFO | [188,  4700] loss: 1.483
2025-02-27T13:40:10.239906+0300 | INFO | [188,  4800] loss: 1.487
2025-02-27T13:40:23.350845+0300 | INFO | [188,  4900] loss: 1.494
2025-02-27T13:40:36.635097+0300 | DEBUG | Saving model to flat file storage. Save #188
2025-02-27T13:40:36.676161+0300 | INFO | Averaging client parameters
2025-02-27T13:40:36.686678+0300 | INFO | Updating parameters on client #0
2025-02-27T13:40:55.307159+0300 | DEBUG | Test set: Accuracy: 7928/10000 (79%)
2025-02-27T13:40:55.308158+0300 | DEBUG | Test set: Loss: 1.6666669845581055
2025-02-27T13:40:55.608019+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.83      0.83      1000
           1       0.90      0.93      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.70      0.53      0.60      1200
           4       0.78      0.80      0.79      1000
           5       0.52      0.65      0.58       800
           6       0.83      0.87      0.85      1000
           7       0.84      0.84      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T13:40:55.612132+0300 | DEBUG | Confusion Matrix:
[[828  15  39   7  12  12   6  11  40  30]
 [  5 925   2   0   1   2   6   2  14  43]
 [ 50   4 713  36  68  48  50  21   6   4]
 [ 18   4  59 637  61 300  51  36  19  15]
 [ 12   6  33  34 804  41  29  34   5   2]
 [ 16   2  40 132  27 517  15  40   6   5]
 [  5   3  35  31  16  23 874   8   4   1]
 [ 16   4  15  23  40  46   3 841   1  11]
 [ 33  18   9   3   3   2   5   2 908  17]
 [ 19  46   9   3   1   4  12  10  15 881]]
2025-02-27T13:40:55.613643+0300 | DEBUG | Class precision: [0.82634731 0.9006816  0.74737945 0.70309051 0.77831559 0.51959799
 0.83158896 0.83681592 0.89194499 0.87314172]
2025-02-27T13:40:55.615655+0300 | DEBUG | Class recall: [0.828      0.925      0.713      0.53083333 0.804      0.64625
 0.874      0.841      0.908      0.881     ]
2025-02-27T13:40:55.786612+0300 | INFO | Training epoch #189 on client #0
2025-02-27T13:40:55.787611+0300 | DEBUG | Saving model to flat file storage. Save #189
2025-02-27T13:40:56.119880+0300 | INFO | [189,     0] loss: 0.015
2025-02-27T13:41:08.404856+0300 | INFO | [189,   100] loss: 1.480
2025-02-27T13:41:20.359346+0300 | INFO | [189,   200] loss: 1.483
2025-02-27T13:41:32.839092+0300 | INFO | [189,   300] loss: 1.483
2025-02-27T13:41:45.997433+0300 | INFO | [189,   400] loss: 1.491
2025-02-27T13:41:58.884128+0300 | INFO | [189,   500] loss: 1.485
2025-02-27T13:42:11.660699+0300 | INFO | [189,   600] loss: 1.487
2025-02-27T13:42:24.905836+0300 | INFO | [189,   700] loss: 1.491
2025-02-27T13:42:37.859320+0300 | INFO | [189,   800] loss: 1.499
2025-02-27T13:42:51.526720+0300 | INFO | [189,   900] loss: 1.490
2025-02-27T13:43:03.145891+0300 | INFO | [189,  1000] loss: 1.495
2025-02-27T13:43:15.605702+0300 | INFO | [189,  1100] loss: 1.487
2025-02-27T13:43:28.731874+0300 | INFO | [189,  1200] loss: 1.486
2025-02-27T13:43:41.018775+0300 | INFO | [189,  1300] loss: 1.492
2025-02-27T13:43:53.367929+0300 | INFO | [189,  1400] loss: 1.489
2025-02-27T13:44:06.481171+0300 | INFO | [189,  1500] loss: 1.488
2025-02-27T13:44:21.575233+0300 | INFO | [189,  1600] loss: 1.496
2025-02-27T13:44:37.578496+0300 | INFO | [189,  1700] loss: 1.486
2025-02-27T13:44:54.292733+0300 | INFO | [189,  1800] loss: 1.487
2025-02-27T13:45:09.233215+0300 | INFO | [189,  1900] loss: 1.492
2025-02-27T13:45:28.849543+0300 | INFO | [189,  2000] loss: 1.492
2025-02-27T13:45:48.043244+0300 | INFO | [189,  2100] loss: 1.497
2025-02-27T13:46:10.120997+0300 | INFO | [189,  2200] loss: 1.487
2025-02-27T13:46:29.820186+0300 | INFO | [189,  2300] loss: 1.477
2025-02-27T13:46:48.856819+0300 | INFO | [189,  2400] loss: 1.492
2025-02-27T13:47:09.170193+0300 | INFO | [189,  2500] loss: 1.492
2025-02-27T13:47:27.691527+0300 | INFO | [189,  2600] loss: 1.495
2025-02-27T13:47:44.520206+0300 | INFO | [189,  2700] loss: 1.495
2025-02-27T13:48:01.455904+0300 | INFO | [189,  2800] loss: 1.493
2025-02-27T13:48:16.815791+0300 | INFO | [189,  2900] loss: 1.495
2025-02-27T13:48:32.605239+0300 | INFO | [189,  3000] loss: 1.492
2025-02-27T13:48:47.760857+0300 | INFO | [189,  3100] loss: 1.488
2025-02-27T13:49:01.988104+0300 | INFO | [189,  3200] loss: 1.493
2025-02-27T13:49:16.227916+0300 | INFO | [189,  3300] loss: 1.489
2025-02-27T13:49:31.775687+0300 | INFO | [189,  3400] loss: 1.480
2025-02-27T13:49:46.844080+0300 | INFO | [189,  3500] loss: 1.487
2025-02-27T13:50:02.788758+0300 | INFO | [189,  3600] loss: 1.495
2025-02-27T13:50:19.078371+0300 | INFO | [189,  3700] loss: 1.489
2025-02-27T13:50:33.743675+0300 | INFO | [189,  3800] loss: 1.488
2025-02-27T13:50:48.881014+0300 | INFO | [189,  3900] loss: 1.485
2025-02-27T13:51:05.662544+0300 | INFO | [189,  4000] loss: 1.493
2025-02-27T13:51:21.497355+0300 | INFO | [189,  4100] loss: 1.496
2025-02-27T13:51:38.614620+0300 | INFO | [189,  4200] loss: 1.490
2025-02-27T13:51:56.152714+0300 | INFO | [189,  4300] loss: 1.483
2025-02-27T13:52:12.540207+0300 | INFO | [189,  4400] loss: 1.493
2025-02-27T13:52:29.037955+0300 | INFO | [189,  4500] loss: 1.486
2025-02-27T13:52:45.600378+0300 | INFO | [189,  4600] loss: 1.481
2025-02-27T13:53:00.267768+0300 | INFO | [189,  4700] loss: 1.491
2025-02-27T13:53:14.319315+0300 | INFO | [189,  4800] loss: 1.505
2025-02-27T13:53:29.318480+0300 | INFO | [189,  4900] loss: 1.487
2025-02-27T13:53:45.576107+0300 | DEBUG | Saving model to flat file storage. Save #189
2025-02-27T13:53:45.620825+0300 | INFO | Averaging client parameters
2025-02-27T13:53:45.639900+0300 | INFO | Updating parameters on client #0
2025-02-27T13:54:13.955719+0300 | DEBUG | Test set: Accuracy: 7956/10000 (80%)
2025-02-27T13:54:13.957729+0300 | DEBUG | Test set: Loss: 1.6643420457839966
2025-02-27T13:54:14.123603+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.79      0.85      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.76      0.70      0.73      1000
           3       0.69      0.57      0.63      1200
           4       0.76      0.82      0.79      1000
           5       0.55      0.61      0.58       800
           6       0.86      0.86      0.86      1000
           7       0.84      0.84      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.88      0.89      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.79     10000

2025-02-27T13:54:14.129123+0300 | DEBUG | Confusion Matrix:
[[849  13  33   7  15   8   4   6  39  26]
 [  9 917   1   0   1   1   4   4  17  46]
 [ 70   4 704  38  77  37  42  18   6   4]
 [ 24   5  57 687  67 248  40  36  19  17]
 [ 14   6  32  34 817  33  22  35   5   2]
 [ 19   3  41 156  29 488  15  39   6   4]
 [ 11   4  32  44  19  17 857   7   6   3]
 [ 16   4  13  22  44  43   3 843   1  11]
 [ 43  16  10   4   2   2   3   2 908  10]
 [ 21  42   8   3   1   5   9   9  16 886]]
2025-02-27T13:54:14.131643+0300 | DEBUG | Class precision: [0.78903346 0.90433925 0.75617615 0.69045226 0.76212687 0.55328798
 0.85785786 0.84384384 0.88758553 0.87809713]
2025-02-27T13:54:14.133643+0300 | DEBUG | Class recall: [0.849  0.917  0.704  0.5725 0.817  0.61   0.857  0.843  0.908  0.886 ]
2025-02-27T13:54:14.138167+0300 | INFO | Training epoch #190 on client #0
2025-02-27T13:54:14.138167+0300 | DEBUG | Saving model to flat file storage. Save #190
2025-02-27T13:54:14.366218+0300 | INFO | [190,     0] loss: 0.015
2025-02-27T13:54:31.158579+0300 | INFO | [190,   100] loss: 1.489
2025-02-27T13:54:47.314598+0300 | INFO | [190,   200] loss: 1.486
2025-02-27T13:55:01.978422+0300 | INFO | [190,   300] loss: 1.493
2025-02-27T13:55:17.414040+0300 | INFO | [190,   400] loss: 1.486
2025-02-27T13:55:34.077188+0300 | INFO | [190,   500] loss: 1.497
2025-02-27T13:55:51.108648+0300 | INFO | [190,   600] loss: 1.482
2025-02-27T13:56:07.301166+0300 | INFO | [190,   700] loss: 1.484
2025-02-27T13:56:26.625481+0300 | INFO | [190,   800] loss: 1.492
2025-02-27T13:56:41.706416+0300 | INFO | [190,   900] loss: 1.490
2025-02-27T13:56:57.151970+0300 | INFO | [190,  1000] loss: 1.489
2025-02-27T13:57:12.570455+0300 | INFO | [190,  1100] loss: 1.491
2025-02-27T13:57:29.177366+0300 | INFO | [190,  1200] loss: 1.497
2025-02-27T13:57:46.264366+0300 | INFO | [190,  1300] loss: 1.486
2025-02-27T13:58:02.435796+0300 | INFO | [190,  1400] loss: 1.491
2025-02-27T13:58:17.517556+0300 | INFO | [190,  1500] loss: 1.485
2025-02-27T13:58:32.604009+0300 | INFO | [190,  1600] loss: 1.491
2025-02-27T13:58:49.291012+0300 | INFO | [190,  1700] loss: 1.491
2025-02-27T13:59:04.089101+0300 | INFO | [190,  1800] loss: 1.487
2025-02-27T13:59:18.527586+0300 | INFO | [190,  1900] loss: 1.498
2025-02-27T13:59:34.179706+0300 | INFO | [190,  2000] loss: 1.492
2025-02-27T13:59:50.384821+0300 | INFO | [190,  2100] loss: 1.489
2025-02-27T14:00:06.630252+0300 | INFO | [190,  2200] loss: 1.483
2025-02-27T14:00:23.399002+0300 | INFO | [190,  2300] loss: 1.491
2025-02-27T14:00:39.063343+0300 | INFO | [190,  2400] loss: 1.487
2025-02-27T14:00:53.981110+0300 | INFO | [190,  2500] loss: 1.483
2025-02-27T14:01:10.043810+0300 | INFO | [190,  2600] loss: 1.492
2025-02-27T14:01:26.661303+0300 | INFO | [190,  2700] loss: 1.490
2025-02-27T14:01:43.355849+0300 | INFO | [190,  2800] loss: 1.499
2025-02-27T14:01:59.152237+0300 | INFO | [190,  2900] loss: 1.486
2025-02-27T14:02:15.504684+0300 | INFO | [190,  3000] loss: 1.482
2025-02-27T14:02:31.719476+0300 | INFO | [190,  3100] loss: 1.488
2025-02-27T14:02:46.623813+0300 | INFO | [190,  3200] loss: 1.492
2025-02-27T14:03:00.192762+0300 | INFO | [190,  3300] loss: 1.494
2025-02-27T14:03:14.112586+0300 | INFO | [190,  3400] loss: 1.485
2025-02-27T14:03:27.433655+0300 | INFO | [190,  3500] loss: 1.489
2025-02-27T14:03:41.546304+0300 | INFO | [190,  3600] loss: 1.498
2025-02-27T14:03:55.241897+0300 | INFO | [190,  3700] loss: 1.490
2025-02-27T14:04:09.149952+0300 | INFO | [190,  3800] loss: 1.487
2025-02-27T14:04:22.561196+0300 | INFO | [190,  3900] loss: 1.495
2025-02-27T14:04:38.071344+0300 | INFO | [190,  4000] loss: 1.484
2025-02-27T14:04:51.694072+0300 | INFO | [190,  4100] loss: 1.494
2025-02-27T14:05:04.876713+0300 | INFO | [190,  4200] loss: 1.488
2025-02-27T14:05:18.949102+0300 | INFO | [190,  4300] loss: 1.483
2025-02-27T14:05:33.144206+0300 | INFO | [190,  4400] loss: 1.492
2025-02-27T14:05:47.216165+0300 | INFO | [190,  4500] loss: 1.500
2025-02-27T14:06:02.568414+0300 | INFO | [190,  4600] loss: 1.483
2025-02-27T14:06:17.237677+0300 | INFO | [190,  4700] loss: 1.494
2025-02-27T14:06:31.668286+0300 | INFO | [190,  4800] loss: 1.480
2025-02-27T14:06:46.144300+0300 | INFO | [190,  4900] loss: 1.500
2025-02-27T14:07:00.624954+0300 | DEBUG | Saving model to flat file storage. Save #190
2025-02-27T14:07:00.654032+0300 | INFO | Averaging client parameters
2025-02-27T14:07:00.659548+0300 | INFO | Updating parameters on client #0
2025-02-27T14:07:21.674378+0300 | DEBUG | Test set: Accuracy: 7929/10000 (79%)
2025-02-27T14:07:21.675887+0300 | DEBUG | Test set: Loss: 1.6674761772155762
2025-02-27T14:07:21.879221+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.68      0.58      0.62      1200
           4       0.76      0.81      0.78      1000
           5       0.53      0.61      0.57       800
           6       0.85      0.86      0.86      1000
           7       0.87      0.81      0.84      1000
           8       0.90      0.91      0.90      1000
           9       0.86      0.90      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T14:07:21.886741+0300 | DEBUG | Confusion Matrix:
[[838  16  35   9  15  10   5   9  34  29]
 [  6 921   3   0   1   2   3   3  14  47]
 [ 59   5 712  39  76  44  40  11   6   8]
 [ 19   8  64 691  60 255  39  26  16  22]
 [ 17   6  34  37 808  38  29  23   4   4]
 [ 17   4  39 158  31 487  18  36   7   3]
 [ 10   4  34  46  15  20 859   5   5   2]
 [ 17   4  16  24  52  56   5 812   1  13]
 [ 33  18  10   6   3   3   4   2 905  16]
 [ 22  38   8   3   1   6   7   6  13 896]]
2025-02-27T14:07:21.887740+0300 | DEBUG | Class precision: [0.80732177 0.89941406 0.74554974 0.68213228 0.76082863 0.52877307
 0.85133796 0.87031083 0.90049751 0.86153846]
2025-02-27T14:07:21.892740+0300 | DEBUG | Class recall: [0.838      0.921      0.712      0.57583333 0.808      0.60875
 0.859      0.812      0.905      0.896     ]
2025-02-27T14:07:21.962407+0300 | INFO | Training epoch #191 on client #0
2025-02-27T14:07:21.964454+0300 | DEBUG | Saving model to flat file storage. Save #191
2025-02-27T14:07:22.279179+0300 | INFO | [191,     0] loss: 0.016
2025-02-27T14:07:37.194908+0300 | INFO | [191,   100] loss: 1.487
2025-02-27T14:07:51.964095+0300 | INFO | [191,   200] loss: 1.489
2025-02-27T14:08:07.303204+0300 | INFO | [191,   300] loss: 1.487
2025-02-27T14:08:20.448516+0300 | INFO | [191,   400] loss: 1.489
2025-02-27T14:08:38.251244+0300 | INFO | [191,   500] loss: 1.483
2025-02-27T14:08:58.077187+0300 | INFO | [191,   600] loss: 1.495
2025-02-27T14:09:16.887427+0300 | INFO | [191,   700] loss: 1.482
2025-02-27T14:09:36.652919+0300 | INFO | [191,   800] loss: 1.487
2025-02-27T14:09:55.801267+0300 | INFO | [191,   900] loss: 1.492
2025-02-27T14:10:13.381054+0300 | INFO | [191,  1000] loss: 1.488
2025-02-27T14:10:31.455116+0300 | INFO | [191,  1100] loss: 1.483
2025-02-27T14:10:45.947747+0300 | INFO | [191,  1200] loss: 1.490
2025-02-27T14:11:01.138046+0300 | INFO | [191,  1300] loss: 1.491
2025-02-27T14:11:13.818953+0300 | INFO | [191,  1400] loss: 1.497
2025-02-27T14:11:27.818837+0300 | INFO | [191,  1500] loss: 1.494
2025-02-27T14:11:45.251901+0300 | INFO | [191,  1600] loss: 1.491
2025-02-27T14:11:59.165235+0300 | INFO | [191,  1700] loss: 1.488
2025-02-27T14:12:12.803969+0300 | INFO | [191,  1800] loss: 1.493
2025-02-27T14:12:26.438285+0300 | INFO | [191,  1900] loss: 1.493
2025-02-27T14:12:39.604067+0300 | INFO | [191,  2000] loss: 1.483
2025-02-27T14:12:53.272658+0300 | INFO | [191,  2100] loss: 1.496
2025-02-27T14:13:07.132568+0300 | INFO | [191,  2200] loss: 1.493
2025-02-27T14:13:20.275023+0300 | INFO | [191,  2300] loss: 1.495
2025-02-27T14:13:33.884342+0300 | INFO | [191,  2400] loss: 1.489
2025-02-27T14:13:48.373193+0300 | INFO | [191,  2500] loss: 1.497
2025-02-27T14:14:03.610529+0300 | INFO | [191,  2600] loss: 1.490
2025-02-27T14:14:19.150885+0300 | INFO | [191,  2700] loss: 1.499
2025-02-27T14:14:35.038125+0300 | INFO | [191,  2800] loss: 1.484
2025-02-27T14:14:50.107648+0300 | INFO | [191,  2900] loss: 1.481
2025-02-27T14:15:05.083274+0300 | INFO | [191,  3000] loss: 1.490
2025-02-27T14:15:22.229345+0300 | INFO | [191,  3100] loss: 1.491
2025-02-27T14:15:38.578762+0300 | INFO | [191,  3200] loss: 1.488
2025-02-27T14:15:55.767073+0300 | INFO | [191,  3300] loss: 1.489
2025-02-27T14:16:12.468283+0300 | INFO | [191,  3400] loss: 1.492
2025-02-27T14:16:28.915680+0300 | INFO | [191,  3500] loss: 1.489
2025-02-27T14:16:44.231571+0300 | INFO | [191,  3600] loss: 1.507
2025-02-27T14:16:58.723963+0300 | INFO | [191,  3700] loss: 1.488
2025-02-27T14:17:15.325985+0300 | INFO | [191,  3800] loss: 1.488
2025-02-27T14:17:31.381947+0300 | INFO | [191,  3900] loss: 1.494
2025-02-27T14:17:47.216633+0300 | INFO | [191,  4000] loss: 1.486
2025-02-27T14:18:03.035236+0300 | INFO | [191,  4100] loss: 1.493
2025-02-27T14:18:22.979367+0300 | INFO | [191,  4200] loss: 1.479
2025-02-27T14:18:39.475557+0300 | INFO | [191,  4300] loss: 1.487
2025-02-27T14:18:54.967338+0300 | INFO | [191,  4400] loss: 1.490
2025-02-27T14:19:11.975114+0300 | INFO | [191,  4500] loss: 1.493
2025-02-27T14:19:27.292843+0300 | INFO | [191,  4600] loss: 1.486
2025-02-27T14:19:45.437925+0300 | INFO | [191,  4700] loss: 1.490
2025-02-27T14:20:03.126327+0300 | INFO | [191,  4800] loss: 1.485
2025-02-27T14:20:20.157012+0300 | INFO | [191,  4900] loss: 1.484
2025-02-27T14:20:35.742362+0300 | DEBUG | Saving model to flat file storage. Save #191
2025-02-27T14:20:35.787821+0300 | INFO | Averaging client parameters
2025-02-27T14:20:35.803824+0300 | INFO | Updating parameters on client #0
2025-02-27T14:21:02.301035+0300 | DEBUG | Test set: Accuracy: 7912/10000 (79%)
2025-02-27T14:21:02.303033+0300 | DEBUG | Test set: Loss: 1.6687755584716797
2025-02-27T14:21:02.477563+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.83      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.71      0.73      1000
           3       0.69      0.56      0.62      1200
           4       0.78      0.80      0.79      1000
           5       0.51      0.65      0.57       800
           6       0.85      0.85      0.85      1000
           7       0.87      0.81      0.84      1000
           8       0.87      0.92      0.89      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T14:21:02.484563+0300 | DEBUG | Confusion Matrix:
[[833  17  35   7  15  10   5   7  46  25]
 [  7 917   3   1   1   2   3   3  21  42]
 [ 61   5 710  36  67  51  40  14   9   7]
 [ 24   6  53 676  55 285  42  25  19  15]
 [ 12   4  35  44 797  46  30  24   5   3]
 [ 16   3  34 142  29 518  12  35   8   3]
 [  9   5  39  45  11  27 849   6   7   2]
 [ 15   5  15  24  50  59   6 812   2  12]
 [ 31  13   9   5   2   4   3   2 921  10]
 [ 25  42  11   3   1   5   8   5  21 879]]
2025-02-27T14:21:02.510071+0300 | DEBUG | Class precision: [0.80638916 0.90167158 0.75211864 0.68769074 0.77529183 0.51439921
 0.8507014  0.87031083 0.86968839 0.88076152]
2025-02-27T14:21:02.516072+0300 | DEBUG | Class recall: [0.833      0.917      0.71       0.56333333 0.797      0.6475
 0.849      0.812      0.921      0.879     ]
2025-02-27T14:21:02.520074+0300 | INFO | Training epoch #192 on client #0
2025-02-27T14:21:02.521073+0300 | DEBUG | Saving model to flat file storage. Save #192
2025-02-27T14:21:02.776854+0300 | INFO | [192,     0] loss: 0.016
2025-02-27T14:21:19.320789+0300 | INFO | [192,   100] loss: 1.501
2025-02-27T14:21:36.441541+0300 | INFO | [192,   200] loss: 1.484
2025-02-27T14:21:53.652059+0300 | INFO | [192,   300] loss: 1.490
2025-02-27T14:22:11.743119+0300 | INFO | [192,   400] loss: 1.489
2025-02-27T14:22:29.360242+0300 | INFO | [192,   500] loss: 1.493
2025-02-27T14:22:47.228875+0300 | INFO | [192,   600] loss: 1.492
2025-02-27T14:23:06.118185+0300 | INFO | [192,   700] loss: 1.485
2025-02-27T14:23:22.815399+0300 | INFO | [192,   800] loss: 1.481
2025-02-27T14:23:37.693978+0300 | INFO | [192,   900] loss: 1.491
2025-02-27T14:23:55.612999+0300 | INFO | [192,  1000] loss: 1.493
2025-02-27T14:24:13.364622+0300 | INFO | [192,  1100] loss: 1.489
2025-02-27T14:24:29.148248+0300 | INFO | [192,  1200] loss: 1.491
2025-02-27T14:24:45.975983+0300 | INFO | [192,  1300] loss: 1.494
2025-02-27T14:25:03.337650+0300 | INFO | [192,  1400] loss: 1.489
2025-02-27T14:25:18.626505+0300 | INFO | [192,  1500] loss: 1.496
2025-02-27T14:25:34.630013+0300 | INFO | [192,  1600] loss: 1.497
2025-02-27T14:25:50.227925+0300 | INFO | [192,  1700] loss: 1.493
2025-02-27T14:26:05.503572+0300 | INFO | [192,  1800] loss: 1.491
2025-02-27T14:26:20.220541+0300 | INFO | [192,  1900] loss: 1.494
2025-02-27T14:26:35.330488+0300 | INFO | [192,  2000] loss: 1.488
2025-02-27T14:26:49.935125+0300 | INFO | [192,  2100] loss: 1.493
2025-02-27T14:27:03.460192+0300 | INFO | [192,  2200] loss: 1.487
2025-02-27T14:27:17.861198+0300 | INFO | [192,  2300] loss: 1.493
2025-02-27T14:27:34.847133+0300 | INFO | [192,  2400] loss: 1.485
2025-02-27T14:27:50.754744+0300 | INFO | [192,  2500] loss: 1.493
2025-02-27T14:28:06.267529+0300 | INFO | [192,  2600] loss: 1.485
2025-02-27T14:28:23.765712+0300 | INFO | [192,  2700] loss: 1.487
2025-02-27T14:28:40.522207+0300 | INFO | [192,  2800] loss: 1.488
2025-02-27T14:28:55.705317+0300 | INFO | [192,  2900] loss: 1.488
2025-02-27T14:29:10.870956+0300 | INFO | [192,  3000] loss: 1.502
2025-02-27T14:29:26.710874+0300 | INFO | [192,  3100] loss: 1.485
2025-02-27T14:29:42.837664+0300 | INFO | [192,  3200] loss: 1.487
2025-02-27T14:29:58.572531+0300 | INFO | [192,  3300] loss: 1.488
2025-02-27T14:30:20.731173+0300 | INFO | [192,  3400] loss: 1.494
2025-02-27T14:30:36.591544+0300 | INFO | [192,  3500] loss: 1.482
2025-02-27T14:30:54.016333+0300 | INFO | [192,  3600] loss: 1.485
2025-02-27T14:31:11.270570+0300 | INFO | [192,  3700] loss: 1.489
2025-02-27T14:31:29.432123+0300 | INFO | [192,  3800] loss: 1.495
2025-02-27T14:31:45.746789+0300 | INFO | [192,  3900] loss: 1.487
2025-02-27T14:32:01.168149+0300 | INFO | [192,  4000] loss: 1.490
2025-02-27T14:32:17.108831+0300 | INFO | [192,  4100] loss: 1.488
2025-02-27T14:32:31.187807+0300 | INFO | [192,  4200] loss: 1.492
2025-02-27T14:32:45.763200+0300 | INFO | [192,  4300] loss: 1.490
2025-02-27T14:33:03.921647+0300 | INFO | [192,  4400] loss: 1.493
2025-02-27T14:33:19.632562+0300 | INFO | [192,  4500] loss: 1.478
2025-02-27T14:33:38.286961+0300 | INFO | [192,  4600] loss: 1.489
2025-02-27T14:33:58.491047+0300 | INFO | [192,  4700] loss: 1.478
2025-02-27T14:34:18.148040+0300 | INFO | [192,  4800] loss: 1.488
2025-02-27T14:34:37.228238+0300 | INFO | [192,  4900] loss: 1.497
2025-02-27T14:34:55.172976+0300 | DEBUG | Saving model to flat file storage. Save #192
2025-02-27T14:34:55.235494+0300 | INFO | Averaging client parameters
2025-02-27T14:34:55.251494+0300 | INFO | Updating parameters on client #0
2025-02-27T14:35:22.582955+0300 | DEBUG | Test set: Accuracy: 7941/10000 (79%)
2025-02-27T14:35:22.583966+0300 | DEBUG | Test set: Loss: 1.666013240814209
2025-02-27T14:35:22.813555+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.82      0.83      0.82      1000
           1       0.90      0.92      0.91      1000
           2       0.75      0.70      0.73      1000
           3       0.68      0.59      0.63      1200
           4       0.77      0.80      0.79      1000
           5       0.54      0.60      0.57       800
           6       0.83      0.88      0.85      1000
           7       0.85      0.83      0.84      1000
           8       0.88      0.92      0.90      1000
           9       0.88      0.88      0.88      1000

    accuracy                           0.79     10000
   macro avg       0.79      0.79      0.79     10000
weighted avg       0.79      0.79      0.79     10000

2025-02-27T14:35:22.819557+0300 | DEBUG | Confusion Matrix:
[[827  16  44  11  14   9   5   8  40  26]
 [  7 919   3   1   2   2   3   4  21  38]
 [ 55   5 705  44  71  40  52  17   6   5]
 [ 15   7  51 706  54 245  50  36  18  18]
 [ 12   5  38  40 800  41  32  25   5   2]
 [ 16   2  38 166  29 479  17  43   7   3]
 [  8   4  30  37  13  15 876   7   6   4]
 [ 14   4  16  25  48  42   3 834   2  12]
 [ 30  14   9   5   1   4   4   2 918  13]
 [ 23  48   8   5   1   3  10   7  18 877]]
2025-02-27T14:35:22.827556+0300 | DEBUG | Class precision: [0.82125124 0.89746094 0.74840764 0.67884615 0.77444337 0.54431818
 0.83269962 0.84842319 0.88184438 0.87875752]
2025-02-27T14:35:22.829557+0300 | DEBUG | Class recall: [0.827      0.919      0.705      0.58833333 0.8        0.59875
 0.876      0.834      0.918      0.877     ]
2025-02-27T14:35:22.833560+0300 | INFO | Training epoch #193 on client #0
2025-02-27T14:35:22.834560+0300 | DEBUG | Saving model to flat file storage. Save #193
2025-02-27T14:35:23.158152+0300 | INFO | [193,     0] loss: 0.015
2025-02-27T14:35:39.594241+0300 | INFO | [193,   100] loss: 1.491
2025-02-27T14:35:55.998758+0300 | INFO | [193,   200] loss: 1.488
2025-02-27T14:36:13.240290+0300 | INFO | [193,   300] loss: 1.498
2025-02-27T14:36:30.478013+0300 | INFO | [193,   400] loss: 1.489
2025-02-27T14:36:48.477943+0300 | INFO | [193,   500] loss: 1.486
2025-02-27T14:37:05.799496+0300 | INFO | [193,   600] loss: 1.497
2025-02-27T14:37:20.937317+0300 | INFO | [193,   700] loss: 1.486
2025-02-27T14:37:36.068360+0300 | INFO | [193,   800] loss: 1.498
2025-02-27T14:37:53.947826+0300 | INFO | [193,   900] loss: 1.490
2025-02-27T14:38:08.558858+0300 | INFO | [193,  1000] loss: 1.492
2025-02-27T14:38:22.511778+0300 | INFO | [193,  1100] loss: 1.483
2025-02-27T14:38:36.384640+0300 | INFO | [193,  1200] loss: 1.491
2025-02-27T14:38:50.850542+0300 | INFO | [193,  1300] loss: 1.492
2025-02-27T14:39:11.693650+0300 | INFO | [193,  1400] loss: 1.484
2025-02-27T14:39:28.278442+0300 | INFO | [193,  1500] loss: 1.495
2025-02-27T14:39:42.151225+0300 | INFO | [193,  1600] loss: 1.486
2025-02-27T14:39:54.776111+0300 | INFO | [193,  1700] loss: 1.483
2025-02-27T14:40:10.857633+0300 | INFO | [193,  1800] loss: 1.482
2025-02-27T14:40:26.734577+0300 | INFO | [193,  1900] loss: 1.488
2025-02-27T14:40:41.846265+0300 | INFO | [193,  2000] loss: 1.483
2025-02-27T14:40:59.870479+0300 | INFO | [193,  2100] loss: 1.492
2025-02-27T14:41:15.371233+0300 | INFO | [193,  2200] loss: 1.488
2025-02-27T14:41:31.267119+0300 | INFO | [193,  2300] loss: 1.486
2025-02-27T14:41:47.724170+0300 | INFO | [193,  2400] loss: 1.494
2025-02-27T14:42:06.359080+0300 | INFO | [193,  2500] loss: 1.495
2025-02-27T14:42:22.115824+0300 | INFO | [193,  2600] loss: 1.492
2025-02-27T14:42:37.355819+0300 | INFO | [193,  2700] loss: 1.490
2025-02-27T14:42:52.123256+0300 | INFO | [193,  2800] loss: 1.485
2025-02-27T14:43:06.307898+0300 | INFO | [193,  2900] loss: 1.494
2025-02-27T14:43:21.599445+0300 | INFO | [193,  3000] loss: 1.485
2025-02-27T14:43:36.916569+0300 | INFO | [193,  3100] loss: 1.486
2025-02-27T14:43:52.337422+0300 | INFO | [193,  3200] loss: 1.495
2025-02-27T14:44:07.834782+0300 | INFO | [193,  3300] loss: 1.485
2025-02-27T14:44:23.065534+0300 | INFO | [193,  3400] loss: 1.485
2025-02-27T14:44:38.380149+0300 | INFO | [193,  3500] loss: 1.489
2025-02-27T14:44:54.797471+0300 | INFO | [193,  3600] loss: 1.497
2025-02-27T14:45:08.547564+0300 | INFO | [193,  3700] loss: 1.487
2025-02-27T14:45:23.768839+0300 | INFO | [193,  3800] loss: 1.488
2025-02-27T14:45:38.941435+0300 | INFO | [193,  3900] loss: 1.487
2025-02-27T14:45:57.225909+0300 | INFO | [193,  4000] loss: 1.493
2025-02-27T14:46:14.964792+0300 | INFO | [193,  4100] loss: 1.493
2025-02-27T14:46:32.421861+0300 | INFO | [193,  4200] loss: 1.489
2025-02-27T14:46:46.840224+0300 | INFO | [193,  4300] loss: 1.479
2025-02-27T14:47:00.242786+0300 | INFO | [193,  4400] loss: 1.503
2025-02-27T14:47:14.433191+0300 | INFO | [193,  4500] loss: 1.490
2025-02-27T14:47:27.541314+0300 | INFO | [193,  4600] loss: 1.483
2025-02-27T14:47:41.209105+0300 | INFO | [193,  4700] loss: 1.495
2025-02-27T14:47:56.769918+0300 | INFO | [193,  4800] loss: 1.495
2025-02-27T14:48:11.915835+0300 | INFO | [193,  4900] loss: 1.489
2025-02-27T14:48:26.284659+0300 | DEBUG | Saving model to flat file storage. Save #193
2025-02-27T14:48:26.343285+0300 | INFO | Averaging client parameters
2025-02-27T14:48:26.358339+0300 | INFO | Updating parameters on client #0
2025-02-27T14:48:50.120062+0300 | DEBUG | Test set: Accuracy: 7970/10000 (80%)
2025-02-27T14:48:50.122061+0300 | DEBUG | Test set: Loss: 1.6636770963668823
2025-02-27T14:48:50.242368+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83      1000
           1       0.91      0.92      0.92      1000
           2       0.76      0.72      0.74      1000
           3       0.68      0.58      0.63      1200
           4       0.79      0.79      0.79      1000
           5       0.54      0.61      0.57       800
           6       0.83      0.88      0.85      1000
           7       0.85      0.84      0.84      1000
           8       0.89      0.91      0.90      1000
           9       0.87      0.89      0.88      1000

    accuracy                           0.80     10000
   macro avg       0.79      0.80      0.79     10000
weighted avg       0.80      0.80      0.80     10000

2025-02-27T14:48:50.246874+0300 | DEBUG | Confusion Matrix:
[[838  14  32  10  10  13   7   8  39  29]
 [  6 923   3   0   1   1   4   4  16  42]
 [ 59   5 719  38  57  42  48  19   6   7]
 [ 18   7  56 695  53 253  47  35  17  19]
 [ 13   4  36  42 794  39  35  28   5   4]
 [ 17   3  40 162  28 485  14  42   5   4]
 [  7   2  33  39  12  17 877   6   5   2]
 [ 16   4  16  25  41  45   5 836   2  10]
 [ 32  13   9   6   3   1   5   2 914  15]
 [ 24  41   8   4   1   3  10   6  14 889]]
2025-02-27T14:48:50.248882+0300 | DEBUG | Class precision: [0.81359223 0.90846457 0.7552521  0.68070519 0.794      0.53948832
 0.83365019 0.84787018 0.89345064 0.87071499]
2025-02-27T14:48:50.250889+0300 | DEBUG | Class recall: [0.838      0.923      0.719      0.57916667 0.794      0.60625
 0.877      0.836      0.914      0.889     ]
2025-02-27T14:48:50.314008+0300 | INFO | Training epoch #194 on client #0
2025-02-27T14:48:50.317525+0300 | DEBUG | Saving model to flat file storage. Save #194
2025-02-27T14:48:50.592502+0300 | INFO | [194,     0] loss: 0.016
2025-02-27T14:49:04.682565+0300 | INFO | [194,   100] loss: 1.491
2025-02-27T14:49:18.369915+0300 | INFO | [194,   200] loss: 1.482
2025-02-27T14:49:31.475275+0300 | INFO | [194,   300] loss: 1.476
2025-02-27T14:49:44.536659+0300 | INFO | [194,   400] loss: 1.486
2025-02-27T14:49:58.030960+0300 | INFO | [194,   500] loss: 1.491
2025-02-27T14:50:12.456644+0300 | INFO | [194,   600] loss: 1.486
2025-02-27T14:50:26.810024+0300 | INFO | [194,   700] loss: 1.495
2025-02-27T14:50:41.103299+0300 | INFO | [194,   800] loss: 1.473
2025-02-27T14:50:54.050585+0300 | INFO | [194,   900] loss: 1.501
2025-02-27T14:51:07.585837+0300 | INFO | [194,  1000] loss: 1.494
2025-02-27T14:51:20.924703+0300 | INFO | [194,  1100] loss: 1.485
2025-02-27T14:51:35.870363+0300 | INFO | [194,  1200] loss: 1.484
2025-02-27T14:51:48.951178+0300 | INFO | [194,  1300] loss: 1.495
2025-02-27T14:52:02.568247+0300 | INFO | [194,  1400] loss: 1.488
2025-02-27T14:52:16.374332+0300 | INFO | [194,  1500] loss: 1.483
2025-02-27T14:52:31.117684+0300 | INFO | [194,  1600] loss: 1.494
2025-02-27T14:52:45.031821+0300 | INFO | [194,  1700] loss: 1.489
2025-02-27T14:52:57.731594+0300 | INFO | [194,  1800] loss: 1.482
2025-02-27T14:53:10.784948+0300 | INFO | [194,  1900] loss: 1.490
2025-02-27T14:53:24.277744+0300 | INFO | [194,  2000] loss: 1.491
2025-02-27T14:53:39.343460+0300 | INFO | [194,  2100] loss: 1.500
2025-02-27T14:53:54.620455+0300 | INFO | [194,  2200] loss: 1.482
2025-02-27T14:54:07.274300+0300 | INFO | [194,  2300] loss: 1.487
2025-02-27T14:54:20.158968+0300 | INFO | [194,  2400] loss: 1.493
2025-02-27T14:54:34.740599+0300 | INFO | [194,  2500] loss: 1.482
2025-02-27T14:54:48.116371+0300 | INFO | [194,  2600] loss: 1.498
2025-02-27T14:55:01.215338+0300 | INFO | [194,  2700] loss: 1.496
2025-02-27T14:55:14.616228+0300 | INFO | [194,  2800] loss: 1.489
2025-02-27T14:55:26.997408+0300 | INFO | [194,  2900] loss: 1.499
2025-02-27T14:55:39.312409+0300 | INFO | [194,  3000] loss: 1.483
2025-02-27T14:55:52.532652+0300 | INFO | [194,  3100] loss: 1.488
2025-02-27T14:56:05.684532+0300 | INFO | [194,  3200] loss: 1.492
2025-02-27T14:56:16.716187+0300 | INFO | [194,  3300] loss: 1.493
2025-02-27T14:56:32.464007+0300 | INFO | [194,  3400] loss: 1.496
2025-02-27T14:56:49.425722+0300 | INFO | [194,  3500] loss: 1.493
2025-02-27T14:57:05.749541+0300 | INFO | [194,  3600] loss: 1.500
2025-02-27T14:57:23.922976+0300 | INFO | [194,  3700] loss: 1.492
2025-02-27T14:57:41.091049+0300 | INFO | [194,  3800] loss: 1.493
2025-02-27T14:57:58.789354+0300 | INFO | [194,  3900] loss: 1.487
2025-02-27T14:58:15.522128+0300 | INFO | [194,  4000] loss: 1.491
2025-02-27T14:58:28.807677+0300 | INFO | [194,  4100] loss: 1.481
2025-02-27T14:58:42.053825+0300 | INFO | [194,  4200] loss: 1.493
2025-02-27T14:58:54.821886+0300 | INFO | [194,  4300] loss: 1.487
2025-02-27T14:59:08.225651+0300 | INFO | [194,  4400] loss: 1.481
2025-02-27T14:59:20.948649+0300 | INFO | [194,  4500] loss: 1.491
2025-02-27T14:59:34.213147+0300 | INFO | [194,  4600] loss: 1.486
2025-02-27T14:59:47.865944+0300 | INFO | [194,  4700] loss: 1.481
2025-02-27T15:00:01.356048+0300 | INFO | [194,  4800] loss: 1.504
2025-02-27T15:00:17.302368+0300 | INFO | [194,  4900] loss: 1.493
2025-02-27T15:00:31.182604+0300 | DEBUG | Saving model to flat file storage. Save #194
2025-02-27T15:00:31.228123+0300 | INFO | Averaging client parameters
2025-02-27T15:00:31.241129+0300 | INFO | Updating parameters on client #0
2025-03-07T11:50:23.814588+0300 | DEBUG | Loading Fashion MNIST train data
2025-03-07T11:50:53.820069+0300 | WARNING | ⚠️ Flipped 1200 samples from Class 5 → Class 3
2025-03-07T11:51:33.413678+0300 | DEBUG | Finished loading Fashion MNIST train data
2025-03-07T11:51:33.422677+0300 | DEBUG | Loading Fashion MNIST test data
2025-03-07T11:51:33.458287+0300 | WARNING | ⚠️ Flipped 200 samples from Class 5 → Class 3
2025-03-07T11:51:38.185207+0300 | DEBUG | Finished loading Fashion MNIST test data
2025-03-07T11:52:25.972880+0300 | DEBUG | Arguments: 
Batch Size: 10
Test Batch Size: 10000
Epochs: 200
Learning Rate: 0.0001
Momentum: 0.5
Beta1: 0.9
Beta2: 0.999
EPS: 1e-08
CUDA Enabled: True
Shuffle Enabled: False
Log Interval: 100
Scheduler Step Size: 50
Scheduler Gamma: 0.5
Scheduler Minimum Learning Rate: 1e-10
Client Selection Strategy: <federated_learning.worker_selection.random.RandomSelectionStrategy object at 0x0000028DC8C6C5F0>
Client Selection Strategy Arguments: {
    "NUM_WORKERS_PER_ROUND": 1
}
Model Saving Enabled: True
Model Saving Interval: 1
Model Saving Path (Relative): 3000_models
Epoch Save Start Prefix: start
Epoch Save End Suffix: end
Number of Clients: 1
Number of Poisoned Clients: 1
NN: <class 'federated_learning.nets.fashion_mnist_cnn.FashionMNISTCNN'>
Train Data Loader Path: data_loaders/fashion-mnist/train_data_loader.pickle
Test Data Loader Path: data_loaders/fashion-mnist/test_data_loader.pickle
Loss Function: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
Default Model Folder Path: default_models
Data Path: data

2025-03-07T11:52:25.977428+0300 | INFO | Loading data loader from file: data_loaders/fashion-mnist/train_data_loader.pickle
2025-03-07T11:52:26.302884+0300 | INFO | Loading data loader from file: data_loaders/fashion-mnist/test_data_loader.pickle
2025-03-07T11:52:31.612222+0300 | INFO | Poisoning data for workers: [0]
2025-03-07T11:52:31.646585+0300 | INFO | Client #0 has data distribution: [6000, 6000, 6000, 7200, 6000, 4800, 6000, 6000, 6000, 6000]
2025-03-07T11:52:31.657609+0300 | INFO | Training epoch #1 on client #0
2025-03-07T11:52:31.659628+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-03-07T11:52:31.810086+0300 | INFO | [1,     0] loss: 0.028
2025-03-07T11:52:34.148889+0300 | INFO | [1,   100] loss: 1.621
2025-03-07T11:52:36.633734+0300 | INFO | [1,   200] loss: 1.005
2025-03-07T11:52:39.078085+0300 | INFO | [1,   300] loss: 0.833
2025-03-07T11:52:41.775096+0300 | INFO | [1,   400] loss: 0.732
2025-03-07T11:53:15.944735+0300 | DEBUG | Arguments: 
Batch Size: 10
Test Batch Size: 10000
Epochs: 200
Learning Rate: 0.0001
Momentum: 0.5
Beta1: 0.9
Beta2: 0.999
EPS: 1e-08
CUDA Enabled: True
Shuffle Enabled: False
Log Interval: 100
Scheduler Step Size: 50
Scheduler Gamma: 0.5
Scheduler Minimum Learning Rate: 1e-10
Client Selection Strategy: <federated_learning.worker_selection.random.RandomSelectionStrategy object at 0x00000238C4EA9190>
Client Selection Strategy Arguments: {
    "NUM_WORKERS_PER_ROUND": 1
}
Model Saving Enabled: True
Model Saving Interval: 1
Model Saving Path (Relative): 3000_models
Epoch Save Start Prefix: start
Epoch Save End Suffix: end
Number of Clients: 1
Number of Poisoned Clients: 1
NN: <class 'federated_learning.nets.fashion_mnist_cnn.FashionMNISTCNN'>
Train Data Loader Path: data_loaders/fashion-mnist/train_data_loader.pickle
Test Data Loader Path: data_loaders/fashion-mnist/test_data_loader.pickle
Loss Function: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
Default Model Folder Path: default_models
Data Path: data

2025-03-07T11:53:15.951910+0300 | INFO | Loading data loader from file: data_loaders/fashion-mnist/train_data_loader.pickle
2025-03-07T11:53:16.297216+0300 | INFO | Loading data loader from file: data_loaders/fashion-mnist/test_data_loader.pickle
2025-03-07T11:53:21.754499+0300 | INFO | Poisoning data for workers: [0]
2025-03-07T11:53:21.790377+0300 | INFO | Client #0 has data distribution: [6000, 6000, 6000, 7200, 6000, 4800, 6000, 6000, 6000, 6000]
2025-03-07T11:53:21.808932+0300 | INFO | Training epoch #1 on client #0
2025-03-07T11:53:21.812023+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-03-07T11:53:21.869048+0300 | INFO | [1,     0] loss: 0.028
2025-03-07T11:53:24.023330+0300 | INFO | [1,   100] loss: 1.621
2025-03-07T11:53:26.241337+0300 | INFO | [1,   200] loss: 1.005
2025-03-07T11:53:29.235206+0300 | INFO | [1,   300] loss: 0.833
2025-03-07T11:53:32.900195+0300 | INFO | [1,   400] loss: 0.732
2025-03-07T11:53:36.046386+0300 | INFO | [1,   500] loss: 0.716
2025-03-07T11:53:38.985720+0300 | INFO | [1,   600] loss: 0.639
2025-03-07T11:53:42.685665+0300 | INFO | [1,   700] loss: 0.642
2025-03-07T11:53:46.876505+0300 | INFO | [1,   800] loss: 0.598
2025-03-07T11:53:50.105407+0300 | INFO | [1,   900] loss: 0.579
2025-03-07T11:53:53.430732+0300 | INFO | [1,  1000] loss: 0.573
2025-03-07T11:53:56.040386+0300 | INFO | [1,  1100] loss: 0.592
2025-03-07T11:54:03.532874+0300 | INFO | [1,  1200] loss: 0.558
2025-03-07T11:54:06.537360+0300 | INFO | [1,  1300] loss: 0.485
2025-03-07T11:54:11.027946+0300 | INFO | [1,  1400] loss: 0.547
2025-03-07T11:54:14.601393+0300 | INFO | [1,  1500] loss: 0.561
2025-03-07T11:54:19.128029+0300 | INFO | [1,  1600] loss: 0.436
2025-03-07T11:54:23.229387+0300 | INFO | [1,  1700] loss: 0.517
2025-03-07T11:54:27.141186+0300 | INFO | [1,  1800] loss: 0.502
2025-03-07T11:54:31.203070+0300 | INFO | [1,  1900] loss: 0.489
2025-03-07T11:54:36.260187+0300 | INFO | [1,  2000] loss: 0.512
2025-03-07T11:54:40.339371+0300 | INFO | [1,  2100] loss: 0.506
2025-03-07T11:54:43.359948+0300 | INFO | [1,  2200] loss: 0.493
2025-03-07T11:54:47.553610+0300 | INFO | [1,  2300] loss: 0.465
2025-03-07T11:54:51.244189+0300 | INFO | [1,  2400] loss: 0.441
2025-03-07T11:54:53.913698+0300 | INFO | [1,  2500] loss: 0.434
2025-03-07T11:54:56.202822+0300 | INFO | [1,  2600] loss: 0.463
2025-03-07T11:54:58.454011+0300 | INFO | [1,  2700] loss: 0.462
2025-03-07T11:55:00.612659+0300 | INFO | [1,  2800] loss: 0.440
2025-03-07T11:55:03.038327+0300 | INFO | [1,  2900] loss: 0.435
2025-03-07T11:55:05.459412+0300 | INFO | [1,  3000] loss: 0.434
2025-03-07T11:55:07.784138+0300 | INFO | [1,  3100] loss: 0.479
2025-03-07T11:55:10.770045+0300 | INFO | [1,  3200] loss: 0.450
2025-03-07T11:55:13.090938+0300 | INFO | [1,  3300] loss: 0.445
2025-03-07T11:55:16.360491+0300 | INFO | [1,  3400] loss: 0.423
2025-03-07T11:55:19.894540+0300 | INFO | [1,  3500] loss: 0.445
2025-03-07T11:55:23.790204+0300 | INFO | [1,  3600] loss: 0.457
2025-03-07T11:55:27.267120+0300 | INFO | [1,  3700] loss: 0.442
2025-03-07T11:55:30.404391+0300 | INFO | [1,  3800] loss: 0.458
2025-03-07T11:55:33.257326+0300 | INFO | [1,  3900] loss: 0.390
2025-03-07T11:55:35.586404+0300 | INFO | [1,  4000] loss: 0.436
2025-03-07T11:55:37.902830+0300 | INFO | [1,  4100] loss: 0.449
2025-03-07T11:55:40.487511+0300 | INFO | [1,  4200] loss: 0.420
2025-03-07T11:55:43.083350+0300 | INFO | [1,  4300] loss: 0.358
2025-03-07T11:55:45.397516+0300 | INFO | [1,  4400] loss: 0.431
2025-03-07T11:55:47.643678+0300 | INFO | [1,  4500] loss: 0.409
2025-03-07T11:55:49.871764+0300 | INFO | [1,  4600] loss: 0.418
2025-03-07T11:55:52.275392+0300 | INFO | [1,  4700] loss: 0.443
2025-03-07T11:55:54.770672+0300 | INFO | [1,  4800] loss: 0.422
2025-03-07T11:55:57.288421+0300 | INFO | [1,  4900] loss: 0.432
2025-03-07T11:55:59.535299+0300 | INFO | [1,  5000] loss: 0.378
2025-03-07T11:56:01.770122+0300 | INFO | [1,  5100] loss: 0.410
2025-03-07T11:56:03.966720+0300 | INFO | [1,  5200] loss: 0.418
2025-03-07T11:56:06.200306+0300 | INFO | [1,  5300] loss: 0.426
2025-03-07T11:56:08.694354+0300 | INFO | [1,  5400] loss: 0.417
2025-03-07T11:56:11.078859+0300 | INFO | [1,  5500] loss: 0.401
2025-03-07T11:56:13.411395+0300 | INFO | [1,  5600] loss: 0.421
2025-03-07T11:56:15.691453+0300 | INFO | [1,  5700] loss: 0.402
2025-03-07T11:56:17.789814+0300 | INFO | [1,  5800] loss: 0.382
2025-03-07T11:56:19.929059+0300 | INFO | [1,  5900] loss: 0.349
2025-03-07T11:56:22.054310+0300 | DEBUG | Saving model to flat file storage. Save #1
2025-03-07T11:56:22.062307+0300 | INFO | Averaging client parameters
2025-03-07T11:56:22.065028+0300 | INFO | Updating parameters on client #0
2025-03-07T11:56:24.205434+0300 | DEBUG | Test set: Accuracy: 8564/10000 (86%)
2025-03-07T11:56:24.207875+0300 | DEBUG | Test set: Loss: 0.4068954586982727
2025-03-07T11:56:24.293144+0300 | DEBUG | Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.81      0.82      1000
           1       0.99      0.97      0.98      1000
           2       0.82      0.80      0.81      1000
           3       0.89      0.71      0.79      1200
           4       0.74      0.87      0.80      1000
           5       0.78      0.93      0.85       800
           6       0.67      0.66      0.67      1000
           7       0.90      0.97      0.93      1000
           8       0.98      0.96      0.97      1000
           9       0.97      0.93      0.95      1000

    accuracy                           0.86     10000
   macro avg       0.86      0.86      0.86     10000
weighted avg       0.86      0.86      0.86     10000

2025-03-07T11:56:24.295143+0300 | DEBUG | Confusion Matrix:
[[807   0  13  24   8   2 140   0   6   0]
 [  2 974   2  13   4   0   4   0   1   0]
 [ 15   1 796   9 111   0  68   0   0   0]
 [ 20  11  15 849  63 188  44   8   1   1]
 [  1   1  60  17 867   0  52   0   2   0]
 [  0   0   0   8   0 741   0  42   1   8]
 [114   0  74  25 115   0 662   0  10   0]
 [  0   0   0   0   0   8   0 975   1  16]
 [  1   1   5   9   6   1  11   5 961   0]
 [  0   0   0   0   0   7   2  59   0 932]]
2025-03-07T11:56:24.297146+0300 | DEBUG | Class precision: [0.840625   0.98582996 0.82487047 0.88993711 0.73850085 0.78247096
 0.67344863 0.8953168  0.97761953 0.9738767 ]
2025-03-07T11:56:24.298513+0300 | DEBUG | Class recall: [0.807   0.974   0.796   0.7075  0.867   0.92625 0.662   0.975   0.961
 0.932  ]
2025-03-07T11:56:24.300681+0300 | INFO | Training epoch #2 on client #0
2025-03-07T11:56:24.302055+0300 | DEBUG | Saving model to flat file storage. Save #2
2025-03-07T11:56:24.338292+0300 | INFO | [2,     0] loss: 0.002
2025-03-07T11:56:26.508375+0300 | INFO | [2,   100] loss: 0.401
